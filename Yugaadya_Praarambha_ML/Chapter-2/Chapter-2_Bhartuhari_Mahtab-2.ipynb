{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2465d463",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " * Copyright (c) 2016 Radhamadhab Dalai\n",
    " *\n",
    " * Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    " * of this software and associated documentation files (the \"Software\"), to deal\n",
    " * in the Software without restriction, including without limitation the rights\n",
    " * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    " * copies of the Software, and to permit persons to whom the Software is\n",
    " * furnished to do so, subject to the following conditions:\n",
    " *\n",
    " * The above copyright notice and this permission notice shall be included in\n",
    " * all copies or substantial portions of the Software.\n",
    " *\n",
    " * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    " * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    " * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    " * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    " * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    " * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
    " * THE SOFTWARE.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabee83b",
   "metadata": {},
   "source": [
    "Let us introduce this more formally.\n",
    "\n",
    "### Definition 3.9 (Orthonormal Basis)\n",
    "\n",
    "Consider an $ n $-dimensional vector space $ V $ and a basis $ \\{b_1, \\ldots, b_n\\} $ of $ V $. If\n",
    "\n",
    "$$\n",
    "\\langle b_i, b_j \\rangle = 0 \\quad \\text{for} \\ i \\neq j \\tag{3.33}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\langle b_i, b_i \\rangle = 1 \\tag{3.34}\n",
    "$$\n",
    "\n",
    "for all $ i, j = 1, \\ldots, n $ then the basis is called an **orthonormal basis (ONB)**. If only (3.33) is satisfied, then the basis is called an **orthogonal basis**. Note that (3.34) implies that every basis vector has length/norm 1.\n",
    "\n",
    "Recall from Section 2.6.1 that we can use Gaussian elimination to find a basis for a vector space spanned by a set of vectors. Assume we are given a set $ \\{\\tilde{b}_1, \\ldots, \\tilde{b}_n\\} $ of non-orthogonal and unnormalized basis vectors. We concatenate them into a matrix $ \\tilde{B} = [\\tilde{b}_1, \\ldots, \\tilde{b}_n] $ and apply Gaussian elimination to the augmented matrix (Section 2.3.2) $ [\\tilde{B}^\\top \\tilde{B} | \\tilde{B}] $ to obtain an orthonormal basis. This constructive way to iteratively build an orthonormal basis $ \\{b_1, \\ldots, b_n\\} $ is called the **Gram-Schmidt process** (Strang, 2003).\n",
    "\n",
    "### Example 3.8 (Orthonormal Basis)\n",
    "\n",
    "The canonical/standard basis for a Euclidean vector space $ \\mathbb{R}^n $ is an orthonormal basis, where the inner product is the dot product of vectors. In $ \\mathbb{R}^2 $, the vectors\n",
    "\n",
    "$$\n",
    "b_1 = \\frac{1}{\\sqrt{2}} \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}, \\quad b_2 = \\frac{1}{\\sqrt{2}} \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix} \\tag{3.35}\n",
    "$$\n",
    "\n",
    "form an orthonormal basis since $ b_1^\\top b_2 = 0 $ and $ \\|b_1\\| = 1 = \\|b_2\\| $.\n",
    "\n",
    "We will exploit the concept of an orthonormal basis in Chapter 12 and Chapter 10 when we discuss support vector machines and principal component analysis.\n",
    "\n",
    "## 3.6 Orthogonal Complement\n",
    "\n",
    "Having defined orthogonality, we will now look at vector spaces that are orthogonal to each other. This will play an important role in Chapter 10, when we discuss linear dimensionality reduction from a geometric perspective.\n",
    "\n",
    "Consider a $ D $-dimensional vector space $ V $ and an $ M $-dimensional subspace $ U \\subseteq V $. Then its **orthogonal complement** $ U^\\perp $ is a $ (D - M) $-dimensional subspace of $ V $ and contains all vectors in $ V $ that are orthogonal to every vector in $ U $. Furthermore, $ U \\cap U^\\perp = \\{0\\} $ so that any vector $ x \\in V $ can be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf889da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 3.8: Testing Orthonormal Basis in R^2\n",
      "Basis vectors: [[0.7071067811865475, 0.7071067811865475], [0.7071067811865475, -0.7071067811865475]]\n",
      "Is orthonormal: True\n",
      "\n",
      "Gram-Schmidt Process: Converting vectors to an orthonormal basis\n",
      "Original vectors: [[1.0, 1.0], [1.0, 0.0]]\n",
      "Orthonormal basis: [[0.707, 0.707], [0.707, -0.707]]\n",
      "\n",
      "Orthogonal Complement (Section 3.6):\n",
      "Subspace U spanned by: [[1.0, 0.0, 0.0]]\n",
      "Basis for U^perp: [[0.0, 1.0, 0.0], [0.0, 0.0, 1.0]]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# --- Dot Product (Standard Inner Product) ---\n",
    "def dot_product(x, y):\n",
    "    \"\"\"\n",
    "    Compute the dot product of two vectors: x^T y = sum(x_i * y_i)\n",
    "    \"\"\"\n",
    "    return sum(xi * yi for xi, yi in zip(x, y))\n",
    "\n",
    "# --- Norm Induced by Dot Product ---\n",
    "def norm(x):\n",
    "    \"\"\"\n",
    "    Compute the Euclidean norm of a vector: ||x|| = sqrt(x^T x)\n",
    "    \"\"\"\n",
    "    return math.sqrt(dot_product(x, x))\n",
    "\n",
    "# --- Check if Vectors Form an Orthonormal Basis (Definition 3.9) ---\n",
    "def is_orthonormal_basis(basis_vectors):\n",
    "    \"\"\"\n",
    "    Check if a set of vectors forms an orthonormal basis:\n",
    "    - Orthogonal: <b_i, b_j> = 0 for i != j (Equation 3.33)\n",
    "    - Unit norm: <b_i, b_i> = 1 (Equation 3.34)\n",
    "    \"\"\"\n",
    "    n = len(basis_vectors)\n",
    "    \n",
    "    # Check unit norms\n",
    "    for i in range(n):\n",
    "        norm_bi = norm(basis_vectors[i])\n",
    "        if abs(norm_bi - 1.0) > 1e-10:\n",
    "            print(f\"Vector {basis_vectors[i]} has norm {norm_bi:.2f}, not 1\")\n",
    "            return False\n",
    "    \n",
    "    # Check orthogonality\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            inner_prod = dot_product(basis_vectors[i], basis_vectors[j])\n",
    "            if abs(inner_prod) > 1e-10:\n",
    "                print(f\"Vectors {basis_vectors[i]} and {basis_vectors[j]} are not orthogonal: <b_i, b_j> = {inner_prod:.2f}\")\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "# --- Gram-Schmidt Process ---\n",
    "def gram_schmidt(vectors):\n",
    "    \"\"\"\n",
    "    Apply the Gram-Schmidt process to convert a set of linearly independent vectors\n",
    "    into an orthonormal basis.\n",
    "    \"\"\"\n",
    "    if not vectors:\n",
    "        return []\n",
    "    \n",
    "    # Start with the first vector\n",
    "    orthonormal_basis = []\n",
    "    v1 = vectors[0]\n",
    "    norm_v1 = norm(v1)\n",
    "    if norm_v1 == 0:\n",
    "        raise ValueError(\"First vector cannot be zero\")\n",
    "    orthonormal_basis.append([vi / norm_v1 for vi in v1])\n",
    "    \n",
    "    # Process remaining vectors\n",
    "    for k in range(1, len(vectors)):\n",
    "        vk = vectors[k]\n",
    "        # Subtract projections onto previous orthonormal vectors\n",
    "        uk = vk[:]\n",
    "        for uj in orthonormal_basis:\n",
    "            proj = dot_product(vk, uj)\n",
    "            uk = [uki - proj * uji for uki, uji in zip(uk, uj)]\n",
    "        \n",
    "        # Normalize the resulting vector\n",
    "        norm_uk = norm(uk)\n",
    "        if norm_uk < 1e-10:\n",
    "            raise ValueError(f\"Vector {vk} is linearly dependent on previous vectors\")\n",
    "        orthonormal_basis.append([uki / norm_uk for uki in uk])\n",
    "    \n",
    "    return orthonormal_basis\n",
    "\n",
    "# --- Compute Orthogonal Complement (Section 3.6) ---\n",
    "def orthogonal_complement(U, V_dim):\n",
    "    \"\"\"\n",
    "    Compute the orthogonal complement U^perp of a subspace U in V.\n",
    "    V_dim is the dimension of V, and U is a list of basis vectors for the subspace.\n",
    "    Assumes the dot product as the inner product.\n",
    "    \"\"\"\n",
    "    # Step 1: Apply Gram-Schmidt to U to get an orthonormal basis for U\n",
    "    U_basis = gram_schmidt(U)\n",
    "    \n",
    "    # Step 2: Extend U_basis to a basis of V (e.g., using standard basis vectors)\n",
    "    n = len(U_basis)  # Dimension of U\n",
    "    if n > V_dim:\n",
    "        raise ValueError(\"Dimension of U cannot exceed dimension of V\")\n",
    "    \n",
    "    # Add standard basis vectors not in span(U)\n",
    "    standard_basis = [[1.0 if i == j else 0.0 for i in range(V_dim)] for j in range(V_dim)]\n",
    "    extended_basis = U_basis[:]\n",
    "    for e in standard_basis:\n",
    "        # Check if e is linearly independent of current basis\n",
    "        is_independent = True\n",
    "        for b in extended_basis:\n",
    "            if abs(dot_product(e, b)) > 1e-10:  # Not orthogonal, may be dependent\n",
    "                # Project e onto b and check if the result is zero\n",
    "                proj = dot_product(e, b) / dot_product(b, b)\n",
    "                e_minus_proj = [ei - proj * bi for ei, bi in zip(e, b)]\n",
    "                if norm(e_minus_proj) < 1e-10:\n",
    "                    is_independent = False\n",
    "                    break\n",
    "        if is_independent:\n",
    "            extended_basis.append(e)\n",
    "            if len(extended_basis) == V_dim:\n",
    "                break\n",
    "    \n",
    "    # Step 3: Apply Gram-Schmidt to the extended basis\n",
    "    full_basis = gram_schmidt(extended_basis)\n",
    "    \n",
    "    # Step 4: The last (V_dim - n) vectors form a basis for U^perp\n",
    "    return full_basis[n:]\n",
    "\n",
    "# --- Run the Implementation ---\n",
    "# Example 3.8: Test the orthonormal basis in R^2\n",
    "print(\"Example 3.8: Testing Orthonormal Basis in R^2\")\n",
    "sqrt_2 = math.sqrt(2)\n",
    "b1 = [1/sqrt_2, 1/sqrt_2]\n",
    "b2 = [1/sqrt_2, -1/sqrt_2]\n",
    "basis = [b1, b2]\n",
    "print(f\"Basis vectors: {basis}\")\n",
    "print(f\"Is orthonormal: {is_orthonormal_basis(basis)}\\n\")\n",
    "\n",
    "# Gram-Schmidt Process: Convert a set of vectors into an orthonormal basis\n",
    "print(\"Gram-Schmidt Process: Converting vectors to an orthonormal basis\")\n",
    "vectors = [[1.0, 1.0], [1.0, 0.0]]  # Non-orthogonal, non-normalized vectors in R^2\n",
    "print(f\"Original vectors: {vectors}\")\n",
    "orthonormal_basis = gram_schmidt(vectors)\n",
    "print(f\"Orthonormal basis: {[[round(x, 3) for x in v] for v in orthonormal_basis]}\\n\")\n",
    "\n",
    "# Orthogonal Complement: Compute U^perp for a subspace U in R^3\n",
    "print(\"Orthogonal Complement (Section 3.6):\")\n",
    "U = [[1.0, 0.0, 0.0]]  # Subspace U spanned by [1, 0, 0] in R^3\n",
    "V_dim = 3\n",
    "print(f\"Subspace U spanned by: {U}\")\n",
    "U_perp_basis = orthogonal_complement(U, V_dim)\n",
    "print(f\"Basis for U^perp: {[[round(x, 3) for x in v] for v in U_perp_basis]}\")"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "58b2e74e",
   "metadata": {},
   "source": [
    "## Analytic Geometry\n",
    "\n",
    "**Figure 3.7** A plane $ U $ in a three-dimensional vector space can be described by its normal vector, which spans its orthogonal complement $ U^\\perp $.\n",
    "\n",
    "$$\n",
    "x = \\sum_{m=1}^M \\lambda_m b_m + \\sum_{j=1}^{D-M} \\psi_j b_j^\\perp, \\quad \\lambda_m, \\psi_j \\in \\mathbb{R}, \\tag{3.36}\n",
    "$$\n",
    "\n",
    "where $ (b_1, \\ldots, b_M) $ is a basis of $ U $ and $ (b_1^\\perp, \\ldots, b_{D-M}^\\perp) $ is a basis of $ U^\\perp $.\n",
    "\n",
    "Therefore, the orthogonal complement can also be used to describe a plane $ U $ (two-dimensional subspace) in a three-dimensional vector space. More specifically, the vector $ w $ with $ \\|w\\| = 1 $, which is orthogonal to the plane $ U $, is the basis vector of $ U^\\perp $. Figure 3.7 illustrates this setting. All vectors that are orthogonal to $ w $ must (by construction) lie in the plane $ U $. The vector $ w $ is called the **normal vector** of $ U $. Generally, orthogonal complements can be used to describe hyperplanes in $ n $-dimensional vector and affine spaces.\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "Fig.7 A plane U in a three-dimensional vector space can be described by its normal vector, which spans its orthogonal complement U ⊥ .\n",
    "\n",
    "## Inner Product of Functions\n",
    "\n",
    "Thus far, we looked at properties of inner products to compute lengths, angles, and distances. We focused on inner products of finite-dimensional vectors. In the following, we will look at an example of inner products of a different type of vectors: inner products of functions.\n",
    "\n",
    "The inner products we discussed so far were defined for vectors with a finite number of entries. We can think of a vector $ x \\in \\mathbb{R}^n $ as a function with $ n $ function values. The concept of an inner product can be generalized to vectors with an infinite number of entries (countably infinite) and also continuous-valued functions (uncountably infinite). Then the sum over individual components of vectors (see Equation (3.5) for example) turns into an integral.\n",
    "\n",
    "An inner product of two functions $ u : \\mathbb{R} \\to \\mathbb{R} $ and $ v : \\mathbb{R} \\to \\mathbb{R} $ can be defined as the definite integral\n",
    "\n",
    "$$\n",
    "\\langle u, v \\rangle := \\int_a^b u(x) v(x) \\, dx \\tag{3.37}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa5d9234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orthogonal Complement and Vector Decomposition (Section 3.6):\n",
      "Subspace U spanned by: [[1.0, 1.0, 0.0]]\n",
      "Orthonormal basis for U: [[0.707, 0.707, 0.0]]\n",
      "Orthonormal basis for U^perp: [[0.707, -0.707, 0.0], [0.0, 0.0, 1.0]]\n",
      "\n",
      "Vector x = [1.0, 2.0, 3.0]\n",
      "Coefficients in U (lambda_m): [2.121]\n",
      "Coefficients in U^perp (psi_j): [-0.707, 3.0]\n",
      "Reconstructed x: [1.0, 2.0, 3.0]\n",
      "Decomposition correct: True\n",
      "\n",
      "Inner Product of Functions (Section 3.7):\n",
      "Functions: u(x) = x^2, v(x) = x\n",
      "Inner product over [0, 1]: 0.2500\n",
      "Expected value (integral of x^3 from 0 to 1): 0.25 = 0.25\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# --- Dot Product (Standard Inner Product) ---\n",
    "def dot_product(x, y):\n",
    "    \"\"\"\n",
    "    Compute the dot product of two vectors: x^T y = sum(x_i * y_i)\n",
    "    \"\"\"\n",
    "    return sum(xi * yi for xi, yi in zip(x, y))\n",
    "\n",
    "# --- Norm Induced by Dot Product ---\n",
    "def norm(x):\n",
    "    \"\"\"\n",
    "    Compute the Euclidean norm of a vector: ||x|| = sqrt(x^T x)\n",
    "    \"\"\"\n",
    "    return math.sqrt(dot_product(x, x))\n",
    "\n",
    "# --- Gram-Schmidt Process ---\n",
    "def gram_schmidt(vectors):\n",
    "    \"\"\"\n",
    "    Apply the Gram-Schmidt process to convert a set of linearly independent vectors\n",
    "    into an orthonormal basis.\n",
    "    \"\"\"\n",
    "    if not vectors:\n",
    "        return []\n",
    "    \n",
    "    orthonormal_basis = []\n",
    "    for k, vk in enumerate(vectors):\n",
    "        # Subtract projections onto previous orthonormal vectors\n",
    "        uk = vk[:]\n",
    "        for uj in orthonormal_basis:\n",
    "            proj = dot_product(uk, uj)\n",
    "            uk = [uki - proj * uji for uki, uji in zip(uk, uj)]\n",
    "        \n",
    "        # Normalize the resulting vector\n",
    "        norm_uk = norm(uk)\n",
    "        if norm_uk < 1e-10:\n",
    "            raise ValueError(f\"Vector {vk} is linearly dependent on previous vectors\")\n",
    "        orthonormal_basis.append([uki / norm_uk for uki in uk])\n",
    "    \n",
    "    return orthonormal_basis\n",
    "\n",
    "# --- Compute Orthogonal Complement (Section 3.6) ---\n",
    "def orthogonal_complement(U, V_dim):\n",
    "    \"\"\"\n",
    "    Compute the orthogonal complement U^perp of a subspace U in V.\n",
    "    V_dim is the dimension of V, and U is a list of basis vectors for the subspace.\n",
    "    \"\"\"\n",
    "    # Step 1: Orthonormalize the basis of U\n",
    "    U_basis = gram_schmidt(U)\n",
    "    n = len(U_basis)  # Dimension of U\n",
    "    if n > V_dim:\n",
    "        raise ValueError(\"Dimension of U cannot exceed dimension of V\")\n",
    "    \n",
    "    # Step 2: Extend U_basis to a basis of V by adding orthogonal vectors\n",
    "    extended_basis = U_basis[:]\n",
    "    standard_basis = [[1.0 if i == j else 0.0 for i in range(V_dim)] for j in range(V_dim)]\n",
    "    \n",
    "    for e in standard_basis:\n",
    "        # Project e onto the current basis and take the orthogonal component\n",
    "        e_ortho = e[:]\n",
    "        for b in extended_basis:\n",
    "            proj = dot_product(e_ortho, b)\n",
    "            e_ortho = [ei - proj * bi for ei, bi in zip(e_ortho, b)]\n",
    "        \n",
    "        # If the orthogonal component is non-zero, add it to the basis\n",
    "        norm_e_ortho = norm(e_ortho)\n",
    "        if norm_e_ortho > 1e-10:\n",
    "            extended_basis.append([ei / norm_e_ortho for ei in e_ortho])\n",
    "        \n",
    "        # Stop once we have V_dim vectors\n",
    "        if len(extended_basis) == V_dim:\n",
    "            break\n",
    "    \n",
    "    # Step 3: The last (V_dim - n) vectors form a basis for U^perp\n",
    "    # Since extended_basis is already orthogonal, we just need to confirm\n",
    "    return extended_basis[n:]\n",
    "\n",
    "# --- Vector Decomposition (Equation 3.36) ---\n",
    "def decompose_vector(x, U_basis, U_perp_basis):\n",
    "    \"\"\"\n",
    "    Decompose a vector x into components in U and U^perp:\n",
    "    x = sum(lambda_m * b_m) + sum(psi_j * b_j^perp)\n",
    "    Returns the coefficients lambda_m and psi_j.\n",
    "    \"\"\"\n",
    "    lambda_coeffs = [dot_product(x, bm) for bm in U_basis]\n",
    "    psi_coeffs = [dot_product(x, bj_perp) for bj_perp in U_perp_basis]\n",
    "    return lambda_coeffs, psi_coeffs\n",
    "\n",
    "# --- Numerical Integration (Trapezoidal Rule) for Inner Product of Functions ---\n",
    "def trapezoidal_integrate(u, v, a, b, n=1000):\n",
    "    \"\"\"\n",
    "    Approximate the integral of u(x) * v(x) from a to b using the trapezoidal rule.\n",
    "    \"\"\"\n",
    "    if a >= b:\n",
    "        raise ValueError(\"Lower limit a must be less than upper limit b\")\n",
    "    \n",
    "    h = (b - a) / n\n",
    "    integral = 0.0\n",
    "    for i in range(n + 1):\n",
    "        x = a + i * h\n",
    "        if i == 0 or i == n:\n",
    "            integral += u(x) * v(x) / 2\n",
    "        else:\n",
    "            integral += u(x) * v(x)\n",
    "    integral *= h\n",
    "    return integral\n",
    "\n",
    "# --- Inner Product of Functions (Equation 3.37) ---\n",
    "def function_inner_product(u, v, a, b):\n",
    "    \"\"\"\n",
    "    Compute the inner product of two functions u and v over [a, b]:\n",
    "    <u, v> = integral from a to b of u(x) v(x) dx\n",
    "    \"\"\"\n",
    "    return trapezoidal_integrate(u, v, a, b)\n",
    "\n",
    "# --- Run the Implementation ---\n",
    "# Orthogonal Complement and Decomposition (Section 3.6, Equation 3.36)\n",
    "print(\"Orthogonal Complement and Vector Decomposition (Section 3.6):\")\n",
    "U = [[1.0, 1.0, 0.0]]  # Subspace U in R^3 (a plane)\n",
    "V_dim = 3\n",
    "print(f\"Subspace U spanned by: {U}\")\n",
    "U_basis = gram_schmidt(U)\n",
    "U_perp_basis = orthogonal_complement(U, V_dim)\n",
    "print(f\"Orthonormal basis for U: {[[round(x, 3) for x in v] for v in U_basis]}\")\n",
    "print(f\"Orthonormal basis for U^perp: {[[round(x, 3) for x in v] for v in U_perp_basis]}\")\n",
    "\n",
    "# Decompose a vector x\n",
    "x = [1.0, 2.0, 3.0]\n",
    "lambda_coeffs, psi_coeffs = decompose_vector(x, U_basis, U_perp_basis)\n",
    "print(f\"\\nVector x = {x}\")\n",
    "print(f\"Coefficients in U (lambda_m): {[round(c, 3) for c in lambda_coeffs]}\")\n",
    "print(f\"Coefficients in U^perp (psi_j): {[round(c, 3) for c in psi_coeffs]}\")\n",
    "\n",
    "# Verify decomposition\n",
    "x_reconstructed = [0.0] * V_dim\n",
    "for lm, bm in zip(lambda_coeffs, U_basis):\n",
    "    for i in range(V_dim):\n",
    "        x_reconstructed[i] += lm * bm[i]\n",
    "for pj, bj in zip(psi_coeffs, U_perp_basis):\n",
    "    for i in range(V_dim):\n",
    "        x_reconstructed[i] += pj * bj[i]\n",
    "print(f\"Reconstructed x: {[round(xi, 3) for xi in x_reconstructed]}\")\n",
    "print(f\"Decomposition correct: {all(abs(xi - xri) < 1e-10 for xi, xri in zip(x, x_reconstructed))}\\n\")\n",
    "\n",
    "# Inner Product of Functions (Section 3.7, Equation 3.37)\n",
    "print(\"Inner Product of Functions (Section 3.7):\")\n",
    "def u(x):\n",
    "    return x**2\n",
    "def v(x):\n",
    "    return x\n",
    "\n",
    "a, b = 0, 1\n",
    "inner_prod = function_inner_product(u, v, a, b)\n",
    "print(f\"Functions: u(x) = x^2, v(x) = x\")\n",
    "print(f\"Inner product over [{a}, {b}]: {inner_prod:.4f}\")\n",
    "print(f\"Expected value (integral of x^3 from 0 to 1): {1/4} = 0.25\")"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "aee02945",
   "metadata": {},
   "source": [
    "for lower and upper limits $ a $, $ b < \\infty $, respectively. As with our usual inner product, we can define norms and orthogonality by looking at the inner product. If (3.37) evaluates to 0, the functions $ u $ and $ v $ are orthogonal. To make the preceding inner product mathematically precise, we need to take care of measures and the definition of integrals, leading to the definition of a Hilbert space. Furthermore, unlike inner products on finite-dimensional vectors, inner products on functions may diverge (have infinite value). All this requires diving into some more intricate details of real and functional analysis, which we do not cover in this book.\n",
    "\n",
    "### Example  (Inner Product of Functions)\n",
    "\n",
    "If we choose $ u = \\sin(x) $ and $ v = \\cos(x) $, the integrand $ f(x) = u(x) v(x) $ of (3.37), is shown in Figure 3.8. We see that this function is odd, i.e., $ f(-x) = -f(x) $. Therefore, the integral with limits $ a = -\\pi $, $ b = \\pi $ of this product evaluates to 0. Therefore, $ \\sin $ and $ \\cos $ are orthogonal functions.\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "**Fig.8** $ f(x) = \\sin(x) \\cos(x) $\n",
    "\n",
    "**Remark.** It also holds that the collection of functions\n",
    "\n",
    "$$\n",
    "\\{1, \\cos(x), \\cos(2x), \\cos(3x), \\ldots\\} \\tag{3.38}\n",
    "$$\n",
    "\n",
    "is orthogonal if we integrate from $ -\\pi $ to $ \\pi $, i.e., any pair of functions are orthogonal to each other. The collection of functions in (3.38) spans a large subspace of the functions that are even and periodic on $ [-\\pi, \\pi) $, and projecting functions onto this subspace is the fundamental idea behind Fourier series. $ \\diamond $\n",
    "\n",
    "In Section 6.4.6, we will have a look at a second type of unconventional inner products: the inner product of random variables.\n",
    "\n",
    "## Orthogonal Projections\n",
    "\n",
    "Projections are an important class of linear transformations (besides rotations and reflections) and play an important role in graphics, coding theory, statistics, and machine learning. In machine learning, we often deal with data that is high-dimensional. High-dimensional data is often hard to analyze or visualize. However, high-dimensional data quite often possesses the property that only a few dimensions contain most information, and most other dimensions are not essential to describe key properties of the data. When we compress or visualize high-dimensional data, we will lose information. To minimize this compression loss, we ideally find the most informative dimensions in the data. As discussed in Chapter 1, “Feature” is a common expression for data representation. Data can be represented as vectors, and in this chapter, we will discuss some of the fundamental tools for data compression. More specifically, we can project the original high-dimensional data onto a lower-dimensional feature space and work in this lower-dimensional space to learn more about the dataset and extract relevant patterns. For example, machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8920a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 3.9: Inner Product of Functions\n",
      "Functions: u(x) = sin(x), v(x) = cos(x)\n",
      "Inner product over [-3.14, 3.14]: 0.0000\n",
      "Functions are orthogonal: True\n",
      "\n",
      "Orthogonal Projection (Section 3.8):\n",
      "Vector x = [1.0, 2.0, 3.0]\n",
      "Subspace basis: [[1.0, 1.0, 0.0], [0.0, 0.0, 1.0]]\n",
      "Projection of x onto subspace: [1.5, 1.5, 3.0]\n",
      "Error vector (x - projection): [-0.5, 0.5, 0.0]\n",
      "Error is orthogonal to subspace: True\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# --- Dot Product (Standard Inner Product) ---\n",
    "def dot_product(x, y):\n",
    "    \"\"\"\n",
    "    Compute the dot product of two vectors: x^T y = sum(x_i * y_i)\n",
    "    \"\"\"\n",
    "    return sum(xi * yi for xi, yi in zip(x, y))\n",
    "\n",
    "# --- Norm Induced by Dot Product ---\n",
    "def norm(x):\n",
    "    \"\"\"\n",
    "    Compute the Euclidean norm of a vector: ||x|| = sqrt(x^T x)\n",
    "    \"\"\"\n",
    "    return math.sqrt(dot_product(x, x))\n",
    "\n",
    "# --- Numerical Integration (Trapezoidal Rule) for Inner Product of Functions ---\n",
    "def trapezoidal_integrate(u, v, a, b, n=1000):\n",
    "    \"\"\"\n",
    "    Approximate the integral of u(x) * v(x) from a to b using the trapezoidal rule.\n",
    "    u and v are functions, a and b are the limits, n is the number of intervals.\n",
    "    \"\"\"\n",
    "    if a >= b:\n",
    "        raise ValueError(\"Lower limit a must be less than upper limit b\")\n",
    "    \n",
    "    h = (b - a) / n  # Step size\n",
    "    integral = 0.0\n",
    "    for i in range(n + 1):\n",
    "        x = a + i * h\n",
    "        if i == 0 or i == n:\n",
    "            integral += u(x) * v(x) / 2  # Endpoints have weight 1/2\n",
    "        else:\n",
    "            integral += u(x) * v(x)  # Interior points have weight 1\n",
    "    integral *= h\n",
    "    return integral\n",
    "\n",
    "# --- Inner Product of Functions (Example 3.9) ---\n",
    "def function_inner_product(u, v, a, b):\n",
    "    \"\"\"\n",
    "    Compute the inner product of two functions u and v over [a, b]:\n",
    "    <u, v> = integral from a to b of u(x) v(x) dx\n",
    "    \"\"\"\n",
    "    return trapezoidal_integrate(u, v, a, b)\n",
    "\n",
    "# --- Gram-Schmidt Process ---\n",
    "def gram_schmidt(vectors):\n",
    "    \"\"\"\n",
    "    Apply the Gram-Schmidt process to convert a set of linearly independent vectors\n",
    "    into an orthonormal basis.\n",
    "    \"\"\"\n",
    "    if not vectors:\n",
    "        return []\n",
    "    \n",
    "    orthonormal_basis = []\n",
    "    for k, vk in enumerate(vectors):\n",
    "        uk = vk[:]\n",
    "        for uj in orthonormal_basis:\n",
    "            proj = dot_product(uk, uj)\n",
    "            uk = [uki - proj * uji for uki, uji in zip(uk, uj)]\n",
    "        \n",
    "        norm_uk = norm(uk)\n",
    "        if norm_uk < 1e-10:\n",
    "            raise ValueError(f\"Vector {vk} is linearly dependent on previous vectors\")\n",
    "        orthonormal_basis.append([uki / norm_uk for uki in uk])\n",
    "    \n",
    "    return orthonormal_basis\n",
    "\n",
    "# --- Orthogonal Projection onto a Subspace (Section 3.8) ---\n",
    "def orthogonal_projection(x, subspace_basis):\n",
    "    \"\"\"\n",
    "    Compute the orthogonal projection of vector x onto the subspace spanned by\n",
    "    the given basis vectors.\n",
    "    \"\"\"\n",
    "    # Orthonormalize the basis\n",
    "    ortho_basis = gram_schmidt(subspace_basis)\n",
    "    \n",
    "    # Project x onto each basis vector\n",
    "    projection = [0.0] * len(x)\n",
    "    for b in ortho_basis:\n",
    "        coeff = dot_product(x, b)\n",
    "        projection = [pi + coeff * bi for pi, bi in zip(projection, b)]\n",
    "    \n",
    "    return projection\n",
    "\n",
    "# --- Run the Implementation ---\n",
    "# Example 3.9: Inner Product of sin(x) and cos(x) over [-pi, pi]\n",
    "print(\"Example 3.9: Inner Product of Functions\")\n",
    "def u(x):\n",
    "    return math.sin(x)\n",
    "def v(x):\n",
    "    return math.cos(x)\n",
    "\n",
    "a, b = -math.pi, math.pi\n",
    "inner_prod = function_inner_product(u, v, a, b)\n",
    "print(f\"Functions: u(x) = sin(x), v(x) = cos(x)\")\n",
    "print(f\"Inner product over [{a:.2f}, {b:.2f}]: {inner_prod:.4f}\")\n",
    "print(f\"Functions are orthogonal: {abs(inner_prod) < 1e-5}\\n\")\n",
    "\n",
    "# Orthogonal Projection (Section 3.8)\n",
    "print(\"Orthogonal Projection (Section 3.8):\")\n",
    "# Example: Project a vector in R^3 onto a 2D subspace (plane)\n",
    "x = [1.0, 2.0, 3.0]  # Vector to project\n",
    "subspace_basis = [[1.0, 1.0, 0.0], [0.0, 0.0, 1.0]]  # Spans a plane in R^3\n",
    "projection = orthogonal_projection(x, subspace_basis)\n",
    "print(f\"Vector x = {x}\")\n",
    "print(f\"Subspace basis: {subspace_basis}\")\n",
    "print(f\"Projection of x onto subspace: {[round(p, 3) for p in projection]}\")\n",
    "\n",
    "# Verify orthogonality of the error vector (x - projection) to the subspace\n",
    "error = [xi - pi for xi, pi in zip(x, projection)]\n",
    "ortho_to_basis = all(abs(dot_product(error, b)) < 1e-10 for b in gram_schmidt(subspace_basis))\n",
    "\n",
    "\n",
    "print(f\"Error vector (x - projection): {[round(e, 3) for e in error]}\")\n",
    "print(f\"Error is orthogonal to subspace: {ortho_to_basis}\")"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOoAAAB5CAIAAAC4BCr0AAAOsUlEQVR4Ae2df1AU5xnHL8Q605hxqI0iQtQYZZIYmo7pJKQ6VRtsGtq0TckvIhPTpkntYCZtAhGTRkRCgTt+NKGpRKOkYXKYEImjoAQjJwlVATMchhOwyB3HDxVBDrj1jlvu3s6ysLt3ty+3e7cX9rjn/tB332f3fZ/9Ph8e3nv33RcFgg8oELAKKALWc3AcFECAL0AQwAoAvgEcPHAd8AUGAlgBwDeAgweuA77AQAArAPgGcPDAdcAXGAhgBQDfAA4euA74AgMBrADgG8DBA9cBX2AggBWQBl8FfGSvgF6vD2BOMa5Lhi+mfaiWiwKALzYSCoU0PwbYDsDgswKAL1ZCwBcrjWwMgC82FIAvVhrZGABfbCgAX6w0sjEAvthQAL5YaWRjAHyxoQB8sdLIxgD4YkMB+GKlkY0B8MWGAvDFSiMbA+CLDQXgi5VGNgbAlw2FxWLRarXDw8N0FeDLSiPXEuDLRqampsbhcBQUFAC+rCjyLgG+bHwIgrDZbEVFRYAvK4o8Snq9PiEhwR1W9xp5+OuTF96vVdBoNFarFSFEr7XyyQu4WAoFaHDpcFRWVro0CfiygqjV6sLCwpKSEroKxr6sNDNR4oKbnp5uNpvdvQB83TWZrAF8sdL42SAEXNoFwBcbCsAXK43fDMLBBXw9BAHw9SCQpGax4AK+HuQHfD0IJJHZO3ABXw/yA74eBPLFbDOjji/0nR0JCQn0rALuy9n0ncDYF6sP4IuVxkeDY9z6wUZjZlTZlgUKhcI7cGkXAF9sKABfrDQ+GPR6/V+e+73u9TAie4lRdT/vdJjw5gFfrFaAL1YarwzcMe7xfzw5XvIoOp3rVUvsRYAvq4VLCfB1EcTrQy647FDBTqKPNiE76XWzCCHAF6se4IuVRrCBH1zm8tbPUevnzJEXBcAXKxrgi5VGgMEDuHQLPidgwJcNhc1ma2xsZI4BX0YKoQWbGX2VOXAyf3PCM0Knw3xLwIAvG5qhoaG9e/cyx4AvI4XAwlDFju7MqPPJi2JXzWXHuNNf7FsCBnyd1C0uLmaOAV9GCo8FeqiQGTe/LTXMnLvS0l7t8RL2BB8SMODLyogQYvCF9b5OuuAPuGPcjPSdY/99B+17ENkI/BVuFh8SMODLqjk4OJiamtrT00NXQfZlpeErccF1Gir0NqAzky9c8V3HV+dtAgZ8+dScqAN8eaSZWKtg6GjzsFbho02iErDpOtn299j7fkTW1/P0OU0V4IsVB/B1ksZmRt1nrMWxxsyoL7fe5mGtgsgEnJKCnl1THnf3yfh4pz49HgC+WImCB98DB9D69ai21lUKgwHFxKCNG9HwoKXvH2svbF/Xv3sVkb2kW7nG81oFMQlYp0Oh88nQUHTggKsP0x8Dvlh9ggRfsxmFhqK4u0+uWOEqxSOPIOWvd9dt+83Ox1MubP8Zkb1Sm/yw7ZNn0Jeprqe6H4tMwGYzMpncW/FQA/hiBQoSfEkS3XYbUicmPbrW6KSF7lND1iMDGfcMZqyuf2XVu0+/cfSFLW9s/oo6R2BmFXiaU6/iDgBfrF5Bgi9CSKdDe3KMtsNJjBZ6vd6QEXU1PfxGduSV7Gjb8VcRQh0dU3ZhmVWtanj7sfz166eu8sP/gC9W1ODBd1KCo39GBx8f+eylFxPjFQpF0ROhg1n3tOzYpEpt59FIQGZdtgw1J8fOCSF1Op4GJKkCfLEyBhu+1v0/H8+NtOQsef/JUHoe98G7upqTYxUK1N/vplJvw0h1QV+fWz2nIiUFKRQoKgqRPi2K5LToVgR83SSZqggKfEkLMl/V6/WbE55pem3hmHKJIy9ysCyF1iAmBs2bS9x+Ow9/ZWVUZp03l6iomNKL738e7vlO87oO8MVKNzvwNZmo2Sj+/Hdj0Pb+Q71vr/rDA7coFIqSzJfIQ89Xvrxt85rPoqMpWUiSmk3jvTYxEUWHX4gOv5CYiBXwOzAEF772iY9AWWWIb309mj7budwaPauwcN5ATIyLhXpPQbV10/nkRYMZ4c05G+h5XLMZzQkh1YlJCgXi25OJbcRgQNHR1KywF7NdbCs+l4II39OnT+/Zs+ebb75Rq9W8ulkslkuXLo2OjtJWueFbVkaxNSeEfO89Xvd5Kg0G6pLm5NiVd04MP21m1Fpu+J+OfuT7/e8pmnM2jBf9pLqomqEwPh6FhSGxT794+v5OqoIF356enra2Np1Od/369ZqaGl5tjxw54nA4SktLaavc8E1LQ8t/YNz5i3xRv6+zs1HG5vK2Q5+g5o/G31k5mrOs8k8/5D7y3bDGqE5MCgvjHyTwCiWfymDBt6urq6mpiSAIZkGZewz27duHEMrPz5cnviYTiotDmteThgfELEdECF1usv/zjhuqpaQqwp4XcUV5r3l0cgd5hFBEBNq27sD8+R5GC+5yyaEmWPBta2urrKzMy8urq6vD6U6/arF//35Z7+873C1qOaJerz++/YHONxdfTQ+35i51vLMCHX+Fq0BtLbXgITubWxcw5WDBd2xszGAwmM3ms2fP4oJz4sQJo9F47Ngx+gS5DR5YtyuThCxHZNbjrlgQYlSuIcueHe9rubhz08W3Hq7TiMzfbN/yKgULvgJVZ7630QlY4FUIUdkrPh6JXa7qsX2TiW+qYZoEbDOjloNdbU2863ErKtDa5Q37nnrtwEuTAySPDsj8BMAXGyDh2bevj/qCv3Z5g/v8FLZ1AYa+PnTrrdSDA555AEwCJj5+ojdzVdOri26+iWfvMJMJ3XIL5WpXZqyQ/C3Axxk+BfDFBkA4viYTmj+fegq1YZ2Uv5QrKih2m5NjH3oIpaVxVswghNwSMD1UqNu2cDAj/LLqXrNpgPfGzGZqgQ4StuaGtwVZVQK+2HAIx5detPVBRoNFI/IdL2znlIEkqQHJv58reOz+hujwC65zW1MJmBnjKhSK93dvIw89j8qemrbhCaOANTeeG5npMwBfbARE4TvZih+YIG8QF3ZsUicm3RNhdHoS1riH/Ff0t7tW33wT9Vo092VJnSrpqV8aPby5MCsSMOArKb7+YcJwMP+NJyv6PnBaj9uUFk1kL/k2ZdF7u//KfXWnv596uqFOTIqIwN6a/37YPHUpsR3wxQrqTfYV/iYCtls+g42gXnA48iI6+y4zq5Cy8dbrqrvGP34MOca515Ak9dR34byBqChuNU954HzD0TcL0tIC8nkbfT+AL09c6Sov8RWZgM1mp1Vd9fXUeJfnIULpb+15S+25kdrkxeysgoX/7bDpVplxbjcuTtCiR84VsisCvtiQeImvmARMktRrkvPmEnFxk27ExFBTs3NCSO5K8K7282blMkdepD038uruaNysAvZOMIYtW6hhxpwQUtQqNkxjM1MN+GJ19x5fwQnYdUUYopYgPrum/IWfltNLwJhZhca/RRLZy4nsFam/K8N6LNJAkkilQmWStSeyeylOB3yxKnqPr5gEvHUrevVXn58qmtyl2WRCqiwrWXjfyKGt9Dtnk7MKo8N7s9vj4ydmbbEuB50B8GVDLuX+voITMNW98x51/XX7+7Pu7HxzcdETk++csS5CyVkBwJfVQ+L9fUXNAbccRMdevlz/aUJCwurFN1/cEXZVea+tZhfrHJT4FAB8nVRhNkgVu2THqRX6QEwCHi37o1W19OKOsBULQtLT0wljE+qpd5kR4+ki6KuCGt/W1tYTU5/BwUHp9/cVkIDpL2dlWxboXg8byF1N9LUGPZMiBAhqfF10kn5/32kTMDOroFAolLt3UEOFji9cXILD6RUAfLH6+DTzwLTKl4C54HLXKjAXQUGgAoAvVihp8HVOwAAuVm6vDIAvVjZp8EUI/edh1HKQeT3dZXUYtnswCFAA8MWKJA2+jnHrvnVDOXe4vJ6O7RUMYhQAfLFq+Y6vXq/fsvlpbfKirrcW96h+zH09HdsrGMQoAPhi1fIFX+4YtyzzOdvRJNQ1sbEztjcweKMA4ItVzTt8ueDCrAJWXIkMgC9WSLH4ArhYKf1mAHyx0grHF8DFiuhnA+CLFVgIvgAuVr7vxAD4sjJbLBatVjs8PLl93fT4AriscDNXAnxZ7WtqahwOR0HB5F4NOHwBXFaymS4BvmwECIKw2WxFRUV0lTu+AC4rljxKQY2v+4JJjUZjtVp58a2rq6O2A3HeEEQeQQxeL4IaX5ewq9XqwsLCkpIS3v19SZKEeVwXxWb8EPDFhsB98IA9FQwzpADgixUe8MVKIxsD4IsNBeCLlUY2BsAXGwrAFyuNbAyALzYUgC9WGtkYAF9sKABfrDSyMQC+2FAAvlhpZGMAfLGhAHyx0sjGAPhiQwH4YqWRjQHwxYYC8MVKIxsD4IsNBeCLlUY2BsAXGwrAFyuNbAyALzYU9Poy+FfOCnD/pBI2kIFmUPjbYYPB4Kcu7HZ7e3u70WiUvP2enp7u7m7Jm6Ub9J/bjMNWq7WP+wc/GMOsK/gX35GREaVS6SfRNBqN3W4vKChwOBwSdmG1Wquqqk6dOtXb2yths0xTfnKbaR8hdPLkSY1Gw62ZrWX/4nvp0iXuLtbSikgQ1F9FLiwslLZZrVbb0NCg0+mqqqqkbZluzU9uM65eu3ZNq9UCvowgQgtjY2NTO1ifaGxs7OzsPHPmzK5du65duya0iWnPu3LlCtN+R0cHQqilpaW7u1va7KvT6erq6rRa7blz56Z1x3ujP9xmvNFoNBUVFf7LGkxHcij4N/uOjo5u3759aGjIH7d67ty5rKwspVIpLb5Wq/Xw4cOVlZV0mpTccz+5zfWzurr6ww8/5NbM1rJ/8Q1Q1cbGxpjX+AL0FoLEbcA3SAI9O28T8J2dcQ2SuwJ8nQKt1+urqqpqamqam5ttNpvdbncyw4HMFAB8nQJis9mKi4tHRkYcDkdpaenly5edzHAgMwUAX6eA1NbW5uTkdHZ2EgTx9ddfA75O6sjvAPB1iglJkg6HY3x8HCFUXl7e3NzsZIYDmSkA+MosIOCOGAUAXzFqwbkyUwDwlVlAwB0xCgC+YtSCc2WmwP8BhPoHOzLWCPcAAAAASUVORK5CYII="
    }
   },
   "cell_type": "markdown",
   "id": "0a263298",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)\n",
    "\n",
    "**Fig.9** Orthogonal projection (orange dots) of a two-dimensional dataset (blue dots) onto a one-dimensional subspace (straight line).\n",
    "\n",
    "learning algorithms, such as principal component analysis (PCA) by Pearson (1901) and Hotelling (1933) and deep neural networks (e.g., deep auto-encoders (Deng et al., 2010)), heavily exploit the idea of dimensionality reduction. In the following, we will focus on orthogonal projections, which we will use in Chapter 10 for linear dimensionality reduction and in Chapter 12 for classification. Even linear regression, which we discuss in Chapter 9, can be interpreted using orthogonal projections. For a given lower-dimensional subspace, orthogonal projections of high-dimensional data retain as much information as possible and minimize the difference/error between the original data and the corresponding projection. An illustration of such an orthogonal projection is given in Figure 3.9.\n",
    "\n",
    "Before we detail how to obtain these projections, let us define what a projection actually is.\n",
    "\n",
    "### Definition 3.10 (Projection)\n",
    "\n",
    "Let $ V $ be a vector space and $ U \\subseteq V $ a subspace of $ V $. A linear mapping $ \\pi : V \\to U $ is called a **projection** if\n",
    "\n",
    "$$\n",
    "\\pi^2 = \\pi \\circ \\pi = \\pi.\n",
    "$$\n",
    "\n",
    "Since linear mappings can be expressed by transformation matrices (see Section 2.7), the preceding definition applies equally to a special kind of transformation matrices, the projection matrices $ P_\\pi $, which exhibit the property that $ P_\\pi^2 = P_\\pi $.\n",
    "\n",
    "In the following, we will derive orthogonal projections of vectors in the inner product space $ (\\mathbb{R}^n, \\langle \\cdot, \\cdot \\rangle) $ onto subspaces. We will start with one-dimensional subspaces, which are also called lines. If not mentioned otherwise, we assume the dot product $ \\langle x, y \\rangle = x^\\top y $ as the inner product.\n",
    "\n",
    "##  Projection onto One-Dimensional Subspaces (Lines)\n",
    "\n",
    "Assume we are given a line (one-dimensional subspace) through the origin with basis vector $ b \\in \\mathbb{R}^n $. The line is a one-dimensional subspace $ U \\subseteq \\mathbb{R}^n $ spanned by $ b $. When we project $ x \\in \\mathbb{R}^n $ onto $ U $, we seek the vector $ \\pi_U(x) \\in U $ that is closest to $ x $. Using geometric arguments, let"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdf7e2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projection onto a One-Dimensional Subspace (Section 3.8.1):\n",
      "Vector x = [1.0, 2.0, 3.0]\n",
      "Line spanned by b = [1.0, 1.0, 0.0]\n",
      "Projection of x onto line: [1.5, 1.5, 0.0]\n",
      "Error vector (x - projection): [-0.5, 0.5, 3.0]\n",
      "Error is orthogonal to b: True\n",
      "\n",
      "Projection Matrix (Definition 3.10):\n",
      "Projection matrix P:\n",
      "[0.5, 0.5, 0.0]\n",
      "[0.5, 0.5, 0.0]\n",
      "[0.0, 0.0, 0.0]\n",
      "P satisfies P^2 = P: True\n",
      "Projection using matrix: [1.5, 1.5, 0.0]\n",
      "Matches direct projection: True\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# --- Dot Product (Standard Inner Product) ---\n",
    "def dot_product(x, y):\n",
    "    \"\"\"\n",
    "    Compute the dot product of two vectors: x^T y = sum(x_i * y_i)\n",
    "    \"\"\"\n",
    "    return sum(xi * yi for xi, yi in zip(x, y))\n",
    "\n",
    "# --- Norm Induced by Dot Product ---\n",
    "def norm(x):\n",
    "    \"\"\"\n",
    "    Compute the Euclidean norm of a vector: ||x|| = sqrt(x^T x)\n",
    "    \"\"\"\n",
    "    return math.sqrt(dot_product(x, x))\n",
    "\n",
    "# --- Projection onto a One-Dimensional Subspace (Section 3.8.1) ---\n",
    "def project_onto_line(x, b):\n",
    "    \"\"\"\n",
    "    Project vector x onto the line (one-dimensional subspace) spanned by vector b.\n",
    "    The projection is: pi_U(x) = (<x, b> / <b, b>) * b\n",
    "    \"\"\"\n",
    "    if norm(b) < 1e-10:\n",
    "        raise ValueError(\"Basis vector b cannot be zero\")\n",
    "    \n",
    "    # Compute the coefficient: <x, b> / <b, b>\n",
    "    coeff = dot_product(x, b) / dot_product(b, b)\n",
    "    \n",
    "    # Projection: (coefficient) * b\n",
    "    projection = [coeff * bi for bi in b]\n",
    "    return projection\n",
    "\n",
    "# --- Construct Projection Matrix (Definition 3.10) ---\n",
    "def projection_matrix(b):\n",
    "    \"\"\"\n",
    "    Construct the projection matrix P for the subspace spanned by vector b.\n",
    "    P = (b b^T) / (b^T b), where b is treated as a column vector.\n",
    "    \"\"\"\n",
    "    n = len(b)\n",
    "    if norm(b) < 1e-10:\n",
    "        raise ValueError(\"Basis vector b cannot be zero\")\n",
    "    \n",
    "    # Compute b^T b (a scalar)\n",
    "    bTb = dot_product(b, b)\n",
    "    \n",
    "    # Compute the matrix P = (b b^T) / (b^T b)\n",
    "    P = [[0.0 for _ in range(n)] for _ in range(n)]\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            P[i][j] = b[i] * b[j] / bTb\n",
    "    \n",
    "    return P\n",
    "\n",
    "# --- Matrix-Vector Multiplication ---\n",
    "def matrix_vector_multiply(A, x):\n",
    "    \"\"\"\n",
    "    Multiply matrix A by vector x.\n",
    "    \"\"\"\n",
    "    n = len(A)\n",
    "    result = [0.0] * n\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            result[i] += A[i][j] * x[j]\n",
    "    return result\n",
    "\n",
    "# --- Matrix-Matrix Multiplication ---\n",
    "def matrix_multiply(A, B):\n",
    "    \"\"\"\n",
    "    Multiply two matrices A and B.\n",
    "    \"\"\"\n",
    "    n = len(A)\n",
    "    result = [[0.0 for _ in range(n)] for _ in range(n)]\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            for k in range(n):\n",
    "                result[i][j] += A[i][k] * B[k][j]\n",
    "    return result\n",
    "\n",
    "# --- Verify Projection Matrix Property (P^2 = P) ---\n",
    "def verify_projection_matrix(P):\n",
    "    \"\"\"\n",
    "    Verify that the projection matrix satisfies P^2 = P.\n",
    "    \"\"\"\n",
    "    P2 = matrix_multiply(P, P)\n",
    "    # Check if P2 equals P within numerical tolerance\n",
    "    n = len(P)\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if abs(P2[i][j] - P[i][j]) > 1e-10:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "# --- Run the Implementation ---\n",
    "# Projection onto a One-Dimensional Subspace (Section 3.8.1)\n",
    "print(\"Projection onto a One-Dimensional Subspace (Section 3.8.1):\")\n",
    "x = [1.0, 2.0, 3.0]  # Vector to project\n",
    "b = [1.0, 1.0, 0.0]  # Basis vector of the line\n",
    "projection = project_onto_line(x, b)\n",
    "print(f\"Vector x = {x}\")\n",
    "print(f\"Line spanned by b = {b}\")\n",
    "print(f\"Projection of x onto line: {[round(p, 3) for p in projection]}\")\n",
    "\n",
    "# Verify orthogonality of the error vector (x - projection) to b\n",
    "error = [xi - pi for xi, pi in zip(x, projection)]\n",
    "error_dot_b = dot_product(error, b)\n",
    "print(f\"Error vector (x - projection): {[round(e, 3) for e in error]}\")\n",
    "print(f\"Error is orthogonal to b: {abs(error_dot_b) < 1e-10}\\n\")\n",
    "\n",
    "# Projection Matrix (Definition 3.10)\n",
    "print(\"Projection Matrix (Definition 3.10):\")\n",
    "P = projection_matrix(b)\n",
    "print(\"Projection matrix P:\")\n",
    "for row in P:\n",
    "    print([round(val, 3) for val in row])\n",
    "\n",
    "# Verify P^2 = P\n",
    "is_idempotent = verify_projection_matrix(P)\n",
    "print(f\"P satisfies P^2 = P: {is_idempotent}\")\n",
    "\n",
    "# Project x using the projection matrix and compare\n",
    "proj_matrix = matrix_vector_multiply(P, x)\n",
    "print(f\"Projection using matrix: {[round(p, 3) for p in proj_matrix]}\")\n",
    "print(f\"Matches direct projection: {all(abs(p1 - p2) < 1e-10 for p1, p2 in zip(projection, proj_matrix))}\")"
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "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"
    },
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAI8AAACCCAIAAADwnwwaAAAR70lEQVR4Ae2d71MT17vAd7x8fdVxbmfud5r+A99Xd3hxa2eczvRFb/P24kzFsYy10uncqY1T1LY0g2gxoAiGH2IGYkW8KAYlCGnBGCGEBt1CKSAYsE4NshSxwQRIxGBIluxzJxw9pCG/Ntn82JBMp549e3485/nkbM559jkPBKQ//NEAwR9R05JCmhafvgQsaFEUxaeRpaKs4dKiaZogCJIkU1EJvBlTuLRIkiQIYu/evbwZWSoKGi6tvXv3EmsfmqZTUQ/8GFNYtNBjkCCIjIyM9MMwgWDDokWSZEZGBppb6YdhstMaHR3NysoiCCIrK6uysjKB4nLVdV9fX3Nzs16v7+rq4qrNOLQT1txCchAEi8JxED3iLoxGo8FgOH78uEwmO3r0aMTtxL8iCwApQ2t5edlsNn/wwQeTk5Nmszn+So+4x81I68cffzx8+PC7777b2dmpVCoj1l38K25GWgCA9iEulyv+Go+mx01Bi6Iou90ejZqSpG6K06JpurCwMGVsZqlMy2w279ixY8uWLQRBpOdWkjwe/ItBkuS2bdvQjn779u1AUSAU+i/Kn9yUnVu5ubloVhEEceXKFaBpEAiA5+8QUpaWw+F4++230dx6talSKCAzkz8TyY+kKUtLJpMJhcLJycnCwsJX46Zp4PnKMDVpURRFEAS/7BR+ptKGrBSkRdO0QCBQKBQbBruWoVaDweD/VtLnpiCtvLw8YZDlH0l6lhv8fKeaarRIkhQIBCF2V5mZoFYn/UTyI2BK0bLb7QKBQB2ShNmcnlt+vgtxzsrJycnLy4tzp/HsLnXmlkKhEAgELJx8JBLezbAUoWU2mwmCMLBa7AmFEGjdGM/5wqavFKElFAplMhmbgYPHcsi3xWEq0JLJZJmZmSyegZgqSfLrYch7WshssUl89PlNi6bpzMzMgGYLPIeCJMxmHhnm+U0rhNkiCCR8i6KAIPhi7eUxLYPBIBAIODDd5uSARILxJXOCr7SQ6Ta02SIc3fPnYchXWjlrn3BYpFIZXtJSq9WhTbdsKVEUJL3fLv9omc1mgUDAzmwRDjmJBHJywimYwDL8oyUUCmNiurXbPYvD5D5bzTNaCoUiQrNFODNCoUjyhyGfaCHT7SYxW/j9dvGGFjJbsDbd+h108ExWhvzgTXF9lze0kMdZJKZbVipDTqJxBmanwEyCPXQ4En7QMhgM8fM4i4+T6OIo9GVB67+Dgnj138PQR4R5QCuExxmrqRNOYZqGvLyYWw7NJDRnvOLUvAVGvwtHNB7QysvLy0n6nVA4ul4vQ9thXALN/+ah1ZwRJioANlG5EnLuOCZmi3W1BU3Fwg0bcVIQQObAn60eWuHNKiRoUs8t5HGWmHgqajXHRxwYGiiFBw+Zs76gsLLzGk5qWgn2OMvM5OZFJeLUJvgbp6CzOtDN5KXF2uMs0BAjzifJaJ2iMCd15vp8iliepP3disTjLAotxKQqpYA2AagzPXspjj7JOLdomo7E44wjjfg2Q9Os/aLMpAdSmJxM3TDb6dtpgOtkpBW5x1mAQUaVzcpJlBUnJNZ0M9z7NkwJk45W0h2UQyeIJifh0qVgOkWc2gSehR/DJoTjb1/C2FHPan71ZbD21+4lFy0OPM5CjphtAYqCf/4T/vGPgK5Rdgp0Qs9PFFtOSBL1f8KKGcaLwfhDSNGSixYHHmchR8y2AEF4OBEEvPGG77tKO+VZlEfMyRPB6AVo/ssjkf5/4GnoI2VJRIszjzO2PIKXJ8lXtAjC3tb2qizipCDgDxm7555PX4wb+vfB9HUYzgNgfG5uvEwWWuEelNs4gjjkkKSBIDLXojl8Jfpfz3xSEB5DH81R7Kiwf+eShVaSe5wJd+xAoTc8IaMuf84ZJ5ZftaSghUy3MX/TyFI168Vpe+a/3sK0uHE5XW+dRSrxtGLlccZCCYGLvjaZK4reQ7TYHb8M3HBkdxJPK1YeZ5HpA9faYDK32+2JeRuARUq4nTC2Hmde42SRxKZY71cbLOrHsGgi51bSHZTDnDgymXPOLWG04udxFo7OvDlxZzIPp2dWZRJGSyKRBIvvw2oQURZmb4rVarWrq6s+3fb29rrdbp9Mbi8TQyuuHmdBFMaeEwAYjUa/i/j5+flYxytPAC0uD8oFIRH8VlCTOcMwN2/e/L+1z8DAgE9LNTU1DOOxEo2PjyuVyp6enhs3bjidTgA4c+aMT2FuLxNAK8EeZ3bK854wqCl2YmKiv79fp9PdvHlzeXnZR+OnT59GEeU7Ojp0Ot2uXbvOnTv3119/AUBJSQkC6VOFq8t400qoxxkLk3lDQ8Pz58/b29sBYHR0dHBw0Gaz6XQ6ACgrKwMAhmFmZmYkEsnFixetViuaW6dOnUodWgnzOGNvMj916tTCwkJVVRUA1NXVWa1Wh8Px8OFDAKiurgaAubm5jz766OOPP66oqKitrUWQKioquJpGftuJ69xKgNkCc2JpMkdLPrTGKy8vB4CxsTGUef/+/bGxsY1/XsNqtTY1NfnVMleZ8aMVb4+z1ya+6F9tNDY2Tk1NTUxMYKXr9fqNK/hbt27F2jAdJ1pxPSjHHSeMZ2VlBacTmIgHrfh5nGFOyWfi44RxPGhJJBKCIPbv30+SZIiItxGPiaE9L919vMwjbi1ZK8acFjLdvvPOOwRBbN26lSCI7du39/X1caYQbOJL0fnkrajY0sIH5cxmM/4bMFu2bOHmT4ViTslqMvdWNCfp2NLy9jgjSRLNra1bt6Kdf+QD8OaUxCbzyAcYoGYMaSGPM+8fKvSHy86ePRtV7LOITLEBhs+z7FjR8utxRtM0ClCHXpew3p1sYk7oaxUrWsE9ztCankUAoKAmc55NkCjEjQmtcDzOwnV1CsNkHsXweVaVe1rhH5QLYY+P3sucZyxCi8s9LaFQKAk78Kn/k8XYFBull3no4fOsBMe02B6Us9vtBEGsB9rCnFiazHmm9UjF5ZKWj8eZ2+2enZ1Fgv3666+BJEQuhR7P8nEJx6cBAnXJ23zOaG30ONPr9cvLy/Pz8wDQ2NgYSEW0w5b5r7fI7zk9tRGoM57nc0Zro8dZT08PALS2tgLA3bt3/Sjq9Xxy9X3MSYACP12kVhY3tPx6nF24cKGgoODQoUOFhYXoZeu66jaHyXx9vBylOKAVxOMM+Zag/78SGJv4NoHJnCNG681wQCu42WK9K8xp05jM18fOUSpaWiF2uEhKb06byWTOEaP1ZqKihUy3IUKzb3pT7Lqyo05FRSuEx1maU9R4fBqInFYwj7O0ydxHzRxdRkgroMdZ2mTOERi/zURCa6PZwtN02mTuV8GcZkZCyzc0OzbFpk3mnLLZ2BhrWn+LcYY5pU3mG1Ubgxx2tLDHWdpkHgMWoZtkR8vjcfbfH6RfbQTRq8FgKCwsDLEHDVI/6C12tN76jzfsDX+PkR209U14U6FQIK/kN998k3Ns7GjhWEfpRPga4NCNnAWtTThRIhgymlsZGRnbtm377rvvuH0kpmlFQCRYFYPBwDkk3F+aFlYFDxJpWjyAhEXcLLQsFsvS0hIeNk8TAWk9ePDAaDTiUf3888/eo9Xr9Z2dnVNTU7iAdyLIKsjlcvX393sXDpKmaVqpVI6MjAQp4/fWyMiISqXq6uoaHh5mGGZpaUmj0Zw8edLlcvktH31meXn5wsJCxO04nU6lUmk0Gp1OZ1tb2+Liot+m/NNaXl4uLS0FALfb/fTpUxRtwNsDt729XaPRVFRUqNVqm8327NkzAFhYWEBhI0wmk/fly5cvbTbb8+fP9Xo9TdM+hW022/z8vHc8K7fbjcS9c+dOf39/8Hghbre7ublZqVTeu3cPj3BxcbGoqAjFk5HL5QCwsrLic8TPbrc7HA4AsNlsL168cDgcSEL32sdHXwsLC95Hm5xO59OnT10u1+LiIqoolUofPnyIGrSufZaXl+1rHwBwOBwWiwWJNzc3h0bkQ/fgwYOowC+//IIH4pPwT0uv16MAU3K5/MbaBwC+/PJLXFmlUnV3d587d663tzcrK+vSpUuXL1++deuWWCxeXFz84osvWlpa9Hr9yZMnHzx4IJPJqqqq1Gr1t99+293dLZVKcWGLxbJ79+7m5mYUkwIAXC5Xfn7+Tz/91NLSUl5eLpfLkRPO48ePNRpNXl5eaWnp8PAwluTq1atYETjTarUWFRXJ5fLS0tLJyUmHw3Hw4MHjx4/jo/kTExM1NTVnzpz5448/9uzZ09nZKRKJkIQzMzNYANQgRVFNTU3eJ2Ly8/MVCkVfX59cLm9paVGpVFKpVKVS7du378mTJ0VFRe3t7cePH29oaNi/f//8/Hx1dfXRo0fn5ubKy8s7Ojq0Wm1tba1Wq730+u83uFyuI0eOAIDT6fT+2uERoYR/Wrdv39ZoNACgUChu3LiB/m7tV199hSurVKri4uJHjx4BgFgsBgCRSAQAVVVVRqNRLBaLRCKtVqvT6WpqalAIl9HR0aamJovFIpVKfQrjRgDAYDDU1dUxDCMSiZqamsbHx1Gn8/PzDofjvffem52dffHiBZakqqpKtfbxHiSi1d/ff/LkSdQ7Lo8S586d+/333+/du1dfX4/kF4vFSEJvAVDhycnJlpaW3Nxc3Mi1a9eOHTs2NTVVV1c3MDCAaJlMJplMNjQ0VFJScvny5fr6eqPRqFQq9Xr9pUuXjh07ZjAY0MAZhsnJydFqtVjm4eFhFBnlt99+w18p3B1O+Kc1OzuLgubk5uZ2dHR88803APD111/jalKp9OzZswAwPz+fnZ1ts9k6Ozvb2trKysoYhikoKGhvb6+rq7t165bRaMzPz29tbZ2amjpw4IBWqxWJRLiwxWLJzs6mKGr37t04/EtpaalSqezu7i4pKVGpVKjTa9euSSSSzz77TKVSPXnyBEvS1dVFkqTP05Ikyc8//7y+vl6n08lksunpaVweJSiKkslk1dXVMzMzu3fvpigqOzt7ZGTkwIEDc3NzWABUuKWlRS6Xf/rpp/gA7okTJ06fPr20tPTJJ5+cP3++pqZGKpU2NDScOHFiYGDg6tWrtbW19fX1tbW1YrH48ePHeXl5xcXFnZ2dUqn0woULDx48qK6uvnLlyuDgIOrCarXK5fKJiQnMz0dgdOmfFgC0t7c/evQI/5x0dXUFbwj9yAGAyWRCpHFdt9uNtOmtU3zXr1h+76J2vBtBdcfGxtrb230dTF+3a7FYNlZB0m7Mxzk+Avhcrq6uopIbI9IAAMqsr69Hzx6sGSQRbgonUL7L5Xr5MsQfnglI6/VgWf+r0WiCzGXWzfG2gkajiWA1G3y43NMK3l/6bjQaCIsWRVEzMzNoJeq9jgeA27dv9/b2BpLgzp07gW6xzR8ZGdFqtWxrpVh5P7QYhjGZTGi74HK55ubmlpaW7Ha7Wq2maVosFi8tLeFn3dDQUGNjI9qd4M0ZirTodrvn5ubQLxnaiKysrJhMJqfTaTKZGIbB+7OFhQWn0zk4OIj2Ijgf7+QAQKlUonVNigFgNRz/tA4ePDg9Pb1z506r1VpaWlpZWTkwMLBr1667d+8ePny4o6Pj0KFDqJuhoaHi4uKCgoLBwUG8OSsuLu7p6RkaGhKJRB0dHa2trWhaLC0t5ebmLi8vV1ZWXr9+HW3ImpqadDpdXV1dfn7+lStXGhoa0L7NYrGgnRzqSCQSnT17tqCgIHb2CFaKS0hhP7QAYGBgoKysrLGxsays7P79+62trUNDQ2gdj3YnhYWFmNa1a9fGx8crKyvx5mx4eFgkElksFrFY/OzZs8OHD+NYwj/88INSqZyensYbMpFIhNZX1dXVT5482bgVQx29//77q6urH374IYq4kRBlJbxT/7TcbvfOnTsZhsnKymIYpqKiQqlUHjlypKenJzs7+88//9yzZw96+g0NDeXn55eUlExPT+PNWXV19fnz54eHh7Ozsy9evKjRaFpaWtBQFxYW9u3bh3YIaEPW1tZWUVGh1+ubmppkMplKpUL7NrQVs9lsqGJBQYFSqfz++++npqauX7+ecMUlRAD/tPyKwqx9/N5CmXgDwTCM90bEO+1dHZfHCTTJ8KV3YbyP8dm++JRJ7UsWtFJbEbwYXZoWLzC9EjJNK02LTxrgk6zpuZWmxScN8EnW/wchyCA9vUjpVgAAAABJRU5ErkJggg=="
    }
   },
   "cell_type": "markdown",
   "id": "861fa446",
   "metadata": {},
   "source": [
    "##  Orthogonal Projections\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "![image-2.png](attachment:image-2.png)\n",
    "**Fig.10** Examples of projections onto one-dimensional subspaces.\n",
    "\n",
    "(a) Projection of $ x \\in \\mathbb{R}^2 $ onto a subspace $ U $ with basis vector $ b $.\n",
    "\n",
    "(b) Projection of a two-dimensional vector $ x $ with $ \\|x\\| = 1 $ onto a one-dimensional subspace spanned by $ b $.\n",
    "\n",
    "Let us characterize some properties of the projection $ \\pi_U(x) $ (Figure 3.10(a) serves as an illustration): The projection $ \\pi_U(x) $ is closest to $ x $, where “closest” implies that the distance $ \\|x - \\pi_U(x)\\| $ is minimal. It follows that the segment $ \\pi_U(x) - x $ from $ \\pi_U(x) $ to $ x $ is orthogonal to $ U $, and therefore the basis vector $ b $ of $ U $. The orthogonality condition yields $ \\langle \\pi_U(x) - x, b \\rangle = 0 $ since angles between vectors are defined via the inner product.\n",
    "\n",
    "The projection $ \\pi_U(x) $ of $ x $ onto $ U $ must be an element of $ U $ and, therefore, a multiple of the basis vector $ b $ that spans $ U $. Hence,\n",
    "\n",
    "$$\n",
    "\\pi_U(x) = \\lambda b,\n",
    "$$\n",
    "\n",
    "for some $ \\lambda \\in \\mathbb{R} $.\n",
    "\n",
    "In the following three steps, we determine the coordinate $ \\lambda $, the projection $ \\pi_U(x) \\in U $, and the projection matrix $ P_\\pi $ that maps any $ x \\in \\mathbb{R}^n $ onto $ U $:\n",
    "\n",
    "1. **Finding the coordinate $ \\lambda $**. The orthogonality condition yields\n",
    "\n",
    "$$\n",
    "\\langle x - \\pi_U(x), b \\rangle = 0 \\quad \\iff \\quad \\langle x - \\lambda b, b \\rangle = 0. \\tag{3.39}\n",
    "$$\n",
    "\n",
    "We can now exploit the bilinearity of the inner product and arrive at\n",
    "\n",
    "$$\n",
    "\\langle x, b \\rangle - \\lambda \\langle b, b \\rangle = 0 \\quad \\iff \\quad \\lambda = \\frac{\\langle x, b \\rangle}{\\langle b, b \\rangle} = \\frac{\\langle b, x \\rangle}{\\|b\\|^2}. \\tag{3.40}\n",
    "$$\n",
    "\n",
    "In the last step, we exploited the fact that inner products are symmetric. If we choose $ \\langle \\cdot, \\cdot \\rangle $ to be the dot product, we obtain\n",
    "\n",
    "$$\n",
    "\\lambda = \\frac{b^\\top x}{b^\\top b} = \\frac{b^\\top x}{\\|b\\|^2}. \\tag{3.41}\n",
    "$$\n",
    "\n",
    "If $ \\|b\\| = 1 $, then the coordinate $ \\lambda $ of the projection is given by $ b^\\top x $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5ec8ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projection onto a One-Dimensional Subspace (Section 3.8.1):\n",
      "Vector x = [1.0, 2.0, 3.0]\n",
      "Line spanned by b = [1.0, 1.0, 0.0]\n",
      "Coordinate lambda = 1.500\n",
      "Projection pi_U(x) = [1.5, 1.5, 0.0]\n",
      "Error vector (x - pi_U(x)) = [-0.5, 0.5, 3.0]\n",
      "Error is orthogonal to b: True\n",
      "\n",
      "Test with unit norm b (||b|| = 1):\n",
      "Unit basis vector b = [0.707, 0.707, 0.0]\n",
      "Norm of b: 1.000\n",
      "Coordinate lambda = 2.121\n",
      "Expected lambda (b^T x) = 2.121\n",
      "Projection pi_U(x) = [1.5, 1.5, 0.0]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# --- Dot Product (Standard Inner Product) ---\n",
    "def dot_product(x, y):\n",
    "    \"\"\"\n",
    "    Compute the dot product of two vectors: x^T y = sum(x_i * y_i)\n",
    "    \"\"\"\n",
    "    return sum(xi * yi for xi, yi in zip(x, y))\n",
    "\n",
    "# --- Norm Induced by Dot Product ---\n",
    "def norm(x):\n",
    "    \"\"\"\n",
    "    Compute the Euclidean norm of a vector: ||x|| = sqrt(x^T x)\n",
    "    \"\"\"\n",
    "    return math.sqrt(dot_product(x, x))\n",
    "\n",
    "# --- Projection onto a One-Dimensional Subspace (Section 3.8.1) ---\n",
    "def project_onto_line(x, b):\n",
    "    \"\"\"\n",
    "    Project vector x onto the line (one-dimensional subspace) spanned by vector b.\n",
    "    Uses the dot product as the inner product.\n",
    "    From Equation 3.41: lambda = (b^T x) / (b^T b), pi_U(x) = lambda * b\n",
    "    Returns the projection pi_U(x) and the coordinate lambda.\n",
    "    \"\"\"\n",
    "    if norm(b) < 1e-10:\n",
    "        raise ValueError(\"Basis vector b cannot be zero\")\n",
    "    \n",
    "    # Compute lambda (Equation 3.41): lambda = (b^T x) / (b^T b)\n",
    "    bTx = dot_product(b, x)\n",
    "    bTb = dot_product(b, b)\n",
    "    lambda_coeff = bTx / bTb\n",
    "    \n",
    "    # Compute the projection: pi_U(x) = lambda * b\n",
    "    projection = [lambda_coeff * bi for bi in b]\n",
    "    return projection, lambda_coeff\n",
    "\n",
    "# --- Run the Implementation ---\n",
    "# Example: Project a vector in R^3 onto a line\n",
    "print(\"Projection onto a One-Dimensional Subspace (Section 3.8.1):\")\n",
    "x = [1.0, 2.0, 3.0]  # Vector to project\n",
    "b = [1.0, 1.0, 0.0]  # Basis vector of the line\n",
    "projection, lambda_coeff = project_onto_line(x, b)\n",
    "print(f\"Vector x = {x}\")\n",
    "print(f\"Line spanned by b = {b}\")\n",
    "print(f\"Coordinate lambda = {lambda_coeff:.3f}\")\n",
    "print(f\"Projection pi_U(x) = {[round(p, 3) for p in projection]}\")\n",
    "\n",
    "# Verify orthogonality (Equation 3.39): <x - pi_U(x), b> = 0\n",
    "error = [xi - pi for xi, pi in zip(x, projection)]\n",
    "error_dot_b = dot_product(error, b)\n",
    "print(f\"Error vector (x - pi_U(x)) = {[round(e, 3) for e in error]}\")\n",
    "print(f\"Error is orthogonal to b: {abs(error_dot_b) < 1e-10}\")\n",
    "\n",
    "# Additional Test: When ||b|| = 1, lambda should be b^T x\n",
    "print(\"\\nTest with unit norm b (||b|| = 1):\")\n",
    "b_unit = [1/math.sqrt(2), 1/math.sqrt(2), 0.0]  # Normalize b\n",
    "projection_unit, lambda_unit = project_onto_line(x, b_unit)\n",
    "print(f\"Unit basis vector b = {[round(bi, 3) for bi in b_unit]}\")\n",
    "print(f\"Norm of b: {norm(b_unit):.3f}\")\n",
    "print(f\"Coordinate lambda = {lambda_unit:.3f}\")\n",
    "print(f\"Expected lambda (b^T x) = {dot_product(b_unit, x):.3f}\")\n",
    "print(f\"Projection pi_U(x) = {[round(p, 3) for p in projection_unit]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6000896",
   "metadata": {},
   "source": [
    "2. **Finding the projection point $ \\pi_U(x) \\in U $**. Since $ \\pi_U(x) = \\lambda b $, we immediately obtain with (3.40) that\n",
    "\n",
    "$$\n",
    "\\pi_U(x) = \\lambda b = \\frac{\\langle x, b \\rangle}{\\|b\\|^2} b = \\frac{b^\\top x}{\\|b\\|^2} b, \\tag{3.42}\n",
    "$$\n",
    "\n",
    "where the last equality holds for the dot product only. We can also compute the length of $ \\pi_U(x) $ by means of Definition 3.1 as\n",
    "\n",
    "$$\n",
    "\\|\\pi_U(x)\\| = \\|\\lambda b\\| = |\\lambda| \\|b\\|. \\tag{3.43}\n",
    "$$\n",
    "\n",
    "Hence, our projection is of length $ |\\lambda| $ times the length of $ b $. This also adds the intuition that $ \\lambda $ is the coordinate of $ \\pi_U(x) $ with respect to the basis vector $ b $ that spans our one-dimensional subspace $ U $.\n",
    "\n",
    "If we use the dot product as an inner product, we get\n",
    "\n",
    "$$\n",
    "\\|\\pi_U(x)\\| = \\|\\lambda b\\| = |\\lambda| \\|b\\| = \\frac{|b^\\top x|}{\\|b\\|^2} \\|b\\| \\stackrel{(3.25)}{=} |\\cos \\omega| \\|x\\| \\frac{\\|b\\|}{\\|b\\|} = |\\cos \\omega| \\|x\\|. \\tag{3.44}\n",
    "$$\n",
    "\n",
    "Here, $ \\omega $ is the angle between $ x $ and $ b $. This equation should be familiar from trigonometry: If $ \\|x\\| = 1 $, then $ x $ lies on the unit circle. It follows that the projection onto the horizontal axis spanned by $ b $ is exactly $ \\cos \\omega $, and the length of the corresponding vector $ \\pi_U(x) = |\\cos \\omega| $. An illustration is given in Figure 3.10(b).\n",
    "\n",
    "3. **Finding the projection matrix $ P_\\pi $**. We know that a projection is a linear mapping (see Definition 3.10). Therefore, there exists a projection matrix $ P_\\pi $, such that $ \\pi_U(x) = P_\\pi x $. With the dot product as inner product and\n",
    "\n",
    "$$\n",
    "\\pi_U(x) = \\lambda b = b \\lambda = b \\frac{b^\\top x}{\\|b\\|^2} = \\frac{b b^\\top}{\\|b\\|^2} x, \\tag{3.45}\n",
    "$$\n",
    "\n",
    "we immediately see that\n",
    "\n",
    "$$\n",
    "P_\\pi = \\frac{b b^\\top}{\\|b\\|^2}. \\tag{3.46}\n",
    "$$\n",
    "\n",
    "Note that $ b b^\\top $ (and, consequently, $ P_\\pi $) is a symmetric matrix (of rank 1), and $ \\|b\\|^2 = \\langle b, b \\rangle $ is a scalar. The projection matrix $ P_\\pi $ projects any vector $ x \\in \\mathbb{R}^n $ onto the line through the origin with direction $ b $ (equivalently, the subspace $ U $ spanned by $ b $).\n",
    "\n",
    "**Remark.** The projection $ \\pi_U(x) \\in \\mathbb{R}^n $ is still an $ n $-dimensional vector and not a scalar. However, we no longer require $ n $ coordinates to represent the projection, but only a single one if we want to express it with respect to the basis vector $ b $ that spans the subspace $ U $: $ \\lambda $. $ \\diamond $\n",
    "\n",
    "2. **Finding the projection point $ \\pi_U(x) \\in U $**. Since $ \\pi_U(x) = \\lambda b $, we immediately obtain with (3.40) that\n",
    "\n",
    "$$\n",
    "\\pi_U(x) = \\lambda b = \\frac{\\langle x, b \\rangle}{\\|b\\|^2} b = \\frac{b^\\top x}{\\|b\\|^2} b, \\tag{3.42}\n",
    "$$\n",
    "\n",
    "where the last equality holds for the dot product only. We can also compute the length of $ \\pi_U(x) $ by means of Definition 3.1 as\n",
    "\n",
    "$$\n",
    "\\|\\pi_U(x)\\| = \\|\\lambda b\\| = |\\lambda| \\|b\\|. \\tag{3.43}\n",
    "$$\n",
    "\n",
    "Hence, our projection is of length $ |\\lambda| $ times the length of $ b $. This also adds the intuition that $ \\lambda $ is the coordinate of $ \\pi_U(x) $ with respect to the basis vector $ b $ that spans our one-dimensional subspace $ U $.\n",
    "\n",
    "If we use the dot product as an inner product, we get\n",
    "\n",
    "$$\n",
    "\\|\\pi_U(x)\\| = \\|\\lambda b\\| = |\\lambda| \\|b\\| = \\frac{|b^\\top x|}{\\|b\\|^2} \\|b\\| \\stackrel{(3.25)}{=} |\\cos \\omega| \\|x\\| \\frac{\\|b\\|}{\\|b\\|} = |\\cos \\omega| \\|x\\|. \\tag{3.44}\n",
    "$$\n",
    "\n",
    "Here, $ \\omega $ is the angle between $ x $ and $ b $. This equation should be familiar from trigonometry: If $ \\|x\\| = 1 $, then $ x $ lies on the unit circle. It follows that the projection onto the horizontal axis spanned by $ b $ is exactly $ \\cos \\omega $, and the length of the corresponding vector $ \\pi_U(x) = |\\cos \\omega| $. An illustration is given in Figure 3.10(b).\n",
    "\n",
    "3. **Finding the projection matrix $ P_\\pi $**. We know that a projection is a linear mapping (see Definition 3.10). Therefore, there exists a projection matrix $ P_\\pi $, such that $ \\pi_U(x) = P_\\pi x $. With the dot product as inner product and\n",
    "\n",
    "$$\n",
    "\\pi_U(x) = \\lambda b = b \\lambda = b \\frac{b^\\top x}{\\|b\\|^2} = \\frac{b b^\\top}{\\|b\\|^2} x, \\tag{3.45}\n",
    "$$\n",
    "\n",
    "we immediately see that\n",
    "\n",
    "$$\n",
    "P_\\pi = \\frac{b b^\\top}{\\|b\\|^2}. \\tag{3.46}\n",
    "$$\n",
    "\n",
    "Note that $ b b^\\top $ (and, consequently, $ P_\\pi $) is a symmetric matrix (of rank 1), and $ \\|b\\|^2 = \\langle b, b \\rangle $ is a scalar. The projection matrix $ P_\\pi $ projects any vector $ x \\in \\mathbb{R}^n $ onto the line through the origin with direction $ b $ (equivalently, the subspace $ U $ spanned by $ b $).\n",
    "\n",
    "**Remark.** The projection $ \\pi_U(x) \\in \\mathbb{R}^n $ is still an $ n $-dimensional vector and not a scalar. However, we no longer require $ n $ coordinates to represent the projection, but only a single one if we want to express it with respect to the basis vector $ b $ that spans the subspace $ U $: $ \\lambda $. $ \\diamond $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b572114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Finding the Projection Point (Equation 3.42)\n",
      "Vector x = [1.0, 2.0, 3.0]\n",
      "Basis vector b = [1.0, 1.0, 0.0]\n",
      "Coordinate lambda = 1.500\n",
      "Projection pi_U(x) = [1.5, 1.5, 0.0]\n",
      "\n",
      "Step 2: Length of Projection (Equation 3.43)\n",
      "||pi_U(x)|| = 2.121\n",
      "|lambda| * ||b|| = 2.121\n",
      "Length matches: True\n",
      "\n",
      "Step 2: Trigonometric Length (Equation 3.44)\n",
      "Angle omega = 0.968 radians\n",
      "|cos(omega)| * ||x|| = 2.121\n",
      "Matches ||pi_U(x)||: True\n",
      "\n",
      "Test with ||x|| = 1:\n",
      "Unit vector x = [0.267, 0.535, 0.802]\n",
      "Projection pi_U(x) = [0.401, 0.401, 0.0]\n",
      "||pi_U(x)|| = 0.567\n",
      "|cos(omega)| = 0.567\n",
      "Matches |cos(omega)|: True\n",
      "\n",
      "Step 3: Finding the Projection Matrix (Equations 3.45 and 3.46)\n",
      "Projection matrix P:\n",
      "[0.5, 0.5, 0.0]\n",
      "[0.5, 0.5, 0.0]\n",
      "[0.0, 0.0, 0.0]\n",
      "P satisfies P^2 = P: True\n",
      "Projection using matrix: [1.5, 1.5, 0.0]\n",
      "Matches direct projection: True\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# --- Dot Product (Standard Inner Product) ---\n",
    "def dot_product(x, y):\n",
    "    \"\"\"\n",
    "    Compute the dot product of two vectors: x^T y = sum(x_i * y_i)\n",
    "    \"\"\"\n",
    "    return sum(xi * yi for xi, yi in zip(x, y))\n",
    "\n",
    "# --- Norm Induced by Dot Product ---\n",
    "def norm(x):\n",
    "    \"\"\"\n",
    "    Compute the Euclidean norm of a vector: ||x|| = sqrt(x^T x)\n",
    "    \"\"\"\n",
    "    return math.sqrt(dot_product(x, x))\n",
    "\n",
    "# --- Compute Angle Between Vectors ---\n",
    "def compute_angle(x, b):\n",
    "    \"\"\"\n",
    "    Compute the angle omega between vectors x and b using the dot product.\n",
    "    cos(omega) = <x, b> / (||x|| ||b||), omega in [0, pi]\n",
    "    Returns the angle in radians.\n",
    "    \"\"\"\n",
    "    if norm(x) < 1e-10 or norm(b) < 1e-10:\n",
    "        raise ValueError(\"Vectors must be non-zero to compute the angle\")\n",
    "    \n",
    "    cos_omega = dot_product(x, b) / (norm(x) * norm(b))\n",
    "    # Ensure cos_omega is in [-1, 1] to avoid numerical errors\n",
    "    cos_omega = max(min(cos_omega, 1.0), -1.0)\n",
    "    return math.acos(cos_omega)\n",
    "\n",
    "# --- Projection onto a One-Dimensional Subspace (Equation 3.42) ---\n",
    "def project_onto_line(x, b):\n",
    "    \"\"\"\n",
    "    Project vector x onto the line spanned by vector b using the dot product.\n",
    "    From Equation 3.42: pi_U(x) = (b^T x / ||b||^2) * b\n",
    "    Returns the projection pi_U(x) and the coordinate lambda.\n",
    "    \"\"\"\n",
    "    if norm(b) < 1e-10:\n",
    "        raise ValueError(\"Basis vector b cannot be zero\")\n",
    "    \n",
    "    bTb = dot_product(b, b)  # ||b||^2\n",
    "    bTx = dot_product(b, x)\n",
    "    lambda_coeff = bTx / bTb  # lambda = (b^T x) / (b^T b)\n",
    "    projection = [lambda_coeff * bi for bi in b]  # pi_U(x) = lambda * b\n",
    "    return projection, lambda_coeff\n",
    "\n",
    "# --- Construct Projection Matrix (Equations 3.45 and 3.46) ---\n",
    "def projection_matrix(b):\n",
    "    \"\"\"\n",
    "    Construct the projection matrix P_pi for the subspace spanned by vector b.\n",
    "    From Equation 3.46: P_pi = (b b^T) / (||b||^2)\n",
    "    \"\"\"\n",
    "    n = len(b)\n",
    "    if norm(b) < 1e-10:\n",
    "        raise ValueError(\"Basis vector b cannot be zero\")\n",
    "    \n",
    "    bTb = dot_product(b, b)  # ||b||^2\n",
    "    P = [[0.0 for _ in range(n)] for _ in range(n)]\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            P[i][j] = b[i] * b[j] / bTb  # (b b^T) / (b^T b)\n",
    "    return P\n",
    "\n",
    "# --- Matrix-Vector Multiplication ---\n",
    "def matrix_vector_multiply(A, x):\n",
    "    \"\"\"\n",
    "    Multiply matrix A by vector x.\n",
    "    \"\"\"\n",
    "    n = len(A)\n",
    "    result = [0.0] * n\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            result[i] += A[i][j] * x[j]\n",
    "    return result\n",
    "\n",
    "# --- Matrix-Matrix Multiplication ---\n",
    "def matrix_multiply(A, B):\n",
    "    \"\"\"\n",
    "    Multiply two matrices A and B.\n",
    "    \"\"\"\n",
    "    n = len(A)\n",
    "    result = [[0.0 for _ in range(n)] for _ in range(n)]\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            for k in range(n):\n",
    "                result[i][j] += A[i][k] * B[k][j]\n",
    "    return result\n",
    "\n",
    "# --- Verify Projection Matrix Property (P^2 = P) ---\n",
    "def verify_projection_matrix(P):\n",
    "    \"\"\"\n",
    "    Verify that the projection matrix satisfies P^2 = P.\n",
    "    \"\"\"\n",
    "    P2 = matrix_multiply(P, P)\n",
    "    n = len(P)\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if abs(P2[i][j] - P[i][j]) > 1e-10:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "# --- Run the Implementation ---\n",
    "# Step 2: Finding the Projection Point (Equation 3.42)\n",
    "print(\"Step 2: Finding the Projection Point (Equation 3.42)\")\n",
    "x = [1.0, 2.0, 3.0]\n",
    "b = [1.0, 1.0, 0.0]\n",
    "projection, lambda_coeff = project_onto_line(x, b)\n",
    "print(f\"Vector x = {x}\")\n",
    "print(f\"Basis vector b = {b}\")\n",
    "print(f\"Coordinate lambda = {lambda_coeff:.3f}\")\n",
    "print(f\"Projection pi_U(x) = {[round(p, 3) for p in projection]}\")\n",
    "\n",
    "# Compute the length of pi_U(x) (Equation 3.43)\n",
    "proj_norm = norm(projection)\n",
    "expected_norm = abs(lambda_coeff) * norm(b)\n",
    "print(f\"\\nStep 2: Length of Projection (Equation 3.43)\")\n",
    "print(f\"||pi_U(x)|| = {proj_norm:.3f}\")\n",
    "print(f\"|lambda| * ||b|| = {expected_norm:.3f}\")\n",
    "print(f\"Length matches: {abs(proj_norm - expected_norm) < 1e-10}\")\n",
    "\n",
    "# Verify the trigonometric interpretation (Equation 3.44)\n",
    "omega = compute_angle(x, b)\n",
    "cos_omega = math.cos(omega)\n",
    "norm_x = norm(x)\n",
    "norm_b = norm(b)\n",
    "expected_norm_trig = abs(cos_omega) * norm_x\n",
    "print(f\"\\nStep 2: Trigonometric Length (Equation 3.44)\")\n",
    "print(f\"Angle omega = {omega:.3f} radians\")\n",
    "print(f\"|cos(omega)| * ||x|| = {expected_norm_trig:.3f}\")\n",
    "print(f\"Matches ||pi_U(x)||: {abs(proj_norm - expected_norm_trig) < 1e-10}\")\n",
    "\n",
    "# Test with ||x|| = 1\n",
    "x_unit = [xi / norm_x for xi in x]  # Normalize x\n",
    "proj_unit, lambda_unit = project_onto_line(x_unit, b)\n",
    "proj_unit_norm = norm(proj_unit)\n",
    "cos_omega_unit = math.cos(compute_angle(x_unit, b))\n",
    "print(f\"\\nTest with ||x|| = 1:\")\n",
    "print(f\"Unit vector x = {[round(xi, 3) for xi in x_unit]}\")\n",
    "print(f\"Projection pi_U(x) = {[round(p, 3) for p in proj_unit]}\")\n",
    "print(f\"||pi_U(x)|| = {proj_unit_norm:.3f}\")\n",
    "print(f\"|cos(omega)| = {abs(cos_omega_unit):.3f}\")\n",
    "print(f\"Matches |cos(omega)|: {abs(proj_unit_norm - abs(cos_omega_unit)) < 1e-10}\\n\")\n",
    "\n",
    "# Step 3: Finding the Projection Matrix (Equations 3.45 and 3.46)\n",
    "print(\"Step 3: Finding the Projection Matrix (Equations 3.45 and 3.46)\")\n",
    "P = projection_matrix(b)\n",
    "print(\"Projection matrix P:\")\n",
    "for row in P:\n",
    "    print([round(val, 3) for val in row])\n",
    "\n",
    "# Verify P^2 = P\n",
    "is_idempotent = verify_projection_matrix(P)\n",
    "print(f\"P satisfies P^2 = P: {is_idempotent}\")\n",
    "\n",
    "# Project x using the projection matrix and compare\n",
    "proj_matrix = matrix_vector_multiply(P, x)\n",
    "print(f\"Projection using matrix: {[round(p, 3) for p in proj_matrix]}\")\n",
    "print(f\"Matches direct projection: {all(abs(p1 - p2) < 1e-10 for p1, p2 in zip(projection, proj_matrix))}\")"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "87ef70c2",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)\n",
    "**Fig.11** Projection onto a two-dimensional subspace $ U $ with basis $ b_1, b_2 $. The projection $ \\pi_U(x) $ of $ x \\in \\mathbb{R}^3 $ onto $ U $ can be expressed as a linear combination of $ b_1, b_2 $, and the displacement vector $ x - \\pi_U(x) $ is orthogonal to both $ b_1 $ and $ b_2 $.\n",
    "\n",
    "### Example 3.10 (Projection onto a Line)\n",
    "\n",
    "Find the projection matrix $ P_\\pi $ onto the line through the origin spanned by $ b = [1, 2, 2]^\\top $. $ b $ is a direction and a basis of the one-dimensional subspace (line through origin). With (3.46), we obtain\n",
    "\n",
    "$$\n",
    "P_\\pi = \\frac{b b^\\top}{b^\\top b} = \\frac{1}{9} \\begin{bmatrix} 1 \\\\ 2 \\\\ 2 \\end{bmatrix} [1, 2, 2] = \\frac{1}{9} \\begin{bmatrix} 1 & 2 & 2 \\\\ 2 & 4 & 4 \\\\ 2 & 4 & 4 \\end{bmatrix}. \\tag{3.47}\n",
    "$$\n",
    "\n",
    "Let us now choose a particular $ x $ and see whether it lies in the subspace spanned by $ b $. For $ x = [1, 1, 1]^\\top $, the projection is\n",
    "\n",
    "$$\n",
    "\\pi_U(x) = P_\\pi x = \\frac{1}{9} \\begin{bmatrix} 1 & 2 & 2 \\\\ 2 & 4 & 4 \\\\ 2 & 4 & 4 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\end{bmatrix} = \\frac{1}{9} \\begin{bmatrix} 5 \\\\ 10 \\\\ 10 \\end{bmatrix} \\in \\text{span}\\left(\\begin{bmatrix} 1 \\\\ 2 \\\\ 2 \\end{bmatrix}\\right). \\tag{3.48}\n",
    "$$\n",
    "\n",
    "Note that the application of $ P_\\pi $ to $ \\pi_U(x) $ does not change anything, i.e., $ P_\\pi \\pi_U(x) = \\pi_U(x) $. This is expected because according to Definition 3.10, we know that a projection matrix $ P_\\pi $ satisfies $ P_\\pi^2 x = P_\\pi x $ for all $ x $.\n",
    "\n",
    "**Remark.** With the results from Chapter 4, we can show that $ \\pi_U(x) $ is an eigenvector of $ P_\\pi $, and the corresponding eigenvalue is 1. $ \\diamond $\n",
    "\n",
    "##  Projection onto General Subspaces\n",
    "\n",
    "In the following, we look at orthogonal projections of vectors $ x \\in \\mathbb{R}^n $ onto lower-dimensional subspaces $ U \\subseteq \\mathbb{R}^n $ with $ \\dim(U) = m \\geq 1 $. An illustration is given in Figure 3.11.\n",
    "\n",
    "> If $ U $ is given by a set of spanning vectors, which are not a basis, make sure you determine a basis $ b_1, \\ldots, b_m $ before proceeding.\n",
    "\n",
    "Assume that $ (b_1, \\ldots, b_m) $ is an ordered basis of $ U $. Any projection $ \\pi_U(x) $ onto $ U $ is necessarily an element of $ U $. Therefore, they can be represented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8910c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 3.10: Projection onto a Line\n",
      "Basis vector b = [1.0, 2.0, 2.0]\n",
      "Projection matrix P_pi (Equation 3.47):\n",
      "[0.111, 0.222, 0.222]\n",
      "[0.222, 0.444, 0.444]\n",
      "[0.222, 0.444, 0.444]\n",
      "\n",
      "Vector x = [1.0, 1.0, 1.0]\n",
      "Projection pi_U(x) = [0.556, 1.111, 1.111]\n",
      "P_pi pi_U(x) = [0.556, 1.111, 1.111]\n",
      "Matches pi_U(x): True\n",
      "P satisfies P^2 = P: True\n",
      "\n",
      "Section 3.8.2: Projection onto General Subspaces\n",
      "Subspace basis: [[1.0, 1.0, 0.0], [0.0, 0.0, 1.0]]\n",
      "Orthonormal basis: [[0.707, 0.707, 0.0], [0.0, 0.0, 1.0]]\n",
      "Projection matrix P for the subspace:\n",
      "[0.5, 0.5, 0.0]\n",
      "[0.5, 0.5, 0.0]\n",
      "[0.0, 0.0, 1.0]\n",
      "\n",
      "Vector x = [1.0, 2.0, 3.0]\n",
      "Projection pi_U(x) = [1.5, 1.5, 3.0]\n",
      "Displacement vector (x - pi_U(x)) = [-0.5, 0.5, 0.0]\n",
      "Displacement is orthogonal to subspace: True\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# --- Dot Product (Standard Inner Product) ---\n",
    "def dot_product(x, y):\n",
    "    \"\"\"\n",
    "    Compute the dot product of two vectors: x^T y = sum(x_i * y_i)\n",
    "    \"\"\"\n",
    "    return sum(xi * yi for xi, yi in zip(x, y))\n",
    "\n",
    "# --- Norm Induced by Dot Product ---\n",
    "def norm(x):\n",
    "    \"\"\"\n",
    "    Compute the Euclidean norm of a vector: ||x|| = sqrt(x^T x)\n",
    "    \"\"\"\n",
    "    return math.sqrt(dot_product(x, x))\n",
    "\n",
    "# --- Gram-Schmidt Process ---\n",
    "def gram_schmidt(vectors):\n",
    "    \"\"\"\n",
    "    Apply the Gram-Schmidt process to convert a set of linearly independent vectors\n",
    "    into an orthonormal basis.\n",
    "    \"\"\"\n",
    "    if not vectors:\n",
    "        return []\n",
    "    \n",
    "    orthonormal_basis = []\n",
    "    for k, vk in enumerate(vectors):\n",
    "        uk = vk[:]\n",
    "        for uj in orthonormal_basis:\n",
    "            proj = dot_product(uk, uj)\n",
    "            uk = [uki - proj * uji for uki, uji in zip(uk, uj)]\n",
    "        \n",
    "        norm_uk = norm(uk)\n",
    "        if norm_uk < 1e-10:\n",
    "            raise ValueError(f\"Vector {vk} is linearly dependent on previous vectors\")\n",
    "        orthonormal_basis.append([uki / norm_uk for uki in uk])\n",
    "    \n",
    "    return orthonormal_basis\n",
    "\n",
    "# --- Construct Projection Matrix for a One-Dimensional Subspace ---\n",
    "def projection_matrix_1d(b):\n",
    "    \"\"\"\n",
    "    Construct the projection matrix P_pi for the line spanned by vector b.\n",
    "    From Equation 3.46: P_pi = (b b^T) / (||b||^2)\n",
    "    \"\"\"\n",
    "    n = len(b)\n",
    "    if norm(b) < 1e-10:\n",
    "        raise ValueError(\"Basis vector b cannot be zero\")\n",
    "    \n",
    "    bTb = dot_product(b, b)  # ||b||^2\n",
    "    P = [[0.0 for _ in range(n)] for _ in range(n)]\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            P[i][j] = b[i] * b[j] / bTb  # (b b^T) / (b^T b)\n",
    "    return P\n",
    "\n",
    "# --- Construct Projection Matrix for a General Subspace ---\n",
    "def projection_matrix_general(basis):\n",
    "    \"\"\"\n",
    "    Construct the projection matrix for a subspace with the given basis.\n",
    "    Orthonormalize the basis, then P = sum(b_i b_i^T) over orthonormal basis vectors.\n",
    "    \"\"\"\n",
    "    # Orthonormalize the basis\n",
    "    ortho_basis = gram_schmidt(basis)\n",
    "    n = len(basis[0])\n",
    "    \n",
    "    # Initialize projection matrix\n",
    "    P = [[0.0 for _ in range(n)] for _ in range(n)]\n",
    "    \n",
    "    # P = sum(b_i b_i^T) for orthonormal basis vectors b_i\n",
    "    for b in ortho_basis:\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                P[i][j] += b[i] * b[j]  # Since b_i are orthonormal, no scaling needed\n",
    "    \n",
    "    return P\n",
    "\n",
    "# --- Matrix-Vector Multiplication ---\n",
    "def matrix_vector_multiply(A, x):\n",
    "    \"\"\"\n",
    "    Multiply matrix A by vector x.\n",
    "    \"\"\"\n",
    "    n = len(A)\n",
    "    result = [0.0] * n\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            result[i] += A[i][j] * x[j]\n",
    "    return result\n",
    "\n",
    "# --- Matrix-Matrix Multiplication ---\n",
    "def matrix_multiply(A, B):\n",
    "    \"\"\"\n",
    "    Multiply two matrices A and B.\n",
    "    \"\"\"\n",
    "    n = len(A)\n",
    "    result = [[0.0 for _ in range(n)] for _ in range(n)]\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            for k in range(n):\n",
    "                result[i][j] += A[i][k] * B[k][j]\n",
    "    return result\n",
    "\n",
    "# --- Verify Projection Matrix Property (P^2 = P) ---\n",
    "def verify_projection_matrix(P):\n",
    "    \"\"\"\n",
    "    Verify that the projection matrix satisfies P^2 = P.\n",
    "    \"\"\"\n",
    "    P2 = matrix_multiply(P, P)\n",
    "    n = len(P)\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if abs(P2[i][j] - P[i][j]) > 1e-10:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "# --- Run the Implementation ---\n",
    "# Example 3.10: Projection onto a Line\n",
    "print(\"Example 3.10: Projection onto a Line\")\n",
    "b = [1.0, 2.0, 2.0]  # Basis vector of the line\n",
    "x = [1.0, 1.0, 1.0]  # Vector to project\n",
    "P = projection_matrix_1d(b)\n",
    "print(f\"Basis vector b = {b}\")\n",
    "print(\"Projection matrix P_pi (Equation 3.47):\")\n",
    "for row in P:\n",
    "    print([round(val, 3) for val in row])\n",
    "\n",
    "# Project x using the projection matrix (Equation 3.48)\n",
    "proj_x = matrix_vector_multiply(P, x)\n",
    "print(f\"\\nVector x = {x}\")\n",
    "print(f\"Projection pi_U(x) = {[round(p, 3) for p in proj_x]}\")\n",
    "\n",
    "# Verify P_pi pi_U(x) = pi_U(x)\n",
    "proj_proj_x = matrix_vector_multiply(P, proj_x)\n",
    "print(f\"P_pi pi_U(x) = {[round(p, 3) for p in proj_proj_x]}\")\n",
    "print(f\"Matches pi_U(x): {all(abs(p1 - p2) < 1e-10 for p1, p2 in zip(proj_x, proj_proj_x))}\")\n",
    "\n",
    "# Verify P^2 = P\n",
    "is_idempotent = verify_projection_matrix(P)\n",
    "print(f\"P satisfies P^2 = P: {is_idempotent}\\n\")\n",
    "\n",
    "# Section 3.8.2: Projection onto General Subspaces\n",
    "print(\"Section 3.8.2: Projection onto General Subspaces\")\n",
    "# Example: Project a vector in R^3 onto a 2D subspace (plane)\n",
    "x_general = [1.0, 2.0, 3.0]\n",
    "basis = [[1.0, 1.0, 0.0], [0.0, 0.0, 1.0]]  # Basis for a 2D subspace\n",
    "ortho_basis = gram_schmidt(basis)\n",
    "print(f\"Subspace basis: {basis}\")\n",
    "print(f\"Orthonormal basis: {[[round(v, 3) for v in b] for b in ortho_basis]}\")\n",
    "\n",
    "# Construct projection matrix\n",
    "P_general = projection_matrix_general(basis)\n",
    "print(\"Projection matrix P for the subspace:\")\n",
    "for row in P_general:\n",
    "    print([round(val, 3) for val in row])\n",
    "\n",
    "# Project x onto the subspace\n",
    "proj_general = matrix_vector_multiply(P_general, x_general)\n",
    "print(f\"\\nVector x = {x_general}\")\n",
    "print(f\"Projection pi_U(x) = {[round(p, 3) for p in proj_general]}\")\n",
    "\n",
    "# Verify the displacement vector x - pi_U(x) is orthogonal to the subspace\n",
    "displacement = [xi - pi for xi, pi in zip(x_general, proj_general)]\n",
    "ortho_to_basis = all(abs(dot_product(displacement, b)) < 1e-10 for b in ortho_basis)\n",
    "print(f\"Displacement vector (x - pi_U(x)) = {[round(d, 3) for d in displacement]}\")\n",
    "print(f\"Displacement is orthogonal to subspace: {ortho_to_basis}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3c28d6",
   "metadata": {},
   "source": [
    "as linear combinations of the basis vectors $ b_1, \\ldots, b_m $ of $ U $, such that\n",
    "\n",
    "$$\n",
    "\\pi_U(x) = \\sum_{i=1}^m \\lambda_i b_i. \\tag{3.49}\n",
    "$$\n",
    "\n",
    "The basis vectors form the columns of $ B \\in \\mathbb{R}^{n \\times m} $, where\n",
    "\n",
    "$$\n",
    "B = [b_1, \\ldots, b_m] \\in \\mathbb{R}^{n \\times m}, \\quad \\lambda = [\\lambda_1, \\ldots, \\lambda_m]^\\top \\in \\mathbb{R}^m, \\tag{3.50}\n",
    "$$\n",
    "\n",
    "As in the 1D case, we follow a three-step procedure to find the projection $ \\pi_U(x) $ and the projection matrix $ P_\\pi $:\n",
    "\n",
    "1. **Find the coordinates $ \\lambda_1, \\ldots, \\lambda_m $ of the projection** (with respect to the basis of $ U $), such that the linear combination\n",
    "\n",
    "$$\n",
    "\\pi_U(x) = \\sum_{i=1}^m \\lambda_i b_i = B \\lambda, \\tag{3.49 repeated}\n",
    "$$\n",
    "\n",
    "is closest to $ x \\in \\mathbb{R}^n $. As in the 1D case, “closest” means “minimum distance”, which implies that the vector connecting $ \\pi_U(x) \\in U $ and $ x \\in \\mathbb{R}^n $ must be orthogonal to all basis vectors of $ U $. Therefore, we obtain $ m $ simultaneous conditions (assuming the dot product as the inner product)\n",
    "\n",
    "$$\n",
    "\\langle b_1, x - \\pi_U(x) \\rangle = b_1^\\top (x - \\pi_U(x)) = 0, \\tag{3.51}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\vdots\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\langle b_m, x - \\pi_U(x) \\rangle = b_m^\\top (x - \\pi_U(x)) = 0, \\tag{3.52}\n",
    "$$\n",
    "\n",
    "which, with $ \\pi_U(x) = B \\lambda $, can be written as\n",
    "\n",
    "$$\n",
    "b_1^\\top (x - B \\lambda) = 0, \\tag{3.53}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\vdots\n",
    "$$\n",
    "\n",
    "$$\n",
    "b_m^\\top (x - B \\lambda) = 0, \\tag{3.54}\n",
    "$$\n",
    "\n",
    "such that we obtain a homogeneous linear equation system\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} b_1^\\top \\\\ \\vdots \\\\ b_m^\\top \\end{bmatrix} (x - B \\lambda) = 0 \\quad \\iff \\quad B^\\top (x - B \\lambda) = 0, \\tag{3.55}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\iff \\quad B^\\top B \\lambda = B^\\top x. \\tag{3.56}\n",
    "$$\n",
    "\n",
    "The last expression is called the **normal equation**. Since $ b_1, \\ldots, b_m $ are a basis of $ U $ and, therefore, linearly independent, $ B^\\top B \\in \\mathbb{R}^{m \\times m} $ is regular and can be inverted. This allows us to solve for the coefficients/coordinates\n",
    "\n",
    "$$\n",
    "\\lambda = (B^\\top B)^{-1} B^\\top x. \\tag{3.57}\n",
    "$$\n",
    "\n",
    "The matrix $ (B^\\top B)^{-1} B^\\top $ is also called the **pseudo-inverse** of $ B $, which can be computed for non-square matrices $ B $. It only requires that $ B^\\top B $ is positive definite, which is the case if $ B $ is full rank. In practical applications (e.g., linear regression), we often add a “jitter term” $ \\epsilon I $ to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a9022a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projection onto a General Subspace (Section 3.8.2):\n",
      "Vector x = [1.0, 2.0, 3.0]\n",
      "Basis matrix B (columns are b1, b2):\n",
      "[1.0, 0.0]\n",
      "[1.0, 0.0]\n",
      "[0.0, 1.0]\n",
      "\n",
      "Coordinates lambda = [1.5, 3.0]\n",
      "Projection pi_U(x) = [1.5, 1.5, 3.0]\n",
      "Displacement vector (x - pi_U(x)) = [-0.5, 0.5, 0.0]\n",
      "Displacement is orthogonal to basis vectors: True\n",
      "\n",
      "Using Pseudo-Inverse (Equation 3.57):\n",
      "Pseudo-inverse (B^T B)^(-1) B^T:\n",
      "[0.5, 0.5, 0.0]\n",
      "[0.0, 0.0, 1.0]\n",
      "Lambda using pseudo-inverse = [1.5, 3.0]\n",
      "Matches computed lambda: True\n",
      "Projection using pseudo-inverse = [1.5, 1.5, 3.0]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# --- Dot Product ---\n",
    "def dot_product(x, y):\n",
    "    \"\"\"\n",
    "    Compute the dot product of two vectors: x^T y\n",
    "    \"\"\"\n",
    "    return sum(xi * yi for xi, yi in zip(x, y))\n",
    "\n",
    "# --- Matrix-Vector Multiplication ---\n",
    "def matrix_vector_multiply(A, x):\n",
    "    \"\"\"\n",
    "    Multiply matrix A (n x m) by vector x (m x 1). Returns a vector.\n",
    "    \"\"\"\n",
    "    n = len(A)\n",
    "    result = [0.0] * n\n",
    "    for i in range(n):\n",
    "        result[i] = sum(A[i][j] * x[j] for j in range(len(x)))\n",
    "    return result\n",
    "\n",
    "# --- Matrix-Matrix Multiplication ---\n",
    "def matrix_multiply(A, B):\n",
    "    \"\"\"\n",
    "    Multiply matrices A (n x m) and B (m x p). Returns an (n x p) matrix.\n",
    "    \"\"\"\n",
    "    n, m = len(A), len(A[0])\n",
    "    p = len(B[0])\n",
    "    result = [[0.0 for _ in range(p)] for _ in range(n)]\n",
    "    for i in range(n):\n",
    "        for j in range(p):\n",
    "            result[i][j] = sum(A[i][k] * B[k][j] for k in range(m))\n",
    "    return result\n",
    "\n",
    "# --- Transpose of a Matrix ---\n",
    "def transpose(A):\n",
    "    \"\"\"\n",
    "    Compute the transpose of matrix A.\n",
    "    \"\"\"\n",
    "    n, m = len(A), len(A[0])\n",
    "    return [[A[j][i] for j in range(n)] for i in range(m)]\n",
    "\n",
    "# --- Inverse of a Matrix (for 2x2 matrices, for simplicity) ---\n",
    "def inverse_2x2(A):\n",
    "    \"\"\"\n",
    "    Compute the inverse of a 2x2 matrix using the determinant formula.\n",
    "    \"\"\"\n",
    "    if len(A) != 2 or len(A[0]) != 2:\n",
    "        raise ValueError(\"Matrix must be 2x2\")\n",
    "    \n",
    "    det = A[0][0] * A[1][1] - A[0][1] * A[1][0]\n",
    "    if abs(det) < 1e-10:\n",
    "        raise ValueError(\"Matrix is not invertible\")\n",
    "    \n",
    "    # Adjugate matrix\n",
    "    adj = [[A[1][1], -A[0][1]], [-A[1][0], A[0][0]]]\n",
    "    # Inverse = (1/det) * adj\n",
    "    return [[adj[i][j] / det for j in range(2)] for i in range(2)]\n",
    "\n",
    "# --- Projection onto a General Subspace (Equations 3.49–3.57) ---\n",
    "def project_onto_subspace(x, B):\n",
    "    \"\"\"\n",
    "    Project vector x onto the subspace spanned by the columns of B.\n",
    "    B is an (n x m) matrix whose columns are the basis vectors b1, ..., bm.\n",
    "    Returns the projection pi_U(x) and the coordinates lambda.\n",
    "    \"\"\"\n",
    "    # Step 1: Compute B^T (m x n)\n",
    "    Bt = transpose(B)\n",
    "    \n",
    "    # Step 2: Compute B^T B (m x m)\n",
    "    BtB = matrix_multiply(Bt, B)\n",
    "    \n",
    "    # Step 3: Compute B^T x (m x 1)\n",
    "    Btx = matrix_vector_multiply(Bt, x)\n",
    "    \n",
    "    # Step 4: Solve the normal equation B^T B lambda = B^T x (Equation 3.56)\n",
    "    # For simplicity, assume m <= 2 so we can use our 2x2 inverse\n",
    "    if len(BtB) > 2:\n",
    "        raise ValueError(\"This implementation only supports m <= 2 for simplicity\")\n",
    "    BtB_inv = inverse_2x2(BtB)\n",
    "    \n",
    "    # Step 5: Compute lambda = (B^T B)^(-1) B^T x (Equation 3.57)\n",
    "    lambda_coeffs = matrix_vector_multiply(BtB_inv, Btx)\n",
    "    \n",
    "    # Step 6: Compute pi_U(x) = B lambda (Equation 3.49)\n",
    "    pi_U_x = matrix_vector_multiply(B, lambda_coeffs)\n",
    "    \n",
    "    return pi_U_x, lambda_coeffs\n",
    "\n",
    "# --- Compute the Pseudo-Inverse ---\n",
    "def pseudo_inverse(B):\n",
    "    \"\"\"\n",
    "    Compute the pseudo-inverse of B: (B^T B)^(-1) B^T\n",
    "    \"\"\"\n",
    "    Bt = transpose(B)\n",
    "    BtB = matrix_multiply(Bt, B)\n",
    "    if len(BtB) > 2:\n",
    "        raise ValueError(\"This implementation only supports m <= 2 for simplicity\")\n",
    "    BtB_inv = inverse_2x2(BtB)\n",
    "    return matrix_multiply(BtB_inv, Bt)\n",
    "\n",
    "# --- Run the Implementation ---\n",
    "# Example: Project a vector in R^3 onto a 2D subspace\n",
    "print(\"Projection onto a General Subspace (Section 3.8.2):\")\n",
    "x = [1.0, 2.0, 3.0]\n",
    "B = [[1.0, 0.0], [1.0, 0.0], [0.0, 1.0]]  # Basis: [1, 1, 0], [0, 0, 1]\n",
    "print(f\"Vector x = {x}\")\n",
    "print(\"Basis matrix B (columns are b1, b2):\")\n",
    "for row in B:\n",
    "    print(row)\n",
    "\n",
    "# Compute the projection\n",
    "pi_U_x, lambda_coeffs = project_onto_subspace(x, B)\n",
    "print(f\"\\nCoordinates lambda = {[round(l, 3) for l in lambda_coeffs]}\")\n",
    "print(f\"Projection pi_U(x) = {[round(p, 3) for p in pi_U_x]}\")\n",
    "\n",
    "# Verify orthogonality: x - pi_U(x) should be orthogonal to each basis vector\n",
    "displacement = [xi - pi for xi, pi in zip(x, pi_U_x)]\n",
    "basis_vectors = [[B[i][j] for i in range(len(B))] for j in range(len(B[0]))]\n",
    "ortho_to_basis = all(abs(dot_product(displacement, b)) < 1e-10 for b in basis_vectors)\n",
    "print(f\"Displacement vector (x - pi_U(x)) = {[round(d, 3) for d in displacement]}\")\n",
    "print(f\"Displacement is orthogonal to basis vectors: {ortho_to_basis}\\n\")\n",
    "\n",
    "# Compute and use the pseudo-inverse\n",
    "print(\"Using Pseudo-Inverse (Equation 3.57):\")\n",
    "pinv_B = pseudo_inverse(B)\n",
    "print(\"Pseudo-inverse (B^T B)^(-1) B^T:\")\n",
    "for row in pinv_B:\n",
    "    print([round(val, 3) for val in row])\n",
    "\n",
    "# Compute lambda using pseudo-inverse\n",
    "lambda_pinv = matrix_vector_multiply(pinv_B, x)\n",
    "print(f\"Lambda using pseudo-inverse = {[round(l, 3) for l in lambda_pinv]}\")\n",
    "print(f\"Matches computed lambda: {all(abs(l1 - l2) < 1e-10 for l1, l2 in zip(lambda_coeffs, lambda_pinv))}\")\n",
    "\n",
    "# Compute projection using B lambda\n",
    "pi_U_x_pinv = matrix_vector_multiply(B, lambda_pinv)\n",
    "print(f\"Projection using pseudo-inverse = {[round(p, 3) for p in pi_U_x_pinv]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321ca372",
   "metadata": {},
   "source": [
    "$ B^\\top B $ to guarantee increased numerical stability and positive definiteness. This “ridge” can be rigorously derived using Bayesian inference. See Chapter 9 for details.\n",
    "\n",
    "2. **Find the projection $ \\pi_U(x) \\in U $**. We already established that $ \\pi_U(x) = B \\lambda $. Therefore, with (3.57)\n",
    "\n",
    "$$\n",
    "\\pi_U(x) = B (B^\\top B)^{-1} B^\\top x. \\tag{3.58}\n",
    "$$\n",
    "\n",
    "3. **Find the projection matrix $ P_\\pi $**. From (3.58), we can immediately see that the projection matrix that solves $ P_\\pi x = \\pi_U(x) $ must be\n",
    "\n",
    "$$\n",
    "P_\\pi = B (B^\\top B)^{-1} B^\\top. \\tag{3.59}\n",
    "$$\n",
    "\n",
    "**Remark.** The solution for projecting onto general subspaces includes the 1D case as a special case: If $ \\dim(U) = 1 $, then $ B^\\top B \\in \\mathbb{R} $ is a scalar and we can rewrite the projection matrix in (3.59)\n",
    "\n",
    "$$\n",
    "P_\\pi = B (B^\\top B)^{-1} B^\\top \\quad \\text{as} \\quad P_\\pi = \\frac{B B^\\top}{B^\\top B},\n",
    "$$\n",
    "\n",
    "which is exactly the projection matrix in (3.46). $ \\diamond $\n",
    "\n",
    "### Example 3.11 (Projection onto a Two-dimensional Subspace)\n",
    "\n",
    "For a subspace $ U = \\text{span}\\left( \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\end{bmatrix}, \\begin{bmatrix} 0 \\\\ 1 \\\\ 2 \\end{bmatrix} \\right) \\subseteq \\mathbb{R}^3 $ and $ x = \\begin{bmatrix} 6 \\\\ 0 \\\\ 0 \\end{bmatrix} \\in \\mathbb{R}^3 $, find the coordinates $ \\lambda $ of $ x $ in terms of the subspace $ U $, the projection point $ \\pi_U(x) $, and the projection matrix $ P_\\pi $.\n",
    "\n",
    "First, we see that the generating set of $ U $ is a basis (linear independence) and write the basis vectors of $ U $ into a matrix\n",
    "\n",
    "$$\n",
    "B = \\begin{bmatrix} 1 & 0 \\\\ 1 & 1 \\\\ 1 & 2 \\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "Second, we compute the matrix $ B^\\top B $ and the vector $ B^\\top x $ as\n",
    "\n",
    "$$\n",
    "B^\\top B = \\begin{bmatrix} 1 & 1 & 1 \\\\ 0 & 1 & 2 \\end{bmatrix} \\begin{bmatrix} 1 & 0 \\\\ 1 & 1 \\\\ 1 & 2 \\end{bmatrix} = \\begin{bmatrix} 3 & 3 \\\\ 3 & 5 \\end{bmatrix}, \\quad B^\\top x = \\begin{bmatrix} 1 & 1 & 1 \\\\ 0 & 1 & 2 \\end{bmatrix} \\begin{bmatrix} 6 \\\\ 0 \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} 6 \\\\ 0 \\end{bmatrix}. \\tag{3.60}\n",
    "$$\n",
    "\n",
    "Third, we solve the normal equation $ B^\\top B \\lambda = B^\\top x $ to find $ \\lambda $:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} 3 & 3 \\\\ 3 & 5 \\end{bmatrix} \\begin{bmatrix} \\lambda_1 \\\\ \\lambda_2 \\end{bmatrix} = \\begin{bmatrix} 6 \\\\ 0 \\end{bmatrix} \\quad \\iff \\quad \\lambda = \\begin{bmatrix} 5 \\\\ -3 \\end{bmatrix}. \\tag{3.61}\n",
    "$$\n",
    "\n",
    "Fourth, the projection $ \\pi_U(x) $ of $ x $ onto $ U $, i.e., into the column space of $ B $, can be directly computed via\n",
    "\n",
    "$$\n",
    "\\pi_U(x) = B \\lambda = \\begin{bmatrix} 5 \\\\ 2 \\\\ -1 \\end{bmatrix}. \\tag{3.62}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ca02990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Example 3.11 Results ---\n",
      "Matrix B:\n",
      " [[1 0]\n",
      " [1 1]\n",
      " [1 2]]\n",
      "\n",
      "Vector x:\n",
      " [6 0 0]\n",
      "\n",
      "Coordinates lambda:\n",
      " [ 4.99999433 -2.999996  ]\n",
      "\n",
      "Projection point pi_U(x):\n",
      " [ 4.99999433  1.99999833 -0.99999767]\n",
      "\n",
      "Projection Matrix P_pi:\n",
      " [[ 0.83333239  0.33333306 -0.16666628]\n",
      " [ 0.33333306  0.33333322  0.33333339]\n",
      " [-0.16666628  0.33333339  0.83333306]]\n",
      "\n",
      "--- Verification using the derived formulas ---\n",
      "\n",
      "B^T B (manual):\n",
      " [[3 3]\n",
      " [3 5]]\n",
      "B^T x (manual):\n",
      " [6 0]\n",
      "\n",
      "Lambda solved from B^T B lambda = B^T x (manual solve, no ridge in manual matrix):\n",
      " [ 5. -3.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def project_onto_subspace(B, x, ridge=1e-6):\n",
    "    \"\"\"\n",
    "    Projects a vector x onto the column space of matrix B.\n",
    "\n",
    "    This function calculates the projection using the normal equation,\n",
    "    B^T B lambda = B^T x, with an added ridge for numerical stability and\n",
    "    to guarantee positive definiteness of B^T B.\n",
    "\n",
    "    Args:\n",
    "        B (numpy.ndarray): The matrix whose column space defines the subspace.\n",
    "                           Shape (m, n), where m >= n.\n",
    "        x (numpy.ndarray): The vector to be projected. Shape (m,).\n",
    "        ridge (float): A small positive value added to the diagonal of B^T B\n",
    "                       to improve numerical stability and ensure positive definiteness.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - lambda_coords (numpy.ndarray): The coordinates of x in terms of the\n",
    "                                           basis vectors of the subspace U (columns of B).\n",
    "                                           Shape (n,).\n",
    "            - projection_point (numpy.ndarray): The projection of x onto the subspace U.\n",
    "                                              Shape (m,).\n",
    "            - projection_matrix (numpy.ndarray): The projection matrix P_pi.\n",
    "                                               Shape (m, m).\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure x is a 2D array (column vector) for consistent matrix operations\n",
    "    if x.ndim == 1:\n",
    "        x = x[:, np.newaxis]\n",
    "\n",
    "    # 1. Compute B^T B\n",
    "    BTB = B.T @ B\n",
    "\n",
    "    # Add a ridge to B^T B for numerical stability and positive definiteness\n",
    "    # This is equivalent to (B^T B + ridge * I)\n",
    "    BTB_ridge = BTB + ridge * np.eye(BTB.shape[0])\n",
    "\n",
    "    # 2. Compute B^T x\n",
    "    BTx = B.T @ x\n",
    "\n",
    "    # 3. Solve for lambda using the normal equation: (B^T B + ridge * I) lambda = B^T x\n",
    "    # np.linalg.solve is more numerically stable than computing the inverse directly\n",
    "    lambda_coords = np.linalg.solve(BTB_ridge, BTx)\n",
    "\n",
    "    # Convert lambda_coords to a 1D array if it's 2D with a single column\n",
    "    if lambda_coords.shape[1] == 1:\n",
    "        lambda_coords = lambda_coords.flatten()\n",
    "\n",
    "    # 4. Find the projection point pi_U(x) = B * lambda\n",
    "    projection_point = B @ lambda_coords\n",
    "\n",
    "    # 5. Find the projection matrix P_pi = B (B^T B)^-1 B^T\n",
    "    # We use the regularized inverse for the projection matrix as well\n",
    "    # However, if the goal is only to project, using the above lambda and B is sufficient.\n",
    "    # The direct computation of P_pi can also use the pseudo-inverse or a stabilized inverse.\n",
    "    # For this specific case of projection matrix, it's often more numerically stable to\n",
    "    # compute B @ np.linalg.inv(BTB_ridge) @ B.T if a projection matrix is explicitly needed.\n",
    "    # Here, we'll follow the formula directly using the regularized inverse of BTB.\n",
    "\n",
    "    # Compute the inverse of the regularized BTB\n",
    "    inv_BTB_ridge = np.linalg.inv(BTB_ridge)\n",
    "    projection_matrix = B @ inv_BTB_ridge @ B.T\n",
    "\n",
    "    return lambda_coords, projection_point, projection_matrix\n",
    "\n",
    "# Example usage from the problem description:\n",
    "# Subspace U spanned by basis vectors [1, 1, 1] and [0, 1, 2]\n",
    "B_example = np.array([[1, 0],\n",
    "                      [1, 1],\n",
    "                      [1, 2]])\n",
    "\n",
    "# Vector x to be projected\n",
    "x_example = np.array([6, 0, 0])\n",
    "\n",
    "# Perform the projection\n",
    "lambda_coords_example, projection_point_example, projection_matrix_example = project_onto_subspace(B_example, x_example)\n",
    "\n",
    "print(\"--- Example 3.11 Results ---\")\n",
    "print(\"Matrix B:\\n\", B_example)\n",
    "print(\"\\nVector x:\\n\", x_example)\n",
    "print(\"\\nCoordinates lambda:\\n\", lambda_coords_example)\n",
    "print(\"\\nProjection point pi_U(x):\\n\", projection_point_example)\n",
    "print(\"\\nProjection Matrix P_pi:\\n\", projection_matrix_example)\n",
    "\n",
    "print(\"\\n--- Verification using the derived formulas ---\")\n",
    "# Verify B^T B and B^T x manually from the problem\n",
    "BTB_manual = np.array([[3, 3],\n",
    "                       [3, 5]])\n",
    "BTx_manual = np.array([6, 0])\n",
    "print(\"\\nB^T B (manual):\\n\", BTB_manual)\n",
    "print(\"B^T x (manual):\\n\", BTx_manual)\n",
    "\n",
    "# Verify lambda by solving the system (using ridge for consistency with function)\n",
    "# Note: In the example, they solve it without a ridge. Our function applies a ridge.\n",
    "# For exact match to the example's lambda, a ridge of 0 would be needed,\n",
    "# but the problem states to guarantee increased numerical stability with a ridge.\n",
    "lambda_manual_solve = np.linalg.solve(BTB_manual, BTx_manual)\n",
    "print(\"\\nLambda solved from B^T B lambda = B^T x (manual solve, no ridge in manual matrix):\\n\", lambda_manual_solve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "184d99b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Example 3.11 Results (No NumPy) ---\n",
      "Matrix B:\n",
      " [[1, 0], [1, 1], [1, 2]]\n",
      "\n",
      "Vector x:\n",
      " [6, 0, 0]\n",
      "\n",
      "Coordinates lambda:\n",
      " [4.999994, -2.999996]\n",
      "\n",
      "Projection point pi_U(x):\n",
      " [4.999994, 1.999998, -0.999998]\n",
      "\n",
      "Projection Matrix P_pi:\n",
      "[0.833332, 0.333333, -0.166666]\n",
      "[0.333333, 0.333333, 0.333333]\n",
      "[-0.166666, 0.333333, 0.833333]\n",
      "\n",
      "--- Verification using the derived formulas (No NumPy) ---\n",
      "\n",
      "B^T B (manual):\n",
      " [[3, 3], [3, 5]]\n",
      "B^T x (manual):\n",
      " [6, 0]\n",
      "\n",
      "Lambda solved from B^T B lambda = B^T x (manual solve, no ridge in manual matrix):\n",
      " [5.0, -3.0]\n"
     ]
    }
   ],
   "source": [
    "def transpose_matrix(matrix):\n",
    "    \"\"\"\n",
    "    Computes the transpose of a matrix.\n",
    "    \"\"\"\n",
    "    if not matrix:\n",
    "        return []\n",
    "    rows = len(matrix)\n",
    "    cols = len(matrix[0])\n",
    "    transposed = [[0 for _ in range(rows)] for _ in range(cols)]\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            transposed[j][i] = matrix[i][j]\n",
    "    return transposed\n",
    "\n",
    "def multiply_matrices(matrix1, matrix2):\n",
    "    \"\"\"\n",
    "    Multiplies two matrices.\n",
    "    \"\"\"\n",
    "    if not matrix1 or not matrix2:\n",
    "        return []\n",
    "\n",
    "    rows1 = len(matrix1)\n",
    "    cols1 = len(matrix1[0])\n",
    "    rows2 = len(matrix2)\n",
    "    cols2 = len(matrix2[0])\n",
    "\n",
    "    if cols1 != rows2:\n",
    "        raise ValueError(\"Number of columns in the first matrix must match number of rows in the second matrix.\")\n",
    "\n",
    "    result = [[0 for _ in range(cols2)] for _ in range(rows1)]\n",
    "    for i in range(rows1):\n",
    "        for j in range(cols2):\n",
    "            for k in range(cols1):\n",
    "                result[i][j] += matrix1[i][k] * matrix2[k][j]\n",
    "    return result\n",
    "\n",
    "def multiply_matrix_vector(matrix, vector):\n",
    "    \"\"\"\n",
    "    Multiplies a matrix by a column vector.\n",
    "    \"\"\"\n",
    "    if not matrix or not vector:\n",
    "        return []\n",
    "\n",
    "    rows = len(matrix)\n",
    "    cols = len(matrix[0])\n",
    "    vec_len = len(vector)\n",
    "\n",
    "    if cols != vec_len:\n",
    "        raise ValueError(\"Number of columns in the matrix must match the length of the vector.\")\n",
    "\n",
    "    result = [0 for _ in range(rows)]\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            result[i] += matrix[i][j] * vector[j]\n",
    "    return result\n",
    "\n",
    "def identity_matrix(size):\n",
    "    \"\"\"\n",
    "    Creates an identity matrix of a given size.\n",
    "    \"\"\"\n",
    "    matrix = [[0 for _ in range(size)] for _ in range(size)]\n",
    "    for i in range(size):\n",
    "        matrix[i][i] = 1\n",
    "    return matrix\n",
    "\n",
    "def invert_2x2_matrix(matrix):\n",
    "    \"\"\"\n",
    "    Inverts a 2x2 matrix.\n",
    "    Formula: [[a, b], [c, d]]^-1 = (1 / (ad - bc)) * [[d, -b], [-c, a]]\n",
    "    \"\"\"\n",
    "    if len(matrix) != 2 or len(matrix[0]) != 2:\n",
    "        raise ValueError(\"Matrix must be 2x2 to use this inverse function.\")\n",
    "\n",
    "    a, b = matrix[0][0], matrix[0][1]\n",
    "    c, d = matrix[1][0], matrix[1][1]\n",
    "\n",
    "    determinant = a * d - b * c\n",
    "    if determinant == 0:\n",
    "        raise ValueError(\"Matrix is singular and cannot be inverted.\")\n",
    "\n",
    "    inv_det = 1.0 / determinant\n",
    "    inverted_matrix = [\n",
    "        [d * inv_det, -b * inv_det],\n",
    "        [-c * inv_det, a * inv_det]\n",
    "    ]\n",
    "    return inverted_matrix\n",
    "\n",
    "def solve_2x2_system(matrix, vector):\n",
    "    \"\"\"\n",
    "    Solves a 2x2 linear system Ax = b using matrix inversion.\n",
    "    \"\"\"\n",
    "    if len(matrix) != 2 or len(matrix[0]) != 2:\n",
    "        raise ValueError(\"Matrix must be 2x2 to use this solver.\")\n",
    "    if len(vector) != 2:\n",
    "        raise ValueError(\"Vector must have length 2.\")\n",
    "\n",
    "    inv_matrix = invert_2x2_matrix(matrix)\n",
    "    solution = multiply_matrix_vector(inv_matrix, vector)\n",
    "    return solution\n",
    "\n",
    "def project_onto_subspace_no_numpy(B, x, ridge=1e-6):\n",
    "    \"\"\"\n",
    "    Projects a vector x onto the column space of matrix B without NumPy.\n",
    "\n",
    "    This function calculates the projection using the normal equation,\n",
    "    B^T B lambda = B^T x, with an added ridge for numerical stability and\n",
    "    to guarantee positive definiteness of B^T B.\n",
    "\n",
    "    Args:\n",
    "        B (list of lists): The matrix whose column space defines the subspace.\n",
    "                           Shape (m, n), where m >= n.\n",
    "        x (list): The vector to be projected. Shape (m,).\n",
    "        ridge (float): A small positive value added to the diagonal of B^T B\n",
    "                       to improve numerical stability and ensure positive definiteness.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - lambda_coords (list): The coordinates of x in terms of the\n",
    "                                           basis vectors of the subspace U (columns of B).\n",
    "            - projection_point (list): The projection of x onto the subspace U.\n",
    "            - projection_matrix (list of lists): The projection matrix P_pi.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Compute B^T\n",
    "    BT = transpose_matrix(B)\n",
    "\n",
    "    # 2. Compute B^T B\n",
    "    BTB = multiply_matrices(BT, B)\n",
    "\n",
    "    # Add a ridge to B^T B for numerical stability and positive definiteness\n",
    "    # This is equivalent to (B^T B + ridge * I)\n",
    "    num_cols_B = len(B[0]) # n in (m, n)\n",
    "    identity = identity_matrix(num_cols_B)\n",
    "    BTB_ridge = [[BTB[i][j] + ridge * identity[i][j] for j in range(num_cols_B)] for i in range(num_cols_B)]\n",
    "\n",
    "    # 3. Compute B^T x\n",
    "    BTx = multiply_matrix_vector(BT, x)\n",
    "\n",
    "    # 4. Solve for lambda using the normal equation: (B^T B + ridge * I) lambda = B^T x\n",
    "    # We assume BTB_ridge is 2x2 based on the example. For larger matrices,\n",
    "    # a more general linear solver (e.g., Gaussian elimination) would be needed.\n",
    "    lambda_coords = solve_2x2_system(BTB_ridge, BTx)\n",
    "\n",
    "    # 5. Find the projection point pi_U(x) = B * lambda\n",
    "    # Convert lambda_coords to a list of lists (column vector) for matrix multiplication\n",
    "    lambda_col_vector = [[l] for l in lambda_coords]\n",
    "    projection_point_matrix_form = multiply_matrices(B, lambda_col_vector)\n",
    "    projection_point = [p[0] for p in projection_point_matrix_form] # Convert back to 1D list\n",
    "\n",
    "    # 6. Find the projection matrix P_pi = B (B^T B)^-1 B^T\n",
    "    inv_BTB_ridge = invert_2x2_matrix(BTB_ridge)\n",
    "    P_pi_temp = multiply_matrices(B, inv_BTB_ridge)\n",
    "    projection_matrix = multiply_matrices(P_pi_temp, BT)\n",
    "\n",
    "    return lambda_coords, projection_point, projection_matrix\n",
    "\n",
    "# Example usage from the problem description:\n",
    "# Subspace U spanned by basis vectors [1, 1, 1] and [0, 1, 2]\n",
    "B_example = [\n",
    "    [1, 0],\n",
    "    [1, 1],\n",
    "    [1, 2]\n",
    "]\n",
    "\n",
    "# Vector x to be projected\n",
    "x_example = [6, 0, 0]\n",
    "\n",
    "# Perform the projection\n",
    "lambda_coords_example, projection_point_example, projection_matrix_example = project_onto_subspace_no_numpy(B_example, x_example)\n",
    "\n",
    "print(\"--- Example 3.11 Results (No NumPy) ---\")\n",
    "print(\"Matrix B:\\n\", B_example)\n",
    "print(\"\\nVector x:\\n\", x_example)\n",
    "print(\"\\nCoordinates lambda:\\n\", [round(val, 6) for val in lambda_coords_example]) # Round for display\n",
    "print(\"\\nProjection point pi_U(x):\\n\", [round(val, 6) for val in projection_point_example]) # Round for display\n",
    "print(\"\\nProjection Matrix P_pi:\")\n",
    "for row in projection_matrix_example:\n",
    "    print([round(val, 6) for val in row])\n",
    "\n",
    "print(\"\\n--- Verification using the derived formulas (No NumPy) ---\")\n",
    "# Verify B^T B and B^T x manually from the problem\n",
    "BTB_manual = [\n",
    "    [3, 3],\n",
    "    [3, 5]\n",
    "]\n",
    "BTx_manual = [6, 0]\n",
    "print(\"\\nB^T B (manual):\\n\", BTB_manual)\n",
    "print(\"B^T x (manual):\\n\", BTx_manual)\n",
    "\n",
    "# Verify lambda by solving the system (using ridge for consistency with function)\n",
    "# Note: In the example, they solve it without a ridge. Our function applies a ridge.\n",
    "# For exact match to the example's lambda, a ridge of 0 would be needed,\n",
    "# but the problem states to guarantee increased numerical stability with a ridge.\n",
    "lambda_manual_solve = solve_2x2_system(BTB_manual, BTx_manual)\n",
    "print(\"\\nLambda solved from B^T B lambda = B^T x (manual solve, no ridge in manual matrix):\\n\", [round(val, 6) for val in lambda_manual_solve])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8a7321",
   "metadata": {},
   "source": [
    "This text covers several important concepts about orthogonal projections in linear algebra. Let me break down the key points:\n",
    "\n",
    "## Projection Error\n",
    "The projection error measures how far the original vector is from its projection onto subspace U. It's calculated as the norm of the difference vector:\n",
    "$$\\|x - \\pi_U(x)\\| = \\sqrt{6}$$\n",
    "\n",
    "This represents the \"distance\" between the original vector and the closest point in the subspace.\n",
    "\n",
    "## Projection Matrix\n",
    "The projection matrix P_π allows you to project any vector onto subspace U:\n",
    "$$P_\\pi = B(B^TB)^{-1}B^T$$\n",
    "\n",
    "Where B contains the basis vectors of U as columns. This matrix has the property that P_π² = P_π (idempotent).\n",
    "\n",
    "## Key Applications\n",
    "\n",
    "**Least Squares Solutions**: When a linear system Ax = b has no exact solution (overdetermined system), we can find the \"best\" approximate solution by projecting b onto the column space of A. This gives the least-squares solution that minimizes the error.\n",
    "\n",
    "**Principal Component Analysis**: The reconstruction error concept (equation 3.63) is fundamental to PCA, where we project data onto lower-dimensional subspaces while minimizing information loss.\n",
    "\n",
    "## Computational Simplification\n",
    "When the basis vectors form an orthonormal basis (ONB), the projection formula simplifies dramatically:\n",
    "$$\\pi_U(x) = BB^Tx$$\n",
    "\n",
    "This eliminates the need to compute $(B^TB)^{-1}$, making calculations much more efficient since $B^TB = I$ for orthonormal bases.\n",
    "\n",
    "The text emphasizes that while projections live in lower-dimensional subspaces, they're still represented as vectors in the original space R^n, though they can be efficiently represented using just the m coordinates relative to the subspace basis.\n",
    "\n",
    "Would you like me to elaborate on any of these concepts or work through a specific example?\n",
    "\n",
    "# Vector Projections and Reconstruction Error\n",
    "\n",
    "## Table of Contents\n",
    "1. [Introduction to Vector Projections](#introduction)\n",
    "2. [Understanding Projection and Reconstruction Error](#projection-error)\n",
    "3. [The Projection Matrix](#projection-matrix)\n",
    "4. [Verifying Projection Properties](#verification)\n",
    "5. [Least-Squares Solutions for Overdetermined Systems](#least-squares)\n",
    "6. [Orthonormal Basis Simplifications](#onb)\n",
    "7. [Applications and Examples](#applications)\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Introduction to Vector Projections {#introduction}\n",
    "\n",
    "When we project a vector $\\mathbf{x}$ onto a subspace $U$, we find the point in $U$ that is closest to $\\mathbf{x}$. This projection, denoted as $\\pi_U(\\mathbf{x})$, represents the \"shadow\" of $\\mathbf{x}$ onto the subspace $U$.\n",
    "\n",
    "**Key Concepts:**\n",
    "- The projection $\\pi_U(\\mathbf{x})$ lies entirely within the subspace $U$\n",
    "- The difference vector $\\mathbf{x} - \\pi_U(\\mathbf{x})$ is orthogonal to every vector in $U$\n",
    "- The projection minimizes the distance from $\\mathbf{x}$ to any point in $U$\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Understanding Projection and Reconstruction Error {#projection-error}\n",
    "\n",
    "### Definition\n",
    "\n",
    "The **projection error** (also called **reconstruction error**) quantifies how much of the original vector $\\mathbf{x}$ cannot be represented within the subspace $U$.\n",
    "\n",
    "$$\\text{Projection Error} = \\|\\mathbf{x} - \\pi_U(\\mathbf{x})\\|$$\n",
    "\n",
    "This error measures how accurately the original vector $\\mathbf{x}$ can be \"reconstructed\" or approximated by its projection onto the subspace $U$.\n",
    "\n",
    "### Geometric Interpretation\n",
    "\n",
    "- **Small error**: The subspace $U$ captures most of the information in $\\mathbf{x}$\n",
    "- **Large error**: Much of $\\mathbf{x}$ lies outside the subspace $U$\n",
    "- **Zero error**: $\\mathbf{x}$ already lies in $U$\n",
    "\n",
    "### Example Calculation\n",
    "\n",
    "Consider a vector $\\mathbf{x} = \\begin{bmatrix} 6 \\\\ 0 \\\\ 0 \\end{bmatrix}$ and its projection $\\pi_U(\\mathbf{x}) = \\begin{bmatrix} 5 \\\\ 2 \\\\ -1 \\end{bmatrix}$.\n",
    "\n",
    "**Step 1:** Calculate the difference vector\n",
    "$$\\mathbf{x} - \\pi_U(\\mathbf{x}) = \\begin{bmatrix} 6 \\\\ 0 \\\\ 0 \\end{bmatrix} - \\begin{bmatrix} 5 \\\\ 2 \\\\ -1 \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ -2 \\\\ 1 \\end{bmatrix}$$\n",
    "\n",
    "**Step 2:** Compute the norm\n",
    "$$\\|\\mathbf{x} - \\pi_U(\\mathbf{x})\\| = \\left\\|\\begin{bmatrix} 1 \\\\ -2 \\\\ 1 \\end{bmatrix}\\right\\| = \\sqrt{1^2 + (-2)^2 + 1^2} = \\sqrt{1 + 4 + 1} = \\sqrt{6}$$\n",
    "\n",
    "Therefore, the projection error is $\\sqrt{6} \\approx 2.45$.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. The Projection Matrix {#projection-matrix}\n",
    "\n",
    "### General Formula\n",
    "\n",
    "The **projection matrix** $P_\\pi$ is a linear transformation that projects any vector onto the subspace $U$. If $B$ is a matrix whose columns form a basis for $U$, then:\n",
    "\n",
    "$$P_\\pi = B(B^T B)^{-1} B^T \\quad \\text{(3.59)}$$\n",
    "\n",
    "### Properties of Projection Matrices\n",
    "\n",
    "1. **Linearity**: $P_\\pi(\\alpha\\mathbf{x} + \\beta\\mathbf{y}) = \\alpha P_\\pi\\mathbf{x} + \\beta P_\\pi\\mathbf{y}$\n",
    "2. **Idempotence**: $P_\\pi^2 = P_\\pi$\n",
    "3. **Symmetry**: $P_\\pi^T = P_\\pi$\n",
    "\n",
    "### Example\n",
    "\n",
    "For a basis matrix $B = \\begin{bmatrix} 1 & 0 \\\\ 1 & 1 \\\\ 1 & 2 \\end{bmatrix}$, the projection matrix is:\n",
    "\n",
    "$$P_\\pi = \\frac{1}{6} \\begin{bmatrix} 5 & 2 & -1 \\\\ 2 & 2 & 2 \\\\ -1 & 2 & 5 \\end{bmatrix} \\quad \\text{(3.64)}$$\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Verifying Projection Properties {#verification}\n",
    "\n",
    "### Property 1: Orthogonality of Displacement Vector\n",
    "\n",
    "The displacement vector $\\mathbf{x} - \\pi_U(\\mathbf{x})$ must be orthogonal to every basis vector of $U$:\n",
    "\n",
    "$$(\\mathbf{x} - \\pi_U(\\mathbf{x}))^T B = \\mathbf{0}^T$$\n",
    "\n",
    "**Verification:**\n",
    "$$(\\mathbf{x} - \\pi_U(\\mathbf{x}))^T B = \\begin{bmatrix} 1 & -2 & 1 \\end{bmatrix} \\begin{bmatrix} 1 & 0 \\\\ 1 & 1 \\\\ 1 & 2 \\end{bmatrix} = \\begin{bmatrix} 0 & 0 \\end{bmatrix}$$\n",
    "\n",
    "✓ The displacement vector is orthogonal to the column space of $B$.\n",
    "\n",
    "### Property 2: Idempotence ($P_\\pi = P_\\pi^2$)\n",
    "\n",
    "A projection matrix applied multiple times should produce the same result:\n",
    "\n",
    "$$P_\\pi^2 = \\left(\\frac{1}{6} \\begin{bmatrix} 5 & 2 & -1 \\\\ 2 & 2 & 2 \\\\ -1 & 2 & 5 \\end{bmatrix}\\right)^2 = \\frac{1}{36} \\begin{bmatrix} 30 & 12 & -6 \\\\ 12 & 12 & 12 \\\\ -6 & 12 & 30 \\end{bmatrix} = \\frac{1}{6} \\begin{bmatrix} 5 & 2 & -1 \\\\ 2 & 2 & 2 \\\\ -1 & 2 & 5 \\end{bmatrix} = P_\\pi$$\n",
    "\n",
    "✓ The projection matrix is idempotent.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Least-Squares Solutions for Overdetermined Systems {#least-squares}\n",
    "\n",
    "### The Problem\n",
    "\n",
    "Consider a linear system $A\\mathbf{x} = \\mathbf{b}$ that has **no exact solution**. This occurs when $\\mathbf{b}$ does not lie in the column space of $A$.\n",
    "\n",
    "### The Solution Approach\n",
    "\n",
    "Instead of finding an exact solution, we find the **least-squares solution** that minimizes:\n",
    "\n",
    "$$\\|A\\mathbf{x} - \\mathbf{b}\\|^2$$\n",
    "\n",
    "### Mathematical Derivation\n",
    "\n",
    "1. **Goal**: Find $\\mathbf{x}$ such that $A\\mathbf{x}$ is as close as possible to $\\mathbf{b}$\n",
    "2. **Key Insight**: The closest point in the column space of $A$ to $\\mathbf{b}$ is the orthogonal projection of $\\mathbf{b}$ onto the column space\n",
    "3. **Projection**: $\\pi_U(\\mathbf{b}) = A(A^T A)^{-1} A^T \\mathbf{b}$\n",
    "4. **Equation**: $A\\mathbf{x} = \\pi_U(\\mathbf{b})$\n",
    "\n",
    "### Normal Equations\n",
    "\n",
    "Setting $A\\mathbf{x} = A(A^T A)^{-1} A^T \\mathbf{b}$ and multiplying both sides by $A^T$:\n",
    "\n",
    "$$A^T A\\mathbf{x} = A^T \\mathbf{b}$$\n",
    "\n",
    "This system, called the **normal equations**, always has a solution when $A^T A$ is invertible.\n",
    "\n",
    "### Applications\n",
    "\n",
    "- **Linear Regression**: Fitting a line to data points\n",
    "- **Data Fitting**: Approximating functions with polynomials\n",
    "- **Signal Processing**: Noise reduction and filtering\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Orthonormal Basis Simplifications {#onb}\n",
    "\n",
    "### Definition\n",
    "\n",
    "An **orthonormal basis (ONB)** consists of vectors that are:\n",
    "1. **Orthogonal**: $\\mathbf{b}_i^T \\mathbf{b}_j = 0$ for $i \\neq j$\n",
    "2. **Normalized**: $\\|\\mathbf{b}_i\\| = 1$ for all $i$\n",
    "\n",
    "### Key Property\n",
    "\n",
    "If $B$ has orthonormal columns, then:\n",
    "$$B^T B = I$$\n",
    "\n",
    "### Simplified Formulas\n",
    "\n",
    "When using an ONB, the projection formulas become much simpler:\n",
    "\n",
    "#### Projection Formula\n",
    "$$\\pi_U(\\mathbf{x}) = B(B^T B)^{-1} B^T \\mathbf{x} = B \\cdot I^{-1} \\cdot B^T \\mathbf{x} = BB^T \\mathbf{x} \\quad \\text{(3.65)}$$\n",
    "\n",
    "#### Coordinate Calculation\n",
    "$$\\boldsymbol{\\lambda} = (B^T B)^{-1} B^T \\mathbf{x} = I^{-1} B^T \\mathbf{x} = B^T \\mathbf{x} \\quad \\text{(3.66)}$$\n",
    "\n",
    "### Computational Advantages\n",
    "\n",
    "1. **No Matrix Inversion**: Eliminates the need to compute $(B^T B)^{-1}$\n",
    "2. **Numerical Stability**: Avoids potential numerical issues with matrix inversion\n",
    "3. **Efficiency**: Faster computation, especially for large matrices\n",
    "4. **Memory**: Reduced memory requirements\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Applications and Examples {#applications}\n",
    "\n",
    "### Principal Component Analysis (PCA)\n",
    "\n",
    "The reconstruction error concept is fundamental to PCA:\n",
    "\n",
    "- **Goal**: Find the best $k$-dimensional subspace to represent $n$-dimensional data\n",
    "- **Criterion**: Minimize the sum of squared reconstruction errors\n",
    "- **Process**: Project data onto the subspace spanned by the first $k$ principal components\n",
    "\n",
    "### Example: 2D Data Projection\n",
    "\n",
    "Consider projecting 3D data points onto a 2D plane to reduce dimensionality while preserving as much information as possible.\n",
    "\n",
    "**Mathematical Framework:**\n",
    "1. Center the data: $\\mathbf{x}_{\\text{centered}} = \\mathbf{x} - \\boldsymbol{\\mu}$\n",
    "2. Find principal components (eigenvectors of covariance matrix)\n",
    "3. Project onto the top $k$ components: $\\mathbf{x}_{\\text{projected}} = P_k \\mathbf{x}_{\\text{centered}}$\n",
    "4. Measure reconstruction error: $\\|\\mathbf{x}_{\\text{centered}} - \\mathbf{x}_{\\text{projected}}\\|$\n",
    "\n",
    "### Linear Regression as Projection\n",
    "\n",
    "In linear regression, we're finding the projection of the response vector $\\mathbf{y}$ onto the column space of the design matrix $X$:\n",
    "\n",
    "$$\\hat{\\mathbf{y}} = X(X^T X)^{-1} X^T \\mathbf{y} = P_X \\mathbf{y}$$\n",
    "\n",
    "The residuals $\\mathbf{y} - \\hat{\\mathbf{y}}$ represent the projection error.\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "**Key Takeaways:**\n",
    "\n",
    "1. **Projection Error** quantifies how much information is lost when projecting onto a subspace\n",
    "2. **Projection Matrices** provide a systematic way to compute projections for any vector\n",
    "3. **Least-Squares Solutions** use projections to solve overdetermined systems optimally\n",
    "4. **Orthonormal Bases** significantly simplify computations and improve numerical stability\n",
    "5. **Applications** span from data analysis (PCA) to optimization (linear regression)\n",
    "\n",
    "The interplay between geometric intuition (projections as \"shadows\") and algebraic computation (matrix operations) makes vector projections a powerful tool in linear algebra and its applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "174343a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 COMPREHENSIVE VECTOR PROJECTION DEMONSTRATION\n",
      "============================================================\n",
      "📊 EXAMPLE 1: Basic Projection\n",
      "------------------------------\n",
      "=== VECTOR PROJECTION CALCULATION ===\n",
      "Original vector x:\n",
      "[6 0 0]\n",
      "Basis matrix B:\n",
      "[[1 0]\n",
      " [1 1]\n",
      " [1 2]]\n",
      "\n",
      "Step 1 - B^T:\n",
      "[[1 1 1]\n",
      " [0 1 2]]\n",
      "Step 2 - B^T * B:\n",
      "[[3 3]\n",
      " [3 5]]\n",
      "Step 3 - (B^T * B)^(-1):\n",
      "[[ 0.83333333 -0.5       ]\n",
      " [-0.5         0.5       ]]\n",
      "Step 4 - B^T * x:\n",
      "[6 0]\n",
      "Step 5 - Coordinates λ:\n",
      "[ 5. -3.]\n",
      "Step 6 - Projection π_U(x):\n",
      "[ 5.  2. -1.]\n",
      "Step 7 - Error vector (x - π_U(x)):\n",
      "[ 1. -2.  1.]\n",
      "Step 7 - Projection error ||x - π_U(x)||: 2.449490\n",
      "Step 8 - Projection matrix P:\n",
      "[[ 0.83333333  0.33333333 -0.16666667]\n",
      " [ 0.33333333  0.33333333  0.33333333]\n",
      " [-0.16666667  0.33333333  0.83333333]]\n",
      "\n",
      "🔍 VERIFICATION:\n",
      "---------------\n",
      "=== VERIFICATION OF PROJECTION PROPERTIES ===\n",
      "Property 1 - Orthogonality check B^T * (x - π_U(x)):\n",
      "[0. 0.]\n",
      "Is orthogonal (should be ~0): True\n",
      "Property 2 - P^2 - P (should be ~0):\n",
      "1.11e-16\n",
      "Is idempotent: True\n",
      "Property 3 - P - P^T (should be ~0):\n",
      "0.00e+00\n",
      "Is symmetric: True\n",
      "\n",
      "\n",
      "============================================================\n",
      "📊 EXAMPLE 2: Orthonormal Basis\n",
      "------------------------------\n",
      "=== GRAM-SCHMIDT ORTHOGONALIZATION ===\n",
      "Input vectors:\n",
      "[[1 0]\n",
      " [1 1]\n",
      " [1 2]]\n",
      "\n",
      "Processing vector 1: [1 1 1]\n",
      "  Normalized: [0.57735027 0.57735027 0.57735027]\n",
      "\n",
      "Processing vector 2: [0 1 2]\n",
      "  Subtract projection onto q_1: [1. 1. 1.]\n",
      "  Normalized: [-7.07106781e-01 -1.57009246e-16  7.07106781e-01]\n",
      "\n",
      "Orthonormal basis matrix:\n",
      "[[ 5.77350269e-01 -7.07106781e-01]\n",
      " [ 5.77350269e-01 -1.57009246e-16]\n",
      " [ 5.77350269e-01  7.07106781e-01]]\n",
      "Verification Q^T * Q:\n",
      "[[ 1.0000000e+00 -3.2385832e-16]\n",
      " [-3.2385832e-16  1.0000000e+00]]\n",
      "\n",
      "=== PROJECTION WITH ORTHONORMAL BASIS ===\n",
      "Orthonormal basis B:\n",
      "[[ 5.77350269e-01 -7.07106781e-01]\n",
      " [ 5.77350269e-01 -1.57009246e-16]\n",
      " [ 5.77350269e-01  7.07106781e-01]]\n",
      "B^T * B (should be identity):\n",
      "[[ 1.0000000e+00 -3.2385832e-16]\n",
      " [-3.2385832e-16  1.0000000e+00]]\n",
      "Is orthonormal: True\n",
      "Coordinates λ = B^T * x:\n",
      "[ 3.46410162 -4.24264069]\n",
      "Projection π_U(x) = B * B^T * x:\n",
      "[ 5.  2. -1.]\n",
      "Projection error: 2.449490\n",
      "\n",
      "🔍 Comparison:\n",
      "Regular projection error: 2.449490\n",
      "ONB projection error: 2.449490\n",
      "Difference: 4.44e-16\n",
      "\n",
      "============================================================\n",
      "📊 EXAMPLE 3: Least Squares Solution\n",
      "------------------------------\n",
      "=== LEAST SQUARES SOLUTION ===\n",
      "Matrix A:\n",
      "[[1 2]\n",
      " [2 1]\n",
      " [1 1]\n",
      " [0 1]]\n",
      "Vector b:\n",
      "[1 2 1 1]\n",
      "System dimensions: 4 equations, 2 unknowns\n",
      "System is overdetermined\n",
      "A^T * A:\n",
      "[[6 5]\n",
      " [5 7]]\n",
      "A^T * b:\n",
      "[6 6]\n",
      "Least squares solution x:\n",
      "[0.70588235 0.35294118]\n",
      "Residual (b - Ax):\n",
      "[-0.41176471  0.23529412 -0.05882353  0.64705882]\n",
      "Residual norm: 0.804400\n",
      "Projection of b onto col(A):\n",
      "[1.41176471 1.76470588 1.05882353 0.35294118]\n",
      "\n",
      "\n",
      "============================================================\n",
      "📊 EXAMPLE 4: 2D Visualization\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 ADVANCED EXAMPLES\n",
      "============================================================\n",
      "📊 EXAMPLE A: High-dimensional space\n",
      "-----------------------------------\n",
      "Original vector dimension: 5\n",
      "Subspace dimension: 2\n",
      "Projection error: 1.634130\n",
      "Information retained: 12.7%\n",
      "\n",
      "📊 EXAMPLE B: Nearly dependent basis\n",
      "-----------------------------------\n",
      "Error: B^T * B is singular - columns of B are linearly dependent\n",
      "\n",
      "✅ All demonstrations completed successfully!\n",
      "📝 This implementation covers:\n",
      "   • Vector projections with general basis\n",
      "   • Orthonormal basis simplifications\n",
      "   • Projection error calculations\n",
      "   • Least squares solutions\n",
      "   • Property verification\n",
      "   • Gram-Schmidt orthogonalization\n",
      "   • 2D visualizations\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class VectorProjection:\n",
    "    \"\"\"\n",
    "    A comprehensive class for vector projections and related operations.\n",
    "    Implements all concepts from the mathematical theory.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.projection_matrix = None\n",
    "        self.basis_matrix = None\n",
    "        \n",
    "    def project_vector(self, x, B, verbose=True):\n",
    "        \"\"\"\n",
    "        Project vector x onto subspace spanned by columns of B.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        x : array-like\n",
    "            Vector to be projected (n x 1)\n",
    "        B : array-like  \n",
    "            Basis matrix (n x m) where columns span the subspace\n",
    "        verbose : bool\n",
    "            Whether to print detailed calculations\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        dict : Contains all projection results\n",
    "        \"\"\"\n",
    "        x = np.array(x).reshape(-1, 1) if np.array(x).ndim == 1 else np.array(x)\n",
    "        B = np.array(B)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"=== VECTOR PROJECTION CALCULATION ===\")\n",
    "            print(f\"Original vector x:\\n{x.flatten()}\")\n",
    "            print(f\"Basis matrix B:\\n{B}\")\n",
    "            print()\n",
    "        \n",
    "        # Step 1: Calculate B^T\n",
    "        B_T = B.T\n",
    "        if verbose:\n",
    "            print(f\"Step 1 - B^T:\\n{B_T}\")\n",
    "        \n",
    "        # Step 2: Calculate B^T * B  \n",
    "        BTB = B_T @ B\n",
    "        if verbose:\n",
    "            print(f\"Step 2 - B^T * B:\\n{BTB}\")\n",
    "        \n",
    "        # Step 3: Calculate (B^T * B)^(-1)\n",
    "        try:\n",
    "            BTB_inv = np.linalg.inv(BTB)\n",
    "            if verbose:\n",
    "                print(f\"Step 3 - (B^T * B)^(-1):\\n{BTB_inv}\")\n",
    "        except np.linalg.LinAlgError:\n",
    "            raise ValueError(\"B^T * B is singular - columns of B are linearly dependent\")\n",
    "        \n",
    "        # Step 4: Calculate B^T * x\n",
    "        BTx = B_T @ x\n",
    "        if verbose:\n",
    "            print(f\"Step 4 - B^T * x:\\n{BTx.flatten()}\")\n",
    "        \n",
    "        # Step 5: Calculate coordinates λ = (B^T * B)^(-1) * B^T * x\n",
    "        lambda_coords = BTB_inv @ BTx\n",
    "        if verbose:\n",
    "            print(f\"Step 5 - Coordinates λ:\\n{lambda_coords.flatten()}\")\n",
    "        \n",
    "        # Step 6: Calculate projection π_U(x) = B * λ\n",
    "        projection = B @ lambda_coords\n",
    "        if verbose:\n",
    "            print(f\"Step 6 - Projection π_U(x):\\n{projection.flatten()}\")\n",
    "        \n",
    "        # Step 7: Calculate projection error\n",
    "        error_vector = x - projection\n",
    "        projection_error = np.linalg.norm(error_vector)\n",
    "        if verbose:\n",
    "            print(f\"Step 7 - Error vector (x - π_U(x)):\\n{error_vector.flatten()}\")\n",
    "            print(f\"Step 7 - Projection error ||x - π_U(x)||: {projection_error:.6f}\")\n",
    "        \n",
    "        # Step 8: Calculate projection matrix P = B(B^T B)^(-1)B^T\n",
    "        projection_matrix = B @ BTB_inv @ B_T\n",
    "        self.projection_matrix = projection_matrix\n",
    "        self.basis_matrix = B\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Step 8 - Projection matrix P:\\n{projection_matrix}\")\n",
    "            print()\n",
    "        \n",
    "        return {\n",
    "            'original_vector': x.flatten(),\n",
    "            'projection': projection.flatten(),\n",
    "            'error_vector': error_vector.flatten(),\n",
    "            'projection_error': projection_error,\n",
    "            'coordinates': lambda_coords.flatten(),\n",
    "            'projection_matrix': projection_matrix,\n",
    "            'B_transpose': B_T,\n",
    "            'BTB': BTB,\n",
    "            'BTB_inverse': BTB_inv\n",
    "        }\n",
    "    \n",
    "    def verify_projection_properties(self, x, result, verbose=True):\n",
    "        \"\"\"\n",
    "        Verify that the projection satisfies required mathematical properties.\n",
    "        \"\"\"\n",
    "        if verbose:\n",
    "            print(\"=== VERIFICATION OF PROJECTION PROPERTIES ===\")\n",
    "        \n",
    "        B = self.basis_matrix\n",
    "        P = self.projection_matrix\n",
    "        error_vec = result['error_vector'].reshape(-1, 1)\n",
    "        \n",
    "        # Property 1: Error vector orthogonal to subspace\n",
    "        orthogonality_check = B.T @ error_vec\n",
    "        is_orthogonal = np.allclose(orthogonality_check, 0, atol=1e-10)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Property 1 - Orthogonality check B^T * (x - π_U(x)):\\n{orthogonality_check.flatten()}\")\n",
    "            print(f\"Is orthogonal (should be ~0): {is_orthogonal}\")\n",
    "        \n",
    "        # Property 2: Projection matrix idempotency P^2 = P\n",
    "        P_squared = P @ P\n",
    "        is_idempotent = np.allclose(P, P_squared, atol=1e-10)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Property 2 - P^2 - P (should be ~0):\\n{np.max(np.abs(P_squared - P)):.2e}\")\n",
    "            print(f\"Is idempotent: {is_idempotent}\")\n",
    "        \n",
    "        # Property 3: Projection matrix symmetry P^T = P\n",
    "        is_symmetric = np.allclose(P, P.T, atol=1e-10)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Property 3 - P - P^T (should be ~0):\\n{np.max(np.abs(P - P.T)):.2e}\")\n",
    "            print(f\"Is symmetric: {is_symmetric}\")\n",
    "            print()\n",
    "        \n",
    "        return {\n",
    "            'is_orthogonal': is_orthogonal,\n",
    "            'is_idempotent': is_idempotent, \n",
    "            'is_symmetric': is_symmetric,\n",
    "            'orthogonality_residual': np.max(np.abs(orthogonality_check)),\n",
    "            'idempotency_residual': np.max(np.abs(P_squared - P)),\n",
    "            'symmetry_residual': np.max(np.abs(P - P.T))\n",
    "        }\n",
    "    \n",
    "    def project_with_onb(self, x, B_onb, verbose=True):\n",
    "        \"\"\"\n",
    "        Project using orthonormal basis - simplified calculations.\n",
    "        \"\"\"\n",
    "        x = np.array(x).reshape(-1, 1) if np.array(x).ndim == 1 else np.array(x)\n",
    "        B_onb = np.array(B_onb)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"=== PROJECTION WITH ORTHONORMAL BASIS ===\")\n",
    "            print(f\"Orthonormal basis B:\\n{B_onb}\")\n",
    "        \n",
    "        # Verify orthonormality\n",
    "        BTB = B_onb.T @ B_onb\n",
    "        is_onb = np.allclose(BTB, np.eye(BTB.shape[0]), atol=1e-10)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"B^T * B (should be identity):\\n{BTB}\")\n",
    "            print(f\"Is orthonormal: {is_onb}\")\n",
    "        \n",
    "        if not is_onb:\n",
    "            print(\"Warning: Basis is not orthonormal!\")\n",
    "        \n",
    "        # Simplified formulas for ONB\n",
    "        # Coordinates: λ = B^T * x\n",
    "        lambda_coords = B_onb.T @ x\n",
    "        \n",
    "        # Projection: π_U(x) = B * B^T * x\n",
    "        projection = B_onb @ B_onb.T @ x\n",
    "        \n",
    "        # Error\n",
    "        error_vector = x - projection\n",
    "        projection_error = np.linalg.norm(error_vector)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Coordinates λ = B^T * x:\\n{lambda_coords.flatten()}\")\n",
    "            print(f\"Projection π_U(x) = B * B^T * x:\\n{projection.flatten()}\")\n",
    "            print(f\"Projection error: {projection_error:.6f}\")\n",
    "            print()\n",
    "        \n",
    "        return {\n",
    "            'projection': projection.flatten(),\n",
    "            'coordinates': lambda_coords.flatten(),\n",
    "            'projection_error': projection_error,\n",
    "            'is_orthonormal': is_onb\n",
    "        }\n",
    "    \n",
    "    def solve_least_squares(self, A, b, verbose=True):\n",
    "        \"\"\"\n",
    "        Solve overdetermined system Ax = b using least squares.\n",
    "        \"\"\"\n",
    "        A = np.array(A)\n",
    "        b = np.array(b).reshape(-1, 1) if np.array(b).ndim == 1 else np.array(b)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"=== LEAST SQUARES SOLUTION ===\")\n",
    "            print(f\"Matrix A:\\n{A}\")\n",
    "            print(f\"Vector b:\\n{b.flatten()}\")\n",
    "        \n",
    "        # Check if system is overdetermined\n",
    "        m, n = A.shape\n",
    "        if verbose:\n",
    "            print(f\"System dimensions: {m} equations, {n} unknowns\")\n",
    "            print(f\"System is {'overdetermined' if m > n else 'square/underdetermined'}\")\n",
    "        \n",
    "        # Normal equations: A^T * A * x = A^T * b\n",
    "        ATA = A.T @ A\n",
    "        ATb = A.T @ b\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"A^T * A:\\n{ATA}\")\n",
    "            print(f\"A^T * b:\\n{ATb.flatten()}\")\n",
    "        \n",
    "        # Solve normal equations\n",
    "        try:\n",
    "            x_ls = np.linalg.solve(ATA, ATb)\n",
    "            if verbose:\n",
    "                print(f\"Least squares solution x:\\n{x_ls.flatten()}\")\n",
    "        except np.linalg.LinAlgError:\n",
    "            raise ValueError(\"A^T * A is singular\")\n",
    "        \n",
    "        # Calculate residual\n",
    "        residual = b - A @ x_ls\n",
    "        residual_norm = np.linalg.norm(residual)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Residual (b - Ax):\\n{residual.flatten()}\")\n",
    "            print(f\"Residual norm: {residual_norm:.6f}\")\n",
    "        \n",
    "        # Projection of b onto column space of A\n",
    "        projection_matrix = A @ np.linalg.inv(ATA) @ A.T\n",
    "        b_projected = projection_matrix @ b\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Projection of b onto col(A):\\n{b_projected.flatten()}\")\n",
    "            print()\n",
    "        \n",
    "        return {\n",
    "            'solution': x_ls.flatten(),\n",
    "            'residual': residual.flatten(),\n",
    "            'residual_norm': residual_norm,\n",
    "            'b_projected': b_projected.flatten(),\n",
    "            'projection_matrix': projection_matrix\n",
    "        }\n",
    "    \n",
    "    def gram_schmidt(self, vectors, verbose=True):\n",
    "        \"\"\"\n",
    "        Convert basis to orthonormal basis using Gram-Schmidt process.\n",
    "        \"\"\"\n",
    "        vectors = np.array(vectors).T if np.array(vectors).shape[0] < np.array(vectors).shape[1] else np.array(vectors)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"=== GRAM-SCHMIDT ORTHOGONALIZATION ===\")\n",
    "            print(f\"Input vectors:\\n{vectors}\")\n",
    "        \n",
    "        orthonormal = []\n",
    "        \n",
    "        for i, v in enumerate(vectors.T):\n",
    "            if verbose:\n",
    "                print(f\"\\nProcessing vector {i+1}: {v}\")\n",
    "            \n",
    "            # Subtract projections onto previous orthonormal vectors\n",
    "            u = v.copy()\n",
    "            for j, q in enumerate(orthonormal):\n",
    "                proj = np.dot(v, q) * q\n",
    "                u = u - proj\n",
    "                if verbose:\n",
    "                    print(f\"  Subtract projection onto q_{j+1}: {proj}\")\n",
    "            \n",
    "            # Normalize\n",
    "            norm = np.linalg.norm(u)\n",
    "            if norm < 1e-10:\n",
    "                if verbose:\n",
    "                    print(f\"  Vector {i+1} is linearly dependent, skipping\")\n",
    "                continue\n",
    "                \n",
    "            q = u / norm\n",
    "            orthonormal.append(q)\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"  Normalized: {q}\")\n",
    "        \n",
    "        onb_matrix = np.array(orthonormal).T\n",
    "        if verbose:\n",
    "            print(f\"\\nOrthonormal basis matrix:\\n{onb_matrix}\")\n",
    "            \n",
    "            # Verify orthonormality\n",
    "            check = onb_matrix.T @ onb_matrix\n",
    "            print(f\"Verification Q^T * Q:\\n{check}\")\n",
    "            print()\n",
    "        \n",
    "        return onb_matrix\n",
    "    \n",
    "    def visualize_projection_2d(self, x, B, title=\"2D Projection Visualization\"):\n",
    "        \"\"\"\n",
    "        Visualize 2D projection (works for 2D vectors projected onto 1D subspace).\n",
    "        \"\"\"\n",
    "        if len(x) != 2 or B.shape[0] != 2:\n",
    "            print(\"Visualization only available for 2D vectors\")\n",
    "            return\n",
    "        \n",
    "        result = self.project_vector(x, B, verbose=False)\n",
    "        proj = result['projection']\n",
    "        \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        \n",
    "        # Plot basis vectors\n",
    "        for i, basis_vec in enumerate(B.T):\n",
    "            plt.arrow(0, 0, basis_vec[0], basis_vec[1], \n",
    "                     head_width=0.1, head_length=0.1, fc='blue', ec='blue', \n",
    "                     label=f'Basis {i+1}' if i == 0 else \"\")\n",
    "        \n",
    "        # Plot original vector\n",
    "        plt.arrow(0, 0, x[0], x[1], \n",
    "                 head_width=0.1, head_length=0.1, fc='red', ec='red', \n",
    "                 label='Original vector x', linewidth=2)\n",
    "        \n",
    "        # Plot projection\n",
    "        plt.arrow(0, 0, proj[0], proj[1], \n",
    "                 head_width=0.1, head_length=0.1, fc='green', ec='green', \n",
    "                 label='Projection π_U(x)', linewidth=2)\n",
    "        \n",
    "        # Plot error vector\n",
    "        plt.arrow(proj[0], proj[1], x[0]-proj[0], x[1]-proj[1], \n",
    "                 head_width=0.1, head_length=0.1, fc='orange', ec='orange', \n",
    "                 label='Error vector', linestyle='--')\n",
    "        \n",
    "        # Plot subspace line (for 1D subspace)\n",
    "        if B.shape[1] == 1:\n",
    "            t = np.linspace(-3, 3, 100)\n",
    "            subspace_line = t[:, np.newaxis] * B.T\n",
    "            plt.plot(subspace_line[:, 0], subspace_line[:, 1], 'b--', alpha=0.5, label='Subspace')\n",
    "        \n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.axis('equal')\n",
    "        plt.legend()\n",
    "        plt.title(title)\n",
    "        plt.xlabel('x₁')\n",
    "        plt.ylabel('x₂')\n",
    "        plt.show()\n",
    "\n",
    "# ===============================\n",
    "# EXAMPLE DEMONSTRATIONS\n",
    "# ===============================\n",
    "\n",
    "def main_example():\n",
    "    \"\"\"\n",
    "    Demonstrate all concepts with the example from the mathematical theory.\n",
    "    \"\"\"\n",
    "    proj = VectorProjection()\n",
    "    \n",
    "    print(\"🔍 COMPREHENSIVE VECTOR PROJECTION DEMONSTRATION\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Example from the mathematical theory\n",
    "    x = [6, 0, 0]\n",
    "    B = [[1, 0],\n",
    "         [1, 1], \n",
    "         [1, 2]]\n",
    "    \n",
    "    print(\"📊 EXAMPLE 1: Basic Projection\")\n",
    "    print(\"-\" * 30)\n",
    "    result = proj.project_vector(x, B)\n",
    "    \n",
    "    print(\"🔍 VERIFICATION:\")\n",
    "    print(\"-\" * 15)\n",
    "    verification = proj.verify_projection_properties(x, result)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"📊 EXAMPLE 2: Orthonormal Basis\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Create orthonormal basis using Gram-Schmidt\n",
    "    B_original = np.array(B)\n",
    "    B_onb = proj.gram_schmidt(B_original)\n",
    "    \n",
    "    # Project using ONB\n",
    "    onb_result = proj.project_with_onb(x, B_onb)\n",
    "    \n",
    "    print(\"🔍 Comparison:\")\n",
    "    print(f\"Regular projection error: {result['projection_error']:.6f}\")\n",
    "    print(f\"ONB projection error: {onb_result['projection_error']:.6f}\")\n",
    "    print(f\"Difference: {abs(result['projection_error'] - onb_result['projection_error']):.2e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"📊 EXAMPLE 3: Least Squares Solution\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Overdetermined system\n",
    "    A = [[1, 2],\n",
    "         [2, 1],\n",
    "         [1, 1],\n",
    "         [0, 1]]\n",
    "    b = [1, 2, 1, 1]\n",
    "    \n",
    "    ls_result = proj.solve_least_squares(A, b)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"📊 EXAMPLE 4: 2D Visualization\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # 2D example for visualization\n",
    "    x_2d = [3, 2]\n",
    "    B_2d = [[1], [1]]  # Project onto line y = x\n",
    "    \n",
    "    result_2d = proj.project_vector(x_2d, B_2d, verbose=False)\n",
    "    proj.visualize_projection_2d(x_2d, np.array(B_2d), \"Projection onto line y = x\")\n",
    "    \n",
    "    return proj, result, verification\n",
    "\n",
    "def advanced_examples():\n",
    "    \"\"\"\n",
    "    Additional examples demonstrating various scenarios.\n",
    "    \"\"\"\n",
    "    proj = VectorProjection()\n",
    "    \n",
    "    print(\"\\n🚀 ADVANCED EXAMPLES\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Example 1: High-dimensional projection\n",
    "    print(\"📊 EXAMPLE A: High-dimensional space\")\n",
    "    print(\"-\" * 35)\n",
    "    np.random.seed(42)\n",
    "    x_high = np.random.randn(5)\n",
    "    B_high = np.random.randn(5, 2)\n",
    "    B_high = proj.gram_schmidt(B_high, verbose=False)  # Make orthonormal\n",
    "    \n",
    "    result_high = proj.project_vector(x_high, B_high, verbose=False)\n",
    "    print(f\"Original vector dimension: {len(x_high)}\")\n",
    "    print(f\"Subspace dimension: {B_high.shape[1]}\")\n",
    "    print(f\"Projection error: {result_high['projection_error']:.6f}\")\n",
    "    print(f\"Information retained: {(1 - result_high['projection_error']**2 / np.linalg.norm(x_high)**2)*100:.1f}%\")\n",
    "    \n",
    "    # Example 2: Nearly linearly dependent basis\n",
    "    print(\"\\n📊 EXAMPLE B: Nearly dependent basis\")\n",
    "    print(\"-\" * 35)\n",
    "    B_dependent = [[1, 1.001],\n",
    "                   [2, 2.002],\n",
    "                   [3, 3.003]]\n",
    "    \n",
    "    try:\n",
    "        result_dep = proj.project_vector([1, 0, 0], B_dependent, verbose=False)\n",
    "        print(\"Projection successful despite near-dependence\")\n",
    "        print(f\"Condition number of B^T*B: {np.linalg.cond(np.array(B_dependent).T @ np.array(B_dependent)):.2e}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run main demonstration\n",
    "    proj_obj, main_result, main_verification = main_example()\n",
    "    \n",
    "    # Run advanced examples\n",
    "    advanced_examples()\n",
    "    \n",
    "    print(\"\\n✅ All demonstrations completed successfully!\")\n",
    "    print(\"📝 This implementation covers:\")\n",
    "    print(\"   • Vector projections with general basis\")\n",
    "    print(\"   • Orthonormal basis simplifications\") \n",
    "    print(\"   • Projection error calculations\")\n",
    "    print(\"   • Least squares solutions\")\n",
    "    print(\"   • Property verification\")\n",
    "    print(\"   • Gram-Schmidt orthogonalization\")\n",
    "    print(\"   • 2D visualizations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551a7993",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
