{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e0488d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " * Copyright (c) 2016 Radhamadhab Dalai\n",
    " *\n",
    " * Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    " * of this software and associated documentation files (the \"Software\"), to deal\n",
    " * in the Software without restriction, including without limitation the rights\n",
    " * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    " * copies of the Software, and to permit persons to whom the Software is\n",
    " * furnished to do so, subject to the following conditions:\n",
    " *\n",
    " * The above copyright notice and this permission notice shall be included in\n",
    " * all copies or substantial portions of the Software.\n",
    " *\n",
    " * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    " * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    " * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    " * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    " * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    " * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
    " * THE SOFTWARE.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f0dfb2",
   "metadata": {},
   "source": [
    "## Means and Covariances\n",
    "\n",
    "Mean and (co)variance are often useful to describe properties of probability distributions (expected values and spread). We will see in Section 6.6 that there is a useful family of distributions (called the exponential family), where the statistics of the random variable capture all possible information. The concept of the expected value is central to machine learning, and the foundational concepts of probability itself can be derived from the expected value (Whittle, 2000).\n",
    "\n",
    "---\n",
    "\n",
    "**Definition 3 (Expected Value).**\n",
    "The **expected value** of a function $g : \\mathbb{R} \\to \\mathbb{R}$ of a univariate continuous random variable $X \\sim p(x)$ is given by:\n",
    "\n",
    "$$\\mathbb{E}_X [g(x)] = \\int_{\\mathcal{X}} g(x)p(x)dx \\quad \\text{(6.28)}$$\n",
    "\n",
    "Correspondingly, the expected value of a function $g$ of a discrete random variable $X \\sim p(x)$ is given by:\n",
    "\n",
    "$$\\mathbb{E}_X [g(x)] = \\sum_{x \\in \\mathcal{X}} g(x)p(x) \\quad \\text{(6.29)}$$\n",
    "\n",
    "where $\\mathcal{X}$ is the set of possible outcomes (the target space) of the random variable $X$. In this section, we consider discrete random variables to have numerical outcomes. This can be seen by observing that the function $g$ takes real numbers as inputs.\n",
    "\n",
    "**Remark.** We consider multivariate random variables $\\mathbf{X}$ as a finite vector of univariate random variables $[X_1, \\ldots, X_D]^\\top$. For multivariate random variables, we define the expected value element-wise:\n",
    "\n",
    "$$\\mathbb{E}_{\\mathbf{X}} [g(\\mathbf{x})] = \\begin{bmatrix} \\mathbb{E}_{X_1} [g(x_1)] \\\\ \\vdots \\\\ \\mathbb{E}_{X_D} [g(x_D)] \\end{bmatrix} \\in \\mathbb{R}^D \\quad \\text{(6.30)}$$\n",
    "\n",
    "where the subscript $\\mathbb{E}_{X_d}$ indicates that we are taking the expected value with respect to the $d$-th element of the vector $\\mathbf{x}$. The expected value of a function of a random variable is sometimes referred to as the law of the unconscious statistician (Casella and Berger, 2002, Section 2.2). $\\diamondsuit$\n",
    "\n",
    "---\n",
    "\n",
    "Definition 6.3 defines the meaning of the notation $\\mathbb{E}_X$ as the operator indicating that we should take the integral with respect to the probability density (for continuous distributions) or the sum over all states (for discrete distributions). The definition of the mean (Definition 6.4), is a special case of the expected value, obtained by choosing $g$ to be the identity function.\n",
    "\n",
    "---\n",
    "\n",
    "**Definition 6.4 (Mean).**\n",
    "The **mean** of a random variable $X$ with states $\\mathbf{x} \\in \\mathbb{R}^D$ is an average and is defined as:\n",
    "\n",
    "$$\\mathbb{E}_{\\mathbf{X}} [\\mathbf{x}] = \\begin{bmatrix} \\mathbb{E}_{X_1} [x_1] \\\\ \\vdots \\\\ \\mathbb{E}_{X_D} [x_D] \\end{bmatrix} \\in \\mathbb{R}^D \\quad \\text{(6.31)}$$\n",
    "\n",
    "where:\n",
    "\n",
    "$$\\mathbb{E}_{X_d} [x_d] := \\begin{cases} \\int_{\\mathcal{X}} x_d p(x_d)dx_d & \\text{if } X \\text{ is a continuous random variable} \\\\ \\sum_{x_i \\in \\mathcal{X}} x_i p(x_d = x_i) & \\text{if } X \\text{ is a discrete random variable} \\end{cases} \\quad \\text{(6.32)}$$\n",
    "\n",
    "for $d = 1, \\ldots, D$, where the subscript $d$ indicates the corresponding dimension of $x$. The integral and sum are over the states $\\mathcal{X}$ of the target space of the random variable $X$.\n",
    "\n",
    "In one dimension, there are two other intuitive notions of “average”, which are the **median** and the **mode**. The median is the “middle” value if we sort the values, i.e., 50% of the values are greater than the median and 50% are smaller than the median. This idea can be generalized to continuous values by considering the value where the cdf (Definition 6.2) is 0.5. For distributions, which are asymmetric or have long tails, the median provides an estimate of a typical value that is closer to human intuition than the mean value. Furthermore, the median is more robust to outliers than the mean. The generalization of the median to higher dimensions is non-trivial as there is no obvious way to “sort” in more than one dimension (Hallin et al., 2010; Kong and Mizera, 2012). The **mode** is the most frequently occurring value. For a discrete random variable, the mode is defined as the value of $x$ having the highest frequency of occurrence. For a continuous random variable, the mode is defined as a peak in the density $p(x)$. A particular density $p(x)$ may have more than one mode, and furthermore there may be a very large number of modes in high-dimensional distributions. Therefore, finding all the modes of a distribution can be computationally challenging.\n",
    "\n",
    "### Example 4\n",
    "\n",
    "Consider the two-dimensional distribution illustrated in Figure 6.4:\n",
    "\n",
    "$$p(\\mathbf{x}) = 0.4 \\mathcal{N}\\left(\\mathbf{x} ; \\begin{bmatrix} 10 \\\\ 1 \\end{bmatrix}, \\begin{bmatrix} 1 & 0 \\\\ 0 & 8.4 \\end{bmatrix}\\right) + 0.6 \\mathcal{N}\\left(\\mathbf{x} ; \\begin{bmatrix} 0 \\\\ 2 \\end{bmatrix}, \\begin{bmatrix} 1 & 0 \\\\ 0 & 1.7 \\end{bmatrix}\\right) \\quad \\text{(6.33)}$$\n",
    "\n",
    "We will define the Gaussian distribution $\\mathcal{N}(\\boldsymbol{\\mu}, \\boldsymbol{\\sigma}^2)$ in Section 6.5. Also shown is its corresponding marginal distribution in each dimension. Observe that the distribution is bimodal (has two modes), but one of the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1989007f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data for Discrete Random Variable X ---\n",
      "States: [0, 1, 2]\n",
      "PMF: {0: 0.49, 1: 0.42, 2: 0.09}\n",
      "--------------------------------------------------\n",
      "--- 1. Expected Value of a Function g(x) ---\n",
      "Expected value of g(x) = x (i.e., the mean): 0.600\n",
      "Expected value of g(x) = x^2: 0.780\n",
      "Expected value of g(x) = x + 5: 5.600\n",
      "--------------------------------------------------\n",
      "--- 2. Mean of X (Average) ---\n",
      "Mean E[X] = 0.600\n",
      "--------------------------------------------------\n",
      "--- 3. Median of X ---\n",
      "Median of X = 1\n",
      "--------------------------------------------------\n",
      "--- 4. Mode(s) of X ---\n",
      "Mode(s) of X = [0]\n",
      "Example Multimodal (States=[1, 2, 3, 4], PMF={1: 0.3, 2: 0.2, 3: 0.3, 4: 0.2}): Mode(s) = [1, 3]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- Data for the Discrete Random Variable (Number of Heads in 2 coin tosses) ---\n",
    "# States (outcomes) and their corresponding probabilities (PMF)\n",
    "states = [0, 1, 2]\n",
    "pmf = {0: 0.49, 1: 0.42, 2: 0.09}\n",
    "\n",
    "# Ensure probabilities sum to 1 (for robustness)\n",
    "total_prob = sum(pmf.values())\n",
    "if abs(total_prob - 1.0) > 1e-9:\n",
    "    print(f\"Warning: Probabilities do not sum to 1.0. Sum = {total_prob}\")\n",
    "\n",
    "print(\"--- Data for Discrete Random Variable X ---\")\n",
    "print(f\"States: {states}\")\n",
    "print(f\"PMF: {pmf}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# --- 1. Expected Value (E_X[g(x)]) - Definition 6.3 (Discrete) ---\n",
    "def expected_value(g_function, states, pmf):\n",
    "    \"\"\"\n",
    "    Calculates the expected value of a function g(x) for a discrete random variable X.\n",
    "    E_X[g(x)] = sum_{x in X} g(x) * p(x)\n",
    "    \"\"\"\n",
    "    sum_of_products = 0.0\n",
    "    for x_val in states:\n",
    "        prob = pmf.get(x_val, 0) # Get probability, 0 if state not in pmf\n",
    "        sum_of_products += g_function(x_val) * prob\n",
    "    return sum_of_products\n",
    "\n",
    "print(\"--- 1. Expected Value of a Function g(x) ---\")\n",
    "\n",
    "# Example g(x) = x (this will be the mean)\n",
    "def identity_function(x):\n",
    "    return x\n",
    "\n",
    "expected_identity = expected_value(identity_function, states, pmf)\n",
    "print(f\"Expected value of g(x) = x (i.e., the mean): {expected_identity:.3f}\")\n",
    "\n",
    "# Example g(x) = x^2\n",
    "def square_function(x):\n",
    "    return x**2\n",
    "\n",
    "expected_square = expected_value(square_function, states, pmf)\n",
    "print(f\"Expected value of g(x) = x^2: {expected_square:.3f}\")\n",
    "\n",
    "# Example g(x) = x + 5\n",
    "def add_five_function(x):\n",
    "    return x + 5\n",
    "\n",
    "expected_add_five = expected_value(add_five_function, states, pmf)\n",
    "print(f\"Expected value of g(x) = x + 5: {expected_add_five:.3f}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# --- 2. Mean (E_X[x]) - Definition 6.4 (Discrete, Univariate) ---\n",
    "# This is a special case of expected_value with g(x) = x\n",
    "def calculate_mean(states, pmf):\n",
    "    \"\"\"Calculates the mean of a discrete random variable.\"\"\"\n",
    "    return expected_value(identity_function, states, pmf)\n",
    "\n",
    "print(\"--- 2. Mean of X (Average) ---\")\n",
    "mean_X = calculate_mean(states, pmf)\n",
    "print(f\"Mean E[X] = {mean_X:.3f}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# --- 3. Median (Discrete) ---\n",
    "def calculate_median(states, pmf):\n",
    "    \"\"\"\n",
    "    Calculates the median of a discrete random variable.\n",
    "    Assumes states are sorted.\n",
    "    \"\"\"\n",
    "    # Create cumulative probabilities\n",
    "    cumulative_prob = 0.0\n",
    "    # Sort states based on their numerical value to find the \"middle\"\n",
    "    sorted_states = sorted(states)\n",
    "    \n",
    "    # Check for median value\n",
    "    # If there's a state where CDF >= 0.5 for the first time, that's often the median.\n",
    "    # For discrete, if CDF(x-1) < 0.5 and CDF(x) >= 0.5, then x is the median.\n",
    "    # If CDF(x) = 0.5, then any value between x and the next value is a median.\n",
    "    \n",
    "    # Simple approach: Find the first value where cumulative probability >= 0.5\n",
    "    current_cumulative_prob = 0.0\n",
    "    for i, x_val in enumerate(sorted_states):\n",
    "        current_cumulative_prob += pmf.get(x_val, 0)\n",
    "        if current_cumulative_prob >= 0.5:\n",
    "            # Check if it exactly hits 0.5 and there's a next value\n",
    "            if current_cumulative_prob == 0.5 and i + 1 < len(sorted_states):\n",
    "                # Median is any value between this state and the next state\n",
    "                # A common convention is the average of these two values\n",
    "                return (x_val + sorted_states[i+1]) / 2.0\n",
    "            else:\n",
    "                return x_val\n",
    "    return None # Should not happen if total_prob is 1.0\n",
    "\n",
    "print(\"--- 3. Median of X ---\")\n",
    "median_X = calculate_median(states, pmf)\n",
    "print(f\"Median of X = {median_X}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# --- 4. Mode (Discrete) ---\n",
    "def calculate_mode(states, pmf):\n",
    "    \"\"\"\n",
    "    Calculates the mode(s) of a discrete random variable.\n",
    "    Returns a list of modes (can be multimodal).\n",
    "    \"\"\"\n",
    "    if not pmf:\n",
    "        return []\n",
    "\n",
    "    max_prob = -1.0\n",
    "    modes = []\n",
    "\n",
    "    for x_val in states:\n",
    "        prob = pmf.get(x_val, 0)\n",
    "        if prob > max_prob:\n",
    "            max_prob = prob\n",
    "            modes = [x_val] # New max, reset modes\n",
    "        elif prob == max_prob:\n",
    "            modes.append(x_val) # Same max, add to modes\n",
    "    return modes\n",
    "\n",
    "print(\"--- 4. Mode(s) of X ---\")\n",
    "modes_X = calculate_mode(states, pmf)\n",
    "print(f\"Mode(s) of X = {modes_X}\")\n",
    "\n",
    "# Example of a multimodal distribution (if we had one)\n",
    "multimodal_states = [1, 2, 3, 4]\n",
    "multimodal_pmf = {1: 0.3, 2: 0.2, 3: 0.3, 4: 0.2}\n",
    "modes_multimodal = calculate_mode(multimodal_states, multimodal_pmf)\n",
    "print(f\"Example Multimodal (States={multimodal_states}, PMF={multimodal_pmf}): Mode(s) = {modes_multimodal}\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "01191cbe",
   "metadata": {},
   "source": [
    "## Covariance, Variance, and Correlation\n",
    "\n",
    "The covariance intuitively represents the notion of how dependent random variables are to one another.\n",
    "\n",
    "### Definition 6.5 (Covariance (Univariate))\n",
    "\n",
    "The covariance between two univariate random variables $ X, Y \\in \\mathbb{R} $ is given by the expected product of their deviations from their respective means, i.e.,\n",
    "\n",
    "$$\n",
    "\\text{Cov}_{X,Y}[x, y] := \\mathbb{E}_{X,Y} \\left[ (x - \\mathbb{E}_X[x])(y - \\mathbb{E}_Y[y]) \\right]. \\quad \\text{(6.35)}\n",
    "$$\n",
    "\n",
    "### Remark\n",
    "\n",
    "When the random variable associated with the expectation or covariance is clear by its arguments, the subscript is often suppressed (for example, $ \\mathbb{E}_X[x] $ is often written as $ \\mathbb{E}[x] $). $ \\diamond $\n",
    "\n",
    "By using the linearity of expectations, the expression in Definition 6.5 can be rewritten as the expected value of the product minus the product of the expected values, i.e.,\n",
    "\n",
    "$$\n",
    "\\text{Cov}[x, y] = \\mathbb{E}[xy] - \\mathbb{E}[x]\\mathbb{E}[y]. \\quad \\text{(6.36)}\n",
    "$$\n",
    "\n",
    "The covariance of a variable with itself $ \\text{Cov}[x, x] $ is called the variance and is denoted by $ V_X[x] $. The square root of the variance is called the standard deviation and is often denoted by $ \\sigma(x) $.\n",
    "\n",
    "The notion of covariance can be generalized to multivariate random variables.\n",
    "\n",
    "### Definition 6.6 (Covariance (Multivariate))\n",
    "\n",
    "If we consider two multivariate random variables $ X $ and $ Y $ with states $ x \\in \\mathbb{R}^D $ and $ y \\in \\mathbb{R}^E $ respectively, the covariance between $ X $ and $ Y $ is defined as\n",
    "\n",
    "$$\n",
    "\\text{Cov}[x, y] = \\mathbb{E}[x y^\\top] - \\mathbb{E}[x] \\mathbb{E}[y]^\\top = \\text{Cov}[y, x]^\\top \\in \\mathbb{R}^{D \\times E}. \\quad \\text{(6.37)}\n",
    "$$\n",
    "\n",
    "Definition 6.6 can be applied with the same multivariate random variable in both arguments, which results in a useful concept that intuitively captures the “spread” of a random variable. For a multivariate random variable, the variance describes the relation between individual dimensions of the random variable.\n",
    "\n",
    "### Definition 6.7 (Variance)\n",
    "\n",
    "The variance of a random variable $ X $ with states $ x \\in \\mathbb{R}^D $ and a mean vector $ \\mu \\in \\mathbb{R}^D $ is defined as\n",
    "\n",
    "$$\n",
    "V_X[x] = \\text{Cov}_X[x, x] \\quad \\text{(6.38a)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\mathbb{E}_X \\left[ (x - \\mu)(x - \\mu)^\\top \\right] = \\mathbb{E}_X [x x^\\top] - \\mathbb{E}_X[x] \\mathbb{E}_X[x]^\\top \\quad \\text{(6.38b)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\begin{bmatrix}\n",
    "\\text{Cov}[x_1, x_1] & \\text{Cov}[x_1, x_2] & \\cdots & \\text{Cov}[x_1, x_D] \\\\\n",
    "\\text{Cov}[x_2, x_1] & \\text{Cov}[x_2, x_2] & \\cdots & \\text{Cov}[x_2, x_D] \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "\\text{Cov}[x_D, x_1] & \\cdots & \\cdots & \\text{Cov}[x_D, x_D]\n",
    "\\end{bmatrix}. \\quad \\text{(6.38c)}\n",
    "$$\n",
    "\n",
    "The $ D \\times D $ matrix in (6.38c) is called the covariance matrix of the multivariate random variable $ X $. The covariance matrix is symmetric and positive semidefinite and tells us something about the spread of the data. On its diagonal, the covariance matrix contains the variances of the marginals\n",
    "\n",
    "$$\n",
    "p(x_i) = \\int p(x_1, \\ldots, x_D) \\, dx_{\\setminus i}, \\quad \\text{(6.39)}\n",
    "$$\n",
    "\n",
    "where “$ \\setminus i $” denotes “all variables but $ i $”. The off-diagonal entries are the cross-covariance terms $ \\text{Cov}[x_i, x_j] $ for $ i, j = 1, \\ldots, D $, $ i \\neq j $.\n",
    "\n",
    "### Remark\n",
    "\n",
    "In this book, we generally assume that covariance matrices are positive definite to enable better intuition. We therefore do not discuss corner cases that result in positive semidefinite (low-rank) covariance matrices. $ \\diamond $\n",
    "\n",
    "When we want to compare the covariances between different pairs of random variables, it turns out that the variance of each random variable affects the value of the covariance. The normalized version of covariance is called the correlation.\n",
    "\n",
    "### Definition 6.8 (Correlation)\n",
    "\n",
    "The correlation between two random variables $ X, Y $ is given by\n",
    "\n",
    "$$\n",
    "\\text{corr}[x, y] = \\frac{\\text{Cov}[x, y]}{\\sqrt{V[x] V[y]}} \\in [-1, 1]. \\quad \\text{(6.40)}\n",
    "$$\n",
    "\n",
    "The correlation matrix is the covariance matrix of standardized random variables, $ x / \\sigma(x) $. In other words, each random variable is divided by its standard deviation (the square root of the variance) in the correlation matrix.\n",
    "\n",
    "The covariance (and correlation) indicate how two random variables are related; see Figure 6.5. Positive correlation $ \\text{corr}[x, y] $ means that when $ x $ grows, then $ y $ is also expected to grow. Negative correlation means that as $ x $ increases, then $ y $ decreases.\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "## Fig.5: Two-Dimensional Datasets\n",
    "\n",
    "Figure 6.5 shows two-dimensional datasets with identical means and variances along each axis (colored lines) but with different covariances.\n",
    "\n",
    "**(a)** $ x $ and $ y $ are negatively correlated.\n",
    "\n",
    "**(b)** $ x $ and $ y $ are positively correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9efb80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance and Correlation Analysis\n",
      "============================================================\n",
      "=== Covariance, Variance, and Correlation ===\n",
      "Definitions 6.5–6.8\n",
      "\n",
      "Generating datasets (Figure 6.5):\n",
      "Univariate Covariance (Equations 6.35–6.36):\n",
      "Negative correlation dataset:\n",
      "Cov[x, y] = -8.3200 (direct method)\n",
      "Cov[x, y] = -8.3200 (alternative method, E[xy] - E[x]E[y])\n",
      "\n",
      "Positive correlation dataset:\n",
      "Cov[x, y] = 8.3450 (direct method)\n",
      "Cov[x, y] = 8.3450 (alternative method, E[xy] - E[x]E[y])\n",
      "\n",
      "Multivariate Variance (Equations 6.38a–c):\n",
      "Negative correlation dataset covariance matrix:\n",
      "[8.3325, -8.32]\n",
      "[-8.32, 8.37]\n",
      "\n",
      "Positive correlation dataset covariance matrix:\n",
      "[8.3325, 8.345]\n",
      "[8.345, 8.42]\n",
      "\n",
      "Correlation (Equation 6.40):\n",
      "Negative correlation dataset: corr[x, y] = -0.9963\n",
      "Positive correlation dataset: corr[x, y] = 0.9963\n",
      "\n",
      "============================================================\n",
      "Summary of Key Results:\n",
      "• Computed univariate covariance using two methods\n",
      "• Computed multivariate variance (covariance matrix)\n",
      "• Computed correlation, confirming positive/negative relationships\n",
      "• Demonstrated concepts with datasets as in Figure 6.5\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# --- Vector and Matrix Operations ---\n",
    "def vector_add(v1, v2):\n",
    "    \"\"\"\n",
    "    Add two vectors.\n",
    "    \"\"\"\n",
    "    return [v1[i] + v2[i] for i in range(len(v1))]\n",
    "\n",
    "def vector_subtract(v1, v2):\n",
    "    \"\"\"\n",
    "    Subtract two vectors.\n",
    "    \"\"\"\n",
    "    return [v1[i] - v2[i] for i in range(len(v1))]\n",
    "\n",
    "def scalar_multiply(scalar, v):\n",
    "    \"\"\"\n",
    "    Multiply a vector by a scalar.\n",
    "    \"\"\"\n",
    "    return [scalar * vi for vi in v]\n",
    "\n",
    "def dot_product(v1, v2):\n",
    "    \"\"\"\n",
    "    Compute the dot product of two vectors.\n",
    "    \"\"\"\n",
    "    return sum(v1[i] * v2[i] for i in range(len(v1)))\n",
    "\n",
    "def outer_product(v1, v2):\n",
    "    \"\"\"\n",
    "    Compute the outer product of two vectors (results in a matrix).\n",
    "    \"\"\"\n",
    "    return [[v1[i] * v2[j] for j in range(len(v2))] for i in range(len(v1))]\n",
    "\n",
    "def matrix_add(M1, M2):\n",
    "    \"\"\"\n",
    "    Add two matrices.\n",
    "    \"\"\"\n",
    "    return [[M1[i][j] + M2[i][j] for j in range(len(M1[0]))] for i in range(len(M1))]\n",
    "\n",
    "def matrix_subtract(M1, M2):\n",
    "    \"\"\"\n",
    "    Subtract two matrices.\n",
    "    \"\"\"\n",
    "    return [[M1[i][j] - M2[i][j] for j in range(len(M1[0]))] for i in range(len(M1))]\n",
    "\n",
    "# --- Random Variable Class ---\n",
    "class RandomVariable:\n",
    "    def __init__(self, data):\n",
    "        \"\"\"\n",
    "        Initialize with data: list of samples (each sample is a list for multivariate).\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.dim = len(data[0]) if data else 0  # Dimension of each sample\n",
    "        self.n_samples = len(data)\n",
    "\n",
    "    def expectation(self, func=None):\n",
    "        \"\"\"\n",
    "        Compute the expectation of a function over the data.\n",
    "        If func is None, compute the mean of the random variable.\n",
    "        \"\"\"\n",
    "        if not self.data:\n",
    "            return [0] * self.dim\n",
    "\n",
    "        if func is None:\n",
    "            # Compute mean: E[x]\n",
    "            result = [0] * self.dim\n",
    "            for sample in self.data:\n",
    "                result = vector_add(result, sample)\n",
    "            return scalar_multiply(1.0 / self.n_samples, result)\n",
    "        else:\n",
    "            # Compute E[func(x)]\n",
    "            result = 0\n",
    "            for sample in self.data:\n",
    "                result += func(sample)\n",
    "            return result / self.n_samples\n",
    "\n",
    "# --- Covariance, Variance, and Correlation Functions ---\n",
    "def covariance_univariate(X, Y):\n",
    "    \"\"\"\n",
    "    Compute univariate covariance (Definition 6.5, Equation 6.35).\n",
    "    Cov[x, y] = E[(x - E[x])(y - E[y])]\n",
    "    \"\"\"\n",
    "    if len(X.data[0]) != 1 or len(Y.data[0]) != 1:\n",
    "        raise ValueError(\"Univariate covariance requires 1D random variables\")\n",
    "    \n",
    "    # Extract scalar values\n",
    "    x_data = [sample[0] for sample in X.data]\n",
    "    y_data = [sample[0] for sample in Y.data]\n",
    "    \n",
    "    # Compute means\n",
    "    mean_x = X.expectation()\n",
    "    mean_y = Y.expectation()\n",
    "    \n",
    "    # Compute E[(x - E[x])(y - E[y])]\n",
    "    def deviation_product(sample):\n",
    "        x, y = sample[0][0], sample[1][0]\n",
    "        return (x - mean_x[0]) * (y - mean_y[0])\n",
    "    \n",
    "    paired_data = list(zip(X.data, Y.data))\n",
    "    cov = sum(deviation_product(pair) for pair in paired_data) / len(paired_data)\n",
    "    \n",
    "    # Alternative computation (Equation 6.36): Cov[x, y] = E[xy] - E[x]E[y]\n",
    "    e_xy = sum(x * y for x, y in zip(x_data, y_data)) / len(x_data)\n",
    "    alt_cov = e_xy - mean_x[0] * mean_y[0]\n",
    "    \n",
    "    return cov, alt_cov\n",
    "\n",
    "def covariance_multivariate(X, Y):\n",
    "    \"\"\"\n",
    "    Compute multivariate covariance (Definition 6.6, Equation 6.37).\n",
    "    Cov[x, y] = E[x y^T] - E[x] E[y]^T\n",
    "    \"\"\"\n",
    "    mean_x = X.expectation()\n",
    "    mean_y = Y.expectation()\n",
    "    \n",
    "    # Compute E[x y^T]\n",
    "    e_xyT = [[0 for _ in range(Y.dim)] for _ in range(X.dim)]\n",
    "    for i in range(X.n_samples):\n",
    "        x = X.data[i]\n",
    "        y = Y.data[i]\n",
    "        outer = outer_product(x, y)\n",
    "        e_xyT = matrix_add(e_xyT, outer)\n",
    "    e_xyT = [[e_xyT[i][j] / X.n_samples for j in range(Y.dim)] for i in range(X.dim)]\n",
    "    \n",
    "    # Compute E[x] E[y]^T\n",
    "    e_x_e_yT = outer_product(mean_x, mean_y)\n",
    "    \n",
    "    # Cov[x, y] = E[x y^T] - E[x] E[y]^T\n",
    "    cov_matrix = matrix_subtract(e_xyT, e_x_e_yT)\n",
    "    return cov_matrix\n",
    "\n",
    "def variance(X):\n",
    "    \"\"\"\n",
    "    Compute variance (covariance matrix) of a multivariate random variable (Definition 6.7, Equation 6.38).\n",
    "    V[x] = Cov[x, x] = E[(x - μ)(x - μ)^T]\n",
    "    \"\"\"\n",
    "    return covariance_multivariate(X, X)\n",
    "\n",
    "def correlation(X, Y):\n",
    "    \"\"\"\n",
    "    Compute correlation (Definition 6.8, Equation 6.40).\n",
    "    corr[x, y] = Cov[x, y] / sqrt(V[x] V[y])\n",
    "    \"\"\"\n",
    "    if len(X.data[0]) != 1 or len(Y.data[0]) != 1:\n",
    "        raise ValueError(\"Correlation implemented for univariate random variables\")\n",
    "    \n",
    "    cov, _ = covariance_univariate(X, Y)\n",
    "    var_x = variance(X)[0][0]\n",
    "    var_y = variance(Y)[0][0]\n",
    "    \n",
    "    if var_x == 0 or var_y == 0:\n",
    "        return 0  # Avoid division by zero\n",
    "    return cov / math.sqrt(var_x * var_y)\n",
    "\n",
    "# --- Demonstration ---\n",
    "def generate_correlated_data(n_samples, correlation_type):\n",
    "    \"\"\"\n",
    "    Generate 2D data with specified correlation (for Figure 6.5).\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    if correlation_type == \"positive\":\n",
    "        # Positive correlation: y increases with x\n",
    "        for i in range(n_samples):\n",
    "            x = i / n_samples * 10 - 5  # x in [-5, 5]\n",
    "            y = x + (i % 2 - 0.5) * 0.5  # y roughly follows x with small noise\n",
    "            data.append([x, y])\n",
    "    else:\n",
    "        # Negative correlation: y decreases as x increases\n",
    "        for i in range(n_samples):\n",
    "            x = i / n_samples * 10 - 5  # x in [-5, 5]\n",
    "            y = -x + (i % 2 - 0.5) * 0.5  # y roughly follows -x with small noise\n",
    "            data.append([x, y])\n",
    "    return data\n",
    "\n",
    "def demonstrate_covariance_correlation():\n",
    "    \"\"\"\n",
    "    Demonstrate covariance, variance, and correlation (Definitions 6.5–6.8).\n",
    "    - Univariate covariance (Equations 6.35–6.36)\n",
    "    - Multivariate variance (Equations 6.38a–c)\n",
    "    - Correlation (Equation 6.40)\n",
    "    - Generate datasets as in Figure 6.5\n",
    "    \"\"\"\n",
    "    print(\"=== Covariance, Variance, and Correlation ===\")\n",
    "    print(\"Definitions 6.5–6.8\\n\")\n",
    "\n",
    "    # Generate datasets (Figure 6.5)\n",
    "    n_samples = 100\n",
    "    print(\"Generating datasets (Figure 6.5):\")\n",
    "    \n",
    "    # (a) Negatively correlated data\n",
    "    data_neg = generate_correlated_data(n_samples, \"negative\")\n",
    "    X_neg = RandomVariable([[d[0]] for d in data_neg])\n",
    "    Y_neg = RandomVariable([[d[1]] for d in data_neg])\n",
    "    XY_neg = RandomVariable(data_neg)\n",
    "    \n",
    "    # (b) Positively correlated data\n",
    "    data_pos = generate_correlated_data(n_samples, \"positive\")\n",
    "    X_pos = RandomVariable([[d[0]] for d in data_pos])\n",
    "    Y_pos = RandomVariable([[d[1]] for d in data_pos])\n",
    "    XY_pos = RandomVariable(data_pos)\n",
    "\n",
    "    # Step 1: Univariate Covariance (Equations 6.35–6.36)\n",
    "    print(\"Univariate Covariance (Equations 6.35–6.36):\")\n",
    "    cov_neg, alt_cov_neg = covariance_univariate(X_neg, Y_neg)\n",
    "    print(f\"Negative correlation dataset:\")\n",
    "    print(f\"Cov[x, y] = {cov_neg:.4f} (direct method)\")\n",
    "    print(f\"Cov[x, y] = {alt_cov_neg:.4f} (alternative method, E[xy] - E[x]E[y])\")\n",
    "    \n",
    "    cov_pos, alt_cov_pos = covariance_univariate(X_pos, Y_pos)\n",
    "    print(f\"\\nPositive correlation dataset:\")\n",
    "    print(f\"Cov[x, y] = {cov_pos:.4f} (direct method)\")\n",
    "    print(f\"Cov[x, y] = {alt_cov_pos:.4f} (alternative method, E[xy] - E[x]E[y])\")\n",
    "\n",
    "    # Step 2: Multivariate Variance (Equations 6.38a–c)\n",
    "    print(\"\\nMultivariate Variance (Equations 6.38a–c):\")\n",
    "    var_neg = variance(XY_neg)\n",
    "    print(\"Negative correlation dataset covariance matrix:\")\n",
    "    for row in var_neg:\n",
    "        print([round(x, 4) for x in row])\n",
    "    \n",
    "    var_pos = variance(XY_pos)\n",
    "    print(\"\\nPositive correlation dataset covariance matrix:\")\n",
    "    for row in var_pos:\n",
    "        print([round(x, 4) for x in row])\n",
    "\n",
    "    # Step 3: Correlation (Equation 6.40)\n",
    "    print(\"\\nCorrelation (Equation 6.40):\")\n",
    "    corr_neg = correlation(X_neg, Y_neg)\n",
    "    print(f\"Negative correlation dataset: corr[x, y] = {corr_neg:.4f}\")\n",
    "    \n",
    "    corr_pos = correlation(X_pos, Y_pos)\n",
    "    print(f\"Positive correlation dataset: corr[x, y] = {corr_pos:.4f}\")\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Covariance and Correlation Analysis\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Run demonstration\n",
    "    demonstrate_covariance_correlation()\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Summary of Key Results:\")\n",
    "    print(\"• Computed univariate covariance using two methods\")\n",
    "    print(\"• Computed multivariate variance (covariance matrix)\")\n",
    "    print(\"• Computed correlation, confirming positive/negative relationships\")\n",
    "    print(\"• Demonstrated concepts with datasets as in Figure 6.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d97775f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
