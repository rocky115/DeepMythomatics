{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7054f09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " * Copyright (c) 2016 Radhamadhab Dalai\n",
    " *\n",
    " * Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    " * of this software and associated documentation files (the \"Software\"), to deal\n",
    " * in the Software without restriction, including without limitation the rights\n",
    " * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    " * copies of the Software, and to permit persons to whom the Software is\n",
    " * furnished to do so, subject to the following conditions:\n",
    " *\n",
    " * The above copyright notice and this permission notice shall be included in\n",
    " * all copies or substantial portions of the Software.\n",
    " *\n",
    " * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    " * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    " * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    " * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    " * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    " * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
    " * THE SOFTWARE.\n",
    "'''"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "dc2ca0f1",
   "metadata": {},
   "source": [
    "# Discrete and Continuous Probabilities (Continued)\n",
    "\n",
    "###  Discrete Probabilities\n",
    "![image.png](attachment:image.png)\n",
    "Fig.2 Visualization of a discrete bivariate probability mass function, with random variables X and Y . \n",
    "\n",
    "**Fig.2: Discrete Bivariate Probability Mass Function**\n",
    "Visualization of a discrete bivariate probability mass function, with random variables $X$ and $Y$. This diagram is adapted from Bishop (2006).*\n",
    "\n",
    "The probability that $X = x$ and $Y = y$ is (lazily) written as $p(x, y)$ and is called the **joint probability**. One can think of a probability as a function that takes state $x$ and $y$ and returns a real number, which is the reason we write $p(x, y)$.\n",
    "\n",
    "The **marginal probability** that $X$ takes the value $x$ irrespective of the value of random variable $Y$ is (lazily) written as $p(x)$. We write $X \\sim p(x)$ to denote that the random variable $X$ is distributed according to $p(x)$.\n",
    "\n",
    "If we consider only the instances where $X = x$, then the fraction of instances (the **conditional probability**) for which $Y = y$ is written (lazily) as $p(y | x)$.\n",
    "\n",
    "### Example 2\n",
    "\n",
    "Consider two random variables $X$ and $Y$, where $X$ has five possible states and $Y$ has three possible states, as shown in Figure 6.2. We denote by $n_{ij}$ the number of events with state $X = x_i$ and $Y = y_j$, and denote by $N$ the total number of events. The value $c_i$ is the sum of the individual frequencies for the $i$-th column, that is, $c_i = \\sum_{j=1}^3 n_{ij}$. Similarly, the value $r_j$ is the row sum, that is, $r_j = \\sum_{i=1}^5 n_{ij}$.\n",
    "\n",
    "Using these definitions, we can compactly express the distribution of $X$ and $Y$. The probability distribution of each random variable, the marginal probability, can be seen as the sum over a row or column:\n",
    "\n",
    "$$P(X = x_i) = \\frac{\\sum_{j=1}^3 n_{ij}}{N} = \\frac{c_i}{N} \\quad \\text{(6.10)}$$\n",
    "\n",
    "and\n",
    "\n",
    "$$P(Y = y_j) = \\frac{\\sum_{i=1}^5 n_{ij}}{N} = \\frac{r_j}{N} \\quad \\text{(6.11)}$$\n",
    "\n",
    "Where $c_i$ and $r_j$ are the $i$-th column and $j$-th row sum of the frequency table, respectively. By convention, for discrete random variables with a finite number of events, we assume that probabilities sum up to one, that is:\n",
    "\n",
    "$$\\sum_{i=1}^5 P(X = x_i) = 1 \\quad \\text{and} \\quad \\sum_{j=1}^3 P(Y = y_j) = 1 \\quad \\text{(6.12)}$$\n",
    "\n",
    "The conditional probability is the fraction of a row or column in a particular cell. For example, the conditional probability of $Y$ given $X$ is:\n",
    "\n",
    "$$P(Y = y_j | X = x_i) = \\frac{n_{ij}}{c_i} \\quad \\text{(6.13)}$$\n",
    "\n",
    "And the conditional probability of $X$ given $Y$ is:\n",
    "\n",
    "$$P(X = x_i | Y = y_j) = \\frac{n_{ij}}{r_j} \\quad \\text{(6.14)}$$\n",
    "\n",
    "In machine learning, we use discrete probability distributions to model categorical variables, i.e., variables that take a finite set of unordered values. They could be categorical features, such as the degree taken at university when used for predicting the salary of a person, or categorical labels, such as letters of the alphabet when doing handwriting recognition. Discrete distributions are also often used to construct probabilistic models that combine a finite number of continuous distributions.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "685ccd0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Synthetic Frequency Table (nij) ---\n",
      "   y1   y2  \n",
      "   ---------\n",
      "x1 | 10   20   \n",
      "x2 | 15   5    \n",
      "x3 | 25   30   \n",
      "----------------------------------------\n",
      "Total number of events (N): 105\n",
      "----------------------------------------\n",
      "--- 4. Joint Probability Table p(x, y) ---\n",
      "   y1     y2    \n",
      "   -------------\n",
      "x1 | 0.095  0.190  \n",
      "x2 | 0.143  0.048  \n",
      "x3 | 0.238  0.286  \n",
      "----------------------------------------\n",
      "--- 5.1. Marginal Probabilities p(x) ---\n",
      "Row sums of nij (c_i): [30, 20, 55]\n",
      "P(X = x1) = 0.286\n",
      "P(X = x2) = 0.190\n",
      "P(X = x3) = 0.524\n",
      "Sum P(X) = 1.000 (should be 1)\n",
      "----------------------------------------\n",
      "--- 5.2. Marginal Probabilities p(y) ---\n",
      "Column sums of nij (r_j): [50, 55]\n",
      "P(Y = y1) = 0.476\n",
      "P(Y = y2) = 0.524\n",
      "Sum P(Y) = 1.000 (should be 1)\n",
      "----------------------------------------\n",
      "--- 6.1. Conditional Probability P(Y | X) ---\n",
      "P(Y = y1 | X = x1) = 0.333\n",
      "P(Y = y2 | X = x1) = 0.667\n",
      "  Sum for X=x1: 1.000 (should be 1)\n",
      "P(Y = y1 | X = x2) = 0.750\n",
      "P(Y = y2 | X = x2) = 0.250\n",
      "  Sum for X=x2: 1.000 (should be 1)\n",
      "P(Y = y1 | X = x3) = 0.455\n",
      "P(Y = y2 | X = x3) = 0.545\n",
      "  Sum for X=x3: 1.000 (should be 1)\n",
      "----------------------------------------\n",
      "--- 6.2. Conditional Probability P(X | Y) ---\n",
      "P(X = x1 | Y = y1) = 0.200\n",
      "P(X = x2 | Y = y1) = 0.300\n",
      "P(X = x3 | Y = y1) = 0.500\n",
      "  Sum for Y=y1: 1.000 (should be 1)\n",
      "P(X = x1 | Y = y2) = 0.364\n",
      "P(X = x2 | Y = y2) = 0.091\n",
      "P(X = x3 | Y = y2) = 0.545\n",
      "  Sum for Y=y2: 1.000 (should be 1)\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Define the states for X and Y ---\n",
    "x_states = ['x1', 'x2', 'x3']\n",
    "y_states = ['y1', 'y2']\n",
    "\n",
    "# --- 2. Create a synthetic frequency table (nij) ---\n",
    "# This represents the counts of events for each (X=xi, Y=yj) pair.\n",
    "# The structure will be nij[i][j] where i corresponds to x_states index and j to y_states index.\n",
    "# Let's make up some numbers for illustration:\n",
    "#        y1  y2\n",
    "#   x1 [ 10, 20 ]\n",
    "#   x2 [ 15,  5 ]\n",
    "#   x3 [ 25, 30 ]\n",
    "\n",
    "nij = [\n",
    "    [10, 20],  # Counts for x1: (x1,y1)=10, (x1,y2)=20\n",
    "    [15, 5],   # Counts for x2: (x2,y1)=15, (x2,y2)=5\n",
    "    [25, 30]   # Counts for x3: (x3,y1)=25, (x3,y2)=30\n",
    "]\n",
    "\n",
    "print(\"--- 1. Synthetic Frequency Table (nij) ---\")\n",
    "print(\"   \" + \" \".join([f\"{y:<4}\" for y in y_states]))\n",
    "print(\"   \" + \"-\" * (len(y_states) * 5 - 1))\n",
    "for i, x_state in enumerate(x_states):\n",
    "    row_str = f\"{x_state} | \"\n",
    "    for count in nij[i]:\n",
    "        row_str += f\"{count:<4} \"\n",
    "    print(row_str)\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# --- 3. Calculate Total Number of Events (N) ---\n",
    "N = sum(sum(row) for row in nij)\n",
    "print(f\"Total number of events (N): {N}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# --- 4. Calculate Joint Probability p(x, y) ---\n",
    "# p(x, y) = nij / N\n",
    "joint_prob_table = [[0.0 for _ in y_states] for _ in x_states]\n",
    "\n",
    "print(\"--- 4. Joint Probability Table p(x, y) ---\")\n",
    "print(\"   \" + \" \".join([f\"{y:<6}\" for y in y_states]))\n",
    "print(\"   \" + \"-\" * (len(y_states) * 7 - 1))\n",
    "for i in range(len(x_states)):\n",
    "    row_str = f\"{x_states[i]} | \"\n",
    "    for j in range(len(y_states)):\n",
    "        joint_prob_table[i][j] = nij[i][j] / N\n",
    "        row_str += f\"{joint_prob_table[i][j]:<6.3f} \"\n",
    "    print(row_str)\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# --- 5. Calculate Marginal Probabilities ---\n",
    "\n",
    "# Marginal probability p(x_i) = c_i / N (column sums from original nij table)\n",
    "# c_i in the text refers to sum over j of nij for a fixed i (row sum of nij)\n",
    "# The text's notation for c_i and r_j might be slightly confusing with row/column.\n",
    "# Let's clarify:\n",
    "# c_i (text) = sum_j nij for fixed i = sum of counts for specific X=xi (row sum)\n",
    "# r_j (text) = sum_i nij for fixed j = sum of counts for specific Y=yj (column sum)\n",
    "\n",
    "# Calculate c_i (sum of nij for a fixed X_i - row sums of nij)\n",
    "ci_sums = [sum(row) for row in nij]\n",
    "print(\"--- 5.1. Marginal Probabilities p(x) ---\")\n",
    "print(\"Row sums of nij (c_i):\", ci_sums)\n",
    "\n",
    "marginal_px = {}\n",
    "for i, x_state in enumerate(x_states):\n",
    "    marginal_px[x_state] = ci_sums[i] / N\n",
    "    print(f\"P(X = {x_state}) = {marginal_px[x_state]:.3f}\")\n",
    "\n",
    "# Verify sum to 1\n",
    "sum_px = sum(marginal_px.values())\n",
    "print(f\"Sum P(X) = {sum_px:.3f} (should be 1)\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Calculate r_j (sum of nij for a fixed Y_j - column sums of nij)\n",
    "rj_sums = [0] * len(y_states)\n",
    "for i in range(len(x_states)):\n",
    "    for j in range(len(y_states)):\n",
    "        rj_sums[j] += nij[i][j]\n",
    "print(\"--- 5.2. Marginal Probabilities p(y) ---\")\n",
    "print(\"Column sums of nij (r_j):\", rj_sums)\n",
    "\n",
    "marginal_py = {}\n",
    "for j, y_state in enumerate(y_states):\n",
    "    marginal_py[y_state] = rj_sums[j] / N\n",
    "    print(f\"P(Y = {y_state}) = {marginal_py[y_state]:.3f}\")\n",
    "\n",
    "# Verify sum to 1\n",
    "sum_py = sum(marginal_py.values())\n",
    "print(f\"Sum P(Y) = {sum_py:.3f} (should be 1)\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# --- 6. Calculate Conditional Probabilities ---\n",
    "\n",
    "# Conditional Probability P(Y = yj | X = xi) = nij / c_i\n",
    "print(\"--- 6.1. Conditional Probability P(Y | X) ---\")\n",
    "conditional_py_given_x = {}\n",
    "for i, x_state in enumerate(x_states):\n",
    "    if ci_sums[i] == 0: # Avoid division by zero if a row sum is 0\n",
    "        print(f\"Cannot calculate P(Y | X = {x_state}) as P(X = {x_state}) is 0.\")\n",
    "        continue\n",
    "    for j, y_state in enumerate(y_states):\n",
    "        prob = nij[i][j] / ci_sums[i]\n",
    "        conditional_py_given_x[(y_state, x_state)] = prob\n",
    "        print(f\"P(Y = {y_state} | X = {x_state}) = {prob:.3f}\")\n",
    "    # Verify sum for each condition\n",
    "    current_sum = sum(conditional_py_given_x[(y_state, x_state)] for y_state in y_states)\n",
    "    print(f\"  Sum for X={x_state}: {current_sum:.3f} (should be 1)\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "\n",
    "# Conditional Probability P(X = xi | Y = yj) = nij / r_j\n",
    "print(\"--- 6.2. Conditional Probability P(X | Y) ---\")\n",
    "conditional_px_given_y = {}\n",
    "for j, y_state in enumerate(y_states):\n",
    "    if rj_sums[j] == 0: # Avoid division by zero if a column sum is 0\n",
    "        print(f\"Cannot calculate P(X | Y = {y_state}) as P(Y = {y_state}) is 0.\")\n",
    "        continue\n",
    "    for i, x_state in enumerate(x_states):\n",
    "        prob = nij[i][j] / rj_sums[j]\n",
    "        conditional_px_given_y[(x_state, y_state)] = prob\n",
    "        print(f\"P(X = {x_state} | Y = {y_state}) = {prob:.3f}\")\n",
    "    # Verify sum for each condition\n",
    "    current_sum = sum(conditional_px_given_y[(x_state, y_state)] for x_state in x_states)\n",
    "    print(f\"  Sum for Y={y_state}: {current_sum:.3f} (should be 1)\")\n",
    "print(\"-\" * 40)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "6b46fd2e",
   "metadata": {},
   "source": [
    "# Discrete and Continuous Probabilities (Continued)\n",
    "\n",
    "### 6.2.2 Continuous Probabilities\n",
    "\n",
    "We consider real-valued random variables in this section, i.e., we consider target spaces that are intervals of the real line $\\mathbb{R}$. In this book, we pretend that we can perform operations on real random variables as if we have discrete probability spaces with finite states. However, this simplification is not precise for two situations: when we repeat something infinitely often, and when we want to draw a point from an interval. The first situation arises when we discuss generalization errors in machine learning (Chapter 8). The second situation arises when we want to discuss continuous distributions, such as the Gaussian (Section 6.5). For our purposes, the lack of precision allows for a briefer introduction to probability.\n",
    "\n",
    "**Remark.** In continuous spaces, there are two additional technicalities, which are counterintuitive. First, the set of all subsets (used to define the event space $\\mathcal{A}$ in Section 6.1) is not well behaved enough. $\\mathcal{A}$ needs to be restricted to behave well under set complements, set intersections, and set unions. Second, the size of a set (which in discrete spaces can be obtained by counting the elements) turns out to be tricky. The size of a set is called its **measure**. For example, the cardinality of discrete sets, the length of an interval in $\\mathbb{R}$, and the volume of a region in $\\mathbb{R}^d$ are all measures. Sets that behave well under set operations and additionally have a topology are called a **Borel $\\sigma$-algebra**. Betancourt details a careful construction of probability spaces from set theory without being bogged down in technicalities; see https://tinyurl.com/yb3t6mfd. For a more precise construction, we refer to Billingsley (1995) and Jacod and Protter (2004).\n",
    "\n",
    "In this book, we consider real-valued random variables with their corresponding Borel $\\sigma$-algebra. We consider random variables with values in $\\mathbb{R}^D$ to be a vector of real-valued random variables. $\\diamondsuit$\n",
    "\n",
    "---\n",
    "\n",
    "**Definition 6.1 (Probability Density Function).**\n",
    "A function $f : \\mathbb{R}^D \\to \\mathbb{R}$ is called a **probability density function (pdf)** if:\n",
    "1.  $\\forall \\mathbf{x} \\in \\mathbb{R}^D : f(\\mathbf{x}) \\geq 0$\n",
    "2.  Its integral exists and\n",
    "    $$\\int_{\\mathbb{R}^D} f(\\mathbf{x}) d\\mathbf{x} = 1 \\quad \\text{(6.15)}$$\n",
    "\n",
    "For probability mass functions (pmf) of discrete random variables, the integral in (6.15) is replaced with a sum (6.12). Observe that the probability density function is any function $f$ that is non-negative and integrates to one.\n",
    "\n",
    "We associate a random variable $X$ with this function $f$ by:\n",
    "\n",
    "$$P(a \\leq X \\leq b) = \\int_a^b f(x) dx \\quad \\text{(6.16)}$$\n",
    "\n",
    "where $a, b \\in \\mathbb{R}$ and $x \\in \\mathbb{R}$ are outcomes of the continuous random variable $X$. States $\\mathbf{x} \\in \\mathbb{R}^D$ are defined analogously by considering a vector of $\\mathbf{x} \\in \\mathbb{R}$. This association (6.16) is called the **law** or **distribution** of the random variable $X$.\n",
    "\n",
    "**Remark.** In contrast to discrete random variables, the probability of a continuous random variable $X$ taking a particular value $P(X = x)$ is zero. This is like trying to specify an interval in (6.16) where $a = b$. $P(X=x)$ is a set of measure zero. $\\diamondsuit$\n",
    "\n",
    "---\n",
    "\n",
    "**Definition 6.2 (Cumulative Distribution Function).**\n",
    "A **cumulative distribution function (cdf)** of a multivariate real-valued random variable $X$ with states $\\mathbf{x} \\in \\mathbb{R}^D$ is given by:\n",
    "\n",
    "$$F_X(\\mathbf{x}) = P(X_1 \\leq x_1, \\ldots, X_D \\leq x_D) \\quad \\text{(6.17)}$$\n",
    "\n",
    "where $X = [X_1, \\ldots, X_D]^\\top$, $\\mathbf{x} = [x_1, \\ldots, x_D]^\\top$, and the right-hand side represents the probability that random variable $X_i$ takes the value smaller than or equal to $x_i$.\n",
    "\n",
    "The cdf can be expressed also as the integral of the probability density function $f(\\mathbf{x})$ so that:\n",
    "\n",
    "$$F_X(\\mathbf{x}) = \\int_{-\\infty}^{x_1} \\cdots \\int_{-\\infty}^{x_D} f(z_1, \\ldots, z_D) dz_1 \\cdots dz_D \\quad \\text{(6.18)}$$\n",
    "\n",
    "There are cdfs which do not have corresponding pdfs.\n",
    "\n",
    "**Remark.** We reiterate that there are in fact two distinct concepts when talking about distributions. First is the idea of a pdf (denoted by $f(x)$), which is a nonnegative function that sums to one. Second is the law of a random variable $X$, that is, the association of a random variable $X$ with the pdf $f(x)$.\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Fig.3 Examples of (a) discrete and (b) continuous uniform distributions. See Example 6.3 for details of the distributions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d30a7cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Continuous Probability Demonstration (Uniform Distribution) ---\n",
      "Distribution: Uniform from 0 to 1\n",
      "PDF value f(x) = 1.0 for x in [0, 1]\n",
      "------------------------------------------------------------\n",
      "1. Checking PDF Normalization (Integral f(x)dx = 1):\n",
      "Approximate integral of PDF: 1.0000\n",
      "PDF approximately integrates to 1 (passes check).\n",
      "------------------------------------------------------------\n",
      "2. Calculating P(a <= X <= b) using PDF (Numerical Integration):\n",
      "P(0.2 <= X <= 0.7) (via PDF integral): 0.5000\n",
      "------------------------------------------------------------\n",
      "3. Calculating P(a <= X <= b) using CDF:\n",
      "P(0.2 <= X <= 0.7) (via CDF): 0.5000\n",
      "------------------------------------------------------------\n",
      "4. Demonstrating P(X = x) for a continuous variable:\n",
      "P(X = 0.5) for a continuous variable is 0.\n",
      "The PDF value f(0.5) = 1.0. This is a density, not a probability.\n",
      "------------------------------------------------------------\n",
      "5. Demonstrating Multivariate CDF (Conceptual Uniform in 2D):\n",
      "F_X([0.5, 0.5]) = P(X1 <= 0.5, X2 <= 0.5) = 0.2500\n",
      "F_X([1.5, 0.5]) = 0.5000\n",
      "F_X([1.5, 1.5]) = 1.0000\n",
      "------------------------------------------------------------\n",
      "\n",
      "--- Summary of Implementation ---\n",
      "This core Python implementation provides a conceptual understanding of PDFs and CDFs for continuous distributions.\n",
      "It uses a simple Uniform Distribution for clarity.\n",
      "Numerical integration is used to approximate integrals, highlighting the conceptual definition.\n",
      "For practical applications involving complex PDFs or accurate integration, libraries like NumPy and SciPy are indispensable.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Define a Probability Density Function (PDF) ---\n",
    "\n",
    "class UniformPDF:\n",
    "    def __init__(self, lower_bound, upper_bound):\n",
    "        if lower_bound >= upper_bound:\n",
    "            raise ValueError(\"Lower bound must be less than upper bound.\")\n",
    "        self.a = lower_bound\n",
    "        self.b = upper_bound\n",
    "        self.density = 1.0 / (self.b - self.a)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        \"\"\"\n",
    "        Evaluates the PDF at a given point x.\n",
    "        f(x) = 1 / (b-a) for a <= x <= b, else 0\n",
    "        \"\"\"\n",
    "        if self.a <= x <= self.b:\n",
    "            return self.density\n",
    "        else:\n",
    "            return 0.0\n",
    "\n",
    "    def check_normalization(self, num_samples=100000):\n",
    "        \"\"\"\n",
    "        Numerically approximates the integral of the PDF to check if it sums to 1.\n",
    "        Uses a simple Riemann sum.\n",
    "        \"\"\"\n",
    "        # Define the range for integration, slightly wider than [a, b] for robustness\n",
    "        integral_range_start = self.a - (self.b - self.a) * 0.1\n",
    "        integral_range_end = self.b + (self.b - self.a) * 0.1\n",
    "        \n",
    "        step_size = (integral_range_end - integral_range_start) / num_samples\n",
    "        approx_integral = 0.0\n",
    "        \n",
    "        for i in range(num_samples):\n",
    "            x = integral_range_start + i * step_size\n",
    "            approx_integral += self(x) * step_size\n",
    "            \n",
    "        return approx_integral\n",
    "\n",
    "# --- 2. Define a Cumulative Distribution Function (CDF) ---\n",
    "\n",
    "class UniformCDF:\n",
    "    def __init__(self, lower_bound, upper_bound):\n",
    "        if lower_bound >= upper_bound:\n",
    "            raise ValueError(\"Lower bound must be less than upper bound.\")\n",
    "        self.a = lower_bound\n",
    "        self.b = upper_bound\n",
    "\n",
    "    def __call__(self, x):\n",
    "        \"\"\"\n",
    "        Evaluates the CDF at a given point x.\n",
    "        F(x) = 0 for x < a\n",
    "        F(x) = (x-a) / (b-a) for a <= x <= b\n",
    "        F(x) = 1 for x > b\n",
    "        \"\"\"\n",
    "        if x < self.a:\n",
    "            return 0.0\n",
    "        elif x > self.b:\n",
    "            return 1.0\n",
    "        else:\n",
    "            return (x - self.a) / (self.b - self.a)\n",
    "\n",
    "# --- 3. Demonstrating P(a <= X <= b) using PDF and CDF ---\n",
    "\n",
    "# Let's set up a Uniform Distribution from 0 to 1\n",
    "my_pdf = UniformPDF(lower_bound=0, upper_bound=1)\n",
    "my_cdf = UniformCDF(lower_bound=0, upper_bound=1)\n",
    "\n",
    "print(\"--- Continuous Probability Demonstration (Uniform Distribution) ---\")\n",
    "print(f\"Distribution: Uniform from {my_pdf.a} to {my_pdf.b}\")\n",
    "print(f\"PDF value f(x) = {my_pdf.density} for x in [{my_pdf.a}, {my_pdf.b}]\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Check PDF normalization (conceptual integral)\n",
    "print(\"1. Checking PDF Normalization (Integral f(x)dx = 1):\")\n",
    "num_integration_points = 100000\n",
    "approx_integral = my_pdf.check_normalization(num_integration_points)\n",
    "print(f\"Approximate integral of PDF: {approx_integral:.4f}\")\n",
    "if abs(approx_integral - 1.0) < 0.01: # Use a small tolerance for numerical approximation\n",
    "    print(\"PDF approximately integrates to 1 (passes check).\")\n",
    "else:\n",
    "    print(\"Warning: PDF does not integrate to 1 properly.\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Calculate P(a <= X <= b) using the PDF integral (approximation)\n",
    "print(\"2. Calculating P(a <= X <= b) using PDF (Numerical Integration):\")\n",
    "interval_start = 0.2\n",
    "interval_end = 0.7\n",
    "num_rectangles = 10000\n",
    "step_size_interval = (interval_end - interval_start) / num_rectangles\n",
    "prob_from_pdf_integral = 0.0\n",
    "\n",
    "for i in range(num_rectangles):\n",
    "    midpoint_x = interval_start + (i + 0.5) * step_size_interval\n",
    "    prob_from_pdf_integral += my_pdf(midpoint_x) * step_size_interval\n",
    "\n",
    "print(f\"P({interval_start} <= X <= {interval_end}) (via PDF integral): {prob_from_pdf_integral:.4f}\")\n",
    "# Analytical solution for Uniform(0,1): (0.7 - 0.2) * 1 = 0.5\n",
    "\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Calculate P(a <= X <= b) using the CDF\n",
    "print(\"3. Calculating P(a <= X <= b) using CDF:\")\n",
    "prob_from_cdf = my_cdf(interval_end) - my_cdf(interval_start)\n",
    "print(f\"P({interval_start} <= X <= {interval_end}) (via CDF): {prob_from_cdf:.4f}\")\n",
    "\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Demonstrate P(X = x) for continuous variable (should be 0)\n",
    "print(\"4. Demonstrating P(X = x) for a continuous variable:\")\n",
    "point_x = 0.5\n",
    "# Analytically, P(X = x) for any single point x is 0 for continuous distributions.\n",
    "# Our PDF function would return a non-zero value, but this is a density, not a probability.\n",
    "# The 'probability' of a single point is conceptualized as an integral from x to x, which is 0.\n",
    "print(f\"P(X = {point_x}) for a continuous variable is 0.\")\n",
    "print(f\"The PDF value f({point_x}) = {my_pdf(point_x)}. This is a density, not a probability.\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# --- 4. Multivariate CDF (Conceptual) ---\n",
    "# For a multivariate uniform distribution (e.g., in 2D)\n",
    "class MultiVariateUniformCDF:\n",
    "    def __init__(self, lower_bounds, upper_bounds):\n",
    "        if len(lower_bounds) != len(upper_bounds):\n",
    "            raise ValueError(\"Lower and upper bounds must have the same dimension.\")\n",
    "        self.lower_bounds = lower_bounds\n",
    "        self.upper_bounds = upper_bounds\n",
    "        self.dimension = len(lower_bounds)\n",
    "        \n",
    "        # Calculate volume for normalization (conceptual)\n",
    "        self.volume = 1.0\n",
    "        for i in range(self.dimension):\n",
    "            self.volume *= (upper_bounds[i] - lower_bounds[i])\n",
    "        \n",
    "        if self.volume == 0:\n",
    "            raise ValueError(\"Volume of the uniform space cannot be zero.\")\n",
    "\n",
    "    def __call__(self, x_vector):\n",
    "        \"\"\"\n",
    "        Evaluates the CDF at a given vector point x = [x1, ..., xD].\n",
    "        For a uniform distribution, this is the product of individual CDFs.\n",
    "        FX(x) = P(X1 <= x1, ..., XD <= xD)\n",
    "        \"\"\"\n",
    "        if len(x_vector) != self.dimension:\n",
    "            raise ValueError(f\"Input vector dimension ({len(x_vector)}) must match distribution dimension ({self.dimension}).\")\n",
    "            \n",
    "        cumulative_prob = 1.0\n",
    "        for i in range(self.dimension):\n",
    "            xi = x_vector[i]\n",
    "            ai = self.lower_bounds[i]\n",
    "            bi = self.upper_bounds[i]\n",
    "            \n",
    "            if xi < ai:\n",
    "                cumulative_prob *= 0.0 # Any dimension below its lower bound makes the total 0\n",
    "            elif xi > bi:\n",
    "                cumulative_prob *= 1.0 # Any dimension above its upper bound is fully covered\n",
    "            else:\n",
    "                cumulative_prob *= (xi - ai) / (bi - ai)\n",
    "                \n",
    "        return cumulative_prob\n",
    "\n",
    "print(\"5. Demonstrating Multivariate CDF (Conceptual Uniform in 2D):\")\n",
    "# Example for a 2D uniform distribution over [0,1] x [0,1]\n",
    "lower_bounds_2d = [0, 0]\n",
    "upper_bounds_2d = [1, 1]\n",
    "my_multivar_cdf = MultiVariateUniformCDF(lower_bounds_2d, upper_bounds_2d)\n",
    "\n",
    "test_point_2d = [0.5, 0.5]\n",
    "cdf_val_2d = my_multivar_cdf(test_point_2d)\n",
    "print(f\"F_X({test_point_2d}) = P(X1 <= {test_point_2d[0]}, X2 <= {test_point_2d[1]}) = {cdf_val_2d:.4f}\")\n",
    "# Expected for uniform [0,1]x[0,1]: (0.5-0)/(1-0) * (0.5-0)/(1-0) = 0.5 * 0.5 = 0.25\n",
    "\n",
    "test_point_2d_outside = [1.5, 0.5]\n",
    "cdf_val_2d_outside = my_multivar_cdf(test_point_2d_outside)\n",
    "print(f\"F_X({test_point_2d_outside}) = {cdf_val_2d_outside:.4f}\") # Expected: 1.0 * 0.5 = 0.5\n",
    "\n",
    "test_point_2d_all_outside = [1.5, 1.5]\n",
    "cdf_val_2d_all_outside = my_multivar_cdf(test_point_2d_all_outside)\n",
    "print(f\"F_X({test_point_2d_all_outside}) = {cdf_val_2d_all_outside:.4f}\") # Expected: 1.0 * 1.0 = 1.0\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(\"\\n--- Summary of Implementation ---\")\n",
    "print(\"This core Python implementation provides a conceptual understanding of PDFs and CDFs for continuous distributions.\")\n",
    "print(\"It uses a simple Uniform Distribution for clarity.\")\n",
    "print(\"Numerical integration is used to approximate integrals, highlighting the conceptual definition.\")\n",
    "print(\"For practical applications involving complex PDFs or accurate integration, libraries like NumPy and SciPy are indispensable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb318c4",
   "metadata": {},
   "source": [
    "# Discrete and Continuous Probabilities (Continued)\n",
    "\n",
    "### 6.2.3 Contrasting Discrete and Continuous Distributions\n",
    "\n",
    "Recall from Section 6.1.2 that probabilities are positive and the total probability sums up to one. For discrete random variables (see (6.12)), this implies that the probability of each state must lie in the interval $[0, 1]$. However, for continuous random variables the normalization (see (6.15)) does not imply that the value of the density is less than or equal to 1 for all values. We illustrate this in Figure 6.3 using the uniform distribution for both discrete and continuous random variables.\n",
    "\n",
    "### Example 3\n",
    "\n",
    "We consider two examples of the uniform distribution, where each state is equally likely to occur. This example illustrates some differences between discrete and continuous probability distributions.\n",
    "\n",
    "Let $Z$ be a discrete uniform random variable with three states $\\{z = -1.1, z = 0.3, z = 1.5\\}$. The probability mass function can be represented as a table of probability values:\n",
    "\n",
    "| $z$           | -1.1 | 0.3 | 1.5 |\n",
    "| :------------ | :--- | :-- | :-- |\n",
    "| $P(Z = z)$    | 1/3  | 1/3 | 1/3 |\n",
    "\n",
    "Alternatively, we can think of this as a graph (Figure 6.3(a)), where we use the fact that the states can be located on the x-axis, and the y-axis represents the probability of a particular state. The y-axis in Figure 6.3(a) is deliberately extended so that it is the same as in Figure 6.3(b).\n",
    "\n",
    "Let $X$ be a continuous random variable taking values in the range $0.9 \\le X \\le 1.6$, as represented by Figure 6.3(b). Observe that the height of the density can be greater than 1. However, it needs to hold that:\n",
    "\n",
    "$$\\int_{0.9}^{1.6} p(x)dx = 1 \\quad \\text{(6.19)}$$\n",
    "\n",
    "**Remark.** There is an additional subtlety with regards to discrete probability distributions. The states $z_1, \\ldots, z_d$ do not in principle have any structure, i.e., there is usually no way to compare them, for example $z_1 = \\text{red}, z_2 = \\text{green}, z_3 = \\text{blue}$. However, in many machine learning applications discrete states take numerical values, e.g., $z_1 = -1.1, z_2 = 0.3, z_3 = 1.5$, where we could say $z_1 < z_2 < z_3$. Discrete states that assume numerical values are particularly useful because we often consider expected values (Section 6.4.1) of random variables. $\\diamondsuit$\n",
    "\n",
    "Unfortunately, machine learning literature uses notation and nomenclature that hides the distinction between the sample space $\\Omega$, the target space $\\mathcal{T}$, and the random variable $X$. For a value $x$ of the set of possible outcomes of the random variable $X$, i.e., $x \\in \\mathcal{T}$, $p(x)$ denotes the probability that random variable $X$ has the outcome $x$. For discrete random variables, this is written as $P(X = x)$, which is known as the probability mass function. The pmf is often referred to as the “distribution”. For continuous variables, $p(x)$ is called the probability density function (often referred to as a density). To muddy things even further, the cumulative distribution function $P(X \\le x)$ is often also referred to as the “distribution”.\n",
    "\n",
    "We think of the outcome $x$ as the argument that results in the probability $p(x)$.\n",
    "\n",
    "In this chapter, we will use the notation $X$ to refer to both univariate and multivariate random variables, and denote the states by $x$ and $\\mathbf{x}$ respectively. We summarize the nomenclature in Table 6.1.\n",
    "\n",
    "---\n",
    "\n",
    "**Table 6.1: Nomenclature for Probability Distributions**\n",
    "\n",
    "| Type       | Point probability | Interval probability |\n",
    "| :--------- | :---------------- | :------------------- |\n",
    "| **Discrete** | $P(X = x)$        | Not applicable       |\n",
    "|            | Probability mass function |                      |\n",
    "| **Continuous** | $p(x)$            | $P(X \\le x)$         |\n",
    "|            | Probability density function | Cumulative distribution function |\n",
    "\n",
    "---\n",
    "\n",
    "**Remark.** We will be using the expression “probability distribution” not only for discrete probability mass functions but also for continuous probability density functions, although this is technically incorrect. In line with most machine learning literature, we also rely on context to distinguish the different uses of the phrase probability distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9e7718a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Example 6.3: Contrasting Discrete and Continuous Uniform Distributions ---\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "### Discrete Uniform Distribution (Z)\n",
      "States (Z): [-1.1, 0.3, 1.5]\n",
      "Number of states: 3\n",
      "Probability per state (1/3): 0.333\n",
      "\n",
      "--- Point Probabilities (P(Z = z)) ---\n",
      "P(Z = -1.1) = 0.333\n",
      "P(Z = 0.3) = 0.333\n",
      "P(Z = 1.5) = 0.333\n",
      "P(Z = 10.0) = 0.000 (for a state not in the set)\n",
      "Sum of P(Z=z) for all states = 1.000 (should be 1)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "### Continuous Uniform Distribution (X)\n",
      "Range (X): [0.9, 1.6]\n",
      "Density (1 / (b-a)): 1.429\n",
      "\n",
      "--- Point Densities (p(x)) ---\n",
      "p(X = 0.5) (density) = 0.000\n",
      "p(X = 1.0) (density) = 1.429\n",
      "p(X = 1.5) (density) = 1.429\n",
      "p(X = 2.0) (density) = 0.000\n",
      "\n",
      "--- Illustrating density > 1 ---\n",
      "For Uniform(0, 0.5): Density p(x) = 2.000 (which is > 1)\n",
      "Approximate integral for Uniform(0, 0.5): 1.000 (should be 1)\n",
      "\n",
      "--- Interval Probabilities (P(a <= X <= b)) ---\n",
      "P(1.0 <= X <= 1.2) = 0.286\n",
      "P(0.5 <= X <= 0.8) = 0.000\n",
      "P(0.8 <= X <= 1.7) = 1.000\n",
      "\n",
      "--- Point Probability for Continuous Variable ---\n",
      "P(X = 1.0) for a continuous variable is 0.\n",
      "The value p(1.0) = 1.429 is a density, not a probability.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "### Summary of Contrasts (as per Table 6.1):\n",
      "- **Discrete (Z):**\n",
      "  - Point Probability (P(Z=-1.1)): 0.333 (actual probability)\n",
      "  - Interval Probability: Not directly applicable as continuous interval.\n",
      "- **Continuous (X):**\n",
      "  - Probability Density Function (p(X=1.0)): 1.429 (a density, can be > 1)\n",
      "  - Point Probability (P(X=1.0)): 0 (for any single point)\n",
      "  - Interval Probability (P(1.0 <= X <= 1.2)): 0.286 (calculated by integrating density)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# --- 1. Discrete Uniform Distribution Class ---\n",
    "class DiscreteUniformDistribution:\n",
    "    def __init__(self, states):\n",
    "        if not states:\n",
    "            raise ValueError(\"States list cannot be empty for discrete distribution.\")\n",
    "        self.states = sorted(list(set(states))) # Ensure unique and sorted states\n",
    "        self.num_states = len(self.states)\n",
    "        self.probability_per_state = 1.0 / self.num_states\n",
    "\n",
    "    def pmf(self, x):\n",
    "        \"\"\"\n",
    "        Probability Mass Function (PMF) for a discrete uniform variable.\n",
    "        P(Z = z)\n",
    "        \"\"\"\n",
    "        if x in self.states:\n",
    "            return self.probability_per_state\n",
    "        else:\n",
    "            return 0.0 # Probability is 0 for states not in the defined set\n",
    "\n",
    "    def get_all_pmf_values(self):\n",
    "        \"\"\"Returns a dictionary of all states and their probabilities.\"\"\"\n",
    "        return {state: self.pmf(state) for state in self.states}\n",
    "\n",
    "# --- 2. Continuous Uniform Distribution Class ---\n",
    "class ContinuousUniformDistribution:\n",
    "    def __init__(self, lower_bound, upper_bound):\n",
    "        if lower_bound >= upper_bound:\n",
    "            raise ValueError(\"Lower bound must be less than upper bound for continuous distribution.\")\n",
    "        self.a = lower_bound\n",
    "        self.b = upper_bound\n",
    "        self.density = 1.0 / (self.b - self.a)\n",
    "\n",
    "    def pdf(self, x):\n",
    "        \"\"\"\n",
    "        Probability Density Function (PDF) for a continuous uniform variable.\n",
    "        p(x)\n",
    "        \"\"\"\n",
    "        if self.a <= x <= self.b:\n",
    "            return self.density\n",
    "        else:\n",
    "            return 0.0\n",
    "\n",
    "    def cdf(self, x):\n",
    "        \"\"\"\n",
    "        Cumulative Distribution Function (CDF) for a continuous uniform variable.\n",
    "        P(X <= x)\n",
    "        \"\"\"\n",
    "        if x < self.a:\n",
    "            return 0.0\n",
    "        elif x > self.b:\n",
    "            return 1.0\n",
    "        else:\n",
    "            return (x - self.a) / (self.b - self.a)\n",
    "\n",
    "    def prob_interval(self, start_interval, end_interval):\n",
    "        \"\"\"\n",
    "        Calculates P(start_interval <= X <= end_interval) for a continuous variable.\n",
    "        This is the integral of the PDF over the interval.\n",
    "        \"\"\"\n",
    "        if start_interval >= end_interval:\n",
    "            return 0.0\n",
    "        \n",
    "        # Adjust interval to be within the distribution's support\n",
    "        actual_start = max(self.a, start_interval)\n",
    "        actual_end = min(self.b, end_interval)\n",
    "\n",
    "        if actual_start >= actual_end:\n",
    "            return 0.0 # No overlap or invalid interval\n",
    "            \n",
    "        # For uniform distribution, integral is simply density * length of interval\n",
    "        return self.density * (actual_end - actual_start)\n",
    "\n",
    "# --- Demonstration and Contrasting Examples ---\n",
    "\n",
    "print(\"--- Example 6.3: Contrasting Discrete and Continuous Uniform Distributions ---\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# --- Discrete Uniform Distribution (Example 6.3a) ---\n",
    "print(\"\\n### Discrete Uniform Distribution (Z)\")\n",
    "discrete_states = [-1.1, 0.3, 1.5]\n",
    "discrete_dist = DiscreteUniformDistribution(discrete_states)\n",
    "\n",
    "print(f\"States (Z): {discrete_dist.states}\")\n",
    "print(f\"Number of states: {discrete_dist.num_states}\")\n",
    "print(f\"Probability per state (1/{discrete_dist.num_states}): {discrete_dist.probability_per_state:.3f}\")\n",
    "\n",
    "print(\"\\n--- Point Probabilities (P(Z = z)) ---\")\n",
    "for state in discrete_states:\n",
    "    prob = discrete_dist.pmf(state)\n",
    "    print(f\"P(Z = {state}) = {prob:.3f}\")\n",
    "\n",
    "# Point probability for a state not in the distribution\n",
    "print(f\"P(Z = 10.0) = {discrete_dist.pmf(10.0):.3f} (for a state not in the set)\")\n",
    "\n",
    "# Illustrate total probability sums to 1\n",
    "total_discrete_prob = sum(discrete_dist.get_all_pmf_values().values())\n",
    "print(f\"Sum of P(Z=z) for all states = {total_discrete_prob:.3f} (should be 1)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "\n",
    "# --- Continuous Uniform Distribution (Example 6.3b) ---\n",
    "print(\"\\n### Continuous Uniform Distribution (X)\")\n",
    "continuous_lower = 0.9\n",
    "continuous_upper = 1.6\n",
    "continuous_dist = ContinuousUniformDistribution(continuous_lower, continuous_upper)\n",
    "\n",
    "print(f\"Range (X): [{continuous_dist.a}, {continuous_dist.b}]\")\n",
    "print(f\"Density (1 / (b-a)): {continuous_dist.density:.3f}\")\n",
    "\n",
    "print(\"\\n--- Point Densities (p(x)) ---\")\n",
    "# Pick some points within and outside the range\n",
    "points_to_check_pdf = [0.5, 1.0, 1.5, 2.0]\n",
    "for point in points_to_check_pdf:\n",
    "    density_val = continuous_dist.pdf(point)\n",
    "    print(f\"p(X = {point}) (density) = {density_val:.3f}\")\n",
    "\n",
    "# Illustrate that density can be > 1\n",
    "# Let's create another continuous distribution with a smaller range\n",
    "narrow_continuous_dist = ContinuousUniformDistribution(0, 0.5) # Range length 0.5, density = 1/0.5 = 2.0\n",
    "print(f\"\\n--- Illustrating density > 1 ---\")\n",
    "print(f\"For Uniform(0, 0.5): Density p(x) = {narrow_continuous_dist.pdf(0.2):.3f} (which is > 1)\")\n",
    "# Check normalization for the narrow distribution\n",
    "approx_integral_narrow = (narrow_continuous_dist.b - narrow_continuous_dist.a) * narrow_continuous_dist.density\n",
    "print(f\"Approximate integral for Uniform(0, 0.5): {approx_integral_narrow:.3f} (should be 1)\")\n",
    "\n",
    "\n",
    "print(\"\\n--- Interval Probabilities (P(a <= X <= b)) ---\")\n",
    "interval1_start, interval1_end = 1.0, 1.2\n",
    "prob1 = continuous_dist.prob_interval(interval1_start, interval1_end)\n",
    "print(f\"P({interval1_start} <= X <= {interval1_end}) = {prob1:.3f}\")\n",
    "\n",
    "interval2_start, interval2_end = 0.5, 0.8 # Outside range\n",
    "prob2 = continuous_dist.prob_interval(interval2_start, interval2_end)\n",
    "print(f\"P({interval2_start} <= X <= {interval2_end}) = {prob2:.3f}\")\n",
    "\n",
    "interval3_start, interval3_end = 0.8, 1.7 # Overlapping range\n",
    "prob3 = continuous_dist.prob_interval(interval3_start, interval3_end)\n",
    "print(f\"P({interval3_start} <= X <= {interval3_end}) = {prob3:.3f}\")\n",
    "\n",
    "print(\"\\n--- Point Probability for Continuous Variable ---\")\n",
    "# As per text, P(X = x) for continuous variable is 0\n",
    "point_x_continuous = 1.0\n",
    "print(f\"P(X = {point_x_continuous}) for a continuous variable is 0.\")\n",
    "print(f\"The value p({point_x_continuous}) = {continuous_dist.pdf(point_x_continuous):.3f} is a density, not a probability.\")\n",
    "\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(\"\\n### Summary of Contrasts (as per Table 6.1):\")\n",
    "print(\"- **Discrete (Z):**\")\n",
    "print(f\"  - Point Probability (P(Z={discrete_states[0]})): {discrete_dist.pmf(discrete_states[0]):.3f} (actual probability)\")\n",
    "print(\"  - Interval Probability: Not directly applicable as continuous interval.\")\n",
    "print(\"- **Continuous (X):**\")\n",
    "print(f\"  - Probability Density Function (p(X={points_to_check_pdf[1]})): {continuous_dist.pdf(points_to_check_pdf[1]):.3f} (a density, can be > 1)\")\n",
    "print(f\"  - Point Probability (P(X={points_to_check_pdf[1]})): 0 (for any single point)\")\n",
    "print(f\"  - Interval Probability (P({interval1_start} <= X <= {interval1_end})): {prob1:.3f} (calculated by integrating density)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d5548e",
   "metadata": {},
   "source": [
    "# 6.3 Sum Rule, Product Rule, and Bayes’ Theorem\n",
    "\n",
    "We think of probability theory as an extension to logical reasoning. As we discussed in Section 6.1.1, the rules of probability presented here follow naturally from fulfilling the desiderata (Jaynes, 2003, chapter 2). Probabilistic modeling (Section 8.4) provides a principled foundation for designing machine learning methods. Once we have defined probability distributions (Section 6.2) corresponding to the uncertainties of the data and our problem, it turns out that there are only two fundamental rules, the sum rule and the product rule.\n",
    "\n",
    "Recall from (6.9) that $p(x, y)$ is the joint distribution of the two random variables $x, y$. The distributions $p(x)$ and $p(y)$ are the corresponding marginal distributions, and $p(y | x)$ is the conditional distribution of $y$ given $x$. Given the definitions of the marginal and conditional probability for discrete and continuous random variables in Section 6.2, we can now present the two fundamental rules in probability theory.\n",
    "\n",
    "The first rule, the **sum rule**, states that:\n",
    "\n",
    "$$ p(x) = \\begin{cases} \\sum_{y \\in \\mathcal{Y}} p(x, y) & \\text{if } y \\text{ is discrete} \\\\ \\int_{\\mathcal{Y}} p(x, y) dy & \\text{if } y \\text{ is continuous} \\end{cases} \\quad \\text{(6.20)}$$\n",
    "\n",
    "where $\\mathcal{Y}$ are the states of the target space of random variable $Y$. This means that we sum out (or integrate out) the set of states $y$ of the random variable $Y$. The sum rule is also known as the **marginalization property**. The sum rule relates the joint distribution to a marginal distribution. In general, when the joint distribution contains more than two random variables, the sum rule can be applied to any subset of the random variables, resulting in a marginal distribution of potentially more than one random variable. More concretely, if $\\mathbf{x} = [x_1, \\ldots, x_D]^\\top$, we obtain the marginal:\n",
    "\n",
    "$$p(x_i) = \\int p(x_1, \\ldots, x_D) d\\mathbf{x}_{\\setminus i} \\quad \\text{(6.21)}$$\n",
    "\n",
    "by repeated application of the sum rule where we integrate/sum out all random variables except $x_i$, which is indicated by $\\setminus i$, which reads “all except $i$.”\n",
    "\n",
    "**Remark.** Many of the computational challenges of probabilistic modeling are due to the application of the sum rule. When there are many variables or discrete variables with many states, the sum rule boils down to performing a high-dimensional sum or integral. Performing high-dimensional sums or integrals is generally computationally hard, in the sense that there is no known polynomial-time algorithm to calculate them exactly. $\\diamondsuit$\n",
    "\n",
    "The second rule, known as the **product rule**, relates the joint distribution to the conditional distribution via:\n",
    "\n",
    "$$p(x, y) = p(y | x)p(x) \\quad \\text{(6.22)}$$\n",
    "\n",
    "The product rule can be interpreted as the fact that every joint distribution of two random variables can be factorized (written as a product) of two other distributions. The two factors are the marginal distribution of the first random variable $p(x)$, and the conditional distribution of the second random variable given the first $p(y | x)$. Since the ordering of random variables is arbitrary in $p(x, y)$, the product rule also implies $p(x, y) = p(x | y)p(y)$. To be precise, (6.22) is expressed in terms of the probability mass functions for discrete random variables. For continuous random variables, the product rule is expressed in terms of the probability density functions (Section 6.2.3).\n",
    "\n",
    "In machine learning and Bayesian statistics, we are often interested in making inferences of unobserved (latent) random variables given that we have observed other random variables. Let us assume we have some prior knowledge $p(x)$ about an unobserved random variable $x$ and some relationship $p(y | x)$ between $x$ and a second random variable $y$, which we can observe. If we observe $y$, we can use Bayes’ theorem to draw some conclusions about $x$ given the observed values of $y$.\n",
    "\n",
    "**Bayes’ theorem** (also Bayes’ rule or Bayes’ law):\n",
    "\n",
    "$$p(x | y) = \\frac{\\overbrace{p(y | x)}^{\\text{likelihood}} \\overbrace{p(x)}^{\\text{prior}}}{\\underbrace{p(y)}_{\\text{evidence}}} \\quad \\text{(6.23)}$$\n",
    "\n",
    "is a direct consequence of the product rule in (6.22) since:\n",
    "\n",
    "$$p(x, y) = p(x | y)p(y) \\quad \\text{(6.24)}$$\n",
    "\n",
    "and\n",
    "\n",
    "$$p(x, y) = p(y | x)p(x) \\quad \\text{(6.25)}$$\n",
    "\n",
    "so that:\n",
    "\n",
    "$$p(x | y)p(y) = p(y | x)p(x) \\quad \\iff \\quad p(x | y) = \\frac{p(y | x)p(x)}{p(y)} \\quad \\text{(6.26)}$$\n",
    "\n",
    "In (6.23), $p(x)$ is the **prior**, which encapsulates our subjective prior knowledge of the unobserved (latent) variable $x$ before observing any data. We can choose any prior that makes sense to us, but it is critical to ensure that the prior has a nonzero pdf (or pmf) on all plausible $x$, even if they are very rare. The likelihood $p(y | x)$ describes how $x$ and $y$ are related, and in the case of discrete probability distributions, it is the probability of the data $y$ if we were to know the latent variable $x$. Note that the likelihood is not a distribution in $x$, but only in $y$. We call $p(y | x)$ either the “likelihood of $x$ (given $y$)” or the “probability of $y$ given $x$” but never the likelihood of $y$ (MacKay, 2003). The **posterior** $p(x | y)$ is the quantity of interest in Bayesian statistics because it expresses exactly what we are interested in, i.e., what we know about $x$ after having observed $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5dca995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Joint Probability Distribution P(X, Y) ---\n",
      "Joint Probabilities:\n",
      "P(X=Sunny, Y=Hiking) = 0.30\n",
      "P(X=Sunny, Y=Shopping) = 0.10\n",
      "P(X=Cloudy, Y=Hiking) = 0.15\n",
      "P(X=Cloudy, Y=Shopping) = 0.25\n",
      "P(X=Rainy, Y=Hiking) = 0.05\n",
      "P(X=Rainy, Y=Shopping) = 0.15\n",
      "Sum of joint probabilities: 1.00 (should be 1.0)\n",
      "Joint probabilities are normalized.\n",
      "--------------------------------------------------\n",
      "--- 2. Sum Rule (Marginal Probabilities) ---\n",
      "P(X) - Marginal Probability of Weather:\n",
      "P(X=Cloudy) = 0.40\n",
      "P(X=Rainy) = 0.20\n",
      "P(X=Sunny) = 0.40\n",
      "Sum P(X): 1.00\n",
      "\n",
      "P(Y) - Marginal Probability of Activity:\n",
      "P(Y=Hiking) = 0.50\n",
      "P(Y=Shopping) = 0.50\n",
      "Sum P(Y): 1.00\n",
      "--------------------------------------------------\n",
      "--- 3. Product Rule (Conditional Probabilities) ---\n",
      "P(Y | X) - Probability of Activity given Weather:\n",
      "P(Y=Hiking | X=Cloudy) = 0.37\n",
      "P(Y=Shopping | X=Cloudy) = 0.62\n",
      "  Sum for X=Cloudy: 1.00 (should be 1.0)\n",
      "P(Y=Hiking | X=Rainy) = 0.25\n",
      "P(Y=Shopping | X=Rainy) = 0.75\n",
      "  Sum for X=Rainy: 1.00 (should be 1.0)\n",
      "P(Y=Hiking | X=Sunny) = 0.75\n",
      "P(Y=Shopping | X=Sunny) = 0.25\n",
      "  Sum for X=Sunny: 1.00 (should be 1.0)\n",
      "\n",
      "P(X | Y) - Probability of Weather given Activity:\n",
      "P(X=Cloudy | Y=Hiking) = 0.30\n",
      "P(X=Rainy | Y=Hiking) = 0.10\n",
      "P(X=Sunny | Y=Hiking) = 0.60\n",
      "  Sum for Y=Hiking: 1.00 (should be 1.0)\n",
      "P(X=Cloudy | Y=Shopping) = 0.50\n",
      "P(X=Rainy | Y=Shopping) = 0.30\n",
      "P(X=Sunny | Y=Shopping) = 0.20\n",
      "  Sum for Y=Shopping: 1.00 (should be 1.0)\n",
      "--------------------------------------------------\n",
      "--- 4. Bayes' Theorem ---\n",
      "Calculating P(X='Sunny' | Y='Shopping') using Bayes' Theorem:\n",
      "  Prior P(X='Sunny'): 0.40\n",
      "  Likelihood P(Y='Shopping' | X='Sunny'): 0.25\n",
      "  Evidence P(Y='Shopping'): 0.50\n",
      "  Posterior P(X='Sunny' | Y='Shopping') = (0.25 * 0.4) / 0.5 = 0.20\n",
      "  (Directly calculated P(X='Sunny' | Y='Shopping') = 0.20)\n",
      "  Bayes' Theorem calculation matches direct conditional probability (consistent).\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Bayes' Theorem Function Demonstration ---\n",
      "P(X='Rainy' | Y='Hiking') (using function) = 0.10\n",
      "(Directly calculated P(X='Rainy' | Y='Hiking') = 0.10)\n",
      "Function result matches direct calculation.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Define the Joint Probability Distribution P(X, Y) ---\n",
    "# This is our starting point, representing p(x, y)\n",
    "# The keys are tuples (weather, activity) and values are probabilities.\n",
    "# These probabilities must sum to 1.0.\n",
    "\n",
    "joint_prob_table = {\n",
    "    ('Sunny', 'Hiking'): 0.30,\n",
    "    ('Sunny', 'Shopping'): 0.10,\n",
    "    ('Cloudy', 'Hiking'): 0.15,\n",
    "    ('Cloudy', 'Shopping'): 0.25,\n",
    "    ('Rainy', 'Hiking'): 0.05,\n",
    "    ('Rainy', 'Shopping'): 0.15\n",
    "}\n",
    "\n",
    "# Extract unique states for X and Y for easier iteration\n",
    "x_states = sorted(list(set(item[0] for item in joint_prob_table.keys())))\n",
    "y_states = sorted(list(set(item[1] for item in joint_prob_table.keys())))\n",
    "\n",
    "print(\"--- 1. Joint Probability Distribution P(X, Y) ---\")\n",
    "print(\"Joint Probabilities:\")\n",
    "for (x, y), prob in joint_prob_table.items():\n",
    "    print(f\"P(X={x}, Y={y}) = {prob:.2f}\")\n",
    "\n",
    "total_joint_prob = sum(joint_prob_table.values())\n",
    "print(f\"Sum of joint probabilities: {total_joint_prob:.2f} (should be 1.0)\")\n",
    "if abs(total_joint_prob - 1.0) < 1e-9:\n",
    "    print(\"Joint probabilities are normalized.\")\n",
    "else:\n",
    "    print(\"Error: Joint probabilities do not sum to 1.0.\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# --- 2. Implement the Sum Rule (Marginalization) ---\n",
    "# p(x) = sum_y p(x, y)\n",
    "# p(y) = sum_x p(x, y)\n",
    "\n",
    "marginal_px = {}\n",
    "for x in x_states:\n",
    "    marginal_px[x] = sum(prob for (wx, wy), prob in joint_prob_table.items() if wx == x)\n",
    "\n",
    "marginal_py = {}\n",
    "for y in y_states:\n",
    "    marginal_py[y] = sum(prob for (wx, wy), prob in joint_prob_table.items() if wy == y)\n",
    "\n",
    "print(\"--- 2. Sum Rule (Marginal Probabilities) ---\")\n",
    "print(\"P(X) - Marginal Probability of Weather:\")\n",
    "for x, prob in marginal_px.items():\n",
    "    print(f\"P(X={x}) = {prob:.2f}\")\n",
    "print(f\"Sum P(X): {sum(marginal_px.values()):.2f}\")\n",
    "\n",
    "print(\"\\nP(Y) - Marginal Probability of Activity:\")\n",
    "for y, prob in marginal_py.items():\n",
    "    print(f\"P(Y={y}) = {prob:.2f}\")\n",
    "print(f\"Sum P(Y): {sum(marginal_py.values()):.2f}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# --- 3. Implement the Product Rule ---\n",
    "# p(x, y) = p(y | x) * p(x)  OR  p(x, y) = p(x | y) * p(y)\n",
    "# From this, we can derive conditional probabilities:\n",
    "# p(y | x) = p(x, y) / p(x)\n",
    "# p(x | y) = p(x, y) / p(y)\n",
    "\n",
    "conditional_py_given_x = {}\n",
    "print(\"--- 3. Product Rule (Conditional Probabilities) ---\")\n",
    "print(\"P(Y | X) - Probability of Activity given Weather:\")\n",
    "for x in x_states:\n",
    "    if marginal_px[x] == 0:\n",
    "        print(f\"Cannot compute P(Y | X={x}) as P(X={x}) is zero.\")\n",
    "        continue\n",
    "    for y in y_states:\n",
    "        joint_prob = joint_prob_table[(x, y)]\n",
    "        cond_prob = joint_prob / marginal_px[x]\n",
    "        conditional_py_given_x[(y, x)] = cond_prob\n",
    "        print(f\"P(Y={y} | X={x}) = {cond_prob:.2f}\")\n",
    "    # Verify sum for each condition\n",
    "    current_sum = sum(conditional_py_given_x[(y, x)] for y in y_states)\n",
    "    print(f\"  Sum for X={x}: {current_sum:.2f} (should be 1.0)\")\n",
    "\n",
    "print(\"\\nP(X | Y) - Probability of Weather given Activity:\")\n",
    "conditional_px_given_y = {}\n",
    "for y in y_states:\n",
    "    if marginal_py[y] == 0:\n",
    "        print(f\"Cannot compute P(X | Y={y}) as P(Y={y}) is zero.\")\n",
    "        continue\n",
    "    for x in x_states:\n",
    "        joint_prob = joint_prob_table[(x, y)]\n",
    "        cond_prob = joint_prob / marginal_py[y]\n",
    "        conditional_px_given_y[(x, y)] = cond_prob\n",
    "        print(f\"P(X={x} | Y={y}) = {cond_prob:.2f}\")\n",
    "    # Verify sum for each condition\n",
    "    current_sum = sum(conditional_px_given_y[(x, y)] for x in x_states)\n",
    "    print(f\"  Sum for Y={y}: {current_sum:.2f} (should be 1.0)\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# --- 4. Implement Bayes' Theorem ---\n",
    "# P(X | Y) = [P(Y | X) * P(X)] / P(Y)\n",
    "# Let's calculate P(X='Sunny' | Y='Shopping') using Bayes' Theorem\n",
    "# We need:\n",
    "#   P(Y='Shopping' | X='Sunny') (likelihood)\n",
    "#   P(X='Sunny') (prior)\n",
    "#   P(Y='Shopping') (evidence)\n",
    "\n",
    "# Example: What's the probability it was Sunny given that someone went Shopping?\n",
    "target_x = 'Sunny'\n",
    "observed_y = 'Shopping'\n",
    "\n",
    "# Get components for Bayes' Theorem\n",
    "prior_px = marginal_px[target_x]\n",
    "likelihood_py_given_x = conditional_py_given_x[(observed_y, target_x)]\n",
    "evidence_py = marginal_py[observed_y]\n",
    "\n",
    "print(\"--- 4. Bayes' Theorem ---\")\n",
    "print(f\"Calculating P(X='{target_x}' | Y='{observed_y}') using Bayes' Theorem:\")\n",
    "print(f\"  Prior P(X='{target_x}'): {prior_px:.2f}\")\n",
    "print(f\"  Likelihood P(Y='{observed_y}' | X='{target_x}'): {likelihood_py_given_x:.2f}\")\n",
    "print(f\"  Evidence P(Y='{observed_y}'): {evidence_py:.2f}\")\n",
    "\n",
    "if evidence_py == 0:\n",
    "    print(\"Cannot apply Bayes' Theorem: Evidence P(Y) is zero.\")\n",
    "else:\n",
    "    posterior_px_given_y_bayes = (likelihood_py_given_x * prior_px) / evidence_py\n",
    "    print(f\"  Posterior P(X='{target_x}' | Y='{observed_y}') = ({likelihood_py_given_x} * {prior_px}) / {evidence_py} = {posterior_px_given_y_bayes:.2f}\")\n",
    "\n",
    "    # Verify with direct calculation from product rule (should match)\n",
    "    direct_px_given_y = conditional_px_given_y[(target_x, observed_y)]\n",
    "    print(f\"  (Directly calculated P(X='{target_x}' | Y='{observed_y}') = {direct_px_given_y:.2f})\")\n",
    "\n",
    "    if abs(posterior_px_given_y_bayes - direct_px_given_y) < 1e-9:\n",
    "        print(\"  Bayes' Theorem calculation matches direct conditional probability (consistent).\")\n",
    "    else:\n",
    "        print(\"  Error: Bayes' Theorem calculation does NOT match direct conditional probability.\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# --- General Function for Bayes' Theorem ---\n",
    "def bayes_theorem(prior_dist, likelihood_dist, evidence_dist, x_val, y_val):\n",
    "    \"\"\"\n",
    "    Applies Bayes' Theorem for discrete variables.\n",
    "    P(X=x_val | Y=y_val) = [P(Y=y_val | X=x_val) * P(X=x_val)] / P(Y=y_val)\n",
    "\n",
    "    Args:\n",
    "        prior_dist (dict): Dictionary of P(X) for all x states.\n",
    "        likelihood_dist (dict): Dictionary of P(Y|X) for all (y,x) pairs.\n",
    "                                Keys are (y_state, x_state).\n",
    "        evidence_dist (dict): Dictionary of P(Y) for all y states.\n",
    "        x_val (str): The specific x state for which to calculate the posterior.\n",
    "        y_val (str): The specific y state that was observed.\n",
    "\n",
    "    Returns:\n",
    "        float: The posterior probability P(X=x_val | Y=y_val), or None if evidence is zero.\n",
    "    \"\"\"\n",
    "    prior = prior_dist.get(x_val)\n",
    "    likelihood = likelihood_dist.get((y_val, x_val))\n",
    "    evidence = evidence_dist.get(y_val)\n",
    "\n",
    "    if prior is None:\n",
    "        print(f\"Error: Prior for X='{x_val}' not found.\")\n",
    "        return None\n",
    "    if likelihood is None:\n",
    "        print(f\"Error: Likelihood for Y='{y_val}' given X='{x_val}' not found.\")\n",
    "        return None\n",
    "    if evidence is None:\n",
    "        print(f\"Error: Evidence for Y='{y_val}' not found.\")\n",
    "        return None\n",
    "    \n",
    "    if evidence == 0:\n",
    "        print(f\"Error: Evidence P(Y='{y_val}') is zero, cannot apply Bayes' Theorem.\")\n",
    "        return None\n",
    "    \n",
    "    return (likelihood * prior) / evidence\n",
    "\n",
    "print(\"\\n--- Bayes' Theorem Function Demonstration ---\")\n",
    "# Let's try another example: P(X='Rainy' | Y='Hiking')\n",
    "target_x_2 = 'Rainy'\n",
    "observed_y_2 = 'Hiking'\n",
    "\n",
    "posterior_2 = bayes_theorem(marginal_px, conditional_py_given_x, marginal_py, target_x_2, observed_y_2)\n",
    "\n",
    "if posterior_2 is not None:\n",
    "    print(f\"P(X='{target_x_2}' | Y='{observed_y_2}') (using function) = {posterior_2:.2f}\")\n",
    "    # Verify\n",
    "    direct_2 = conditional_px_given_y[(target_x_2, observed_y_2)]\n",
    "    print(f\"(Directly calculated P(X='{target_x_2}' | Y='{observed_y_2}') = {direct_2:.2f})\")\n",
    "    if abs(posterior_2 - direct_2) < 1e-9:\n",
    "        print(\"Function result matches direct calculation.\")\n",
    "    else:\n",
    "        print(\"Function result does NOT match direct calculation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769f440e",
   "metadata": {},
   "source": [
    "##  Sum Rule, Product Rule, and Bayes’ Theorem (Continued)\n",
    "\n",
    "The quantity:\n",
    "\n",
    "$$p(y) := \\int p(y | x)p(x)dx = \\mathbb{E}_X [p(y | x)] \\quad \\text{(6.27)}$$\n",
    "\n",
    "is the **marginal likelihood** / **evidence**. The right-hand side of (6.27) uses the expectation operator which we define in Section 6.4.1. By definition, the marginal likelihood integrates the numerator of (6.23) with respect to the latent variable $x$. Therefore, the marginal likelihood is independent of $x$, and it ensures that the posterior $p(x | y)$ is normalized. The marginal likelihood can also be interpreted as the expected likelihood where we take the expectation with respect to the prior $p(x)$. Beyond normalization of the posterior, the marginal likelihood also plays an important role in Bayesian model selection, as we will discuss in Section 8.6. Due to the integration in (8.44), the evidence is often hard to compute.\n",
    "\n",
    "Bayes’ theorem (6.23) allows us to invert the relationship between $x$ and $y$ given by the likelihood. Therefore, Bayes’ theorem is sometimes called the **probabilistic inverse**. We will discuss Bayes’ theorem further in Section 8.4.\n",
    "\n",
    "**Remark.** In Bayesian statistics, the posterior distribution is the quantity of interest as it encapsulates all available information from the prior and the data. Instead of carrying the posterior around, it is possible to focus on some statistic of the posterior, such as the maximum of the posterior, which we will discuss in Section 8.3. However, focusing on some statistic of the posterior leads to loss of information. If we think in a bigger context, then the posterior can be used within a decision-making system, and having the full posterior can be extremely useful and lead to decisions that are robust to disturbances. For example, in the context of model-based reinforcement learning, Deisenroth et al. (2015) show that using the full posterior distribution of plausible transition functions leads to very fast (data/sample efficient) learning, whereas focusing on the maximum of the posterior leads to consistent failures. Therefore, having the full posterior can be very useful for a downstream task. In Chapter 9, we will continue this discussion in the context of linear regression. $\\diamondsuit$\n",
    "\n",
    "##  Summary Statistics and Independence\n",
    "\n",
    "We are often interested in summarizing sets of random variables and comparing pairs of random variables. A **statistic** of a random variable is a deterministic function of that random variable. The **summary statistics** of a distribution provide one useful view of how a random variable behaves, and as the name suggests, provide numbers that summarize and characterize the distribution. We describe the mean and the variance, two well-known summary statistics. Then we discuss two ways to compare a pair of random variables: first, how to say that two random variables are independent; and second, how to compute an inner product between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8f7d570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Marginal Likelihood / Evidence (for Discrete Variables) ---\n",
      "Calculating P(Y='Shopping') as Evidence using sum_x P(Y='Shopping'|X=x) * P(X=x):\n",
      "  P(Y='Shopping'|X='Cloudy') * P(X='Cloudy') = 0.62 * 0.40 = 0.25\n",
      "  P(Y='Shopping'|X='Rainy') * P(X='Rainy') = 0.75 * 0.20 = 0.15\n",
      "  P(Y='Shopping'|X='Sunny') * P(X='Sunny') = 0.25 * 0.40 = 0.10\n",
      "Marginal Likelihood / Evidence P(Y='Shopping') = 0.50\n",
      "(Matches previously calculated marginal P(Y='Shopping') = 0.50)\n",
      "--------------------------------------------------\n",
      "\n",
      "--- 2. Summary Statistics: Mean (Expected Value) ---\n",
      "Random Variable X (Number of Heads): States=[0, 1, 2], PMF={0: 0.49, 1: 0.42, 2: 0.09}\n",
      "Mean E[X] = 0.600\n",
      "--------------------------------------------------\n",
      "\n",
      "--- 3. Summary Statistics: Variance ---\n",
      "Variance Var(X) = 0.420\n",
      "--------------------------------------------------\n",
      "\n",
      "--- 4. Independence Check ---\n",
      "Checking if Weather (X) and Activity (Y) are independent:\n",
      "  P(X=Cloudy, Y=Hiking) = 0.15\n",
      "  P(X=Cloudy) * P(Y=Hiking) = 0.40 * 0.50 = 0.20\n",
      "  --> Mismatch found for (X=Cloudy, Y=Hiking). Joint(0.15) != Product Marginals(0.20)\n",
      "\n",
      "Conclusion: X and Y are NOT independent.\n",
      "This is expected given our sample data, as weather likely influences activity choices.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- Reuse the Joint Probability Distribution and Marginals from previous example ---\n",
    "\n",
    "joint_prob_table = {\n",
    "    ('Sunny', 'Hiking'): 0.30,\n",
    "    ('Sunny', 'Shopping'): 0.10,\n",
    "    ('Cloudy', 'Hiking'): 0.15,\n",
    "    ('Cloudy', 'Shopping'): 0.25,\n",
    "    ('Rainy', 'Hiking'): 0.05,\n",
    "    ('Rainy', 'Shopping'): 0.15\n",
    "}\n",
    "\n",
    "x_states = sorted(list(set(item[0] for item in joint_prob_table.keys())))\n",
    "y_states = sorted(list(set(item[1] for item in joint_prob_table.keys())))\n",
    "\n",
    "# Calculate marginals (Sum Rule) - these are needed for evidence and independence check\n",
    "marginal_px = {}\n",
    "for x in x_states:\n",
    "    marginal_px[x] = sum(prob for (wx, wy), prob in joint_prob_table.items() if wx == x)\n",
    "\n",
    "marginal_py = {}\n",
    "for y in y_states:\n",
    "    marginal_py[y] = sum(prob for (wx, wy), prob in joint_prob_table.items() if wy == y)\n",
    "\n",
    "# Calculate conditional P(Y | X) - needed for Bayes' Theorem interpretation\n",
    "conditional_py_given_x = {}\n",
    "for x in x_states:\n",
    "    if marginal_px[x] == 0:\n",
    "        continue\n",
    "    for y in y_states:\n",
    "        joint_prob = joint_prob_table[(x, y)]\n",
    "        cond_prob = joint_prob / marginal_px[x]\n",
    "        conditional_py_given_x[(y, x)] = cond_prob\n",
    "\n",
    "\n",
    "print(\"--- 1. Marginal Likelihood / Evidence (for Discrete Variables) ---\")\n",
    "# For discrete variables, p(y) = sum_x p(y|x)p(x)\n",
    "# We already calculated P(Y) which is the evidence.\n",
    "# Let's demonstrate it by manually calculating one for 'Shopping'.\n",
    "\n",
    "observed_y_val = 'Shopping'\n",
    "evidence_calc = 0.0\n",
    "print(f\"Calculating P(Y='{observed_y_val}') as Evidence using sum_x P(Y='{observed_y_val}'|X=x) * P(X=x):\")\n",
    "for x_state in x_states:\n",
    "    prior_x = marginal_px[x_state]\n",
    "    likelihood_y_given_x = conditional_py_given_x.get((observed_y_val, x_state), 0) # Use .get with default 0 in case of missing key\n",
    "    term = likelihood_y_given_x * prior_x\n",
    "    evidence_calc += term\n",
    "    print(f\"  P(Y='{observed_y_val}'|X='{x_state}') * P(X='{x_state}') = {likelihood_y_given_x:.2f} * {prior_x:.2f} = {term:.2f}\")\n",
    "\n",
    "print(f\"Marginal Likelihood / Evidence P(Y='{observed_y_val}') = {evidence_calc:.2f}\")\n",
    "print(f\"(Matches previously calculated marginal P(Y='{observed_y_val}') = {marginal_py.get(observed_y_val, 0):.2f})\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# --- 2. Summary Statistics: Mean (Expected Value) ---\n",
    "# For discrete random variable X with states x_i and probabilities p(x_i):\n",
    "# E[X] = sum_i x_i * p(x_i)\n",
    "# This example requires numerical states for X. Let's create a new discrete variable.\n",
    "\n",
    "# Example: X = number of heads in 2 coin tosses (from Section 6.1.2)\n",
    "# States: {0, 1, 2}\n",
    "# Probabilities: P(X=0)=0.49, P(X=1)=0.42, P(X=2)=0.09 (from Example 6.1)\n",
    "coin_toss_x_states = [0, 1, 2]\n",
    "coin_toss_pmf = {0: 0.49, 1: 0.42, 2: 0.09}\n",
    "\n",
    "def calculate_mean(states, pmf):\n",
    "    \"\"\"Calculates the mean (expected value) for a discrete random variable.\"\"\"\n",
    "    expected_value = 0.0\n",
    "    for state in states:\n",
    "        expected_value += state * pmf.get(state, 0)\n",
    "    return expected_value\n",
    "\n",
    "print(\"\\n--- 2. Summary Statistics: Mean (Expected Value) ---\")\n",
    "mean_coin_toss = calculate_mean(coin_toss_x_states, coin_toss_pmf)\n",
    "print(f\"Random Variable X (Number of Heads): States={coin_toss_x_states}, PMF={coin_toss_pmf}\")\n",
    "print(f\"Mean E[X] = {mean_coin_toss:.3f}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# --- 3. Summary Statistics: Variance ---\n",
    "# Var(X) = E[(X - E[X])^2] = sum_i (x_i - E[X])^2 * p(x_i)\n",
    "\n",
    "def calculate_variance(states, pmf, mean_val):\n",
    "    \"\"\"Calculates the variance for a discrete random variable.\"\"\"\n",
    "    variance = 0.0\n",
    "    for state in states:\n",
    "        variance += ((state - mean_val)**2) * pmf.get(state, 0)\n",
    "    return variance\n",
    "\n",
    "print(\"\\n--- 3. Summary Statistics: Variance ---\")\n",
    "variance_coin_toss = calculate_variance(coin_toss_x_states, coin_toss_pmf, mean_coin_toss)\n",
    "print(f\"Variance Var(X) = {variance_coin_toss:.3f}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# --- 4. Independence ---\n",
    "# Two random variables X and Y are independent if and only if:\n",
    "# P(X=x, Y=y) = P(X=x) * P(Y=y) for all x and y.\n",
    "\n",
    "print(\"\\n--- 4. Independence Check ---\")\n",
    "print(\"Checking if Weather (X) and Activity (Y) are independent:\")\n",
    "are_independent = True\n",
    "for x in x_states:\n",
    "    for y in y_states:\n",
    "        joint = joint_prob_table[(x, y)]\n",
    "        product_marginals = marginal_px[x] * marginal_py[y]\n",
    "        \n",
    "        print(f\"  P(X={x}, Y={y}) = {joint:.2f}\")\n",
    "        print(f\"  P(X={x}) * P(Y={y}) = {marginal_px[x]:.2f} * {marginal_py[y]:.2f} = {product_marginals:.2f}\")\n",
    "        \n",
    "        if abs(joint - product_marginals) > 1e-9: # Use a small tolerance for float comparison\n",
    "            print(f\"  --> Mismatch found for (X={x}, Y={y}). Joint({joint:.2f}) != Product Marginals({product_marginals:.2f})\")\n",
    "            are_independent = False\n",
    "            # We can break here since we found a single case of non-independence\n",
    "            break\n",
    "    if not are_independent:\n",
    "        break\n",
    "\n",
    "if are_independent:\n",
    "    print(\"\\nConclusion: X and Y are independent.\")\n",
    "else:\n",
    "    print(\"\\nConclusion: X and Y are NOT independent.\")\n",
    "    print(\"This is expected given our sample data, as weather likely influences activity choices.\")\n",
    "\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95304725",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
