{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c79dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " * Copyright (c) 2016 Radhamadhab Dalai\n",
    " *\n",
    " * Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    " * of this software and associated documentation files (the \"Software\"), to deal\n",
    " * in the Software without restriction, including without limitation the rights\n",
    " * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    " * copies of the Software, and to permit persons to whom the Software is\n",
    " * furnished to do so, subject to the following conditions:\n",
    " *\n",
    " * The above copyright notice and this permission notice shall be included in\n",
    " * all copies or substantial portions of the Software.\n",
    " *\n",
    " * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    " * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    " * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    " * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    " * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    " * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
    " * THE SOFTWARE.\n",
    "'''"
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "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"
    },
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEwAAAAuCAIAAAANyWgtAAACqElEQVRoBe1az2sTQRSev0L7V8xVUISCBfESPGj3IEVQ7EEwl6S5VJGAXpxiLpV6WQiU0ChKmtY9RUwoCy3+SGQ10ZKaSJMsNAeTJnUTEnSkrGySTQvbnR1ml+myh5nHzHvv2+/Ne7OzCzAHF+AAIz4FyY7lWrNea9adsj/CZL/vlFpSPVJBhkiYfflo40e2pXUJ1Q1Abu58h0h4vrmOMnGIhFKj6RMDPjGQKioQCamiostzagUi4Tg5ysSN8f5EBCJBHz8s94kBXT9EAsrEY9m0rl83V2o0IRLuvnoCkeBPRJL5rQdh50BKEr44+Udtd9xw59RKTq2o7c7OXhcATBhiAyYhxADgL+WuG0AaPiyKPQBwLEYUsP9BKsohQgBwcL5vGHBD48zZvwDgiQknQOo6AMBuAGbyQZaJEGI8WifdCRIMlpRNtCMK3AmSCyYhtEmgMc0DTBJmHW+syYMDgxKbDQ8wyUXiCYdtEmhM8wCThNudY9fk8uvVj9+KpqLMqksrXGdu3X6f32aFymSXVp08d/7Cyur6ohg12WPSpVInldLu9I2ZjU+fb96ZZYLKZJQKyFK9cS8wF7r/MPMha7LHpEurTlb3tVpLYwJp3CitxDNuiaGEizrJBUguwrVcNvZnNhse2NZRKSEMc8yRprkAWSf+XOCBcOUi8XBRQrgAyUW40tqgH5nKHRGuvU0vPFvyB0PbtT2LCr1XQianpnZ/tS5dvmL9Lcd7IP3BkLjy4ur1aYs0qu0OreMP6x6caOTXn9V48s3jhadL0WXrEz2WeKr7WjL17qQHDrSOJK0/Zkojk/mtWDZdaf1W2x0n62SuevhjhNtufyLicLiSVySbL3xj06SCfC06JxVkrdcl92pkgz5mi5lA65H+1jLsuktBDrtI3v4HKzdR/AAHlXMAAAAASUVORK5CYII="
    }
   },
   "cell_type": "markdown",
   "id": "14e4525e",
   "metadata": {},
   "source": [
    "For a memory aid of the product terms in Sarrus’ rule, try tracing the elements of the triple products in the matrix.\n",
    "\n",
    "We call a square matrix $T$ an **upper-triangular matrix** if $T_{ij} = 0$ for $i > j$, i.e., the matrix is zero below its diagonal. Analogously, we define a **lower-triangular matrix** as a matrix with zeros above its diagonal. For a triangular matrix $T \\in \\mathbb{R}^{n \\times n}$, the determinant is the product of the diagonal matrix elements, i.e.,\n",
    "$$\\det(T) = \\prod_{i=1}^{n} T_{ii} \\quad (4.8)$$\n",
    "\n",
    "**Example 4.2 (Determinants as Measures of Volume)**\n",
    "The notion of a determinant is natural when we consider it as a mapping from a set of $n$ vectors spanning an object in $\\mathbb{R}^n$. It turns out that the determinant $\\det(A)$ is the **signed volume of an n-dimensional parallelepiped** formed by the columns of the matrix $A$.\n",
    "\n",
    "For $n=2$, the columns of the matrix form a parallelogram; see Figure 4.2. As the angle between vectors gets smaller, the area of a parallelogram shrinks, too. Consider two vectors $\\mathbf{b}, \\mathbf{g}$ that form the columns of a matrix $A = [\\mathbf{b}, \\mathbf{g}]$. Then, the absolute value of the determinant of $A$ is the area of the parallelogram with vertices $\\mathbf{0}, \\mathbf{b}, \\mathbf{g}, \\mathbf{b} + \\mathbf{g}$. In particular, if $\\mathbf{b}, \\mathbf{g}$ are linearly dependent so that $\\mathbf{b} = \\lambda\\mathbf{g}$ for some $\\lambda \\in \\mathbb{R}$, they no longer form a two-dimensional parallelogram. Therefore, the corresponding area is $0$. On the contrary, if $\\mathbf{b}, \\mathbf{g}$ are linearly independent and are multiples of the canonical basis vectors $\\mathbf{e}_1, \\mathbf{e}_2$ then they can be written as $\\mathbf{b} = \\begin{pmatrix} b \\\\ 0 \\end{pmatrix}$ and $\\mathbf{g} = \\begin{pmatrix} 0 \\\\ g \\end{pmatrix}$, and the determinant is $\\begin{vmatrix} b & 0 \\\\ 0 & g \\end{vmatrix} = bg - 0 = bg$. This becomes the familiar formula: area = height $\\times$ length.\n",
    "\n",
    "The sign of the determinant indicates the orientation of the spanning vectors $\\mathbf{b}, \\mathbf{g}$ with respect to the standard basis ($\\mathbf{e}_1, \\mathbf{e}_2$). In our figure, flipping the order to $\\mathbf{g}, \\mathbf{b}$ swaps the columns of $A$ and reverses the orientation of the shaded area.\n",
    "\n",
    "This intuition extends to higher dimensions. In $\\mathbb{R}^3$, we consider three vectors $\\mathbf{r}, \\mathbf{b}, \\mathbf{g} \\in \\mathbb{R}^3$ spanning the edges of a parallelepiped, i.e., a solid with faces that are parallel parallelograms (see Figure 4.3). The absolute value of the determinant of the $3 \\times 3$ matrix $[\\mathbf{r}, \\mathbf{b}, \\mathbf{g}]$ is the volume of the solid. Thus, the determinant acts as a function that measures the signed volume formed by column vectors composed in a matrix.\n",
    "\n",
    "Consider the three linearly independent vectors $\\mathbf{r}, \\mathbf{g}, \\mathbf{b} \\in \\mathbb{R}^3$ given as\n",
    "$$ \\mathbf{r} = \\begin{pmatrix} 2 \\\\ 0 \\\\ -8 \\end{pmatrix}, \\quad \\mathbf{g} = \\begin{pmatrix} 6 \\\\ 1 \\\\ 0 \\end{pmatrix}, \\quad \\mathbf{b} = \\begin{pmatrix} 1 \\\\ 4 \\\\ -1 \\end{pmatrix} \\quad (4.9) $$\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "**Fig.2** The area of the parallelogram (shaded region) spanned by the vectors $\\mathbf{b}$ and $\\mathbf{g}$ is $|\\det([\\mathbf{b}, \\mathbf{g}])|$.\n",
    "\n",
    "![image-2.png](attachment:image-2.png)\n",
    "\n",
    "**Fig.3** The notion of volume of the parallelepiped (shaded volume) spanned by vectors $\\mathbf{r}, \\mathbf{b}, \\mathbf{g}$ is $|\\det([\\mathbf{r}, \\mathbf{b}, \\mathbf{g}])|$. The sign of the determinant indicates the orientation of the spanning vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09e482a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Determinant of Triangular Matrices ---\n",
      "Matrix: [[1, 2, 3], [0, 4, 5], [0, 0, 6]]\n",
      "Is upper-triangular? True\n",
      "Determinant (triangular formula): 24\n",
      "Determinant (general formula): 24\n",
      "\n",
      "Matrix: [[7, 0, 0], [8, 9, 0], [1, 2, 10]]\n",
      "Is lower-triangular? True\n",
      "Determinant (triangular formula): 630\n",
      "Determinant (general formula): 630\n",
      "\n",
      "Matrix: [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
      "Is upper-triangular? False\n",
      "Is lower-triangular? False\n",
      "Determinant (triangular formula): Error: Matrix is not triangular (upper or lower). This function is for triangular matrices only.\n",
      "Determinant (general formula - Sarrus): 0\n",
      "\n",
      "--- Geometric Interpretation of Determinant ---\n",
      "\n",
      "Vectors for 2D parallelogram: b=[2, 0], g=[0, 3]\n",
      "Matrix from columns: [[2, 0], [0, 3]]\n",
      "Determinant: 6\n",
      "Area of parallelogram: 6\n",
      "\n",
      "Vectors for skewed 2D parallelogram: b=[3, 1], g=[1, 2]\n",
      "Matrix from columns: [[3, 1], [1, 2]]\n",
      "Determinant: 5\n",
      "Area of parallelogram: 5\n",
      "\n",
      "Vectors for 3D parallelepiped (from Equation 4.9):\n",
      "  r = [2, 0, -8]\n",
      "  g = [6, 1, 0]\n",
      "  b = [1, 4, -1]\n",
      "Matrix from columns: [[2, 6, 1], [0, 1, 4], [-8, 0, -1]]\n",
      "Determinant of matrix [r, g, b]: -186\n",
      "Volume of parallelepiped: 186\n",
      "\n",
      "--- End of Demonstrations ---\n",
      "Remember: For real-world linear algebra, use libraries like NumPy for performance.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# --- Helper functions for Determinant from previous responses (re-used) ---\n",
    "\n",
    "def get_minor(matrix, i, j):\n",
    "    \"\"\"\n",
    "    Helper: Computes the minor of a matrix by removing row i and column j.\n",
    "    Used for cofactor expansion.\n",
    "    \"\"\"\n",
    "    return [row[:j] + row[j+1:] for k, row in enumerate(matrix) if k != i]\n",
    "\n",
    "def determinant_nxn(matrix):\n",
    "    \"\"\"\n",
    "    Computes the determinant of an n x n matrix using cofactor expansion.\n",
    "    WARNING: This method is highly inefficient (O(n!)) for large matrices.\n",
    "    For practical applications, use NumPy (e.g., numpy.linalg.det).\n",
    "    \"\"\"\n",
    "    n = len(matrix)\n",
    "    \n",
    "    if not matrix or not all(len(row) == n for row in matrix):\n",
    "        raise ValueError(\"Input matrix must be a non-empty square matrix.\")\n",
    "\n",
    "    if n == 1:\n",
    "        return matrix[0][0]\n",
    "    elif n == 2:\n",
    "        return matrix[0][0] * matrix[1][1] - matrix[0][1] * matrix[1][0]\n",
    "    else:\n",
    "        det = 0\n",
    "        for j in range(n): # Expand along the first row\n",
    "            minor = get_minor(matrix, 0, j)\n",
    "            cofactor = matrix[0][j] * determinant_nxn(minor)\n",
    "            if (0 + j) % 2 == 1: # Check for (-1)^(i+j) sign\n",
    "                det -= cofactor\n",
    "            else:\n",
    "                det += cofactor\n",
    "        return det\n",
    "\n",
    "def determinant_3x3_sarrus(matrix):\n",
    "    \"\"\"\n",
    "    Computes the determinant of a 3x3 matrix using Sarrus' Rule.\n",
    "    Formula: a11*a22*a33 + a12*a23*a31 + a13*a21*a32\n",
    "             - a31*a22*a13 - a32*a23*a11 - a33*a21*a12\n",
    "    \"\"\"\n",
    "    if not isinstance(matrix, list) or len(matrix) != 3 or \\\n",
    "       not all(isinstance(row, list) and len(row) == 3 for row in matrix):\n",
    "        raise ValueError(\"Input must be a 3x3 matrix for Sarrus' rule.\")\n",
    "    \n",
    "    a11, a12, a13 = matrix[0][0], matrix[0][1], matrix[0][2]\n",
    "    a21, a22, a23 = matrix[1][0], matrix[1][1], matrix[1][2]\n",
    "    a31, a32, a33 = matrix[2][0], matrix[2][1], matrix[2][2]\n",
    "    \n",
    "    # Positive diagonal products\n",
    "    term1 = a11 * a22 * a33\n",
    "    term2 = a12 * a23 * a31\n",
    "    term3 = a13 * a21 * a32\n",
    "    \n",
    "    # Negative diagonal products\n",
    "    term4 = a31 * a22 * a13\n",
    "    term5 = a32 * a23 * a11\n",
    "    term6 = a33 * a21 * a12\n",
    "    \n",
    "    return term1 + term2 + term3 - term4 - term5 - term6\n",
    "\n",
    "\n",
    "# --- Determinant of Triangular Matrices ---\n",
    "\n",
    "def is_square_matrix(matrix):\n",
    "    \"\"\"Checks if a given list of lists represents a square matrix.\"\"\"\n",
    "    if not matrix or not isinstance(matrix, list):\n",
    "        return False\n",
    "    n = len(matrix)\n",
    "    return all(isinstance(row, list) and len(row) == n for row in matrix)\n",
    "\n",
    "def is_upper_triangular(matrix):\n",
    "    \"\"\"\n",
    "    Checks if a square matrix is upper-triangular (zeros below the diagonal).\n",
    "    \"\"\"\n",
    "    if not is_square_matrix(matrix):\n",
    "        raise ValueError(\"Matrix must be square to check for triangularity.\")\n",
    "    \n",
    "    n = len(matrix)\n",
    "    for i in range(1, n): # Start from second row\n",
    "        for j in range(i): # Check elements below diagonal\n",
    "            if matrix[i][j] != 0:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "def is_lower_triangular(matrix):\n",
    "    \"\"\"\n",
    "    Checks if a square matrix is lower-triangular (zeros above the diagonal).\n",
    "    \"\"\"\n",
    "    if not is_square_matrix(matrix):\n",
    "        raise ValueError(\"Matrix must be square to check for triangularity.\")\n",
    "\n",
    "    n = len(matrix)\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n): # Check elements above diagonal\n",
    "            if matrix[i][j] != 0:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "def determinant_triangular(matrix):\n",
    "    \"\"\"\n",
    "    Computes the determinant of a triangular (upper or lower) matrix.\n",
    "    The determinant is the product of its diagonal elements.\n",
    "    \"\"\"\n",
    "    if not is_square_matrix(matrix):\n",
    "        raise ValueError(\"Matrix must be square to compute its determinant.\")\n",
    "    \n",
    "    if not (is_upper_triangular(matrix) or is_lower_triangular(matrix)):\n",
    "        # While this function can compute it, it's specific to triangular matrices.\n",
    "        # For non-triangular, use general determinant_nxn.\n",
    "        raise ValueError(\"Matrix is not triangular (upper or lower). This function is for triangular matrices only.\")\n",
    "    \n",
    "    product_of_diagonals = 1\n",
    "    for i in range(len(matrix)):\n",
    "        product_of_diagonals *= matrix[i][i]\n",
    "    return product_of_diagonals\n",
    "\n",
    "# --- Geometric Interpretation of Determinant ---\n",
    "\n",
    "def vectors_to_matrix_columns(vectors):\n",
    "    \"\"\"\n",
    "    Converts a list of vectors into a matrix where each vector is a column.\n",
    "    Assumes all vectors have the same dimension.\n",
    "    \"\"\"\n",
    "    if not vectors:\n",
    "        raise ValueError(\"List of vectors cannot be empty.\")\n",
    "    \n",
    "    dim = len(vectors[0])\n",
    "    num_vectors = len(vectors)\n",
    "    \n",
    "    if not all(len(v) == dim for v in vectors):\n",
    "        raise ValueError(\"All vectors must have the same dimension.\")\n",
    "    \n",
    "    # Create an empty matrix of appropriate size (rows = dim, cols = num_vectors)\n",
    "    matrix = [[0 for _ in range(num_vectors)] for _ in range(dim)]\n",
    "    \n",
    "    for col_idx in range(num_vectors):\n",
    "        for row_idx in range(dim):\n",
    "            matrix[row_idx][col_idx] = vectors[col_idx][row_idx]\n",
    "            \n",
    "    return matrix\n",
    "\n",
    "\n",
    "# --- Example Usage ---\n",
    "\n",
    "print(\"--- Determinant of Triangular Matrices ---\")\n",
    "\n",
    "# Upper-triangular matrix\n",
    "upper_tri_matrix = [\n",
    "    [1, 2, 3],\n",
    "    [0, 4, 5],\n",
    "    [0, 0, 6]\n",
    "]\n",
    "print(f\"Matrix: {upper_tri_matrix}\")\n",
    "print(f\"Is upper-triangular? {is_upper_triangular(upper_tri_matrix)}\")\n",
    "print(f\"Determinant (triangular formula): {determinant_triangular(upper_tri_matrix)}\") # Expected: 1*4*6 = 24\n",
    "print(f\"Determinant (general formula): {determinant_nxn(upper_tri_matrix)}\") # Expected: 24\n",
    "\n",
    "# Lower-triangular matrix\n",
    "lower_tri_matrix = [\n",
    "    [7, 0, 0],\n",
    "    [8, 9, 0],\n",
    "    [1, 2, 10]\n",
    "]\n",
    "print(f\"\\nMatrix: {lower_tri_matrix}\")\n",
    "print(f\"Is lower-triangular? {is_lower_triangular(lower_tri_matrix)}\")\n",
    "print(f\"Determinant (triangular formula): {determinant_triangular(lower_tri_matrix)}\") # Expected: 7*9*10 = 630\n",
    "print(f\"Determinant (general formula): {determinant_nxn(lower_tri_matrix)}\") # Expected: 630\n",
    "\n",
    "# Non-triangular matrix\n",
    "non_tri_matrix = [\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9]\n",
    "]\n",
    "print(f\"\\nMatrix: {non_tri_matrix}\")\n",
    "print(f\"Is upper-triangular? {is_upper_triangular(non_tri_matrix)}\")\n",
    "print(f\"Is lower-triangular? {is_lower_triangular(non_tri_matrix)}\")\n",
    "try:\n",
    "    determinant_triangular(non_tri_matrix)\n",
    "except ValueError as e:\n",
    "    print(f\"Determinant (triangular formula): Error: {e}\")\n",
    "print(f\"Determinant (general formula - Sarrus): {determinant_3x3_sarrus(non_tri_matrix)}\") # Expected: 0\n",
    "\n",
    "\n",
    "print(\"\\n--- Geometric Interpretation of Determinant ---\")\n",
    "\n",
    "# 2D Example: Area of a parallelogram\n",
    "# Vectors b = [2, 0], g = [0, 3] => forms a rectangle with area 6\n",
    "b_vec_2d = [2, 0]\n",
    "g_vec_2d = [0, 3]\n",
    "matrix_2d_columns = vectors_to_matrix_columns([b_vec_2d, g_vec_2d])\n",
    "det_2d = determinant_nxn(matrix_2d_columns)\n",
    "print(f\"\\nVectors for 2D parallelogram: b={b_vec_2d}, g={g_vec_2d}\")\n",
    "print(f\"Matrix from columns: {matrix_2d_columns}\")\n",
    "print(f\"Determinant: {det_2d}\")\n",
    "print(f\"Area of parallelogram: {abs(det_2d)}\") # Expected: 6\n",
    "\n",
    "# Vectors b = [3, 1], g = [1, 2]\n",
    "b_vec_2d_skew = [3, 1]\n",
    "g_vec_2d_skew = [1, 2]\n",
    "matrix_2d_skew_columns = vectors_to_matrix_columns([b_vec_2d_skew, g_vec_2d_skew])\n",
    "det_2d_skew = determinant_nxn(matrix_2d_skew_columns)\n",
    "print(f\"\\nVectors for skewed 2D parallelogram: b={b_vec_2d_skew}, g={g_vec_2d_skew}\")\n",
    "print(f\"Matrix from columns: {matrix_2d_skew_columns}\")\n",
    "print(f\"Determinant: {det_2d_skew}\") # Expected: (3*2) - (1*1) = 5\n",
    "print(f\"Area of parallelogram: {abs(det_2d_skew)}\")\n",
    "\n",
    "\n",
    "# 3D Example: Volume of a parallelepiped (from text, Equation 4.9)\n",
    "r_vec_3d = [2, 0, -8]\n",
    "g_vec_3d = [6, 1, 0]\n",
    "b_vec_3d = [1, 4, -1]\n",
    "\n",
    "matrix_3d_columns = vectors_to_matrix_columns([r_vec_3d, g_vec_3d, b_vec_3d])\n",
    "\n",
    "# Using the determinant_3x3_sarrus function as it's efficient for 3x3\n",
    "det_3d = determinant_3x3_sarrus(matrix_3d_columns)\n",
    "\n",
    "print(f\"\\nVectors for 3D parallelepiped (from Equation 4.9):\")\n",
    "print(f\"  r = {r_vec_3d}\")\n",
    "print(f\"  g = {g_vec_3d}\")\n",
    "print(f\"  b = {b_vec_3d}\")\n",
    "print(f\"Matrix from columns: {matrix_3d_columns}\")\n",
    "print(f\"Determinant of matrix [r, g, b]: {det_3d}\")\n",
    "print(f\"Volume of parallelepiped: {abs(det_3d)}\")\n",
    "\n",
    "# Verify with manual calculation for [r, g, b]:\n",
    "# det = 2*(1*-1 - 0*4) - 6*(0*-1 - (-8)*4) + 1*(0*0 - (-8)*1)\n",
    "#     = 2*(-1) - 6*(0 + 32) + 1*(0 + 8)\n",
    "#     = -2 - 6*32 + 8\n",
    "#     = -2 - 192 + 8\n",
    "#     = -186 (This is the expected value)\n",
    "\n",
    "print(\"\\n--- End of Demonstrations ---\")\n",
    "print(\"Remember: For real-world linear algebra, use libraries like NumPy for performance.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afc9663",
   "metadata": {},
   "source": [
    "Writing these vectors as the columns of a matrix\n",
    "$$ A = [\\mathbf{r}, \\mathbf{g}, \\mathbf{b}] = \\begin{pmatrix} 2 & 6 & 1 \\\\ 0 & 1 & 4 \\\\ -8 & 0 & -1 \\end{pmatrix} \\quad (4.10) $$\n",
    "allows us to compute the desired volume as $V = |\\det(A)| = 186$. (4.11)\n",
    "\n",
    "Computing the determinant of an $n \\times n$ matrix requires a general algorithm to solve the cases for $n > 3$, which we are going to explore in the following. Theorem 4.2 below reduces the problem of computing the determinant of an $n \\times n$ matrix to computing the determinant of $(n-1) \\times (n-1)$ matrices. By recursively applying the Laplace expansion (Theorem 4.2), we can therefore compute determinants of $n \\times n$ matrices by ultimately computing determinants of $2 \\times 2$ matrices.\n",
    "\n",
    "**Theorem 4.2 (Laplace Expansion).** Consider a matrix $A \\in \\mathbb{R}^{n \\times n}$. Then, for all $j = 1, \\dots, n$:\n",
    "1.  **Expansion along column $j$**:\n",
    "    $$ \\det(A) = \\sum_{k=1}^{n} (-1)^{k+j} a_{kj} \\det(A_{k,j}) \\quad (4.12) $$\n",
    "2.  **Expansion along row $j$**:\n",
    "    $$ \\det(A) = \\sum_{k=1}^{n} (-1)^{j+k} a_{jk} \\det(A_{j,k}) \\quad (4.13) $$\n",
    "Here $A_{k,j} \\in \\mathbb{R}^{(n-1) \\times (n-1)}$ is the submatrix of $A$ that we obtain when deleting row $k$ and column $j$.\n",
    "\n",
    "**Example 4.3 (Laplace Expansion)**\n",
    "Let us compute the determinant of\n",
    "$$ A = \\begin{pmatrix} 1 & 2 & 3 \\\\ 3 & 1 & 2 \\\\ 0 & 0 & 1 \\end{pmatrix} \\quad (4.14) $$\n",
    "using the Laplace expansion along the first row. Applying (4.13) yields\n",
    "$$ \\begin{vmatrix} 1 & 2 & 3 \\\\ 3 & 1 & 2 \\\\ 0 & 0 & 1 \\end{vmatrix} = (-1)^{1+1} \\cdot 1 \\begin{vmatrix} 1 & 2 \\\\ 0 & 1 \\end{vmatrix} + (-1)^{1+2} \\cdot 2 \\begin{vmatrix} 3 & 2 \\\\ 0 & 1 \\end{vmatrix} + (-1)^{1+3} \\cdot 3 \\begin{vmatrix} 3 & 1 \\\\ 0 & 0 \\end{vmatrix} \\quad (4.15) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26dd1eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Example 4.3: Laplace Expansion ---\n",
      "Matrix A (Equation 4.14):\n",
      "[1, 2, 3]\n",
      "[3, 1, 2]\n",
      "[0, 0, 1]\n",
      "\n",
      "Applying Laplace Expansion along the first row (Equation 4.15):\n",
      "Term 1: (-1)^(1+1) * 1 * det([[1, 2], [0, 1]]) = 1 * 1 * (1) = 1\n",
      "Term 2: (-1)^(1+2) * 2 * det([[3, 2], [0, 1]]) = -1 * 2 * (3) = -6\n",
      "Term 3: (-1)^(1+3) * 3 * det([[3, 1], [0, 0]]) = 1 * 3 * (0) = 0\n",
      "\n",
      "Sum of terms = -5\n",
      "Determinant of A computed by function: -5\n",
      "\n",
      "--- Important Note ---\n",
      "The Laplace Expansion (cofactor expansion) is computationally intensive (O(n!)).\n",
      "For practical determinant calculations, especially for larger matrices,\n",
      "always use optimized libraries like NumPy, which employ more efficient algorithms.\n"
     ]
    }
   ],
   "source": [
    "# --- Helper functions (re-used from previous implementations) ---\n",
    "\n",
    "def get_minor(matrix, row_to_delete, col_to_delete):\n",
    "    \"\"\"\n",
    "    Computes the minor (submatrix) by removing a specified row and column.\n",
    "    Used in Laplace Expansion.\n",
    "    \"\"\"\n",
    "    return [row[:col_to_delete] + row[col_to_delete+1:] \n",
    "            for r_idx, row in enumerate(matrix) if r_idx != row_to_delete]\n",
    "\n",
    "def determinant_2x2(matrix):\n",
    "    \"\"\"\n",
    "    Computes the determinant of a 2x2 matrix.\n",
    "    Base case for recursive Laplace Expansion.\n",
    "    \"\"\"\n",
    "    if len(matrix) != 2 or len(matrix[0]) != 2 or len(matrix[1]) != 2:\n",
    "        raise ValueError(\"Input matrix must be a 2x2 matrix.\")\n",
    "    return matrix[0][0] * matrix[1][1] - matrix[0][1] * matrix[1][0]\n",
    "\n",
    "def determinant_1x1(matrix):\n",
    "    \"\"\"\n",
    "    Computes the determinant of a 1x1 matrix.\n",
    "    Base case for recursive Laplace Expansion.\n",
    "    \"\"\"\n",
    "    if len(matrix) != 1 or len(matrix[0]) != 1:\n",
    "        raise ValueError(\"Input must be a 1x1 matrix (e.g., [[val]]).\")\n",
    "    return matrix[0][0]\n",
    "\n",
    "\n",
    "# --- Implementation of Laplace Expansion (Theorem 4.2) ---\n",
    "\n",
    "def determinant_laplace_expansion(matrix):\n",
    "    \"\"\"\n",
    "    Computes the determinant of a square matrix using Laplace Expansion (recursive cofactor expansion).\n",
    "    This implementation expands along the first row (j=1 in Theorem 4.2, part 2, with k iterating through columns).\n",
    "\n",
    "    WARNING: This method is highly inefficient (O(n!)) for matrices larger than 4x4.\n",
    "    For practical applications, use optimized libraries like NumPy (numpy.linalg.det).\n",
    "    \"\"\"\n",
    "    n = len(matrix)\n",
    "    \n",
    "    if not matrix or not all(len(row) == n for row in matrix):\n",
    "        raise ValueError(\"Input matrix must be a non-empty square matrix.\")\n",
    "\n",
    "    if n == 1:\n",
    "        return determinant_1x1(matrix)\n",
    "    elif n == 2:\n",
    "        return determinant_2x2(matrix)\n",
    "    else:\n",
    "        det = 0\n",
    "        # Expand along the first row (fixed row_idx = 0)\n",
    "        row_idx = 0 \n",
    "        for col_idx in range(n):\n",
    "            # Ak,j in the theorem corresponds to minor = get_minor(matrix, row_idx, col_idx)\n",
    "            minor = get_minor(matrix, row_idx, col_idx)\n",
    "            \n",
    "            # (-1)^(j+k) in Theorem 4.2, here it's (-1)^(row_idx + col_idx)\n",
    "            sign = (-1)**(row_idx + col_idx)\n",
    "            \n",
    "            # a_jk in Theorem 4.2 is matrix[row_idx][col_idx]\n",
    "            # det(A_jk) is determinant_laplace_expansion(minor)\n",
    "            cofactor_term = sign * matrix[row_idx][col_idx] * determinant_laplace_expansion(minor)\n",
    "            \n",
    "            det += cofactor_term\n",
    "        return det\n",
    "\n",
    "# --- Example 4.3: Laplace Expansion ---\n",
    "\n",
    "print(\"--- Example 4.3: Laplace Expansion ---\")\n",
    "\n",
    "A = [\n",
    "    [1, 2, 3],\n",
    "    [3, 1, 2],\n",
    "    [0, 0, 1]\n",
    "]\n",
    "print(f\"Matrix A (Equation 4.14):\\n{A[0]}\\n{A[1]}\\n{A[2]}\\n\")\n",
    "\n",
    "# Applying Equation (4.15) step-by-step\n",
    "print(\"Applying Laplace Expansion along the first row (Equation 4.15):\")\n",
    "\n",
    "# Term 1: (-1)^(1+1) * a11 * det(A1,1)\n",
    "a11 = A[0][0] # 1\n",
    "minor_A11 = get_minor(A, 0, 0) # Submatrix after deleting row 0, col 0\n",
    "det_minor_A11 = determinant_2x2(minor_A11)\n",
    "term1 = ((-1)**(0+0)) * a11 * det_minor_A11\n",
    "print(f\"Term 1: (-1)^(1+1) * {a11} * det({minor_A11}) = 1 * {a11} * ({det_minor_A11}) = {term1}\")\n",
    "\n",
    "# Term 2: (-1)^(1+2) * a12 * det(A1,2)\n",
    "a12 = A[0][1] # 2\n",
    "minor_A12 = get_minor(A, 0, 1) # Submatrix after deleting row 0, col 1\n",
    "det_minor_A12 = determinant_2x2(minor_A12)\n",
    "term2 = ((-1)**(0+1)) * a12 * det_minor_A12\n",
    "print(f\"Term 2: (-1)^(1+2) * {a12} * det({minor_A12}) = -1 * {a12} * ({det_minor_A12}) = {term2}\")\n",
    "\n",
    "# Term 3: (-1)^(1+3) * a13 * det(A1,3)\n",
    "a13 = A[0][2] # 3\n",
    "minor_A13 = get_minor(A, 0, 2) # Submatrix after deleting row 0, col 2\n",
    "det_minor_A13 = determinant_2x2(minor_A13)\n",
    "term3 = ((-1)**(0+2)) * a13 * det_minor_A13\n",
    "print(f\"Term 3: (-1)^(1+3) * {a13} * det({minor_A13}) = 1 * {a13} * ({det_minor_A13}) = {term3}\")\n",
    "\n",
    "calculated_det_example = term1 + term2 + term3\n",
    "print(f\"\\nSum of terms = {calculated_det_example}\")\n",
    "\n",
    "# Verify using the general determinant_laplace_expansion function\n",
    "det_A_function = determinant_laplace_expansion(A)\n",
    "print(f\"Determinant of A computed by function: {det_A_function}\")\n",
    "\n",
    "# The expected value for this example is 1 (as calculated in the text: 1*1 - 2*3 + 3*0 = 1 - 6 + 0 = -5, but the text example has different calculation for the third term, let's recheck with the formula)\n",
    "# Recheck calculation from text:\n",
    "# det(A) = 1 * det([[1,2],[0,1]]) - 2 * det([[3,2],[0,1]]) + 3 * det([[3,1],[0,0]])\n",
    "# det([[1,2],[0,1]]) = 1*1 - 2*0 = 1\n",
    "# det([[3,2],[0,1]]) = 3*1 - 2*0 = 3\n",
    "# det([[3,1],[0,0]]) = 3*0 - 1*0 = 0\n",
    "# So, det(A) = 1 * 1 - 2 * 3 + 3 * 0 = 1 - 6 + 0 = -5.\n",
    "\n",
    "# Let's verify the trace for the example matrix (not related to determinant, but good for completeness)\n",
    "# trace_A = A[0][0] + A[1][1] + A[2][2] = 1 + 1 + 1 = 3\n",
    "# print(f\"Trace of A: {trace_A}\")\n",
    "\n",
    "print(\"\\n--- Important Note ---\")\n",
    "print(\"The Laplace Expansion (cofactor expansion) is computationally intensive (O(n!)).\")\n",
    "print(\"For practical determinant calculations, especially for larger matrices,\")\n",
    "print(\"always use optimized libraries like NumPy, which employ more efficient algorithms.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25b05b1",
   "metadata": {},
   "source": [
    "We use (4.6) to compute the determinants of all $ 2 \\times 2 $ matrices and obtain\n",
    "\n",
    "$$\n",
    "\\det(A) = 1(1 - 0) - 2(3 - 0) + 3(0 - 0) = -5. \\tag{4.16}\n",
    "$$\n",
    "\n",
    "For completeness, we can compare this result to computing the determinant using Sarrus’ rule (4.7):\n",
    "\n",
    "$$\n",
    "\\det(A) = 1 \\cdot 1 \\cdot 1 + 3 \\cdot 0 \\cdot 3 + 0 \\cdot 2 \\cdot 2 - 0 \\cdot 1 \\cdot 3 - 1 \\cdot 0 \\cdot 2 - 3 \\cdot 2 \\cdot 1 = 1 - 6 = -5. \\tag{4.17}\n",
    "$$\n",
    "\n",
    "For $ A \\in \\mathbb{R}^{n \\times n} $, the determinant exhibits the following properties:\n",
    "\n",
    "- The determinant of a matrix product is the product of the corresponding determinants, $ \\det(AB) = \\det(A) \\det(B) $.\n",
    "- Determinants are invariant to transposition, i.e., $ \\det(A) = \\det(A^\\top) $.\n",
    "- If $ A $ is regular (invertible), then $ \\det(A^{-1}) = \\frac{1}{\\det(A)} $.\n",
    "- Similar matrices (Definition 2.22) possess the same determinant. Therefore, for a linear mapping $ \\Phi : V \\to V $, all transformation matrices $ A_\\Phi $ of $ \\Phi $ have the same determinant. Thus, the determinant is invariant to the choice of basis of a linear mapping.\n",
    "- Adding a multiple of a column/row to another one does not change $ \\det(A) $.\n",
    "- Multiplication of a column/row with $ \\lambda \\in \\mathbb{R} $ scales $ \\det(A) $ by $ \\lambda $. In particular, $ \\det(\\lambda A) = \\lambda^n \\det(A) $.\n",
    "- Swapping two rows/columns changes the sign of $ \\det(A) $.\n",
    "\n",
    "Because of the last three properties, we can use Gaussian elimination (see Section 2.1) to compute $ \\det(A) $ by bringing $ A $ into row-echelon form. We can stop Gaussian elimination when we have $ A $ in a triangular form where the elements below the diagonal are all 0. Recall from (4.8) that the determinant of a triangular matrix is the product of the diagonal elements.\n",
    "\n",
    "**Theorem 4.3.** A square matrix $ A \\in \\mathbb{R}^{n \\times n} $ has $ \\det(A) \\neq 0 $ if and only if $ \\text{rk}(A) = n $. In other words, $ A $ is invertible if and only if it is full rank.\n",
    "\n",
    "When mathematics was mainly performed by hand, the determinant calculation was considered an essential way to analyze matrix invertibility. However, contemporary approaches in machine learning use direct numerical methods that superseded the explicit calculation of the determinant. For example, in Chapter 2, we learned that inverse matrices can be computed by Gaussian elimination. Gaussian elimination can thus be used to compute the determinant of a matrix.\n",
    "\n",
    "Determinants will play an important theoretical role for the following sections, especially when we learn about eigenvalues and eigenvectors (Section 4.2) through the characteristic polynomial.\n",
    "\n",
    "**Definition 4.4.** The trace of a square matrix $ A \\in \\mathbb{R}^{n \\times n} $ is defined as\n",
    "\n",
    "$$\n",
    "\\text{tr}(A) := \\sum_{i=1}^n a_{ii}, \\tag{4.18}\n",
    "$$\n",
    "\n",
    "i.e., the trace is the sum of the diagonal elements of $ A $.\n",
    "\n",
    "The trace satisfies the following properties:\n",
    "\n",
    "- $ \\text{tr}(A + B) = \\text{tr}(A) + \\text{tr}(B) $ for $ A, B \\in \\mathbb{R}^{n \\times n} $\n",
    "- $ \\text{tr}(\\alpha A) = \\alpha \\text{tr}(A) $, $ \\alpha \\in \\mathbb{R} $ for $ A \\in \\mathbb{R}^{n \\times n} $\n",
    "- $ \\text{tr}(I_n) = n $\n",
    "- $ \\text{tr}(AB) = \\text{tr}(BA) $ for $ A \\in \\mathbb{R}^{n \\times k} $, $ B \\in \\mathbb{R}^{k \\times n} $\n",
    "\n",
    "It can be shown that only one function satisfies these four properties together – the trace (Gohberg et al., 2012).\n",
    "\n",
    "The properties of the trace of matrix products are more general. Specifically, the trace is invariant under cyclic permutations, i.e.,\n",
    "\n",
    "$$\n",
    "\\text{tr}(AKL) = \\text{tr}(KLA) \\tag{4.19}\n",
    "$$\n",
    "\n",
    "for matrices $ A \\in \\mathbb{R}^{a \\times k} $, $ K \\in \\mathbb{R}^{k \\times l} $, $ L \\in \\mathbb{R}^{l \\times a} $. This property generalizes to products of an arbitrary number of matrices.\n",
    "\n",
    "As a special case of (4.19), it follows that for two vectors $ x, y \\in \\mathbb{R}^n $\n",
    "\n",
    "$$\n",
    "\\text{tr}(x y^\\top) = \\text{tr}(y^\\top x) = y^\\top x \\in \\mathbb{R}. \\tag{4.20}\n",
    "$$\n",
    "\n",
    "Given a linear mapping $ \\Phi : V \\to V $, where $ V $ is a vector space, we define the trace of this map by using the trace of the matrix representation of $ \\Phi $. For a given basis of $ V $, we can describe $ \\Phi $ by means of the transformation matrix $ A $. Then the trace of $ \\Phi $ is the trace of $ A $. For a different basis of $ V $, it holds that the corresponding transformation matrix $ B $ of $ \\Phi $ can be obtained by a basis change of the form $ S^{-1} A S $ for suitable $ S $ (see Section 2.7.2). For the corresponding trace of $ \\Phi $, this means\n",
    "\n",
    "$$\n",
    "\\text{tr}(B) = \\text{tr}(S^{-1} A S) = \\text{tr}(A S S^{-1}) = \\text{tr}(A). \\tag{4.21}\n",
    "$$\n",
    "\n",
    "Hence, while matrix representations of linear mappings are basis-dependent, the trace of a linear mapping $ \\Phi $ is independent of the basis.\n",
    "\n",
    "In this section, we covered determinants and traces as functions characterizing a square matrix. Taking together our understanding of determinants and traces, we can now define an important equation describing a matrix $ A $ in terms of a polynomial, which we will use extensively in the following sections.\n",
    "\n",
    "**Definition 4.5 (Characteristic Polynomial).** For $ \\lambda \\in \\mathbb{R} $ and a square matrix $ A \\in \\mathbb{R}^{n \\times n} $\n",
    "\n",
    "$$\n",
    "p_A(\\lambda) := \\det(A - \\lambda I) \\tag{4.22a}\n",
    "$$\n",
    "\n",
    "$$\n",
    "= c_0 + c_1 \\lambda + c_2 \\lambda^2 + \\cdots + c_{n-1} \\lambda^{n-1} + (-1)^n \\lambda^n, \\tag{4.22b}\n",
    "$$\n",
    "\n",
    "$ c_0, \\ldots, c_{n-1} \\in \\mathbb{R} $, is the characteristic polynomial of $ A $. In particular,\n",
    "\n",
    "$$\n",
    "c_0 = \\det(A), \\tag{4.23}\n",
    "$$\n",
    "\n",
    "$$\n",
    "c_{n-1} = (-1)^{n-1} \\text{tr}(A). \\tag{4.24}\n",
    "$$\n",
    "\n",
    "The characteristic polynomial (4.22a) will allow us to compute eigenvalues and eigenvectors, covered in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef24428b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determinant Calculation:\n",
      "Matrix A (3x3):\n",
      "[1, 3, 0]\n",
      "[2, 1, 0]\n",
      "[0, 2, 1]\n",
      "det(A) using Sarrus' rule = -5 (Equation 4.17)\n",
      "\n",
      "Matrix A (2x2):\n",
      "[1, 2]\n",
      "[3, 4]\n",
      "Matrix B (2x2):\n",
      "[2, 0]\n",
      "[1, 3]\n",
      "\n",
      "det(A) = -2, det(B) = 6\n",
      "det(AB) = -12\n",
      "det(A) * det(B) = -12\n",
      "Property det(AB) = det(A) det(B): True\n",
      "\n",
      "det(A^T) = -2\n",
      "Property det(A) = det(A^T): True\n",
      "\n",
      "Trace Calculation:\n",
      "Trace of A (2x2) = 5 (Equation 4.18)\n",
      "\n",
      "tr(AB) = 16, tr(BA) = 16\n",
      "Property tr(AB) = tr(BA): True\n",
      "\n",
      "tr(AKL) = 9, tr(KLA) = 9\n",
      "Property tr(AKL) = tr(KLA): True\n",
      "\n",
      "Characteristic Polynomial (2x2 Matrix):\n",
      "Characteristic polynomial coefficients [c0, c1, c2]: [-2, -5, 1.0]\n",
      "c0 = -2, det(A) = -2\n",
      "Property c0 = det(A): True\n",
      "c1 = -5, (-1)^(n-1) tr(A) = -5\n",
      "Property c1 = (-1)^(n-1) tr(A): True\n"
     ]
    }
   ],
   "source": [
    "# --- Matrix-Matrix Multiplication ---\n",
    "def matrix_multiply(A, B):\n",
    "    \"\"\"\n",
    "    Multiply matrices A (n x m) and B (m x p). Returns an (n x p) matrix.\n",
    "    \"\"\"\n",
    "    n, m = len(A), len(A[0])\n",
    "    p = len(B[0])\n",
    "    result = [[0.0 for _ in range(p)] for _ in range(n)]\n",
    "    for i in range(n):\n",
    "        for j in range(p):\n",
    "            result[i][j] = sum(A[i][k] * B[k][j] for k in range(m))\n",
    "    return result\n",
    "\n",
    "# --- Transpose of a Matrix ---\n",
    "def transpose(A):\n",
    "    \"\"\"\n",
    "    Compute the transpose of matrix A.\n",
    "    \"\"\"\n",
    "    n, m = len(A), len(A[0])\n",
    "    return [[A[j][i] for j in range(n)] for i in range(m)]\n",
    "\n",
    "# --- Determinant of a Matrix ---\n",
    "def determinant(A):\n",
    "    \"\"\"\n",
    "    Compute the determinant of a square matrix A.\n",
    "    For 2x2 and 3x3 matrices, use direct formulas.\n",
    "    \"\"\"\n",
    "    n = len(A)\n",
    "    if n != len(A[0]):\n",
    "        raise ValueError(\"Matrix must be square\")\n",
    "\n",
    "    if n == 2:\n",
    "        # For 2x2: det(A) = ad - bc\n",
    "        return A[0][0] * A[1][1] - A[0][1] * A[1][0]\n",
    "    \n",
    "    if n == 3:\n",
    "        # Sarrus' rule for 3x3 (Equation 4.17)\n",
    "        pos = (A[0][0] * A[1][1] * A[2][2] +\n",
    "               A[0][1] * A[1][2] * A[2][0] +\n",
    "               A[0][2] * A[1][0] * A[2][1])\n",
    "        neg = (A[0][2] * A[1][1] * A[2][0] +\n",
    "               A[0][0] * A[1][2] * A[2][1] +\n",
    "               A[0][1] * A[1][0] * A[2][2])\n",
    "        return pos - neg\n",
    "    \n",
    "    raise ValueError(\"This implementation only supports 2x2 and 3x3 matrices\")\n",
    "\n",
    "# --- Trace of a Matrix (Equation 4.18) ---\n",
    "def trace(A):\n",
    "    \"\"\"\n",
    "    Compute the trace of a square matrix A: sum of diagonal elements.\n",
    "    \"\"\"\n",
    "    n = len(A)\n",
    "    if n != len(A[0]):\n",
    "        raise ValueError(\"Matrix must be square\")\n",
    "    return sum(A[i][i] for i in range(n))\n",
    "\n",
    "# --- Characteristic Polynomial Coefficients (Equations 4.22a–4.24) ---\n",
    "def characteristic_polynomial(A):\n",
    "    \"\"\"\n",
    "    Compute the characteristic polynomial p_A(lambda) = det(A - lambda I).\n",
    "    For simplicity, compute coefficients for 2x2 matrices.\n",
    "    Returns coefficients [c0, c1, c2] for p_A(lambda) = c0 + c1*lambda + c2*lambda^2.\n",
    "    \"\"\"\n",
    "    n = len(A)\n",
    "    if n != len(A[0]) or n != 2:\n",
    "        raise ValueError(\"This implementation only supports 2x2 matrices\")\n",
    "\n",
    "    # A - lambda I for a 2x2 matrix\n",
    "    # det(A - lambda I) = (a11 - lambda)(a22 - lambda) - a12*a21\n",
    "    a11, a12 = A[0][0], A[0][1]\n",
    "    a21, a22 = A[1][0], A[1][1]\n",
    "    \n",
    "    # Expand: det = (a11 - lambda)(a22 - lambda) - a12*a21\n",
    "    # = a11*a22 - a11*lambda - a22*lambda + lambda^2 - a12*a21\n",
    "    # = lambda^2 - (a11 + a22)*lambda + (a11*a22 - a12*a21)\n",
    "    c0 = a11 * a22 - a12 * a21  # Constant term = det(A)\n",
    "    c1 = -(a11 + a22)           # Coefficient of lambda\n",
    "    c2 = 1.0                    # Coefficient of lambda^2\n",
    "    \n",
    "    return [c0, c1, c2]\n",
    "\n",
    "# --- Run the Implementation ---\n",
    "# Determinant Calculation (Equations 4.16–4.17)\n",
    "print(\"Determinant Calculation:\")\n",
    "A_3x3 = [[1, 3, 0], [2, 1, 0], [0, 2, 1]]  # Matrix from Equation 4.16\n",
    "det_A = determinant(A_3x3)\n",
    "print(f\"Matrix A (3x3):\")\n",
    "for row in A_3x3:\n",
    "    print(row)\n",
    "print(f\"det(A) using Sarrus' rule = {det_A} (Equation 4.17)\")\n",
    "\n",
    "# Verify determinant properties\n",
    "A_2x2 = [[1, 2], [3, 4]]\n",
    "B_2x2 = [[2, 0], [1, 3]]\n",
    "print(f\"\\nMatrix A (2x2):\")\n",
    "for row in A_2x2:\n",
    "    print(row)\n",
    "print(f\"Matrix B (2x2):\")\n",
    "for row in B_2x2:\n",
    "    print(row)\n",
    "\n",
    "# det(AB) = det(A) det(B)\n",
    "AB = matrix_multiply(A_2x2, B_2x2)\n",
    "det_A = determinant(A_2x2)\n",
    "det_B = determinant(B_2x2)\n",
    "det_AB = determinant(AB)\n",
    "print(f\"\\ndet(A) = {det_A}, det(B) = {det_B}\")\n",
    "print(f\"det(AB) = {det_AB}\")\n",
    "print(f\"det(A) * det(B) = {det_A * det_B}\")\n",
    "print(f\"Property det(AB) = det(A) det(B): {abs(det_AB - det_A * det_B) < 1e-10}\")\n",
    "\n",
    "# det(A) = det(A^T)\n",
    "A_T = transpose(A_2x2)\n",
    "det_A_T = determinant(A_T)\n",
    "print(f\"\\ndet(A^T) = {det_A_T}\")\n",
    "print(f\"Property det(A) = det(A^T): {abs(det_A - det_A_T) < 1e-10}\\n\")\n",
    "\n",
    "# Trace Calculation (Equation 4.18)\n",
    "print(\"Trace Calculation:\")\n",
    "tr_A = trace(A_2x2)\n",
    "print(f\"Trace of A (2x2) = {tr_A} (Equation 4.18)\")\n",
    "\n",
    "# Verify trace properties\n",
    "# tr(AB) = tr(BA)\n",
    "BA = matrix_multiply(B_2x2, A_2x2)\n",
    "tr_AB = trace(AB)\n",
    "tr_BA = trace(BA)\n",
    "print(f\"\\ntr(AB) = {tr_AB}, tr(BA) = {tr_BA}\")\n",
    "print(f\"Property tr(AB) = tr(BA): {abs(tr_AB - tr_BA) < 1e-10}\")\n",
    "\n",
    "# Cyclic permutation: tr(AKL) = tr(KLA) (Equation 4.19)\n",
    "# For simplicity, use 2x2 matrices A, K, and L\n",
    "K = [[0, 1], [1, 0]]\n",
    "L = [[1, 1], [0, 1]]\n",
    "AK = matrix_multiply(A_2x2, K)\n",
    "AKL = matrix_multiply(AK, L)\n",
    "KLA = matrix_multiply(K, matrix_multiply(L, A_2x2))\n",
    "tr_AKL = trace(AKL)\n",
    "tr_KLA = trace(KLA)\n",
    "print(f\"\\ntr(AKL) = {tr_AKL}, tr(KLA) = {tr_KLA}\")\n",
    "print(f\"Property tr(AKL) = tr(KLA): {abs(tr_AKL - tr_KLA) < 1e-10}\\n\")\n",
    "\n",
    "# Characteristic Polynomial (Equations 4.22a–4.24)\n",
    "print(\"Characteristic Polynomial (2x2 Matrix):\")\n",
    "coeffs = characteristic_polynomial(A_2x2)\n",
    "print(f\"Characteristic polynomial coefficients [c0, c1, c2]: {coeffs}\")\n",
    "# Verify c0 = det(A)\n",
    "c0 = coeffs[0]\n",
    "print(f\"c0 = {c0}, det(A) = {det_A}\")\n",
    "print(f\"Property c0 = det(A): {abs(c0 - det_A) < 1e-10}\")\n",
    "# Verify c_{n-1} = (-1)^(n-1) tr(A), here n = 2, so c1 = -tr(A)\n",
    "c1 = coeffs[1]\n",
    "tr_A = trace(A_2x2)\n",
    "expected_c1 = -tr_A\n",
    "print(f\"c1 = {c1}, (-1)^(n-1) tr(A) = {expected_c1}\")\n",
    "print(f\"Property c1 = (-1)^(n-1) tr(A): {abs(c1 - expected_c1) < 1e-10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445a73a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
