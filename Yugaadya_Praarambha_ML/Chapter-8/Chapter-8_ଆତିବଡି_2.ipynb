{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27f07ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " * Copyright (c) 2016 Radhamadhab Dalai\n",
    " *\n",
    " * Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    " * of this software and associated documentation files (the \"Software\"), to deal\n",
    " * in the Software without restriction, including without limitation the rights\n",
    " * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    " * copies of the Software, and to permit persons to whom the Software is\n",
    " * furnished to do so, subject to the following conditions:\n",
    " *\n",
    " * The above copyright notice and this permission notice shall be included in\n",
    " * all copies or substantial portions of the Software.\n",
    " *\n",
    " * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    " * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    " * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    " * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    " * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    " * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
    " * THE SOFTWARE.\n",
    "'''"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "01cd6d05",
   "metadata": {},
   "source": [
    "##  Parameter Estimation\n",
    "\n",
    "Consider the linear regression setting (9.4) and assume we are given a training set $ \\mathcal{D} := \\{(\\mathbf{x}_1, y_1), \\ldots, (\\mathbf{x}_N, y_N)\\} $ consisting of $ N $ inputs $ \\mathbf{x}_n \\in \\mathbb{R}^D $ and corresponding observations/targets $ y_n \\in \\mathbb{R} $, $ n = 1, \\ldots, N $. The corresponding graphical model is given in Fig.3. Note that 4 y_i $ and $ y_j $ are conditionally independent given their respective inputs $ \\mathbf{x}_i $, $ \\mathbf{x}_j $, so that the likelihood factorizes according to\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "Fig.3 Probabilistic graphical model for linear regression. Observed random variables are shaded, deterministic/ known values are without circles.\n",
    "\n",
    "$$\n",
    "p(\\mathbf{Y} \\mid \\mathbf{X}, \\theta) = p(y_1, \\ldots, y_N \\mid \\mathbf{x}_1, \\ldots, \\mathbf{x}_N, \\theta) \\tag{9.5a}\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\prod_{n=1}^N p(y_n \\mid \\mathbf{x}_n, \\theta) = \\prod_{n=1}^N \\mathcal{N}(y_n \\mid \\mathbf{x}_n^\\top \\theta, \\sigma^2), \\tag{9.5b}\n",
    "$$\n",
    "\n",
    "where we defined $ \\mathbf{X} := \\{\\mathbf{x}_1, \\ldots, \\mathbf{x}_N\\} $ and $ \\mathbf{Y} := \\{y_1, \\ldots, y_N\\} $ as the sets of training inputs and corresponding targets, respectively. The likelihood and the factors $ p(y_n \\mid \\mathbf{x}_n, \\theta) $ are Gaussian due to the noise distribution; see (9.3).\n",
    "\n",
    "In the following, we will discuss how to find optimal parameters $ \\theta^* \\in \\mathbb{R}^D $ for the linear regression model (9.4). Once the parameters $ \\theta^* $ are found, we can predict function values by using this parameter estimate in (9.4) so that at an arbitrary test input $ \\mathbf{x}_* $, the distribution of the corresponding target $ y_* $ is\n",
    "\n",
    "$$\n",
    "p(y_* \\mid \\mathbf{x}_*, \\theta^*) = \\mathcal{N}(y_* \\mid \\mathbf{x}_*^\\top \\theta^*, \\sigma^2). \\tag{9.6}\n",
    "$$\n",
    "\n",
    "In the following, we will have a look at parameter estimation by maximizing the likelihood, a topic that we already covered to some degree in Section 8.3.\n",
    "\n",
    "###  Maximum Likelihood Estimation\n",
    "\n",
    "A widely used approach to finding the desired parameters $ \\theta_{\\text{ML}} \\$ is **maximum likelihood estimation**, where we find parameters $ \\theta_{\\text{ML}} $ that maximize the likelihood (9.5b). Intuitively, maximizing the likelihood means maximizing the predictive distribution of the training data given the model parameters. We obtain the maximum likelihood parameters as\n",
    "\n",
    "$$\n",
    "\\theta_{\\text{ML}} \\in \\arg \\max_{\\theta} p(\\mathbf{Y} \\mid \\mathbf{X}, \\theta). \\tag{9.7}\n",
    "$$\n",
    "\n",
    "> **Remark**: The likelihood $ p(\\mathbf{y} \\mid \\mathbf{x}, \\theta) $ is *not* a probability distribution in $ \\theta $: It is simply a function of the parameters $ \\theta $ but does not integrate to 1 (i.e., it is unnormalized), and may not even be integrable with respect to $ \\theta $. However, the likelihood in (9.7) is a normalized probability distribution in $ \\mathbf{y} $. ♢\n",
    "\n",
    "To find the desired parameters $ \\theta_{\\text{ML}} $ that maximize the likelihood, we typically perform gradient ascent (or gradient descent on the negative likelihood). In the case of linear regression we consider here, however, a closed-form solution exists, which makes iterative gradient descent unnecessary. In practice, instead of maximizing the likelihood directly, we apply the log-transformation to the likelihood function and minimize the negative log-likelihood.\n",
    "\n",
    "> **Remark (Log-Transformation)**: Since the likelihood (9.5b) is a product of $ N $ Gaussian distributions, the log-transformation is useful since (a) it does not suffer from numerical underflow, and (b) the differentiation rules will turn out simpler. More specifically, numerical underflow will be a problem when we multiply $ N $ probabilities, where $ N $ is the number of data points, since we cannot represent very small numbers, such as $ 10^{-256} $. Furthermore, the log-transform will turn the product into a sum of log-probabilities such that the corresponding gradient is a sum of individual gradients, instead of a repeated application of the product rule (5.46) to compute the gradient of a product of $ N $ terms. Since the logarithm is a (strictly) monotonically increasing function, the optimum of a function $ f $ is identical to the optimum of $ \\log f $. \n",
    "\n",
    "To find the optimal parameters $ \\theta_{\\text{ML}} $ of our linear regression problem, we minimize the negative log-likelihood\n",
    "\n",
    "$$\n",
    "-\\log p(\\mathbf{Y} \\mid \\mathbf{X}, \\theta) = -\\log \\left( \\prod_{n=1}^N p(y_n \\mid \\mathbf{x}_n, \\theta) \\right) = -\\sum_{n=1}^N \\log p(y_n \\mid \\mathbf{x}_n, \\theta), \\tag{9.8}\n",
    "$$\n",
    "\n",
    "where we exploited that the likelihood (9.5b) factorizes over the number of data points due to our independence assumption on the training set. In the linear regression model (9.4), the likelihood is Gaussian (due to the Gaussian additive noise term), such that we arrive at\n",
    "\n",
    "$$\n",
    "\\log p(y_n \\mid \\mathbf{x}_n, \\theta) = -\\frac{1}{2\\sigma^2} (y_n - \\mathbf{x}_n^\\top \\theta)^2 + \\text{const}, \\tag{9.9}\n",
    "$$\n",
    "\n",
    "where the constant includes all terms independent of $ \\theta $.\n",
    "\n",
    "Using (9.9) in the negative log-likelihood (9.8), we obtain (ignoring the constant terms)\n",
    "\n",
    "$$\n",
    "L(\\theta) := \\frac{1}{2\\sigma^2} \\sum_{n=1}^N (y_n - \\mathbf{x}_n^\\top \\theta)^2 \\tag{9.10a}\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\frac{1}{2\\sigma^2} (\\mathbf{y} - \\mathbf{X}\\theta)^\\top (\\mathbf{y} - \\mathbf{X}\\theta) = \\frac{1}{2\\sigma^2} \\|\\mathbf{y} - \\mathbf{X}\\theta\\|^2, \\tag{9.10b}\n",
    "$$\n",
    "\n",
    "where we define the design matrix\n",
    "\n",
    "$$\n",
    "\\mathbf{X} := [\\mathbf{x}_1, \\ldots, \\mathbf{x}_N]^\\top \\in \\mathbb{R}^{N \\times D}\n",
    "$$\n",
    "\n",
    "as the collection of training inputs and\n",
    "\n",
    "$$\n",
    "\\mathbf{y} := [y_1, \\ldots, y_N]^\\top \\in \\mathbb{R}^N\n",
    "$$\n",
    "\n",
    "as a vector that collects all training targets. Note that the $ n $-th row in the design matrix $ \\mathbf{X} $ corresponds to the training input $ \\mathbf{x}_n \\). In (9.10b), we used the fact that the sum of squared errors between the observations $ y_n $ and the corresponding model prediction $ \\mathbf{x}_n^\\top \\theta $ equals the squared distance between $ \\mathbf{y} $ and $ \\mathbf{X}\\theta $.\n",
    "\n",
    "With (9.10b), we have now a concrete form of the negative log-likelihood function we need to optimize. We immediately see that (9.10b) is quadratic in $ \\theta $. This means that we can find a unique global solution $ \\theta_{\\text{ML}} $ for minimizing the negative log-likelihood $ L $. We can find the global optimum by computing the gradient of $ L $, setting it to 0, and solving for $ \\theta $. Using the results from Chapter 5, we compute the gradient of $ L $ with respect to the parameters as\n",
    "\n",
    "$$\n",
    "\\frac{\\mathrm{d}L}{\\mathrm{d}\\theta} = \\frac{\\mathrm{d}}{\\mathrm{d}\\theta} \\left( \\frac{1}{2\\sigma^2} (\\mathbf{y} - \\mathbf{X}\\theta)^\\top (\\mathbf{y} - \\mathbf{X}\\theta) \\right) \\tag{9.11a}\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\frac{1}{2\\sigma^2} \\frac{\\mathrm{d}}{\\mathrm{d}\\theta} \\left( \\mathbf{y}^\\top \\mathbf{y} - 2 \\mathbf{y}^\\top \\mathbf{X}\\theta + \\theta^\\top \\mathbf{X}^\\top \\mathbf{X}\\theta \\right) \\tag{9.11b}\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\frac{1}{\\sigma^2} \\left( -\\mathbf{y}^\\top \\mathbf{X} + \\theta^\\top \\mathbf{X}^\\top \\mathbf{X} \\right) \\in \\mathbb{R}^{1 \\times D}. \\tag{9.11c}\n",
    "$$\n",
    "\n",
    "The maximum likelihood estimator $ \\theta_{\\text{ML}} $ solves\n",
    "\n",
    "$$\n",
    "\\frac{\\mathrm{d}L}{\\mathrm{d}\\theta} = \\mathbf{0}^\\top\n",
    "$$\n",
    "\n",
    "(necessary optimality condition), and we obtain\n",
    "\n",
    "$$\n",
    "\\frac{\\mathrm{d}L}{\\mathrm{d}\\theta} \\stackrel{(9.11c)}{=} \\mathbf{0}^\\top \\quad \\Leftrightarrow \\quad \\theta_{\\text{ML}}^\\top \\mathbf{X}^\\top \\mathbf{X} = \\mathbf{y}^\\top \\mathbf{X} \\tag{9.12a}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Leftrightarrow \\quad \\theta_{\\text{ML}}^\\top = \\mathbf{y}^\\top \\mathbf{X} (\\mathbf{X}^\\top \\mathbf{X})^{-1} \\tag{9.12b}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Leftrightarrow \\quad \\theta_{\\text{ML}} = (\\mathbf{X}^\\top \\mathbf{X})^{-1} \\mathbf{X}^\\top \\mathbf{y}. \\tag{9.12c}\n",
    "$$\n",
    "\n",
    "We could right-multiply the first equation by\n",
    "\n",
    "$$\n",
    "(\\mathbf{X}^\\top \\mathbf{X})^{-1}\n",
    "$$\n",
    "\n",
    "because $ \\mathbf{X}^\\top \\mathbf{X} $ is positive definite if\n",
    "\n",
    "$$\n",
    "\\text{rk}(\\mathbf{X}) = D,\n",
    "$$\n",
    "\n",
    "where \\( \\text{rk}(\\mathbf{X}) \\) denotes the rank of \\( \\mathbf{X} \\).\n",
    "\n",
    "> **Remark**: Setting the gradient to\n",
    "\n",
    "$$\n",
    "\\mathbf{0}^\\top\n",
    "$$\n",
    "\n",
    "is a necessary and sufficient condition, and we obtain a global minimum since the Hessian\n",
    "\n",
    "$$\n",
    "\\nabla_\\theta^2 L(\\theta) = \\mathbf{X}^\\top \\mathbf{X} \\in \\mathbb{R}^{D \\times D}\n",
    "$$\n",
    "\n",
    "is positive definite. ♢\n",
    "\n",
    "> **Remark**: The maximum likelihood solution in (9.12c) requires us to solve a system of linear equations of the form\n",
    "\n",
    "$$\n",
    "\\mathbf{A}\\theta = \\mathbf{b}\n",
    "$$\n",
    "\n",
    "with\n",
    "\n",
    "$$\n",
    "\\mathbf{A} = (\\mathbf{X}^\\top \\mathbf{X})\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "\\mathbf{b} = \\mathbf{X}^\\top \\mathbf{y}.\n",
    "$$\n",
    "\n",
    "♢\n",
    "\n",
    "### Example 9.2 (Fitting Lines)\n",
    "\n",
    "Let us have a look at Figure 9.2, where we aim to fit a straight line\n",
    "\n",
    "$$\n",
    "f(x) = \\theta x,\n",
    "$$\n",
    "\n",
    "where $ \\theta $ is an unknown slope, to a dataset using maximum likelihood estimation. Examples of functions in this model class (straight lines) are shown in Figure 9.2(a). For the dataset shown in Figure 9.2(b), we find the maximum likelihood estimate of the slope parameter $ \\theta $ using (9.12c) and obtain the maximum likelihood linear function in Fig.2(c).\n",
    "\n",
    "### Maximum Likelihood Estimation with Features\n",
    "\n",
    "So far, we considered the linear regression setting described in (9.4), which allowed us to fit straight lines to data using maximum likelihood estimation. However, straight lines are not sufficiently expressive when it comes to fitting more interesting data. Fortunately, linear regression offers us a way to fit nonlinear functions within the linear regression framework: Since “linear regression” only refers to “linear in the parameters”, we can perform an arbitrary nonlinear transformation $ \\phi(\\mathbf{x}) $ of the inputs $ \\mathbf{x} $ and then linearly combine the components of this transformation. The corresponding linear regression model is\n",
    "\n",
    "$$\n",
    "p(y \\mid \\mathbf{x}, \\theta) = \\mathcal{N}(y \\mid \\phi^\\top(\\mathbf{x})\\theta, \\sigma^2) \\tag{9.13}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Leftrightarrow \\quad y = \\phi^\\top(\\mathbf{x})\\theta + \\epsilon = \\sum_{k=0}^{K-1} \\theta_k \\phi_k(\\mathbf{x}) + \\epsilon,\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\phi: \\mathbb{R}^D \\to \\mathbb{R}^K\n",
    "$$\n",
    "\n",
    "is a (nonlinear) transformation of the inputs $ \\mathbf{x} $, and\n",
    "\n",
    "$$\n",
    "\\phi_k: \\mathbb{R}^D \\to \\mathbb{R}\n",
    "$$\n",
    "\n",
    "is the $ k $-th component of the feature vector $ \\phi $. Note that the model parameters $ \\theta $ still appear only linearly.\n",
    "\n",
    "### Example 3 (Polynomial Regression)\n",
    "\n",
    "We are concerned with a regression problem\n",
    "\n",
    "$$\n",
    "y = \\phi^\\top(\\mathbf{x})\\theta + \\epsilon,\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\mathbf{x} \\in \\mathbb{R}\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "\\theta \\in \\mathbb{R}^K.\n",
    "$$\n",
    "\n",
    "A transformation that is often used in this context is\n",
    "\n",
    "$$\n",
    "\\phi(\\mathbf{x}) = \\begin{bmatrix}\n",
    "\\phi_0(\\mathbf{x}) \\\\\n",
    "\\phi_1(\\mathbf{x}) \\\\\n",
    "\\phi_2(\\mathbf{x}) \\\\\n",
    "\\vdots \\\\\n",
    "\\phi_{K-1}(\\mathbf{x})\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "1 \\\\\n",
    "\\mathbf{x} \\\\\n",
    "\\mathbf{x}^2 \\\\\n",
    "\\vdots \\\\\n",
    "\\mathbf{x}^{K-1}\n",
    "\\end{bmatrix} \\in \\mathbb{R}^K. \\tag{9.14}\n",
    "$$\n",
    "\n",
    "This means that we “lift” the original one-dimensional input space into a $ K $-dimensional feature space consisting of all monomials\n",
    "\n",
    "$$\n",
    "\\mathbf{x}^k \\quad \\text{for} \\quad k = 0, \\ldots, K-1.\n",
    "$$\n",
    "\n",
    "With these features, we can model polynomials of degree $ \\leq K-1 $ within the framework of linear regression: A polynomial of degree"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "9bb30d8a",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)\n",
    "\n",
    "Fig.4 Polynomial regression: (a) dataset consisting of (xn , yn ) pairs, n = 1, . . . , 10; (b) maximum likelihood polynomial of degree 4.\n",
    "\n",
    "$ \\leq K-1 $ is\n",
    "\n",
    "$$\n",
    "f(x) = \\sum_{k=0}^{K-1} \\theta_k x^k = \\phi^\\top(x)\\theta, \\tag{9.15}\n",
    "$$\n",
    "\n",
    "where $ \\phi $ is defined in (9.14) and\n",
    "\n",
    "$$\n",
    "\\theta = [\\theta_0, \\ldots, \\theta_{K-1}]^\\top \\in \\mathbb{R}^K\n",
    "$$\n",
    "\n",
    "contains the (linear) parameters $ \\theta_k $.\n",
    "\n",
    "Let us now have a look at maximum likelihood estimation of the parameters $ \\theta $ in the linear regression model (9.13). We consider training inputs $ \\mathbf{x}_n \\in \\mathbb{R}^D $ and targets $ y_n \\in \\mathbb{R} $, $ n = 1, \\ldots, N $, and define the feature matrix (design matrix) as\n",
    "\n",
    "$$\n",
    "\\Phi := \\begin{bmatrix}\n",
    "\\phi_0(\\mathbf{x}_1) & \\cdots & \\phi_{K-1}(\\mathbf{x}_1) \\\\\n",
    "\\phi_0(\\mathbf{x}_2) & \\cdots & \\phi_{K-1}(\\mathbf{x}_2) \\\\\n",
    "\\vdots & \\ddots & \\vdots \\\\\n",
    "\\phi_0(\\mathbf{x}_N) & \\cdots & \\phi_{K-1}(\\mathbf{x}_N)\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "\\phi^\\top(\\mathbf{x}_1) \\\\\n",
    "\\vdots \\\\\n",
    "\\phi^\\top(\\mathbf{x}_N)\n",
    "\\end{bmatrix} \\in \\mathbb{R}^{N \\times K}, \\tag{9.16}\n",
    "$$\n",
    "\n",
    "where $ \\Phi_{ij} = \\phi_j(\\mathbf{x}_i) $ and $ \\phi_j: \\mathbb{R}^D \\to \\mathbb{R} $.\n",
    "\n",
    "### Example .4 (Feature Matrix for Second-order Polynomials)\n",
    "\n",
    "For a second-order polynomial and $ N $ training points $ \\mathbf{x}_n \\in \\mathbb{R} $, $ n = 1, \\ldots, N $, the feature matrix is\n",
    "\n",
    "$$\n",
    "\\Phi = \\begin{bmatrix}\n",
    "1 & \\mathbf{x}_1 & \\mathbf{x}_1^2 \\\\\n",
    "1 & \\mathbf{x}_2 & \\mathbf{x}_2^2 \\\\\n",
    "\\vdots & \\vdots & \\vdots \\\\\n",
    "1 & \\mathbf{x}_N & \\mathbf{x}_N^2\n",
    "\\end{bmatrix}. \\tag{9.17}\n",
    "$$\n",
    "\n",
    "With the feature matrix $ \\Phi $ defined in (9.16), the negative log-likelihood for the linear regression model (9.13) can be written as\n",
    "\n",
    "$$\n",
    "-\\log p(\\mathbf{Y} \\mid \\mathbf{X}, \\theta) = \\frac{1}{2\\sigma^2} (\\mathbf{y} - \\Phi\\theta)^\\top (\\mathbf{y} - \\Phi\\theta) + \\text{const}. \\tag{9.18}\n",
    "$$\n",
    "\n",
    "Comparing (9.18) with the negative log-likelihood in (9.10b) for the “feature-free” model, we immediately see we just need to replace $ \\mathbf{X} $ with $ \\Phi $. Since both $ \\mathbf{X} $ and $ \\Phi $ are independent of the parameters $ \\theta $ that we wish to optimize, we arrive immediately at the maximum likelihood estimate\n",
    "\n",
    "$$\n",
    "\\theta_{\\text{ML}} = (\\Phi^\\top \\Phi)^{-1} \\Phi^\\top \\mathbf{y} \\tag{9.19}\n",
    "$$\n",
    "\n",
    "for the linear regression problem with nonlinear features defined in (9.13).\n",
    "\n",
    "> **Remark**: When we were working without features, we required $ \\mathbf{X}^\\top \\mathbf{X} $ to be invertible, which is the case when $ \\text{rk}(\\mathbf{X}) = D $, i.e., the columns of $ \\mathbf{X} $ are linearly independent. In (9.19), we therefore require $ \\Phi^\\top \\Phi \\in \\mathbb{R}^{K \\times K} $ to be invertible. This is the case if and only if\n",
    "\n",
    "$$\n",
    "\\text{rk}(\\Phi) = K.\n",
    "$$\n",
    "\n",
    "♢\n",
    "\n",
    "### Example 9.5 (Maximum Likelihood Polynomial Fit)\n",
    "\n",
    "**Figure 9.4: Polynomial MLE regression**  \n",
    "(a) dataset consisting of $ (\\mathbf{x}_n, y_n) $ pairs, $ n = 1, \\ldots, 10 $; (b) maximum likelihood polynomial of degree 4.\n",
    "\n",
    "Consider the dataset in Figure 9.4(a). The dataset consists of $ N = 10 $ pairs $ (\\mathbf{x}_n, y_n) $, where\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_n \\sim \\mathcal{U}[-5, 5]\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "y_n = -\\sin\\left(\\frac{\\mathbf{x}_n}{5}\\right) + \\cos(\\mathbf{x}_n) + \\epsilon, \\quad \\text{where} \\quad \\epsilon \\sim \\mathcal{N}(0, 0.2^2).\n",
    "$$\n",
    "\n",
    "We fit a polynomial of degree 4 using maximum likelihood estimation, i.e., parameters $ \\theta_{\\text{ML}} $ are given in (9.19). The maximum likelihood estimate yields function values $ \\phi^\\top(\\mathbf{x}_*) \\theta_{\\text{ML}} $ at any test location $ \\mathbf{x}_* $. The result is shown in Figure 9.4(b).\n",
    "\n",
    "*(Note: The actual figures are not included here as they are illustrative. Figure 9.4(a) would show scattered data points, and Figure 9.4(b) would show a fitted polynomial curve of degree 4 through the data points representing the maximum likelihood estimate.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee8f6431",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "from typing import List, Tuple, Callable\n",
    "\n",
    "class LinearRegressionWithFeatures:\n",
    "    def __init__(self, sigma2: float = 1.0, feature_transform: Callable[[List[float]], List[float]] = None):\n",
    "        \"\"\"\n",
    "        Linear Regression model: y = phi(x)^T theta + epsilon, epsilon ~ N(0, sigma^2).\n",
    "        sigma2 is the known noise variance.\n",
    "        feature_transform is a function that maps x to phi(x).\n",
    "        \"\"\"\n",
    "        self.sigma2 = sigma2  # Known noise variance\n",
    "        self.feature_transform = feature_transform if feature_transform else lambda x: x  # Default: no transformation\n",
    "        self.theta = None     # Parameters to learn\n",
    "        self.fitted = False\n",
    "\n",
    "    def _compute_features(self, X: List[List[float]]) -> List[List[float]]:\n",
    "        \"\"\"\n",
    "        Apply feature transformation to each input in X to compute Phi.\n",
    "        \"\"\"\n",
    "        return [self.feature_transform(x) for x in X]\n",
    "\n",
    "    def fit_mle(self, X: List[List[float]], y: List[float]):\n",
    "        \"\"\"\n",
    "        Fit using Maximum Likelihood Estimation.\n",
    "        Likelihood: p(y|x,theta) = N(y|phi(x)^T theta, sigma^2).\n",
    "        MLE solution: theta_ML = (Phi^T Phi)^(-1) Phi^T y.\n",
    "        \"\"\"\n",
    "        # Compute feature matrix Phi\n",
    "        Phi = self._compute_features(X)\n",
    "        n_samples = len(Phi)\n",
    "        n_features = len(Phi[0])  # Number of features K after transformation\n",
    "\n",
    "        # Compute Phi^T Phi\n",
    "        PhiT_Phi = [[0.0] * n_features for _ in range(n_features)]\n",
    "        for i in range(n_features):\n",
    "            for j in range(n_features):\n",
    "                PhiT_Phi[i][j] = sum(Phi[k][i] * Phi[k][j] for k in range(n_samples))\n",
    "\n",
    "        # Compute Phi^T y\n",
    "        PhiT_y = [0.0] * n_features\n",
    "        for i in range(n_features):\n",
    "            PhiT_y[i] = sum(Phi[k][i] * y[k] for k in range(n_samples))\n",
    "\n",
    "        # Solve (Phi^T Phi) theta = Phi^T y\n",
    "        PhiT_Phi_inv = self._matrix_inverse(PhiT_Phi)\n",
    "        self.theta = [0.0] * n_features\n",
    "        for i in range(n_features):\n",
    "            self.theta[i] = sum(PhiT_Phi_inv[i][j] * PhiT_y[j] for j in range(n_features))\n",
    "\n",
    "        self.fitted = True\n",
    "\n",
    "    def predict(self, X: List[List[float]]) -> List[float]:\n",
    "        \"\"\"\n",
    "        Predict y = phi(x)^T theta for given inputs X.\n",
    "        \"\"\"\n",
    "        if not self.fitted:\n",
    "            raise ValueError(\"Model must be fitted before prediction\")\n",
    "        Phi = self._compute_features(X)\n",
    "        predictions = []\n",
    "        for phi in Phi:\n",
    "            pred = sum(t * p for t, p in zip(self.theta, phi))\n",
    "            predictions.append(pred)\n",
    "        return predictions\n",
    "\n",
    "    def compute_log_likelihood(self, X: List[List[float]], y: List[float]) -> float:\n",
    "        \"\"\"\n",
    "        Compute log-likelihood: sum log p(y_i|x_i,theta) = sum log N(y_i|phi(x_i)^T theta, sigma^2).\n",
    "        \"\"\"\n",
    "        if not self.fitted:\n",
    "            self.fit_mle(X, y)\n",
    "        predictions = self.predict(X)\n",
    "        n_samples = len(y)\n",
    "        log_likelihood = -(n_samples / 2.0) * math.log(2 * math.pi * self.sigma2)\n",
    "        residual_sum = sum((yi - pred)**2 for yi, pred in zip(y, predictions))\n",
    "        log_likelihood -= (1 / (2 * self.sigma2)) * residual_sum\n",
    "        return log_likelihood\n",
    "\n",
    "    def _matrix_inverse(self, matrix: List[List[float]]) -> List[List[float]]:\n",
    "        \"\"\"\n",
    "        Compute the inverse of a square matrix using Gauss-Jordan elimination.\n",
    "        \"\"\"\n",
    "        n = len(matrix)\n",
    "        augmented = []\n",
    "        for i in range(n):\n",
    "            row = matrix[i][:] + [0.0] * n\n",
    "            row[n + i] = 1.0\n",
    "            augmented.append(row)\n",
    "        for i in range(n):\n",
    "            max_row = i\n",
    "            for k in range(i + 1, n):\n",
    "                if abs(augmented[k][i]) > abs(augmented[max_row][i]):\n",
    "                    max_row = k\n",
    "            augmented[i], augmented[max_row] = augmented[max_row], augmented[i]\n",
    "            pivot = augmented[i][i]\n",
    "            if abs(pivot) < 1e-10:\n",
    "                raise ValueError(\"Matrix is singular\")\n",
    "            for j in range(2 * n):\n",
    "                augmented[i][j] /= pivot\n",
    "            for k in range(n):\n",
    "                if k != i:\n",
    "                    factor = augmented[k][i]\n",
    "                    for j in range(2 * n):\n",
    "                        augmented[k][j] -= factor * augmented[i][j]\n",
    "        inverse = []\n",
    "        for i in range(n):\n",
    "            inverse.append(augmented[i][n:])\n",
    "        return inverse\n",
    "\n",
    "def polynomial_features(degree: int) -> Callable[[List[float]], List[float]]:\n",
    "    \"\"\"\n",
    "    Create a feature transformation function for polynomial features up to given degree.\n",
    "    For x in R, returns [1, x, x^2, ..., x^degree].\n",
    "    \"\"\"\n",
    "    def transform(x: List[float]) -> List[float]:\n",
    "        x_val = x[0] if x else 0.0  # Assuming x is 1D (x in R)\n",
    "        return [x_val ** k for k in range(degree + 1)]\n",
    "    return transform\n",
    "\n",
    "def generate_data_example_9_5(n_samples: int = 10, sigma2: float = 0.04) -> Tuple[List[List[float]], List[float]]:\n",
    "    \"\"\"\n",
    "    Generate data as in Example 9.5:\n",
    "    x_n ~ U[-5, 5], y_n = -sin(x_n/5) + cos(x_n) + epsilon, epsilon ~ N(0, 0.2^2).\n",
    "    \"\"\"\n",
    "    random.seed(42)\n",
    "    X = []\n",
    "    y = []\n",
    "    for _ in range(n_samples):\n",
    "        x_val = random.uniform(-5, 5)\n",
    "        y_val = -math.sin(x_val / 5) + math.cos(x_val)\n",
    "        noise = random.gauss(0, math.sqrt(sigma2))  # sigma = 0.2, so sigma2 = 0.04\n",
    "        y_val += noise\n",
    "        X.append([x_val])\n",
    "        y.append(y_val)\n",
    "    return X, y\n",
    "\n",
    "def print_feature_matrix(Phi: List[List[float]]):\n",
    "    \"\"\"\n",
    "    Print the feature matrix Phi in a readable format.\n",
    "    \"\"\"\n",
    "    print(\"Feature Matrix Phi:\")\n",
    "    for row in Phi:\n",
    "        print(\"  \" + \" \".join(f\"{val:8.4f}\" for val in row))\n",
    "\n",
    "def main():\n",
    "    print(\"=\"*60)\n",
    "    print(\"LINEAR REGRESSION WITH FEATURES DEMONSTRATION (SECTION 9.2)\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Example 9.4: Feature Matrix for Second-order Polynomials\n",
    "    print(\"\\n1. Example 9.4: Feature Matrix for Second-order Polynomials...\")\n",
    "    # Generate a small dataset for demonstration\n",
    "    X_small = [[x] for x in [-2.0, 0.0, 1.0]]  # 3 points: x = -2, 0, 1\n",
    "    feature_transform = polynomial_features(degree=2)  # [1, x, x^2]\n",
    "    Phi = [feature_transform(x) for x in X_small]\n",
    "    print(f\"   Input points: {[-2.0, 0.0, 1.0]}\")\n",
    "    print_feature_matrix(Phi)\n",
    "\n",
    "    # Example 9.5: Maximum Likelihood Polynomial Fit"
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "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"
    },
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "2a8c5347",
   "metadata": {},
   "source": [
    "### Estimating the Noise Variance\n",
    "\n",
    "Thus far, we assumed that the noise variance $ \\sigma^2 $ is known. However, we can also use the principle of maximum likelihood estimation to obtain the maximum likelihood estimator $ \\sigma_{\\text{ML}}^2 $ for the noise variance. To do this, we follow the standard procedure: We write down the log-likelihood, compute its derivative with respect to $ \\sigma^2 > 0 $, set it to 0, and solve. The log-likelihood is given by\n",
    "\n",
    "$$\n",
    "\\log p(\\mathbf{Y} \\mid \\mathbf{X}, \\theta, \\sigma^2) = \\sum_{n=1}^N \\log \\mathcal{N}(y_n \\mid \\phi^\\top(\\mathbf{x}_n)\\theta, \\sigma^2) \\tag{9.20a}\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\sum_{n=1}^N \\left( -\\frac{1}{2} \\log(2\\pi) - \\frac{1}{2} \\log \\sigma^2 - \\frac{1}{2\\sigma^2} (y_n - \\phi^\\top(\\mathbf{x}_n)\\theta)^2 \\right) \\tag{9.20b}\n",
    "$$\n",
    "\n",
    "$$\n",
    "= -\\frac{N}{2} \\log \\sigma^2 - \\frac{1}{2\\sigma^2} \\sum_{n=1}^N (y_n - \\phi^\\top(\\mathbf{x}_n)\\theta)^2 + \\text{const}, \\tag{9.20c}\n",
    "$$\n",
    "\n",
    "where we define\n",
    "\n",
    "$$\n",
    "s := \\sum_{n=1}^N (y_n - \\phi^\\top(\\mathbf{x}_n)\\theta)^2.\n",
    "$$\n",
    "\n",
    "The partial derivative of the log-likelihood with respect to \\( \\sigma^2 \\) is then\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\log p(\\mathbf{Y} \\mid \\mathbf{X}, \\theta, \\sigma^2)}{\\partial \\sigma^2} = -\\frac{N}{2\\sigma^2} + \\frac{1}{2(\\sigma^2)^2} s = 0 \\tag{9.21a}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Leftrightarrow \\quad \\frac{N}{2\\sigma^2} = \\frac{s}{2(\\sigma^2)^2} \\tag{9.21b}\n",
    "$$\n",
    "\n",
    "so that we identify\n",
    "\n",
    "$$\n",
    "\\sigma_{\\text{ML}}^2 = \\frac{s}{N} = \\frac{1}{N} \\sum_{n=1}^N (y_n - \\phi^\\top(\\mathbf{x}_n)\\theta)^2. \\tag{9.22}\n",
    "$$\n",
    "\n",
    "Therefore, the maximum likelihood estimate of the noise variance is the empirical mean of the squared distances between the noise-free function values $ \\phi^\\top(\\mathbf{x}_n)\\theta $ and the corresponding noisy observations $ y_n $ at input locations $ \\mathbf{x}_n $.\n",
    "\n",
    "###  Overfitting in Linear Regression\n",
    "\n",
    "We just discussed how to use maximum likelihood estimation to fit linear models (e.g., polynomials) to data. We can evaluate the quality of the model by computing the error/loss incurred. One way of doing this is to compute the negative log-likelihood (9.10b), which we minimized to determine the maximum likelihood estimator. Alternatively, given that the noise parameter $ \\sigma^2 $ is not a free model parameter, we can ignore the scaling by $ 1/\\sigma^2 $, so that we end up with a squared-error-loss function\n",
    "\n",
    "$$\n",
    "\\|\\mathbf{y} - \\Phi\\theta\\|^2.\n",
    "$$\n",
    "\n",
    "Instead of using this squared loss, we often use the root mean square error (RMSE)\n",
    "\n",
    "$$\n",
    "\\|\\mathbf{y} - \\Phi\\theta\\| = \\sqrt{\\frac{1}{N} \\sum_{n=1}^N (y_n - \\phi^\\top(\\mathbf{x}_n)\\theta)^2}, \\tag{9.23}\n",
    "$$\n",
    "\n",
    "which (a) allows us to compare errors of datasets with different sizes and (b) has the same scale and the same units as the observed function values $ y_n $. For example, if we fit a model that maps post-codes $( \\mathbf{x} $ is given in latitude, longitude) to house prices $( y $-values are EUR), then the RMSE is also measured in EUR, whereas the squared error is given in EUR$ ^2 $. If we choose to include the factor $ \\sigma^2 $ from the original negative log-likelihood (9.10b), then we end up with a unitless objective, i.e., in the preceding example, our objective would no longer be in EUR or EUR$ ^2 $.\n",
    "\n",
    "For model selection (see Section 8.6), we can use the RMSE (or the negative log-likelihood) to determine the best degree of the polynomial by finding the polynomial degree $ M $ that minimizes the objective. Given that the polynomial degree is a natural number, we can perform a brute-force search and enumerate all (reasonable) values of $ M $. For a training set of size $ N $, it is sufficient to test\n",
    "\n",
    "$$\n",
    "0 \\leq M \\leq N - 1.\n",
    "$$\n",
    "\n",
    "For $ M < N $, the maximum likelihood estimator is unique. For $ M \\geq N $, we have more parametersthan data points, and would need to solve an underdetermined system of linear equations (\\( \\Phi^\\top \\Phi \\) in (9.19) would also no longer be invertible) so that there are infinitely many possible maximum likelihood estimators.\n",
    "\n",
    "**Figure 9.5: Maximum likelihood fits for different polynomial degrees \\( M \\)**  \n",
    "(a) \\( M = 0 \\), (b) \\( M = 1 \\), (c) \\( M = 3 \\), (d) \\( M = 4 \\), (e) \\( M = 6 \\), (f) \\( M = 9 \\).\n",
    "\n",
    "Figure 9.5 shows a number of polynomial fits determined by maximum likelihood for the dataset from Figure 9.4(a) with \\( N = 10 \\) observations. We notice that polynomials of low degree (e.g., constants (\\( M = 0 \\)) or linear (\\( M = 1 \\))) fit the data poorly and, hence, are poor representations of the true underlying function. For degrees \\( M = 3, \\ldots, 6 \\), the fits look plausible and smoothly interpolate the data. When we go to higher-degree polynomials, we notice that they fit the data better and better. In the extreme case of\n",
    "\n",
    "$$\n",
    "M = N - 1 = 9,\n",
    "$$\n",
    "\n",
    "the function will pass through every single data point. However, these high-degree polynomials oscillate wildly and are a poor representation of the underlying function that generated the data, such that we suffer from **overfitting**.\n",
    "\n",
    "> **Remark**: The case of $ M = N - 1 $ is extreme in the sense that otherwise the null space of the corresponding system of linear equations would be non-trivial, and we would have infinitely many optimal solutions to the linear regression problem. Note that the noise variance $ \\sigma^2 > 0 $. ♢\n",
    "\n",
    "Remember that the goal is to achieve good generalization by making accurate predictions for new (unseen) data. We obtain some quantitative insight into the dependence of the generalization performance on the polynomial of degree $ M $ by considering a separate test set comprising 200 data points generated using exactly the same procedure used to generate the training set. As test inputs, we chose a linear grid of 200 points in the interval of\n",
    "\n",
    "$$\n",
    "[-5, 5].\n",
    "$$\n",
    "\n",
    "For each choice of $ M $, we evaluate the RMSE (9.23) for both the training data and the test data.\n",
    "\n",
    "Looking now at the test error, which is a qualitative measure of the generalization properties of the corresponding polynomial, we notice that initially the test error decreases; see Figure 9.6 (orange). For fourth-order polynomials, the test error is relatively low and stays relatively constant up to degree 5. However, from degree 6 onward, the test error increases significantly, and high-order polynomials have very bad generalization properties. In this particular example, this also is evident from the corresponding maximum likelihood fits in Figure 9.5. Note that the training error (blue curve in Figure 9.6) never increases when the degree of the polynomial increases. In our example, the best generalization (the point of the smallest test error) is obtained for a polynomial of degree\n",
    "\n",
    "$$\n",
    "M = 4.\n",
    "$$\n",
    "\n",
    "**Fig.6: RMSE vs. Polynomial Degree**  \n",
    "Training error (blue) and test error (orange) for different polynomial degrees, showing that the test error is minimized at $ M = 4 $.\n",
    "\n",
    "*(Note: The actual figures are not included here as they are illustrative. Figure 9.5 would show polynomial fits of degrees 0, 1, 3, 4, 6, and 9 over the dataset, with higher degrees showing oscillations indicative of overfitting. Figure 9.6 would show two curves: the training error decreasing monotonically with polynomial degree, and the test error decreasing until $ M = 4 $, then increasing sharply for higher degrees.)*\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Fig.5 Maximum likelihood fits for different polynomial degrees M .\n",
    "\n",
    "\n",
    "![image-2.png](attachment:image-2.png)\n",
    "\n",
    "Fig.6 Training and test error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38ff93a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "LINEAR REGRESSION: NOISE ESTIMATION AND OVERFITTING (SECTION 9.2)\n",
      "============================================================\n",
      "Training data: 10 points\n",
      "Test data: 200 points\n",
      "\n",
      "1. Estimating Noise Variance...\n",
      "   True sigma^2: 0.0400\n",
      "   Estimated sigma^2: 0.0290\n",
      "   Log-Likelihood: 3.5136\n",
      "\n",
      "2. Overfitting Demonstration (Varying Polynomial Degrees)...\n",
      "     Degree | Train RMSE |  Test RMSE\n",
      "   ---------+------------+-----------\n",
      "          0 |     0.8261 |     0.9729\n",
      "          1 |     0.8063 |     0.8275\n",
      "          2 |     0.7771 |     0.6452\n",
      "          3 |     0.1982 |     4.0163\n",
      "          4 |     0.1703 |     2.3378\n",
      "          5 |     0.1291 |     2.3242\n",
      "          6 |     0.1213 |     5.2721\n",
      "          7 |     0.0729 |    65.7111\n",
      "          8 |     0.0667 |   202.9251\n",
      "          9 |     0.0000 |  6941.3388\n",
      "\n",
      "   Optimal degree (lowest test RMSE): M = 2\n",
      "   Test RMSE at optimal degree: 0.6452\n",
      "\n",
      "3. Predictions at Sample Test Points (Mimicking Figure 9.5)...\n",
      "          x |   True y |      M=0 |      M=1 |      M=3 |      M=4 |      M=6 |      M=9 |\n",
      "   ---------+----------+----------+----------+----------+----------+----------+----------\n",
      "     -5.000 |    1.425 |    0.230 |    0.475 |    1.162 |    1.307 |    1.043 |    1.621 |\n",
      "     -2.990 |   -0.678 |    0.230 |    0.331 |   -0.501 |   -0.541 |   -0.650 |   -2.931 |\n",
      "     -0.980 |    1.094 |    0.230 |    0.186 |    0.604 |    0.779 |    0.910 |    1.981 |\n",
      "      1.030 |   -0.133 |    0.230 |    0.042 |    0.752 |    0.602 |    0.493 |   -0.841 |\n",
      "      3.040 |   -1.282 |    0.230 |   -0.102 |   -3.781 |   -3.019 |   -3.108 | -395.750 |\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "from typing import List, Tuple, Callable\n",
    "\n",
    "class LinearRegressionWithFeatures:\n",
    "    def __init__(self, sigma2: float = None, feature_transform: Callable[[List[float]], List[float]] = None):\n",
    "        \"\"\"\n",
    "        Linear Regression model: y = phi(x)^T theta + epsilon, epsilon ~ N(0, sigma^2).\n",
    "        sigma2 can be provided or estimated via MLE.\n",
    "        feature_transform maps x to phi(x).\n",
    "        \"\"\"\n",
    "        self.sigma2 = sigma2  # Known or to be estimated\n",
    "        self.feature_transform = feature_transform if feature_transform else lambda x: x\n",
    "        self.theta = None\n",
    "        self.fitted = False\n",
    "        self.estimated_sigma2 = None\n",
    "\n",
    "    def _compute_features(self, X: List[List[float]]) -> List[List[float]]:\n",
    "        \"\"\"\n",
    "        Apply feature transformation to each input in X to compute Phi.\n",
    "        \"\"\"\n",
    "        return [self.feature_transform(x) for x in X]\n",
    "\n",
    "    def fit_mle(self, X: List[List[float]], y: List[float]):\n",
    "        \"\"\"\n",
    "        Fit using Maximum Likelihood Estimation.\n",
    "        MLE solution: theta_ML = (Phi^T Phi)^(-1) Phi^T y.\n",
    "        \"\"\"\n",
    "        Phi = self._compute_features(X)\n",
    "        n_samples = len(Phi)\n",
    "        n_features = len(Phi[0])\n",
    "\n",
    "        # Compute Phi^T Phi\n",
    "        PhiT_Phi = [[0.0] * n_features for _ in range(n_features)]\n",
    "        for i in range(n_features):\n",
    "            for j in range(n_features):\n",
    "                PhiT_Phi[i][j] = sum(Phi[k][i] * Phi[k][j] for k in range(n_samples))\n",
    "\n",
    "        # Compute Phi^T y\n",
    "        PhiT_y = [0.0] * n_features\n",
    "        for i in range(n_features):\n",
    "            PhiT_y[i] = sum(Phi[k][i] * y[k] for k in range(n_samples))\n",
    "\n",
    "        # Solve (Phi^T Phi) theta = Phi^T y\n",
    "        PhiT_Phi_inv = self._matrix_inverse(PhiT_Phi)\n",
    "        self.theta = [0.0] * n_features\n",
    "        for i in range(n_features):\n",
    "            self.theta[i] = sum(PhiT_Phi_inv[i][j] * PhiT_y[j] for j in range(n_features))\n",
    "\n",
    "        self.fitted = True\n",
    "\n",
    "        # Estimate sigma^2 if not provided\n",
    "        if self.sigma2 is None:\n",
    "            self.estimate_noise_variance(X, y)\n",
    "\n",
    "    def predict(self, X: List[List[float]]) -> List[float]:\n",
    "        \"\"\"\n",
    "        Predict y = phi(x)^T theta for given inputs X.\n",
    "        \"\"\"\n",
    "        if not self.fitted:\n",
    "            raise ValueError(\"Model must be fitted before prediction\")\n",
    "        Phi = self._compute_features(X)\n",
    "        predictions = []\n",
    "        for phi in Phi:\n",
    "            pred = sum(t * p for t, p in zip(self.theta, phi))\n",
    "            predictions.append(pred)\n",
    "        return predictions\n",
    "\n",
    "    def estimate_noise_variance(self, X: List[List[float]], y: List[float]) -> float:\n",
    "        \"\"\"\n",
    "        Estimate sigma^2 using MLE: sigma_ML^2 = (1/N) sum(y_n - phi(x_n)^T theta)^2.\n",
    "        \"\"\"\n",
    "        if not self.fitted:\n",
    "            self.fit_mle(X, y)\n",
    "        predictions = self.predict(X)\n",
    "        n_samples = len(y)\n",
    "        squared_errors = sum((yi - pred)**2 for yi, pred in zip(y, predictions))\n",
    "        self.estimated_sigma2 = squared_errors / n_samples\n",
    "        return self.estimated_sigma2\n",
    "\n",
    "    def compute_rmse(self, X: List[List[float]], y: List[float]) -> float:\n",
    "        \"\"\"\n",
    "        Compute RMSE: sqrt((1/N) sum(y_n - phi(x_n)^T theta)^2).\n",
    "        \"\"\"\n",
    "        predictions = self.predict(X)\n",
    "        n_samples = len(y)\n",
    "        mse = sum((yi - pred)**2 for yi, pred in zip(y, predictions)) / n_samples\n",
    "        return math.sqrt(mse)\n",
    "\n",
    "    def compute_log_likelihood(self, X: List[List[float]], y: List[float]) -> float:\n",
    "        \"\"\"\n",
    "        Compute log-likelihood: sum log p(y_i|x_i,theta) = sum log N(y_i|phi(x_i)^T theta, sigma^2).\n",
    "        \"\"\"\n",
    "        if not self.fitted:\n",
    "            self.fit_mle(X, y)\n",
    "        sigma2 = self.sigma2 if self.sigma2 is not None else self.estimated_sigma2\n",
    "        if sigma2 is None:\n",
    "            raise ValueError(\"Noise variance must be estimated or provided\")\n",
    "        predictions = self.predict(X)\n",
    "        n_samples = len(y)\n",
    "        log_likelihood = -(n_samples / 2.0) * math.log(2 * math.pi * sigma2)\n",
    "        residual_sum = sum((yi - pred)**2 for yi, pred in zip(y, predictions))\n",
    "        log_likelihood -= (1 / (2 * sigma2)) * residual_sum\n",
    "        return log_likelihood\n",
    "\n",
    "    def _matrix_inverse(self, matrix: List[List[float]]) -> List[List[float]]:\n",
    "        \"\"\"\n",
    "        Compute the inverse of a square matrix using Gauss-Jordan elimination.\n",
    "        \"\"\"\n",
    "        n = len(matrix)\n",
    "        augmented = []\n",
    "        for i in range(n):\n",
    "            row = matrix[i][:] + [0.0] * n\n",
    "            row[n + i] = 1.0\n",
    "            augmented.append(row)\n",
    "        for i in range(n):\n",
    "            max_row = i\n",
    "            for k in range(i + 1, n):\n",
    "                if abs(augmented[k][i]) > abs(augmented[max_row][i]):\n",
    "                    max_row = k\n",
    "            augmented[i], augmented[max_row] = augmented[max_row], augmented[i]\n",
    "            pivot = augmented[i][i]\n",
    "            if abs(pivot) < 1e-10:\n",
    "                raise ValueError(\"Matrix is singular\")\n",
    "            for j in range(2 * n):\n",
    "                augmented[i][j] /= pivot\n",
    "            for k in range(n):\n",
    "                if k != i:\n",
    "                    factor = augmented[k][i]\n",
    "                    for j in range(2 * n):\n",
    "                        augmented[k][j] -= factor * augmented[i][j]\n",
    "        inverse = []\n",
    "        for i in range(n):\n",
    "            inverse.append(augmented[i][n:])\n",
    "        return inverse\n",
    "\n",
    "def polynomial_features(degree: int) -> Callable[[List[float]], List[float]]:\n",
    "    \"\"\"\n",
    "    Create a feature transformation function for polynomial features up to given degree.\n",
    "    \"\"\"\n",
    "    def transform(x: List[float]) -> List[float]:\n",
    "        x_val = x[0] if x else 0.0  # Assuming x is 1D (x in R)\n",
    "        return [x_val ** k for k in range(degree + 1)]\n",
    "    return transform\n",
    "\n",
    "def generate_data(n_samples: int = 10, sigma2: float = 0.04) -> Tuple[List[List[float]], List[float]]:\n",
    "    \"\"\"\n",
    "    Generate data as in Example 9.5:\n",
    "    x_n ~ U[-5, 5], y_n = -sin(x_n/5) + cos(x_n) + epsilon, epsilon ~ N(0, 0.2^2).\n",
    "    \"\"\"\n",
    "    random.seed(42)\n",
    "    X = []\n",
    "    y = []\n",
    "    for _ in range(n_samples):\n",
    "        x_val = random.uniform(-5, 5)\n",
    "        y_val = -math.sin(x_val / 5) + math.cos(x_val)\n",
    "        noise = random.gauss(0, math.sqrt(sigma2))\n",
    "        y_val += noise\n",
    "        X.append([x_val])\n",
    "        y.append(y_val)\n",
    "    return X, y\n",
    "\n",
    "def generate_test_data(n_samples: int = 200, sigma2: float = 0.04) -> Tuple[List[List[float]], List[float]]:\n",
    "    \"\"\"\n",
    "    Generate test data on a linear grid in [-5, 5].\n",
    "    \"\"\"\n",
    "    random.seed(43)\n",
    "    X = [[x] for x in [((i / (n_samples - 1)) * 10 - 5) for i in range(n_samples)]]  # Linear grid from -5 to 5\n",
    "    y = []\n",
    "    for x in X:\n",
    "        x_val = x[0]\n",
    "        y_val = -math.sin(x_val / 5) + math.cos(x_val)\n",
    "        noise = random.gauss(0, math.sqrt(sigma2))\n",
    "        y_val += noise\n",
    "        y.append(y_val)\n",
    "    return X, y\n",
    "\n",
    "def main():\n",
    "    print(\"=\"*60)\n",
    "    print(\"LINEAR REGRESSION: NOISE ESTIMATION AND OVERFITTING (SECTION 9.2)\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Generate training and test data\n",
    "    sigma2_true = 0.04  # sigma = 0.2\n",
    "    X_train, y_train = generate_data(n_samples=10, sigma2=sigma2_true)\n",
    "    X_test, y_test = generate_test_data(n_samples=200, sigma2=sigma2_true)\n",
    "    print(f\"Training data: {len(X_train)} points\")\n",
    "    print(f\"Test data: {len(X_test)} points\")\n",
    "\n",
    "    # Part 1: Estimating Noise Variance\n",
    "    print(\"\\n1. Estimating Noise Variance...\")\n",
    "    degree = 4  # Use degree 4 as it was found to be optimal\n",
    "    feature_transform = polynomial_features(degree=degree)\n",
    "    model = LinearRegressionWithFeatures(sigma2=None, feature_transform=feature_transform)\n",
    "    model.fit_mle(X_train, y_train)\n",
    "    sigma2_estimated = model.estimated_sigma2\n",
    "    print(f\"   True sigma^2: {sigma2_true:.4f}\")\n",
    "    print(f\"   Estimated sigma^2: {sigma2_estimated:.4f}\")\n",
    "    print(f\"   Log-Likelihood: {model.compute_log_likelihood(X_train, y_train):.4f}\")\n",
    "\n",
    "    # Part 2: Overfitting Demonstration (Figures 9.5 and 9.6)\n",
    "    print(\"\\n2. Overfitting Demonstration (Varying Polynomial Degrees)...\")\n",
    "    max_degree = 9  # M from 0 to 9\n",
    "    train_rmse = []\n",
    "    test_rmse = []\n",
    "    print(f\"   {'Degree':>8s} | {'Train RMSE':>10s} | {'Test RMSE':>10s}\")\n",
    "    print(f\"   {'-'*8}-+-{'-'*10}-+-{'-'*10}\")\n",
    "    \n",
    "    for M in range(max_degree + 1):\n",
    "        feature_transform = polynomial_features(degree=M)\n",
    "        model = LinearRegressionWithFeatures(sigma2=sigma2_true, feature_transform=feature_transform)\n",
    "        try:\n",
    "            model.fit_mle(X_train, y_train)\n",
    "            rmse_train = model.compute_rmse(X_train, y_train)\n",
    "            rmse_test = model.compute_rmse(X_test, y_test)\n",
    "            train_rmse.append(rmse_train)\n",
    "            test_rmse.append(rmse_test)\n",
    "            print(f\"   {M:8d} | {rmse_train:10.4f} | {rmse_test:10.4f}\")\n",
    "        except ValueError as e:\n",
    "            print(f\"   {M:8d} | {'Error':>10s} | {'Error':>10s} ({str(e)})\")\n",
    "            train_rmse.append(float('inf'))\n",
    "            test_rmse.append(float('inf'))\n",
    "\n",
    "    # Find the degree with minimum test RMSE\n",
    "    min_test_rmse = min(rmse for rmse in test_rmse if rmse != float('inf'))\n",
    "    optimal_degree = test_rmse.index(min_test_rmse)\n",
    "    print(f\"\\n   Optimal degree (lowest test RMSE): M = {optimal_degree}\")\n",
    "    print(f\"   Test RMSE at optimal degree: {min_test_rmse:.4f}\")\n",
    "\n",
    "    # Part 3: Predictions for M = 0, 1, 3, 4, 6, 9 (as in Figure 9.5)\n",
    "    print(\"\\n3. Predictions at Sample Test Points (Mimicking Figure 9.5)...\")\n",
    "    sample_test_points = X_test[::40]  # Select a few points for demonstration\n",
    "    print(f\"   {'x':>8s} | {'True y':>8s} |\", end=\"\")\n",
    "    degrees_to_show = [0, 1, 3, 4, 6, 9]\n",
    "    for M in degrees_to_show:\n",
    "        print(f\" {'M='+str(M):>8s} |\", end=\"\")\n",
    "    print()\n",
    "    print(\"   \" + \"-\".join([\"-\"*8 + \"-+\" for _ in range(len(degrees_to_show) + 2)])[:-1])\n",
    "    \n",
    "    models = {}\n",
    "    for M in degrees_to_show:\n",
    "        feature_transform = polynomial_features(degree=M)\n",
    "        model = LinearRegressionWithFeatures(sigma2=sigma2_true, feature_transform=feature_transform)\n",
    "        try:\n",
    "            model.fit_mle(X_train, y_train)\n",
    "            models[M] = model\n",
    "        except ValueError:\n",
    "            models[M] = None\n",
    "\n",
    "    for i, x in enumerate(sample_test_points):\n",
    "        true_y = y_test[::40][i]\n",
    "        print(f\"   {x[0]:8.3f} | {true_y:8.3f} |\", end=\"\")\n",
    "        for M in degrees_to_show:\n",
    "            if models[M]:\n",
    "                pred = models[M].predict([x])[0]\n",
    "                print(f\" {pred:8.3f} |\", end=\"\")\n",
    "            else:\n",
    "                print(f\" {'Error':>8s} |\", end=\"\")\n",
    "        print()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "04d64d65",
   "metadata": {},
   "source": [
    "### Maximum A Posteriori Estimation\n",
    "\n",
    "We just saw that maximum likelihood estimation is prone to overfitting. We often observe that the magnitude of the parameter values becomes relatively large if we run into overfitting (Bishop, 2006). To mitigate the effect of huge parameter values, we can place a prior distribution $ p(\\theta) $ on the parameters. The prior distribution explicitly encodes what parameter values are plausible (before having seen any data). For example, a Gaussian prior\n",
    "\n",
    "$$\n",
    "p(\\theta) = \\mathcal{N}(0, 1)\n",
    "$$\n",
    "\n",
    "on a single parameter $ \\theta $ encodes that parameter values are expected to lie in the interval\n",
    "\n",
    "$$\n",
    "[-2, 2]\n",
    "$$\n",
    "\n",
    "(two standard deviations around the mean value).\n",
    "\n",
    "Once a dataset $ \\mathbf{X}, \\mathbf{Y} $ is available, instead of maximizing the likelihood, we seek parameters that maximize the posterior distribution $ p(\\theta \\mid \\mathbf{X}, \\mathbf{Y}) $. This procedure is called **maximum a posteriori (MAP)** estimation. The posterior over the parameters $ \\theta $, given the training data $ \\mathbf{X}, \\mathbf{Y} $, is obtained by applying Bayes’ theorem (Section 6.3) as\n",
    "\n",
    "$$\n",
    "p(\\theta \\mid \\mathbf{X}, \\mathbf{Y}) = \\frac{p(\\mathbf{Y} \\mid \\mathbf{X}, \\theta) p(\\theta)}{p(\\mathbf{Y} \\mid \\mathbf{X})}. \\tag{9.24}\n",
    "$$\n",
    "\n",
    "Since the posterior explicitly depends on the parameter prior $ p(\\theta) $, the prior will have an effect on the parameter vector we find as the maximizer of the posterior. We will see this more explicitly in the following.\n",
    "\n",
    "The parameter vector $ \\theta_{\\text{MAP}} $ that maximizes the posterior (9.24) is the MAP estimate. To find the MAP estimate, we follow steps that are similar in flavor to maximum likelihood estimation. We start with the log-transform and compute the log-posterior as\n",
    "\n",
    "$$\n",
    "\\log p(\\theta \\mid \\mathbf{X}, \\mathbf{Y}) = \\log p(\\mathbf{Y} \\mid \\mathbf{X}, \\theta) + \\log p(\\theta) + \\text{const}, \\tag{9.25}\n",
    "$$\n",
    "\n",
    "where the constant comprises the terms that are independent of $ \\theta $. We see that the log-posterior in (9.25) is the sum of the log-likelihood $ p(\\mathbf{Y} \\mid \\mathbf{X}, \\theta) $ and the log-prior $ \\log p(\\theta) $, so that the MAP estimate will be a “compromise” between the prior (our suggestion for plausible parameter values before observing data) and the data-dependent likelihood.\n",
    "\n",
    "To find the MAP estimate $ \\theta_{\\text{MAP}} $, we minimize the negative log-posterior distribution with respect to $ \\theta $, i.e., we solve\n",
    "\n",
    "$$\n",
    "\\theta_{\\text{MAP}} \\in \\arg \\min_{\\theta} \\{ -\\log p(\\mathbf{Y} \\mid \\mathbf{X}, \\theta) - \\log p(\\theta) \\}. \\tag{9.26}\n",
    "$$\n",
    "\n",
    "The gradient of the negative log-posterior with respect to \\( \\theta \\) is\n",
    "\n",
    "$$\n",
    "-\\frac{\\mathrm{d} \\log p(\\theta \\mid \\mathbf{X}, \\mathbf{Y})}{\\mathrm{d}\\theta} = -\\frac{\\mathrm{d} \\log p(\\mathbf{Y} \\mid \\mathbf{X}, \\theta)}{\\mathrm{d}\\theta} - \\frac{\\mathrm{d} \\log p(\\theta)}{\\mathrm{d}\\theta}, \\tag{9.27}\n",
    "$$\n",
    "\n",
    "where we identify the first term on the right-hand side as the gradient of the negative log-likelihood from (9.11c).\n",
    "\n",
    "With a (conjugate) Gaussian prior\n",
    "\n",
    "$$\n",
    "p(\\theta) = \\mathcal{N}(0, b^2 \\mathbf{I})\n",
    "$$\n",
    "\n",
    "on the parameters $ \\theta $, the negative log-posterior for the linear regression setting (9.13), we obtain the negative log-posterior\n",
    "\n",
    "$$\n",
    "-\\log p(\\theta \\mid \\mathbf{X}, \\mathbf{Y}) = \\frac{1}{2\\sigma^2} (\\mathbf{y} - \\Phi\\theta)^\\top (\\mathbf{y} - \\Phi\\theta) + \\frac{1}{2b^2} \\theta^\\top \\theta + \\text{const}. \\tag{9.28}\n",
    "$$\n",
    "\n",
    "Here, the first term corresponds to the contribution from the log-likelihood, and the second term originates from the log-prior. The gradient of the log-posterior with respect to the parameters $ \\theta $ is then\n",
    "\n",
    "$$\n",
    "-\\frac{\\mathrm{d} \\log p(\\theta \\mid \\mathbf{X}, \\mathbf{Y})}{\\mathrm{d}\\theta} = \\frac{1}{\\sigma^2} (\\theta^\\top \\Phi^\\top \\Phi - \\mathbf{y}^\\top \\Phi) + \\frac{1}{b^2} \\theta^\\top. \\tag{9.29}\n",
    "$$\n",
    "\n",
    "We will find the MAP estimate $ \\theta_{\\text{MAP}} $ by setting this gradient to $ \\mathbf{0}^\\top $ and solving for $ \\theta_{\\text{MAP}} $. We obtain\n",
    "\n",
    "$$\n",
    "\\frac{1}{\\sigma^2} (\\theta^\\top \\Phi^\\top \\Phi - \\mathbf{y}^\\top \\Phi) + \\frac{1}{b^2} \\theta^\\top = \\mathbf{0}^\\top \\tag{9.30a}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Leftrightarrow \\quad \\theta^\\top \\left( \\frac{1}{\\sigma^2} \\Phi^\\top \\Phi + \\frac{1}{b^2} \\mathbf{I} \\right) - \\frac{1}{\\sigma^2} \\mathbf{y}^\\top \\Phi = \\mathbf{0}^\\top \\tag{9.30b}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Leftrightarrow \\quad \\theta^\\top \\left( \\frac{1}{\\sigma^2} \\Phi^\\top \\Phi + \\frac{1}{b^2} \\mathbf{I} \\right) = \\frac{1}{\\sigma^2} \\mathbf{y}^\\top \\Phi \\tag{9.30c}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Leftrightarrow \\quad \\theta^\\top = \\mathbf{y}^\\top \\Phi \\left( \\frac{1}{\\sigma^2} \\Phi^\\top \\Phi + \\frac{1}{b^2} \\mathbf{I} \\right)^{-1} \\tag{9.30d}\n",
    "$$\n",
    "\n",
    "so that the MAP estimate is (by transposing both sides of the last equality)\n",
    "\n",
    "$$\n",
    "\\theta_{\\text{MAP}} = \\left( \\Phi^\\top \\Phi + \\frac{\\sigma^2}{b^2} \\mathbf{I} \\right)^{-1} \\Phi^\\top \\mathbf{y}. \\tag{9.31}\n",
    "$$\n",
    "\n",
    "> **Remark**: $ \\Phi^\\top \\Phi $ is symmetric, positive semi-definite. The additional term in (9.31) is strictly positive definite so that the inverse exists. ♢\n",
    "\n",
    "Comparing the MAP estimate in (9.31) with the maximum likelihood estimate in (9.19), we see that the only difference between both solutions is the additional term\n",
    "\n",
    "$$\n",
    "\\frac{\\sigma^2}{b^2} \\mathbf{I}\n",
    "$$\n",
    "\n",
    "in the inverse matrix. This term ensures that $ \\Phi^\\top \\Phi + \\frac{\\sigma^2}{b^2} \\mathbf{I} $ is symmetric and strictly positive definite (i.e., its inverse exists and the MAP estimate is the unique solution of a system of linear equations). Moreover, it reflects the impact of the regularizer.\n",
    "\n",
    "### Example .6 (MAP Estimation for Polynomial Regression)\n",
    "\n",
    "In the polynomial regression example from Section 9.2.1, we place a Gaussian prior\n",
    "\n",
    "$$\n",
    "p(\\theta) = \\mathcal{N}(0, \\mathbf{I})\n",
    "$$\n",
    "\n",
    "on the parameters $ \\theta $ and determine the MAP estimates according to (9.31). In Fig.7, we show both the maximum likelihood and the MAP estimates for polynomials of degree 6 (left) and degree 8 (right). The prior (regularizer) does not play a significant role for the low-degree polynomial, but keeps the function relatively smooth for higher-degree polynomials. Although the MAP estimate can push the boundaries of overfitting, it is not a general solution to this problem, so we need a more principled approach to tackle overfitting.\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "\n",
    "**Fig.7: MLE vs. MAP Estimates**  \n",
    "(a) Polynomials of degree 6, (b) Polynomials of degree 8.\n",
    "\n",
    "*(Note: The actual figures are not included here as they are illustrative. Figure 9.7(a) would show the MLE and MAP polynomial fits of degree 6, with the MAP fit being slightly smoother. Figure 9.7(b) would show the same for degree 8, where the MAP fit is noticeably smoother, reducing the oscillations seen in the MLE fit.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b00baa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "LINEAR REGRESSION: MAP ESTIMATION (SECTION 9.2.3)\n",
      "============================================================\n",
      "Training data: 10 points\n",
      "Test data: 200 points\n",
      "\n",
      "1. Example 9.6: MAP vs. MLE for Polynomial Regression...\n",
      "\n",
      "   Polynomial Degree: 6\n",
      "   MLE - Train RMSE: 0.1213, Test RMSE: 5.2721\n",
      "   MAP - Train RMSE: 0.1218, Test RMSE: 6.2083\n",
      "\n",
      "   Predictions at Sample Test Points (Degree 6):\n",
      "          x |   True y |      MLE |      MAP\n",
      "   ---------+----------+----------+---------\n",
      "     -5.000 |    1.425 |    1.043 |    1.042\n",
      "     -2.990 |   -0.678 |   -0.650 |   -0.649\n",
      "     -0.980 |    1.094 |    0.910 |    0.900\n",
      "      1.030 |   -0.133 |    0.493 |    0.490\n",
      "      3.040 |   -1.282 |   -3.108 |   -3.308\n",
      "\n",
      "   Polynomial Degree: 8\n",
      "   MLE - Train RMSE: 0.0667, Test RMSE: 202.9251\n",
      "   MAP - Train RMSE: 0.0681, Test RMSE: 156.5050\n",
      "\n",
      "   Predictions at Sample Test Points (Degree 8):\n",
      "          x |   True y |      MLE |      MAP\n",
      "   ---------+----------+----------+---------\n",
      "     -5.000 |    1.425 |    0.735 |    0.732\n",
      "     -2.990 |   -0.678 |   -0.826 |   -0.807\n",
      "     -0.980 |    1.094 |    1.047 |    1.019\n",
      "      1.030 |   -0.133 |    0.818 |    0.748\n",
      "      3.040 |   -1.282 |   17.778 |   13.358\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "from typing import List, Tuple, Callable\n",
    "\n",
    "class LinearRegressionWithFeatures:\n",
    "    def __init__(self, sigma2: float = None, feature_transform: Callable[[List[float]], List[float]] = None, prior_b2: float = None):\n",
    "        \"\"\"\n",
    "        Linear Regression model: y = phi(x)^T theta + epsilon, epsilon ~ N(0, sigma^2).\n",
    "        sigma2 can be provided or estimated.\n",
    "        prior_b2 is the variance of the Gaussian prior N(0, b^2 I) for MAP estimation.\n",
    "        \"\"\"\n",
    "        self.sigma2 = sigma2\n",
    "        self.feature_transform = feature_transform if feature_transform else lambda x: x\n",
    "        self.prior_b2 = prior_b2  # Variance of the Gaussian prior\n",
    "        self.theta = None\n",
    "        self.fitted = False\n",
    "        self.estimated_sigma2 = None\n",
    "        self.fit_method = None\n",
    "\n",
    "    def _compute_features(self, X: List[List[float]]) -> List[List[float]]:\n",
    "        return [self.feature_transform(x) for x in X]\n",
    "\n",
    "    def fit_mle(self, X: List[List[float]], y: List[float]):\n",
    "        \"\"\"\n",
    "        Fit using Maximum Likelihood Estimation: theta_ML = (Phi^T Phi)^(-1) Phi^T y.\n",
    "        \"\"\"\n",
    "        self.fit_method = \"MLE\"\n",
    "        Phi = self._compute_features(X)\n",
    "        n_samples = len(Phi)\n",
    "        n_features = len(Phi[0])\n",
    "\n",
    "        # Compute Phi^T Phi\n",
    "        PhiT_Phi = [[0.0] * n_features for _ in range(n_features)]\n",
    "        for i in range(n_features):\n",
    "            for j in range(n_features):\n",
    "                PhiT_Phi[i][j] = sum(Phi[k][i] * Phi[k][j] for k in range(n_samples))\n",
    "\n",
    "        # Compute Phi^T y\n",
    "        PhiT_y = [0.0] * n_features\n",
    "        for i in range(n_features):\n",
    "            PhiT_y[i] = sum(Phi[k][i] * y[k] for k in range(n_samples))\n",
    "\n",
    "        # Solve (Phi^T Phi) theta = Phi^T y\n",
    "        PhiT_Phi_inv = self._matrix_inverse(PhiT_Phi)\n",
    "        self.theta = [0.0] * n_features\n",
    "        for i in range(n_features):\n",
    "            self.theta[i] = sum(PhiT_Phi_inv[i][j] * PhiT_y[j] for j in range(n_features))\n",
    "\n",
    "        self.fitted = True\n",
    "        if self.sigma2 is None:\n",
    "            self.estimate_noise_variance(X, y)\n",
    "\n",
    "    def fit_map(self, X: List[List[float]], y: List[float]):\n",
    "        \"\"\"\n",
    "        Fit using Maximum A Posteriori Estimation: theta_MAP = (Phi^T Phi + (sigma^2/b^2) I)^(-1) Phi^T y.\n",
    "        \"\"\"\n",
    "        if self.prior_b2 is None:\n",
    "            raise ValueError(\"Prior variance b^2 must be provided for MAP estimation\")\n",
    "        if self.sigma2 is None:\n",
    "            # Temporarily fit with MLE to estimate sigma^2\n",
    "            self.fit_mle(X, y)\n",
    "            self.sigma2 = self.estimated_sigma2\n",
    "            self.fitted = False  # Reset for MAP fitting\n",
    "\n",
    "        self.fit_method = \"MAP\"\n",
    "        Phi = self._compute_features(X)\n",
    "        n_samples = len(Phi)\n",
    "        n_features = len(Phi[0])\n",
    "\n",
    "        # Compute Phi^T Phi\n",
    "        PhiT_Phi = [[0.0] * n_features for _ in range(n_features)]\n",
    "        for i in range(n_features):\n",
    "            for j in range(n_features):\n",
    "                PhiT_Phi[i][j] = sum(Phi[k][i] * Phi[k][j] for k in range(n_samples))\n",
    "\n",
    "        # Add (sigma^2/b^2) I to Phi^T Phi\n",
    "        lambda_reg = self.sigma2 / self.prior_b2\n",
    "        for i in range(n_features):\n",
    "            PhiT_Phi[i][i] += lambda_reg\n",
    "\n",
    "        # Compute Phi^T y\n",
    "        PhiT_y = [0.0] * n_features\n",
    "        for i in range(n_features):\n",
    "            PhiT_y[i] = sum(Phi[k][i] * y[k] for k in range(n_samples))\n",
    "\n",
    "        # Solve (Phi^T Phi + (sigma^2/b^2) I) theta = Phi^T y\n",
    "        PhiT_Phi_inv = self._matrix_inverse(PhiT_Phi)\n",
    "        self.theta = [0.0] * n_features\n",
    "        for i in range(n_features):\n",
    "            self.theta[i] = sum(PhiT_Phi_inv[i][j] * PhiT_y[j] for j in range(n_features))\n",
    "\n",
    "        self.fitted = True\n",
    "\n",
    "    def predict(self, X: List[List[float]]) -> List[float]:\n",
    "        if not self.fitted:\n",
    "            raise ValueError(\"Model must be fitted before prediction\")\n",
    "        Phi = self._compute_features(X)\n",
    "        predictions = []\n",
    "        for phi in Phi:\n",
    "            pred = sum(t * p for t, p in zip(self.theta, phi))\n",
    "            predictions.append(pred)\n",
    "        return predictions\n",
    "\n",
    "    def estimate_noise_variance(self, X: List[List[float]], y: List[float]) -> float:\n",
    "        if not self.fitted:\n",
    "            self.fit_mle(X, y)\n",
    "        predictions = self.predict(X)\n",
    "        n_samples = len(y)\n",
    "        squared_errors = sum((yi - pred)**2 for yi, pred in zip(y, predictions))\n",
    "        self.estimated_sigma2 = squared_errors / n_samples\n",
    "        return self.estimated_sigma2\n",
    "\n",
    "    def compute_rmse(self, X: List[List[float]], y: List[float]) -> float:\n",
    "        predictions = self.predict(X)\n",
    "        n_samples = len(y)\n",
    "        mse = sum((yi - pred)**2 for yi, pred in zip(y, predictions)) / n_samples\n",
    "        return math.sqrt(mse)\n",
    "\n",
    "    def compute_log_likelihood(self, X: List[List[float]], y: List[float]) -> float:\n",
    "        sigma2 = self.sigma2 if self.sigma2 is not None else self.estimated_sigma2\n",
    "        if sigma2 is None:\n",
    "            raise ValueError(\"Noise variance must be estimated or provided\")\n",
    "        predictions = self.predict(X)\n",
    "        n_samples = len(y)\n",
    "        log_likelihood = -(n_samples / 2.0) * math.log(2 * math.pi * sigma2)\n",
    "        residual_sum = sum((yi - pred)**2 for yi, pred in zip(y, predictions))\n",
    "        log_likelihood -= (1 / (2 * sigma2)) * residual_sum\n",
    "        return log_likelihood\n",
    "\n",
    "    def _matrix_inverse(self, matrix: List[List[float]]) -> List[List[float]]:\n",
    "        n = len(matrix)\n",
    "        augmented = []\n",
    "        for i in range(n):\n",
    "            row = matrix[i][:] + [0.0] * n\n",
    "            row[n + i] = 1.0\n",
    "            augmented.append(row)\n",
    "        for i in range(n):\n",
    "            max_row = i\n",
    "            for k in range(i + 1, n):\n",
    "                if abs(augmented[k][i]) > abs(augmented[max_row][i]):\n",
    "                    max_row = k\n",
    "            augmented[i], augmented[max_row] = augmented[max_row], augmented[i]\n",
    "            pivot = augmented[i][i]\n",
    "            if abs(pivot) < 1e-10:\n",
    "                raise ValueError(\"Matrix is singular\")\n",
    "            for j in range(2 * n):\n",
    "                augmented[i][j] /= pivot\n",
    "            for k in range(n):\n",
    "                if k != i:\n",
    "                    factor = augmented[k][i]\n",
    "                    for j in range(2 * n):\n",
    "                        augmented[k][j] -= factor * augmented[i][j]\n",
    "        inverse = []\n",
    "        for i in range(n):\n",
    "            inverse.append(augmented[i][n:])\n",
    "        return inverse\n",
    "\n",
    "def polynomial_features(degree: int) -> Callable[[List[float]], List[float]]:\n",
    "    def transform(x: List[float]) -> List[float]:\n",
    "        x_val = x[0] if x else 0.0\n",
    "        return [x_val ** k for k in range(degree + 1)]\n",
    "    return transform\n",
    "\n",
    "def generate_data(n_samples: int = 10, sigma2: float = 0.04) -> Tuple[List[List[float]], List[float]]:\n",
    "    random.seed(42)\n",
    "    X = []\n",
    "    y = []\n",
    "    for _ in range(n_samples):\n",
    "        x_val = random.uniform(-5, 5)\n",
    "        y_val = -math.sin(x_val / 5) + math.cos(x_val)\n",
    "        noise = random.gauss(0, math.sqrt(sigma2))\n",
    "        y_val += noise\n",
    "        X.append([x_val])\n",
    "        y.append(y_val)\n",
    "    return X, y\n",
    "\n",
    "def generate_test_data(n_samples: int = 200, sigma2: float = 0.04) -> Tuple[List[List[float]], List[float]]:\n",
    "    random.seed(43)\n",
    "    X = [[x] for x in [((i / (n_samples - 1)) * 10 - 5) for i in range(n_samples)]]\n",
    "    y = []\n",
    "    for x in X:\n",
    "        x_val = x[0]\n",
    "        y_val = -math.sin(x_val / 5) + math.cos(x_val)\n",
    "        noise = random.gauss(0, math.sqrt(sigma2))\n",
    "        y_val += noise\n",
    "        y.append(y_val)\n",
    "    return X, y\n",
    "\n",
    "def main():\n",
    "    print(\"=\"*60)\n",
    "    print(\"LINEAR REGRESSION: MAP ESTIMATION (SECTION 9.2.3)\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Generate training and test data\n",
    "    sigma2 = 0.04  # sigma = 0.2\n",
    "    X_train, y_train = generate_data(n_samples=10, sigma2=sigma2)\n",
    "    X_test, y_test = generate_test_data(n_samples=200, sigma2=sigma2)\n",
    "    print(f\"Training data: {len(X_train)} points\")\n",
    "    print(f\"Test data: {len(X_test)} points\")\n",
    "\n",
    "    # Example 9.6: Compare MLE and MAP for degrees 6 and 8\n",
    "    print(\"\\n1. Example 9.6: MAP vs. MLE for Polynomial Regression...\")\n",
    "    degrees = [6, 8]\n",
    "    prior_b2 = 1.0  # As specified: p(theta) = N(0, I), so b^2 = 1\n",
    "\n",
    "    for degree in degrees:\n",
    "        print(f\"\\n   Polynomial Degree: {degree}\")\n",
    "        feature_transform = polynomial_features(degree=degree)\n",
    "\n",
    "        # MLE Model\n",
    "        mle_model = LinearRegressionWithFeatures(sigma2=sigma2, feature_transform=feature_transform)\n",
    "        try:\n",
    "            mle_model.fit_mle(X_train, y_train)\n",
    "            mle_rmse_train = mle_model.compute_rmse(X_train, y_train)\n",
    "            mle_rmse_test = mle_model.compute_rmse(X_test, y_test)\n",
    "            print(f\"   MLE - Train RMSE: {mle_rmse_train:.4f}, Test RMSE: {mle_rmse_test:.4f}\")\n",
    "        except ValueError as e:\n",
    "            print(f\"   MLE - Error: {str(e)}\")\n",
    "            mle_model = None\n",
    "\n",
    "        # MAP Model\n",
    "        map_model = LinearRegressionWithFeatures(sigma2=sigma2, feature_transform=feature_transform, prior_b2=prior_b2)\n",
    "        try:\n",
    "            map_model.fit_map(X_train, y_train)\n",
    "            map_rmse_train = map_model.compute_rmse(X_train, y_train)\n",
    "            map_rmse_test = map_model.compute_rmse(X_test, y_test)\n",
    "            print(f\"   MAP - Train RMSE: {map_rmse_train:.4f}, Test RMSE: {map_rmse_test:.4f}\")\n",
    "        except ValueError as e:\n",
    "            print(f\"   MAP - Error: {str(e)}\")\n",
    "            map_model = None\n",
    "\n",
    "        # Compare predictions at sample test points (mimicking Figure 9.7)\n",
    "        if mle_model and map_model:\n",
    "            print(f\"\\n   Predictions at Sample Test Points (Degree {degree}):\")\n",
    "            sample_test_points = X_test[::40]\n",
    "            print(f\"   {'x':>8s} | {'True y':>8s} | {'MLE':>8s} | {'MAP':>8s}\")\n",
    "            print(f\"   {'-'*8}-+-{'-'*8}-+-{'-'*8}-+-{'-'*8}\")\n",
    "            for i, x in enumerate(sample_test_points):\n",
    "                true_y = y_test[::40][i]\n",
    "                mle_pred = mle_model.predict([x])[0]\n",
    "                map_pred = map_model.predict([x])[0]\n",
    "                print(f\"   {x[0]:8.3f} | {true_y:8.3f} | {mle_pred:8.3f} | {map_pred:8.3f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6681f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "LINEAR REGRESSION: MAP ESTIMATION PLOTS WITH MATPLOTLIB (SECTION 9.2.3)\n",
      "============================================================\n",
      "Training data: 10 points\n",
      "Test data: 200 points\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "from typing import List, Tuple, Callable\n",
    "\n",
    "# Import Matplotlib for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class LinearRegressionWithFeatures:\n",
    "    def __init__(self, sigma2: float = None, feature_transform: Callable[[List[float]], List[float]] = None, prior_b2: float = None):\n",
    "        \"\"\"\n",
    "        Linear Regression model: y = phi(x)^T theta + epsilon, epsilon ~ N(0, sigma^2).\n",
    "        sigma2 can be provided or estimated.\n",
    "        prior_b2 is the variance of the Gaussian prior N(0, b^2 I) for MAP estimation.\n",
    "        \"\"\"\n",
    "        self.sigma2 = sigma2\n",
    "        self.feature_transform = feature_transform if feature_transform else lambda x: x\n",
    "        self.prior_b2 = prior_b2\n",
    "        self.theta = None\n",
    "        self.fitted = False\n",
    "        self.estimated_sigma2 = None\n",
    "        self.fit_method = None\n",
    "\n",
    "    def _compute_features(self, X: List[List[float]]) -> List[List[float]]:\n",
    "        return [self.feature_transform(x) for x in X]\n",
    "\n",
    "    def fit_mle(self, X: List[List[float]], y: List[float]):\n",
    "        self.fit_method = \"MLE\"\n",
    "        Phi = self._compute_features(X)\n",
    "        n_samples = len(Phi)\n",
    "        n_features = len(Phi[0])\n",
    "\n",
    "        PhiT_Phi = [[0.0] * n_features for _ in range(n_features)]\n",
    "        for i in range(n_features):\n",
    "            for j in range(n_features):\n",
    "                PhiT_Phi[i][j] = sum(Phi[k][i] * Phi[k][j] for k in range(n_samples))\n",
    "\n",
    "        PhiT_y = [0.0] * n_features\n",
    "        for i in range(n_features):\n",
    "            PhiT_y[i] = sum(Phi[k][i] * y[k] for k in range(n_samples))\n",
    "\n",
    "        PhiT_Phi_inv = self._matrix_inverse(PhiT_Phi)\n",
    "        self.theta = [0.0] * n_features\n",
    "        for i in range(n_features):\n",
    "            self.theta[i] = sum(PhiT_Phi_inv[i][j] * PhiT_y[j] for j in range(n_features))\n",
    "\n",
    "        self.fitted = True\n",
    "        if self.sigma2 is None:\n",
    "            self.estimate_noise_variance(X, y)\n",
    "\n",
    "    def fit_map(self, X: List[List[float]], y: List[float]):\n",
    "        if self.prior_b2 is None:\n",
    "            raise ValueError(\"Prior variance b^2 must be provided for MAP estimation\")\n",
    "        if self.sigma2 is None:\n",
    "            self.fit_mle(X, y)\n",
    "            self.sigma2 = self.estimated_sigma2\n",
    "            self.fitted = False\n",
    "\n",
    "        self.fit_method = \"MAP\"\n",
    "        Phi = self._compute_features(X)\n",
    "        n_samples = len(Phi)\n",
    "        n_features = len(Phi[0])\n",
    "\n",
    "        PhiT_Phi = [[0.0] * n_features for _ in range(n_features)]\n",
    "        for i in range(n_features):\n",
    "            for j in range(n_features):\n",
    "                PhiT_Phi[i][j] = sum(Phi[k][i] * Phi[k][j] for k in range(n_samples))\n",
    "\n",
    "        lambda_reg = self.sigma2 / self.prior_b2\n",
    "        for i in range(n_features):\n",
    "            PhiT_Phi[i][i] += lambda_reg\n",
    "\n",
    "        PhiT_y = [0.0] * n_features\n",
    "        for i in range(n_features):\n",
    "            PhiT_y[i] = sum(Phi[k][i] * y[k] for k in range(n_samples))\n",
    "\n",
    "        PhiT_Phi_inv = self._matrix_inverse(PhiT_Phi)\n",
    "        self.theta = [0.0] * n_features\n",
    "        for i in range(n_features):\n",
    "            self.theta[i] = sum(PhiT_Phi_inv[i][j] * PhiT_y[j] for j in range(n_features))\n",
    "\n",
    "        self.fitted = True\n",
    "\n",
    "    def predict(self, X: List[List[float]]) -> List[float]:\n",
    "        if not self.fitted:\n",
    "            raise ValueError(\"Model must be fitted before prediction\")\n",
    "        Phi = self._compute_features(X)\n",
    "        predictions = []\n",
    "        for phi in Phi:\n",
    "            pred = sum(t * p for t, p in zip(self.theta, phi))\n",
    "            predictions.append(pred)\n",
    "        return predictions\n",
    "\n",
    "    def estimate_noise_variance(self, X: List[List[float]], y: List[float]) -> float:\n",
    "        if not self.fitted:\n",
    "            self.fit_mle(X, y)\n",
    "        predictions = self.predict(X)\n",
    "        n_samples = len(y)\n",
    "        squared_errors = sum((yi - pred)**2 for yi, pred in zip(y, predictions))\n",
    "        self.estimated_sigma2 = squared_errors / n_samples\n",
    "        return self.estimated_sigma2\n",
    "\n",
    "    def compute_rmse(self, X: List[List[float]], y: List[float]) -> float:\n",
    "        predictions = self.predict(X)\n",
    "        n_samples = len(y)\n",
    "        mse = sum((yi - pred)**2 for yi, pred in zip(y, predictions)) / n_samples\n",
    "        return math.sqrt(mse)\n",
    "\n",
    "    def _matrix_inverse(self, matrix: List[List[float]]) -> List[List[float]]:\n",
    "        n = len(matrix)\n",
    "        augmented = []\n",
    "        for i in range(n):\n",
    "            row = matrix[i][:] + [0.0] * n\n",
    "            row[n + i] = 1.0\n",
    "            augmented.append(row)\n",
    "        for i in range(n):\n",
    "            max_row = i\n",
    "            for k in range(i + 1, n):\n",
    "                if abs(augmented[k][i]) > abs(augmented[max_row][i]):\n",
    "                    max_row = k\n",
    "            augmented[i], augmented[max_row] = augmented[max_row], augmented[i]\n",
    "            pivot = augmented[i][i]\n",
    "            if abs(pivot) < 1e-10:\n",
    "                raise ValueError(\"Matrix is singular\")\n",
    "            for j in range(2 * n):\n",
    "                augmented[i][j] /= pivot\n",
    "            for k in range(n):\n",
    "                if k != i:\n",
    "                    factor = augmented[k][i]\n",
    "                    for j in range(2 * n):\n",
    "                        augmented[k][j] -= factor * augmented[i][j]\n",
    "        inverse = []\n",
    "        for i in range(n):\n",
    "            inverse.append(augmented[i][n:])\n",
    "        return inverse\n",
    "\n",
    "def polynomial_features(degree: int) -> Callable[[List[float]], List[float]]:\n",
    "    def transform(x: List[float]) -> List[float]:\n",
    "        x_val = x[0] if x else 0.0\n",
    "        return [x_val ** k for k in range(degree + 1)]\n",
    "    return transform\n",
    "\n",
    "def generate_data(n_samples: int = 10, sigma2: float = 0.04) -> Tuple[List[List[float]], List[float]]:\n",
    "    random.seed(42)\n",
    "    X = []\n",
    "    y = []\n",
    "    for _ in range(n_samples):\n",
    "        x_val = random.uniform(-5, 5)\n",
    "        y_val = -math.sin(x_val / 5) + math.cos(x_val)\n",
    "        noise = random.gauss(0, math.sqrt(sigma2))\n",
    "        y_val += noise\n",
    "        X.append([x_val])\n",
    "        y.append(y_val)\n",
    "    return X, y\n",
    "\n",
    "def generate_test_data(n_samples: int = 200, sigma2: float = 0.04) -> Tuple[List[List[float]], List[float]]:\n",
    "    random.seed(43)\n",
    "    X = [[x] for x in [((i / (n_samples - 1)) * 10 - 5) for i in range(n_samples)]]\n",
    "    y = []\n",
    "    for x in X:\n",
    "        x_val = x[0]\n",
    "        y_val = -math.sin(x_val / 5) + math.cos(x_val)\n",
    "        noise = random.gauss(0, math.sqrt(sigma2))\n",
    "        y_val += noise\n",
    "        y.append(y_val)\n",
    "    return X, y\n",
    "\n",
    "def plot_fits(X_train, y_train, X_test, y_test, degrees, sigma2, prior_b2):\n",
    "    # Create a figure with two subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    for degree, ax in zip(degrees, [ax1, ax2]):\n",
    "        feature_transform = polynomial_features(degree=degree)\n",
    "\n",
    "        # MLE Model\n",
    "        mle_model = LinearRegressionWithFeatures(sigma2=sigma2, feature_transform=feature_transform)\n",
    "        try:\n",
    "            mle_model.fit_mle(X_train, y_train)\n",
    "            mle_predictions = mle_model.predict(X_test)\n",
    "        except ValueError as e:\n",
    "            print(f\"MLE (Degree {degree}) - Error: {str(e)}\")\n",
    "            mle_predictions = [0] * len(X_test)\n",
    "\n",
    "        # MAP Model\n",
    "        map_model = LinearRegressionWithFeatures(sigma2=sigma2, feature_transform=feature_transform, prior_b2=prior_b2)\n",
    "        try:\n",
    "            map_model.fit_map(X_train, y_train)\n",
    "            map_predictions = map_model.predict(X_test)\n",
    "        except ValueError as e:\n",
    "            print(f\"MAP (Degree {degree}) - Error: {str(e)}\")\n",
    "            map_predictions = [0] * len(X_test)\n",
    "\n",
    "        # Extract x values for plotting\n",
    "        x_test_values = [x[0] for x in X_test]\n",
    "        x_train_values = [x[0] for x in X_train]\n",
    "\n",
    "        # Plot training data as scatter points\n",
    "        ax.scatter(x_train_values, y_train, color='blue', label='Training Data', s=50)\n",
    "\n",
    "        # Plot MLE and MAP fits as lines\n",
    "        ax.plot(x_test_values, mle_predictions, color='red', label='MLE Fit', linewidth=2)\n",
    "        ax.plot(x_test_values, map_predictions, color='green', label='MAP Fit', linewidth=2)\n",
    "\n",
    "        # Set plot limits and labels\n",
    "        ax.set_xlim(-5, 5)\n",
    "        ax.set_ylim(-4, 4)\n",
    "        ax.set_xlabel('x')\n",
    "        ax.set_ylabel('y')\n",
    "        ax.set_title(f'Polynomial Degree {degree}: MLE vs MAP')\n",
    "        ax.grid(True)\n",
    "        ax.legend()\n",
    "\n",
    "    # Adjust layout and display the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    print(\"=\"*60)\n",
    "    print(\"LINEAR REGRESSION: MAP ESTIMATION PLOTS WITH MATPLOTLIB (SECTION 9.2.3)\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Generate training and test data\n",
    "    sigma2 = 0.04\n",
    "    X_train, y_train = generate_data(n_samples=10, sigma2=sigma2)\n",
    "    X_test, y_test = generate_test_data(n_samples=200, sigma2=sigma2)\n",
    "    print(f\"Training data: {len(X_train)} points\")\n",
    "    print(f\"Test data: {len(X_test)} points\")\n",
    "\n",
    "    # Plot for degrees 6 and 8\n",
    "    degrees = [6, 8]\n",
    "    prior_b2 = 1.0\n",
    "    plot_fits(X_train, y_train, X_test, y_test, degrees, sigma2, prior_b2)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cb7fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
