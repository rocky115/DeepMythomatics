{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32b6f5bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (5,1) into shape (5,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13022/1794417714.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mh_forward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbirnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# Backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_13022/1794417714.py\u001b[0m in \u001b[0;36mforward_pass\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0mh_forward\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWxf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mh_forward\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWxf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWhf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_forward\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (5,1) into shape (5,)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class BiRNN:\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Initialize forward weights and biases\n",
    "        self.Wxf = np.random.randn(hidden_size, input_size)\n",
    "        self.Whf = np.random.randn(hidden_size, hidden_size)\n",
    "        self.bf = np.zeros((hidden_size, 1))\n",
    "        \n",
    "        # Initialize backward weights and biases\n",
    "        self.Wxb = np.random.randn(hidden_size, input_size)\n",
    "        self.Whb = np.random.randn(hidden_size, hidden_size)\n",
    "        self.bb = np.zeros((hidden_size, 1))\n",
    "        \n",
    "    def forward_pass(self, x):\n",
    "        T = x.shape[1]  # Length of input sequence\n",
    "        h_forward = np.zeros((self.hidden_size, T))\n",
    "        \n",
    "        # Forward pass\n",
    "        for t in range(T):\n",
    "            if t == 0:\n",
    "                h_forward[:, t] = np.tanh(np.dot(self.Wxf, x[:, t].reshape(-1, 1)) + self.bf)\n",
    "            else:\n",
    "                h_forward[:, t] = np.tanh(np.dot(self.Wxf, x[:, t].reshape(-1, 1)) + np.dot(self.Whf, h_forward[:, t-1].reshape(-1, 1)) + self.bf)\n",
    "                \n",
    "        return h_forward\n",
    "    \n",
    "    def backward_pass(self, x):\n",
    "        T = x.shape[1]  # Length of input sequence\n",
    "        h_backward = np.zeros((self.hidden_size, T))\n",
    "        \n",
    "        # Backward pass\n",
    "        for t in range(T-1, -1, -1):\n",
    "            if t == T-1:\n",
    "                h_backward[:, t] = np.tanh(np.dot(self.Wxb, x[:, t].reshape(-1, 1)) + self.bb)\n",
    "            else:\n",
    "                h_backward[:, t] = np.tanh(np.dot(self.Wxb, x[:, t].reshape(-1, 1)) + np.dot(self.Whb, h_backward[:, t+1].reshape(-1, 1)) + self.bb)\n",
    "                \n",
    "        return h_backward\n",
    "\n",
    "# Example usage\n",
    "input_size = 10\n",
    "hidden_size = 5\n",
    "\n",
    "# Create Bi-RNN instance\n",
    "birnn = BiRNN(input_size, hidden_size)\n",
    "\n",
    "# Generate random input sequence\n",
    "x = np.random.randn(input_size, 5)\n",
    "\n",
    "# Forward pass\n",
    "h_forward = birnn.forward_pass(x)\n",
    "\n",
    "# Backward pass\n",
    "h_backward = birnn.backward_pass(x)\n",
    "\n",
    "print(\"Forward hidden states shape:\", h_forward.shape)\n",
    "print(\"Backward hidden states shape:\", h_backward.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86088dba",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (5,1) into shape (5,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13022/1048589417.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mh_forward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbirnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# Backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_13022/1048589417.py\u001b[0m in \u001b[0;36mforward_pass\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0mh_forward\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWxf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mh_forward\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWxf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWhf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_forward\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (5,1) into shape (5,)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class BiRNN:\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Initialize forward weights and biases\n",
    "        self.Wxf = np.random.randn(hidden_size, input_size)\n",
    "        self.Whf = np.random.randn(hidden_size, hidden_size)\n",
    "        self.bf = np.zeros((hidden_size, 1))\n",
    "        \n",
    "        # Initialize backward weights and biases\n",
    "        self.Wxb = np.random.randn(hidden_size, input_size)\n",
    "        self.Whb = np.random.randn(hidden_size, hidden_size)\n",
    "        self.bb = np.zeros((hidden_size, 1))\n",
    "        \n",
    "    def forward_pass(self, x):\n",
    "        T = x.shape[1]  # Length of input sequence\n",
    "        h_forward = np.zeros((self.hidden_size, T))\n",
    "        \n",
    "        # Forward pass\n",
    "        for t in range(T):\n",
    "            if t == 0:\n",
    "                h_forward[:, t] = np.tanh(np.dot(self.Wxf, x[:, t].reshape(-1, 1)) + self.bf)\n",
    "            else:\n",
    "                h_forward[:, t] = np.tanh(np.dot(self.Wxf, x[:, t].reshape(-1, 1)) + np.dot(self.Whf, h_forward[:, t-1]) + self.bf)\n",
    "                \n",
    "        return h_forward\n",
    "    \n",
    "    def backward_pass(self, x):\n",
    "        T = x.shape[1]  # Length of input sequence\n",
    "        h_backward = np.zeros((self.hidden_size, T))\n",
    "        \n",
    "        # Backward pass\n",
    "        for t in range(T-1, -1, -1):\n",
    "            if t == T-1:\n",
    "                h_backward[:, t] = np.tanh(np.dot(self.Wxb, x[:, t].reshape(-1, 1)) + self.bb)\n",
    "            else:\n",
    "                h_backward[:, t] = np.tanh(np.dot(self.Wxb, x[:, t].reshape(-1, 1)) + np.dot(self.Whb, h_backward[:, t+1]) + self.bb)\n",
    "                \n",
    "        return h_backward\n",
    "\n",
    "# Example usage\n",
    "input_size = 10\n",
    "hidden_size = 5\n",
    "\n",
    "# Create Bi-RNN instance\n",
    "birnn = BiRNN(input_size, hidden_size)\n",
    "\n",
    "# Generate random input sequence\n",
    "x = np.random.randn(input_size, 5)\n",
    "\n",
    "# Forward pass\n",
    "h_forward = birnn.forward_pass(x)\n",
    "\n",
    "# Backward pass\n",
    "h_backward = birnn.backward_pass(x)\n",
    "\n",
    "print(\"Forward hidden states shape:\", h_forward.shape)\n",
    "print(\"Backward hidden states shape:\", h_backward.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3971a0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (5,5) into shape (5,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13022/754678847.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mh_forward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbirnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# Backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_13022/754678847.py\u001b[0m in \u001b[0;36mforward_pass\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0mh_forward\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWxf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mh_forward\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWxf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWhf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_forward\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (5,5) into shape (5,)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class BiRNN:\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Initialize forward weights and biases\n",
    "        self.Wxf = np.random.randn(hidden_size, input_size)\n",
    "        self.Whf = np.random.randn(hidden_size, hidden_size)\n",
    "        self.bf = np.zeros((hidden_size, 1))\n",
    "        \n",
    "        # Initialize backward weights and biases\n",
    "        self.Wxb = np.random.randn(hidden_size, input_size)\n",
    "        self.Whb = np.random.randn(hidden_size, hidden_size)\n",
    "        self.bb = np.zeros((hidden_size, 1))\n",
    "        \n",
    "    def forward_pass(self, x):\n",
    "        T = x.shape[1]  # Length of input sequence\n",
    "        h_forward = np.zeros((self.hidden_size, T))\n",
    "        \n",
    "        # Forward pass\n",
    "        for t in range(T):\n",
    "            if t == 0:\n",
    "                h_forward[:, t] = np.tanh(np.dot(self.Wxf, x[:, t].reshape(-1, 1)) + self.bf[:, 0])\n",
    "            else:\n",
    "                h_forward[:, t] = np.tanh(np.dot(self.Wxf, x[:, t].reshape(-1, 1)) + np.dot(self.Whf, h_forward[:, t-1]) + self.bf[:, 0])\n",
    "                \n",
    "        return h_forward\n",
    "    \n",
    "    def backward_pass(self, x):\n",
    "        T = x.shape[1]  # Length of input sequence\n",
    "        h_backward = np.zeros((self.hidden_size, T))\n",
    "        \n",
    "        # Backward pass\n",
    "        for t in range(T-1, -1, -1):\n",
    "            if t == T-1:\n",
    "                h_backward[:, t] = np.tanh(np.dot(self.Wxb, x[:, t].reshape(-1, 1)) + self.bb[:, 0])\n",
    "            else:\n",
    "                h_backward[:, t] = np.tanh(np.dot(self.Wxb, x[:, t].reshape(-1, 1)) + np.dot(self.Whb, h_backward[:, t+1]) + self.bb[:, 0])\n",
    "                \n",
    "        return h_backward\n",
    "\n",
    "# Example usage\n",
    "input_size = 10\n",
    "hidden_size = 5\n",
    "\n",
    "# Create Bi-RNN instance\n",
    "birnn = BiRNN(input_size, hidden_size)\n",
    "\n",
    "# Generate random input sequence\n",
    "x = np.random.randn(input_size, 5)\n",
    "\n",
    "# Forward pass\n",
    "h_forward = birnn.forward_pass(x)\n",
    "\n",
    "# Backward pass\n",
    "h_backward = birnn.backward_pass(x)\n",
    "\n",
    "print(\"Forward hidden states shape:\", h_forward.shape)\n",
    "print(\"Backward hidden states shape:\", h_backward.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2d19df",
   "metadata": {},
   "source": [
    "The bidirectional recurrent neural network (Bi-RNN) consists of two recurrent neural networks (RNNs) running in opposite directions: one running forward through time and the other running backward. This architecture allows the model to capture dependencies in both directions, providing richer context information for sequence modeling tasks.\n",
    "\n",
    "The forward pass of the Bi-RNN computes hidden states from the input sequence in a forward direction, while the backward pass computes hidden states in a backward direction. These hidden states are then concatenated to form the final output of the Bi-RNN.\n",
    "\n",
    "Mathematically, the forward pass of the Bi-RNN can be represented as follows:\n",
    "\n",
    "$$\n",
    "\\mathbf{h}_{\\text{forward}}[t] = \\tanh(\\mathbf{W}_{\\text{xf}} \\mathbf{x}[t] + \\mathbf{W}_{\\text{hf}} \\mathbf{h}_{\\text{forward}}[t-1] + \\mathbf{b}_f)\n",
    "$$\n",
    "\n",
    "where:\n",
    "- \\(\\mathbf{h}_{\\text{forward}}[t]\\) is the hidden state at time step \\(t\\) in the forward pass,\n",
    "- \\(\\mathbf{x}[t]\\) is the input at time step \\(t\\),\n",
    "- \\(\\mathbf{W}_{\\text{xf}}\\) and \\(\\mathbf{W}_{\\text{hf}}\\) are the weight matrices for the input and hidden-to-hidden connections in the forward RNN, respectively,\n",
    "- \\(\\mathbf{b}_f\\) is the bias vector for the forward RNN, and\n",
    "- \\(\\tanh\\) is the hyperbolic tangent activation function.\n",
    "\n",
    "Similarly, the backward pass of the Bi-RNN can be represented as:\n",
    "\n",
    "$$\n",
    "\\mathbf{h}_{\\text{backward}}[t] = \\tanh(\\mathbf{W}_{\\text{xb}} \\mathbf{x}[t] + \\mathbf{W}_{\\text{hb}} \\mathbf{h}_{\\text{backward}}[t+1] + \\mathbf{b}_b)\n",
    "$$\n",
    "\n",
    "where:\n",
    "- \\(\\mathbf{h}_{\\text{backward}}[t]\\) is the hidden state at time step \\(t\\) in the backward pass,\n",
    "- \\(\\mathbf{x}[t]\\) is the input at time step \\(t\\),\n",
    "- \\(\\mathbf{W}_{\\text{xb}}\\) and \\(\\mathbf{W}_{\\text{hb}}\\) are the weight matrices for the input and hidden-to-hidden connections in the backward RNN, respectively,\n",
    "- \\(\\mathbf{b}_b\\) is the bias vector for the backward RNN, and\n",
    "- \\(\\tanh\\) is the hyperbolic tangent activation function.\n",
    "\n",
    "The final output of the Bi-RNN is obtained by concatenating the forward and backward hidden states at each time step:\n",
    "\n",
    "$$\n",
    "\\mathbf{h}[t] = [\\mathbf{h}_{\\text{forward}}[t], \\mathbf{h}_{\\text{backward}}[t]]\n",
    "$$\n",
    "\n",
    "where \\([\\cdot, \\cdot]\\) denotes concatenation.\n",
    "\n",
    "This architecture enables the Bi-RNN to capture both past and future context information, making it effective for tasks such as sequence labeling, speech recognition, and machine translation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfef57c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
