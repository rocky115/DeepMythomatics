{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de8a2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " * Copyright (c) 2018 Radhamadhab Dalai\n",
    " *\n",
    " * Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    " * of this software and associated documentation files (the \"Software\"), to deal\n",
    " * in the Software without restriction, including without limitation the rights\n",
    " * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    " * copies of the Software, and to permit persons to whom the Software is\n",
    " * furnished to do so, subject to the following conditions:\n",
    " *\n",
    " * The above copyright notice and this permission notice shall be included in\n",
    " * all copies or substantial portions of the Software.\n",
    " *\n",
    " * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    " * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    " * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    " * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    " * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    " * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
    " * THE SOFTWARE.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d914d1fe",
   "metadata": {},
   "source": [
    "Energy-based models are a special class of neural networks. The simplest energy model is the Hopfield Network, first introduced by Hopfield in 1982, which is usually viewed as a form of recurrent neural network.\n",
    "\n",
    "The Hopfield network is a fully connected neural network with binary thresholding neural units whose values are either 0 or 1. These units are fully connected in a \"recurrent\" way in which the connection between weights and neurons are bidirectional.\n",
    "\n",
    "With this setting, the energy of a Hopfield network is defined as:\n",
    "\n",
    "$$\n",
    "E = - \\sum_{i} s_i b_i - \\sum_{i,j} s_i s_j w_{ij}\n",
    "$$\n",
    "\n",
    "where $s_i $ is the state of unit i, $ b_i$ denotes its bias, and $w_{ij}$ denotes the bidirectional weights connecting units i and j.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5288e48a",
   "metadata": {},
   "source": [
    "The Boltzmann machine and the Hopfield network share the following common features:\n",
    "\n",
    "- Their processing units have binary values (say +1 and −1) for their states.\n",
    "- All the synaptic connections between their units are symmetric.\n",
    "- The units are picked at random and one at a time for updating.\n",
    "- They have no self-feedback.\n",
    "\n",
    "There are three important differences between the Boltzmann machine and the Hopfield network:\n",
    "\n",
    "(a) The Boltzmann machine permits the use of hidden neurons, while no such neurons exist in the Hopfield network.\n",
    "(b) The Boltzmann machine uses stochastic neurons with a probabilistic firing mechanism, whereas the standard Hopfield network uses neurons with a deterministic firing mechanism.\n",
    "(c) The Boltzmann machine operates in a supervised manner, while the Hopfield network operates in an unsupervised manner.\n",
    "\n",
    "The above common features and important differences help in providing a better understanding of the following discussion on the Boltzmann machine.\n",
    "\n",
    "The Boltzmann machine has the same definition of energy functions as that of the Hopfield network, except the Boltzmann machine splits the energy function according to hidden units and visible units:\n",
    "\n",
    "$$\n",
    "E(x, h) = -b^T x - c^T h - h^T Wx - x^T Ux - h^T Vh,\n",
    "$$\n",
    "\n",
    "where \\( b \\) and \\( c \\) are the offsets associated with the input \\( x \\) (visible vector) and the hidden output \\( h \\) (hidden vector), respectively, while \\( W \\), \\( U \\), and \\( V \\) are the weight matrices of hidden-visible units, visible-visible units, and hidden-hidden units, respectively.\n",
    "\n",
    "If considering only one observed part (denoted by \\( x \\)) and a hidden part \\( h \\), then the energy-based probability distribution can be defined as:\n",
    "\n",
    "$$\n",
    "P(x, h) = \\frac{e^{-E(x,h)}}{Z},\n",
    "$$\n",
    "\n",
    "where the normalizing factor with a sum running over the visible and hidden spaces given by\n",
    "\n",
    "$$\n",
    "Z = \\sum_{x,h} e^{-E(x,h)}\n",
    "$$\n",
    "\n",
    "is called the partition function by analogy with physical systems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90354221",
   "metadata": {},
   "source": [
    "Because only \\( x \\) is observed, it only needs to care about the marginal\n",
    "\n",
    "$$\n",
    "p(x) = \\frac{1}{Z} \\sum_h e^{-E(x,h)}.\n",
    "$$\n",
    "\n",
    "Substituting (7.6.4) into this equation yields\n",
    "\n",
    "$$\n",
    "p(x) = \\frac{\\sum_h e^{-E(x,h)}}{\\sum_{x̄,h} e^{-E(x̄,h)}},\n",
    "$$\n",
    "\n",
    "whose log-likelihood form is given by\n",
    "\n",
    "$$\n",
    "\\log p(x) = \\log \\sum_h e^{-E(x,h)} - \\log \\sum_{x̄,h} e^{-E(x̄,h)}.\n",
    "$$\n",
    "\n",
    "Then, by letting \\( \\theta = (b, c, W, U, V) \\) denote the parameters of the Boltzmann model, one has:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\log p(x)}{\\partial \\theta} = \\frac{\\partial \\log \\sum_h e^{-E(x,h)}}{\\partial \\theta} - \\frac{\\partial \\log \\sum_{x̄,h} e^{-E(x̄,h)}}{\\partial \\theta}.\n",
    "$$\n",
    "\n",
    "This can be rewritten as:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\log p(x)}{\\partial \\theta} = - \\sum_h \\frac{e^{-E(x,h)}}{\\sum_h e^{-E(x,h)}} \\frac{\\partial E(x, h)}{\\partial \\theta} + \\sum_{x̄,h} \\frac{e^{-E(x̄,h)}}{\\sum_{x̄,h} e^{-E(x̄,h)}} \\frac{\\partial E(x̄, h)}{\\partial \\theta}.\n",
    "$$\n",
    "\n",
    "Let \\( s = \\begin{pmatrix} x \\\\ h \\end{pmatrix} \\) denote all the units in the Boltzmann machine. Then (7.6.2) can be rewritten as:\n",
    "\n",
    "$$\n",
    "E(s) = -\\begin{pmatrix} b^T & c^T \\end{pmatrix} \\begin{pmatrix} x \\\\ h \\end{pmatrix} - \\begin{pmatrix} x^T & h^T \\end{pmatrix} \\begin{pmatrix} U & O \\\\ W & V \\end{pmatrix} \\begin{pmatrix} x \\\\ h \\end{pmatrix} = -d^T s - s^T A s,\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "$$\n",
    "d = \\begin{pmatrix} b \\\\ c \\end{pmatrix}, \\quad A = \\begin{pmatrix} U & O \\\\ W & V \\end{pmatrix}.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b98a02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Epoch 100\n",
      "Epoch 200\n",
      "Epoch 300\n",
      "Epoch 400\n",
      "Epoch 500\n",
      "Epoch 600\n",
      "Epoch 700\n",
      "Epoch 800\n",
      "Epoch 900\n",
      "Original sample:      [0 0 1 0 0 1]\n",
      "Reconstructed sample: [0. 0. 1. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class BoltzmannMachine:\n",
    "    def __init__(self, visible_size, hidden_size):\n",
    "        self.visible_size = visible_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # Initialize weights and biases\n",
    "        self.W = np.random.randn(hidden_size, visible_size)\n",
    "        self.b = np.random.randn(visible_size)\n",
    "        self.c = np.random.randn(hidden_size)\n",
    "\n",
    "    def energy(self, v, h):\n",
    "        \"\"\"\n",
    "        Compute the energy of the configuration (v, h)\n",
    "        \"\"\"\n",
    "        term1 = -np.dot(self.b, v)\n",
    "        term2 = -np.dot(self.c, h)\n",
    "        term3 = -np.dot(h, np.dot(self.W, v))\n",
    "        return term1 + term2 + term3\n",
    "\n",
    "    def probability_h_given_v(self, v):\n",
    "        \"\"\"\n",
    "        Compute the probability of hidden units given visible units\n",
    "        \"\"\"\n",
    "        return 1 / (1 + np.exp(-np.dot(self.W, v) - self.c))\n",
    "\n",
    "    def sample_h_given_v(self, v):\n",
    "        \"\"\"\n",
    "        Sample hidden units given visible units\n",
    "        \"\"\"\n",
    "        p_h_given_v = self.probability_h_given_v(v)\n",
    "        return (np.random.rand(self.hidden_size) < p_h_given_v).astype(float)\n",
    "\n",
    "    def probability_v_given_h(self, h):\n",
    "        \"\"\"\n",
    "        Compute the probability of visible units given hidden units\n",
    "        \"\"\"\n",
    "        return 1 / (1 + np.exp(-np.dot(self.W.T, h) - self.b))\n",
    "\n",
    "    def sample_v_given_h(self, h):\n",
    "        \"\"\"\n",
    "        Sample visible units given hidden units\n",
    "        \"\"\"\n",
    "        p_v_given_h = self.probability_v_given_h(h)\n",
    "        return (np.random.rand(self.visible_size) < p_v_given_h).astype(float)\n",
    "\n",
    "    def train(self, data, learning_rate=0.1, epochs=1000):\n",
    "        \"\"\"\n",
    "        Train the Boltzmann Machine using Contrastive Divergence\n",
    "        \"\"\"\n",
    "        for epoch in range(epochs):\n",
    "            for v0 in data:\n",
    "                v0 = v0.astype(float)\n",
    "                h0 = self.sample_h_given_v(v0)\n",
    "\n",
    "                # Gibbs sampling\n",
    "                vk = self.sample_v_given_h(h0)\n",
    "                hk = self.sample_h_given_v(vk)\n",
    "\n",
    "                # Update weights and biases\n",
    "                self.W += learning_rate * (np.outer(h0, v0) - np.outer(hk, vk))\n",
    "                self.b += learning_rate * (v0 - vk)\n",
    "                self.c += learning_rate * (h0 - hk)\n",
    "\n",
    "            if epoch % 100 == 0:\n",
    "                print(f\"Epoch {epoch}\")\n",
    "\n",
    "    def reconstruct(self, v):\n",
    "        \"\"\"\n",
    "        Reconstruct the visible units from hidden units\n",
    "        \"\"\"\n",
    "        h = self.sample_h_given_v(v)\n",
    "        return self.sample_v_given_h(h)\n",
    "\n",
    "# Example usage:\n",
    "visible_size = 6  # Number of visible units\n",
    "hidden_size = 3   # Number of hidden units\n",
    "bm = BoltzmannMachine(visible_size, hidden_size)\n",
    "\n",
    "# Generate some example data (6 visible units)\n",
    "data = np.random.randint(0, 2, (10, visible_size))\n",
    "\n",
    "# Train the Boltzmann Machine\n",
    "bm.train(data, learning_rate=0.1, epochs=1000)\n",
    "\n",
    "# Reconstruct a sample from the data\n",
    "sample = data[0]\n",
    "reconstructed_sample = bm.reconstruct(sample)\n",
    "\n",
    "print(\"Original sample:     \", sample)\n",
    "print(\"Reconstructed sample:\", reconstructed_sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943fbb33",
   "metadata": {},
   "source": [
    "# Restricted Boltzmann Machine (RBM)\n",
    "\n",
    "A Restricted Boltzmann Machine (RBM) is a version of the Boltzmann machine with an added restriction: there should be no connections either between visible units or between hidden units. The RBM was originally known as Harmonium when invented by Smolensky in 1986 [139].\n",
    "\n",
    "Figure 7.8 shows a comparison between the restricted Boltzmann machine and the Boltzmann machine.\n",
    "\n",
    "The RBM is a two-layer, bipartite, undirected graphical model with a set of binary hidden units \\( h \\), a set of (binary or real-valued) visible units \\( x \\), and symmetric connections between these two layers represented by a weight matrix \\( W \\). The probabilistic semantics for an RBM is denoted by \\( p(x; h) \\), and is defined by its energy function:\n",
    "\n",
    "$$\n",
    "p(x, h) = \\frac{e^{-E(x,h)}}{Z(h)},\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "$$\n",
    "Z(h) = \\sum_{\\bar{h}} e^{-E(x,\\bar{h})}\n",
    "$$\n",
    "\n",
    "is known as the partition function for hidden units.\n",
    "\n",
    "Consider a training set of binary vectors which are assumed to be binary images. The training set can be modeled using a two-layer network called an RBM in which stochastic, binary pixels are connected to stochastic, binary feature detectors using symmetrically weighted connections. Because states of the pixels are observed, these pixels correspond to “visible” units of the RBM, while the feature detectors correspond to “hidden” units. Without connections either between visible units or between hidden units, \\( U \\) and \\( V \\) in (7.6.2) are two null weight matrices.\n",
    "\n",
    "Let \\( x_i \\), \\( i = 1, \\ldots, m \\) and \\( h_j \\), \\( j = 1, \\ldots, F \\) be the observed visible variables and the binary values of hidden (latent) variables, respectively. Then the energy function (7.6.2) of the Boltzmann machine reduces to that of the restricted Boltzmann machine [65]:\n",
    "\n",
    "$$\n",
    "E(x, h) = -\\sum_{i=1}^m b_i x_i - \\sum_{j=1}^F c_j h_j - \\sum_{i,j} x_i W_{ij} h_j = -x^T Wh - b^T x - c^T h,\n",
    "$$\n",
    "\n",
    "where \\( x_i \\) and \\( h_j \\) are the binary states of visible unit \\( i \\) and hidden unit \\( j \\), \\( b_i \\) and \\( c_j \\) are their biases, and \\( W_{ij} \\) is the weight between them, while \\( b = [b_i] \\) is the visible unit bias vector and \\( c = [c_j] \\) is the hidden unit bias vector.\n",
    "\n",
    "In regression problems, the visible units \\( x \\) are real-valued, and the energy function is defined as:\n",
    "\n",
    "$$\n",
    "E(x, h) = \\frac{1}{2} \\sum_{i=1}^m x_i^2 - \\sum_{i=1}^m \\sum_{j=1}^F x_i W_{ij} h_j - \\sum_{i=1}^m b_i x_i - \\sum_{j=1}^F c_j h_j = \\frac{1}{2} x^T x - x^T Wh - b^T x - c^T h.\n",
    "$$\n",
    "\n",
    "Clearly, the hidden units are conditionally independent of one another given the visible layer, and vice versa. In particular, the units of a binary layer (conditioned on the other layer) are independent Bernoulli random variables, and if the visible layer is real-valued then the visible units (conditioned on the hidden layer) are Gaussian with diagonal covariance [92].\n",
    "\n",
    "Therefore, a tractable expression for the conditional probability for RBM can be readily obtained as [8]:\n",
    "\n",
    "$$\n",
    "p(h|x) = \\frac{p(x, h)}{p(x)} = \\frac{\\exp(b^T x + c^T h + x^T Wh)}{\\sum_{\\bar{h}} \\exp(b^T x + c^T \\bar{h} + x^T W \\bar{h})} = \\prod_{j=1}^F P(h_j |x),\n",
    "$$\n",
    "\n",
    "where \\( w_j \\) is the \\( j \\)-th column of the weight matrix \\( W = [w_1, \\ldots, w_F] \\in \\mathbb{R}^{m \\times F} \\).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04d4557",
   "metadata": {},
   "source": [
    "# Activation Probabilities in RBM\n",
    "\n",
    "By the special structure of RBM (that is, there is connection between layers and no connection within layers), it is known that the activation states of hidden units are conditionally independent given the state of visible units. At this time, the activation probability of the \\( j \\)-th hidden unit is given by\n",
    "\n",
    "$$\n",
    "p(h_j = 1|x) = \\frac{e^{c_j + w_j^T x}}{1 + e^{c_j + w_j^T x}} = \\sigma(c_j + w_j^T x),\n",
    "$$\n",
    "\n",
    "where \\( \\sigma(z) \\) is the logistic sigmoid function \\( \\frac{1}{1 + \\exp(-z)} \\).\n",
    "\n",
    "Since \\( x \\) and \\( h \\) play a symmetric role in the energy function, a similar derivation gives the conditional probability of \\( x \\) given \\( h \\):\n",
    "\n",
    "$$\n",
    "p(x|h) = \\prod_{i=1}^m p(x_i |h).\n",
    "$$\n",
    "\n",
    "Because the structure of RBM is symmetrical, when the state of the hidden unit is given, the activation state of each visible unit is conditionally independent. That is, the activation probability of the \\( i \\)-th visible unit is given by\n",
    "\n",
    "$$\n",
    "p(x_i = 1|h) = \\sigma(b_i + \\tilde{w}_i h),\n",
    "$$\n",
    "\n",
    "where \\( \\tilde{w}_i \\) is the \\( i \\)-th row of \\( W \\in \\mathbb{R}^{m \\times F} \\).\n",
    "\n",
    "Consider a probability distribution over a vector \\( x \\) and with parameters \\( W \\) [15]:\n",
    "\n",
    "$$\n",
    "p(x; W) = \\frac{1}{Z(W)} e^{-E(x; W)},\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "$$\n",
    "Z(W) = \\sum_x e^{-E(x; W)}\n",
    "$$\n",
    "\n",
    "is a normalization constant and \\( E(x; W) \\) is an energy function.\n",
    "\n",
    "Maximum-likelihood (ML) learning of the parameters \\( W \\) given an i.i.d. sample \\( X = \\{x_n\\}_{n=1}^N \\) can be updated by gradient ascent:\n",
    "\n",
    "$$\n",
    "W^{(t+1)} = W^{(t)} + \\eta \\left. \\frac{\\partial L(W; X)}{\\partial W} \\right|_{W = W^{(t)}},\n",
    "$$\n",
    "\n",
    "where the learning rate \\( \\eta \\) need not be constant, and the average log-likelihood is\n",
    "\n",
    "$$\n",
    "L(W; X) = \\frac{1}{N} \\sum_{n=1}^N \\log p(x_n; W).\n",
    "$$\n",
    "\n",
    "This can be expressed as\n",
    "\n",
    "$$\n",
    "L(W; X) = \\mathbb{E}_{P_0}[\\log p(x; W)] = -\\mathbb{E}_{P_0}[E(x; W)] - \\log Z(W),\n",
    "$$\n",
    "\n",
    "where \\( \\mathbb{E}_{P_0} \\) denotes an average with respect to the data distribution, i.e., \\( P_0(x) = \\frac{1}{N} \\sum_{n=1}^N \\delta(x - x_n) \\).\n",
    "\n",
    "A well-known difficulty arises in the computation of the gradient:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial L(W; X)}{\\partial W} = - \\mathbb{E}_{P_0} \\left[ \\frac{\\partial E(x; W)}{\\partial W} \\right] + \\mathbb{E}_{P_\\infty} \\left[ \\frac{\\partial E(x; W)}{\\partial W} \\right],\n",
    "$$\n",
    "\n",
    "where \\( \\mathbb{E}_{P_\\infty} \\) denotes an average with respect to the model distribution \\( P_\\infty(x; W) = p(x; W) \\). The average \\( \\mathbb{E}_{P_0} \\) is readily computed using the sample data \\( X = \\{x_n\\}_{n=1}^N \\), but the average \\( \\mathbb{E}_{P_\\infty} \\) involves the normalization constant \\( Z(W) \\), which cannot generally be computed efficiently (being a sum of an exponential number of terms).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "479f449b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Epoch 100\n",
      "Epoch 200\n",
      "Epoch 300\n",
      "Epoch 400\n",
      "Epoch 500\n",
      "Epoch 600\n",
      "Epoch 700\n",
      "Epoch 800\n",
      "Epoch 900\n",
      "Original sample:      [1 0 0 1 1 1]\n",
      "Reconstructed sample: [1. 0. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class RBM:\n",
    "    def __init__(self, visible_size, hidden_size):\n",
    "        self.visible_size = visible_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Initialize weights and biases\n",
    "        self.W = np.random.randn(hidden_size, visible_size) * 0.1\n",
    "        self.b = np.zeros(visible_size)  # Bias for visible units\n",
    "        self.c = np.zeros(hidden_size)  # Bias for hidden units\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def sample_prob(self, probs):\n",
    "        return (np.random.rand(*probs.shape) < probs).astype(float)\n",
    "\n",
    "    def energy(self, v, h):\n",
    "        term1 = -np.dot(self.b, v)\n",
    "        term2 = -np.dot(self.c, h)\n",
    "        term3 = -np.dot(h, np.dot(self.W, v))\n",
    "        return term1 + term2 + term3\n",
    "\n",
    "    def probability_h_given_v(self, v):\n",
    "        return self.sigmoid(np.dot(self.W, v) + self.c)\n",
    "\n",
    "    def sample_h_given_v(self, v):\n",
    "        p_h_given_v = self.probability_h_given_v(v)\n",
    "        return self.sample_prob(p_h_given_v)\n",
    "\n",
    "    def probability_v_given_h(self, h):\n",
    "        return self.sigmoid(np.dot(self.W.T, h) + self.b)\n",
    "\n",
    "    def sample_v_given_h(self, h):\n",
    "        p_v_given_h = self.probability_v_given_h(h)\n",
    "        return self.sample_prob(p_v_given_h)\n",
    "\n",
    "    def train(self, data, learning_rate=0.1, epochs=1000):\n",
    "        for epoch in range(epochs):\n",
    "            for v0 in data:\n",
    "                v0 = v0.astype(float)\n",
    "                h0 = self.sample_h_given_v(v0)\n",
    "\n",
    "                # Gibbs sampling\n",
    "                vk = self.sample_v_given_h(h0)\n",
    "                hk = self.sample_h_given_v(vk)\n",
    "\n",
    "                # Update weights and biases\n",
    "                self.W += learning_rate * (np.outer(h0, v0) - np.outer(hk, vk))\n",
    "                self.b += learning_rate * (v0 - vk)\n",
    "                self.c += learning_rate * (h0 - hk)\n",
    "\n",
    "            if epoch % 100 == 0:\n",
    "                print(f\"Epoch {epoch}\")\n",
    "\n",
    "    def reconstruct(self, v):\n",
    "        h = self.sample_h_given_v(v)\n",
    "        return self.sample_v_given_h(h)\n",
    "\n",
    "# Example usage:\n",
    "visible_size = 6  # Number of visible units\n",
    "hidden_size = 3   # Number of hidden units\n",
    "rbm = RBM(visible_size, hidden_size)\n",
    "\n",
    "# Generate some example data (6 visible units)\n",
    "data = np.random.randint(0, 2, (10, visible_size))\n",
    "\n",
    "# Train the RBM\n",
    "rbm.train(data, learning_rate=0.1, epochs=1000)\n",
    "\n",
    "# Reconstruct a sample from the data\n",
    "sample = data[0]\n",
    "reconstructed_sample = rbm.reconstruct(sample)\n",
    "\n",
    "print(\"Original sample:     \", sample)\n",
    "print(\"Reconstructed sample:\", reconstructed_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7b06ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 complete. Free energy: [-2.37217511 -1.82369575 -2.14785729 -1.99671449 -2.50263147 -2.18177309\n",
      " -2.44321332 -1.94103867 -2.11201328 -2.28434181 -2.06644901 -2.15552803\n",
      " -2.11267439 -2.23073405 -2.4197584  -1.94103867 -2.4197584  -2.14785729\n",
      " -2.44321332 -2.12469088 -2.51474191 -2.09957989 -2.34233973 -2.1525991\n",
      " -2.51474191 -2.04749584 -2.06644901 -2.43289915 -2.20489043 -2.25331079\n",
      " -1.89755048 -2.26671518 -2.22392148 -2.336069   -1.89755048 -2.44321332\n",
      " -1.82369575 -2.336069   -2.21187651 -2.23073405 -2.199998   -2.4529002\n",
      " -2.30215921 -2.06644901 -2.44321332 -2.51474191 -2.28434181 -2.37217511\n",
      " -2.28122929 -2.06644901 -2.23934631 -2.05381314 -2.22392148 -2.11201328\n",
      " -2.07340392 -2.25371458 -2.36145258 -2.07340392 -2.26101945 -2.31375481\n",
      " -2.51474191 -2.44321332 -2.4197584  -2.04075127 -2.00741408 -2.16906751\n",
      " -2.06644901 -2.51474191 -2.25331079 -2.04749584 -2.199998   -2.36145258\n",
      " -2.34233973 -1.89755048 -2.4529002  -2.08211914 -2.20489043 -2.1525991\n",
      " -2.09957989 -2.00741408 -2.28434181 -2.25371458 -2.04075127 -2.23876261\n",
      " -1.8865409  -2.05291857 -2.14785729 -1.89755048 -2.25331079 -2.02101064\n",
      " -1.83574405 -2.43289915 -1.89755048 -2.23073405 -2.23934631 -2.32726056\n",
      " -2.02101064 -2.08211914 -2.09957989 -2.37217511]\n",
      "Epoch 11 complete. Free energy: [-2.32114869 -2.17220586 -2.44247048 -2.3362609  -2.36895356 -2.35331928\n",
      " -2.3362609  -2.70493244 -2.74016233 -2.32114869 -2.11228974 -2.09485902\n",
      " -2.06689238 -2.06689238 -2.2591921  -1.87368283 -2.27378776 -2.72527856\n",
      " -2.2591921  -2.54594216 -2.72527856 -2.72527856 -2.39794478 -2.06689238\n",
      " -2.62569164 -2.23093013 -2.74016233 -2.39794478 -2.38219402 -2.69056695\n",
      " -2.64358459 -2.06470556 -2.23093013 -2.62569164 -2.70493244 -1.84458664\n",
      " -1.87368283 -2.87318614 -2.72527856 -1.87368283 -2.91946133 -2.6091735\n",
      " -2.49164037 -2.57916754 -2.6091735  -2.8377324  -2.19927535 -2.44247048\n",
      " -2.35119774 -2.66062238 -2.87318614 -2.71705415 -2.38219402 -2.27815201\n",
      " -2.49164037 -2.36895356 -2.35119774 -2.50274231 -1.87368283 -2.11228974\n",
      " -2.32114869 -2.5241374  -2.66859623 -2.36895356 -2.91946133 -2.23093013\n",
      " -2.17220586 -2.6091735  -2.46637462 -2.06470556 -2.4768482  -2.50274231\n",
      " -2.41027966 -2.75060345 -2.95521189 -2.72527856 -2.05072099 -2.66859623\n",
      " -2.69056695 -2.63535104 -2.64358459 -2.63535104 -2.8377324  -2.05072099\n",
      " -2.87318614 -2.87318614 -2.91946133 -2.30235182 -2.23093013 -2.49164037\n",
      " -2.23093013 -2.53575867 -2.75060345 -2.31011264 -2.87318614 -2.51103287\n",
      " -2.14392508 -1.87368283 -2.51103287 -2.75060345]\n",
      "Epoch 21 complete. Free energy: [-2.72028514 -2.2582492  -2.74512927 -2.86686379 -2.2582492  -2.17182512\n",
      " -2.14494686 -2.53903203 -2.34906797 -2.28840119 -2.7589234  -2.53903203\n",
      " -1.96854007 -2.7589234  -2.77331518 -2.70694448 -1.97800275 -2.76796384\n",
      " -2.76796384 -2.91993972 -2.70635147 -2.04218628 -2.28840119 -2.96675479\n",
      " -1.96854007 -2.91993972 -2.55252191 -2.68489255 -2.98038674 -2.74512927\n",
      " -2.90610919 -2.20608785 -2.92721208 -2.34050948 -2.64641188 -2.96675479\n",
      " -1.96854007 -2.92721208 -2.18435337 -2.3360937  -2.78110497 -2.7589234\n",
      " -2.14494686 -2.32734832 -2.19362009 -2.19700831 -2.83423412 -2.53903203\n",
      " -2.91356698 -2.50009622 -2.56050589 -2.05975811 -2.91993972 -2.63240701\n",
      " -2.82110624 -2.40127603 -2.85302026 -2.05975811 -2.2582492  -2.83423412\n",
      " -1.97800275 -2.18494922 -2.86686379 -2.85302026 -2.85302026 -2.18494922\n",
      " -2.53903203 -1.96854007 -1.91707418 -2.68489255 -2.70694448 -2.91993972\n",
      " -2.61303102 -2.53903203 -2.28840119 -2.04218628 -2.90610919 -2.69254451\n",
      " -2.96675479 -2.02956857 -2.64641188 -2.96675479 -2.13334944 -2.48659346\n",
      " -2.18435337 -2.69888474 -2.91993972 -2.77331518 -2.56050589 -2.13334944\n",
      " -2.18435337 -2.69254451 -1.96854007 -2.96675479 -2.78110497 -2.92721208\n",
      " -2.20608785 -2.64641188 -2.91356698 -2.19362009]\n",
      "Epoch 31 complete. Free energy: [-2.30399819 -2.84295166 -2.1789353  -2.39075462 -2.39075462 -2.52049581\n",
      " -1.9641196  -2.61624603 -2.84295166 -2.84295166 -2.30169074 -2.66219204\n",
      " -2.67970117 -1.8672483  -2.45031711 -2.84295166 -2.99515286 -2.63028063\n",
      " -2.74612215 -2.16270443 -2.53225393 -2.84295166 -2.52944613 -2.50042417\n",
      " -2.54643131 -2.4165129  -2.63028063 -2.30399819 -1.98265256 -2.2090629\n",
      " -2.50042417 -2.84652164 -2.32045043 -1.73823484 -2.74612215 -2.99515286\n",
      " -2.99515286 -2.4165129  -2.1789353  -2.76375206 -2.54643131 -2.0313931\n",
      " -2.4165129  -2.40472995 -2.2090629  -2.86458108 -2.18839738 -2.30169074\n",
      " -2.76375206 -2.86458108 -2.0313931  -2.45031711 -2.07964452 -1.72339624\n",
      " -2.66219204 -2.66219204 -1.98265256 -2.07762032 -2.43355172 -2.30860505\n",
      " -2.52944613 -1.9641196  -2.39075462 -2.4165129  -2.16270443 -2.61624603\n",
      " -2.27500845 -2.71302394 -2.40773022 -2.54945057 -2.27500845 -2.4165129\n",
      " -1.9641196  -1.72339624 -2.99515286 -1.9641196  -2.86080052 -2.63028063\n",
      " -2.29206076 -2.63356325 -2.48363141 -2.48363141 -2.53778432 -2.61317464\n",
      " -2.86080052 -2.16041603 -2.07964452 -1.9485353  -2.84652164 -1.9641196\n",
      " -2.99515286 -1.8672483  -2.45031711 -2.97678157 -2.30860505 -2.61317464\n",
      " -2.30860505 -2.27500845 -2.74612215 -2.31793119]\n",
      "Epoch 41 complete. Free energy: [-2.37640723 -2.649072   -2.48809549 -2.48329588 -2.2491299  -2.64420455\n",
      " -2.84136501 -2.41670089 -2.6070006  -2.41670089 -2.64254131 -2.64719877\n",
      " -2.649072   -2.64719877 -2.02694489 -2.44790286 -2.6504447  -2.6054161\n",
      " -2.6070006  -2.64855348 -2.60241917 -2.2524079  -2.84136501 -2.87714909\n",
      " -2.25781735 -2.84136501 -2.2491299  -2.8371328  -2.2524079  -2.41887977\n",
      " -1.97843861 -2.60241917 -2.25104209 -2.21030899 -2.21030899 -2.60403914\n",
      " -2.84136501 -2.60840915 -2.25427938 -2.87987118 -2.2107762  -2.21030899\n",
      " -2.37854278 -2.25047771 -2.8398222  -2.60883053 -1.98412222 -2.44611125\n",
      " -2.87714909 -2.88145723 -2.60377817 -2.649072   -2.41340241 -2.21605984\n",
      " -2.48329588 -2.37121633 -2.25781735 -2.87987118 -2.37854278 -2.44159759\n",
      " -2.25104209 -2.37314155 -2.6102571  -2.64855348 -2.6504447  -2.44317928\n",
      " -1.98412222 -2.37854278 -2.21030899 -2.6070006  -2.8398222  -2.87987118\n",
      " -2.2107762  -2.25640187 -2.60883053 -2.87577262 -2.60377817 -2.60377817\n",
      " -2.21030899 -2.60840915 -2.87987118 -2.64420455 -2.6504447  -2.41340241\n",
      " -2.0187567  -2.60377817 -2.25567683 -2.87987118 -2.48329588 -2.44159759\n",
      " -2.60377817 -2.0187567  -2.64552768 -2.02694489 -2.21605984 -2.64254131\n",
      " -2.8371328  -2.21605984 -2.84136501 -2.44159759]\n",
      "Epoch 51 complete. Free energy: [-2.41351304 -2.28023661 -2.01439056 -2.53359109 -2.63330897 -2.40206742\n",
      " -2.93362432 -2.62406468 -1.83005246 -2.36739706 -2.93362432 -2.75768251\n",
      " -1.96020916 -2.46141045 -1.94685779 -2.4854915  -2.59083486 -2.56970055\n",
      " -2.29029576 -1.96020916 -2.35366213 -2.4654414  -2.62406468 -2.36739706\n",
      " -2.7996124  -2.36739706 -2.22596118 -1.96020916 -1.94685779 -2.4654414\n",
      " -2.05861893 -2.4854915  -2.82174805 -2.22596118 -2.21663326 -2.76664836\n",
      " -2.43100624 -2.11416106 -2.52149073 -2.73588883 -2.05067292 -1.96020916\n",
      " -2.01439056 -2.29476322 -2.39205026 -2.75768251 -2.05067292 -2.31919584\n",
      " -2.05861893 -1.84842448 -2.45788992 -2.68778065 -1.71831248 -2.41351304\n",
      " -2.86955121 -2.11416106 -2.36739706 -2.93362432 -2.4654414  -2.68778065\n",
      " -2.68778065 -2.73588883 -1.96020916 -2.53359109 -2.22596118 -2.76664836\n",
      " -2.35860909 -2.59731542 -2.36739706 -2.24676436 -2.18804047 -2.41351304\n",
      " -2.65478556 -1.99535771 -2.29476322 -2.63330897 -2.73588883 -2.18804047\n",
      " -2.52149073 -2.82174805 -2.4854915  -2.40206742 -2.59083486 -1.71831248\n",
      " -2.75768251 -2.29029576 -2.25559426 -1.89319837 -2.93362432 -2.52537126\n",
      " -2.86955121 -2.29476322 -2.29980621 -2.42177478 -2.45788992 -2.73588883\n",
      " -2.73588883 -1.89319837 -2.93362432 -2.24676436]\n",
      "Epoch 61 complete. Free energy: [-2.23831883 -2.11311522 -2.40882962 -2.29506888 -2.4779691  -2.70488503\n",
      " -2.02085843 -2.37309989 -2.61259654 -2.09728813 -2.23831883 -2.65393337\n",
      " -2.79481659 -2.84577501 -2.2796694  -2.33063637 -2.57029369 -2.52893834\n",
      " -2.24203548 -2.70488503 -2.2441192  -2.05594705 -2.71152714 -2.66055173\n",
      " -2.09728813 -2.33063637 -2.70488503 -2.7167035  -2.66055173 -2.84577501\n",
      " -2.26773694 -2.84577501 -2.49321089 -2.74084741 -2.84577501 -2.40882962\n",
      " -2.8361629  -2.29506888 -2.57029369 -2.8361629  -2.27734886 -2.62440828\n",
      " -2.69948343 -2.68987847 -2.84577501 -2.31869802 -2.66055173 -2.87254108\n",
      " -2.49321089 -2.68987847 -2.8361629  -2.40882962 -2.92351619 -2.27734886\n",
      " -2.46538131 -2.79481659 -2.11311522 -2.23831883 -2.23831883 -2.65393337\n",
      " -2.66574594 -2.67536641 -2.66055173 -2.66354878 -2.50115607 -2.62440828\n",
      " -2.75289196 -2.66574594 -2.74084741 -2.24203548 -2.42405043 -2.26773694\n",
      " -2.61259654 -2.02085843 -2.88214275 -2.49321089 -2.24203548 -2.31869802\n",
      " -2.28335687 -2.7167035  -2.7167035  -2.66055173 -2.92351619 -2.44225894\n",
      " -2.45979744 -2.88712074 -2.88214275 -2.48358711 -2.2324131  -2.48358711\n",
      " -2.50115607 -2.64851391 -2.64851391 -2.8361629  -2.61259654 -2.66354878\n",
      " -2.53453849 -2.50115607 -2.8361629  -2.23831883]\n",
      "Epoch 71 complete. Free energy: [-2.35688987 -2.66233619 -2.98866623 -2.66233619 -2.58869345 -2.63538363\n",
      " -2.78357273 -2.41717351 -2.83049632 -2.15483329 -2.79359369 -2.30929066\n",
      " -2.79359369 -2.84389523 -2.86734407 -2.98866623 -2.45398926 -2.66255569\n",
      " -2.46749223 -2.52743813 -2.7102443  -2.80683442 -2.43085595 -2.53119317\n",
      " -2.52743813 -2.53119317 -2.80683442 -2.32247755 -2.41717351 -2.93851485\n",
      " -2.91544923 -2.56529798 -2.3596318  -2.62539479 -2.53119317 -2.91544923\n",
      " -2.75950701 -2.84389523 -2.55475079 -2.35688987 -2.56199412 -2.7702698\n",
      " -2.30929066 -2.43039095 -2.69890732 -2.83049632 -2.22571231 -2.80683442\n",
      " -2.98866623 -2.3596318  -2.93851485 -2.86734407 -2.08098855 -2.58869345\n",
      " -2.90389725 -2.86734407 -2.98866623 -3.01185644 -2.43039095 -2.7102443\n",
      " -2.98866623 -2.49097194 -2.58869345 -2.45739648 -2.52743813 -2.18887634\n",
      " -2.45398926 -2.53119317 -2.78357273 -2.86734407 -2.43085595 -2.38314861\n",
      " -2.15483329 -2.7702698  -2.40709845 -2.3596318  -2.86734407 -2.32247755\n",
      " -2.15483329 -2.53119317 -2.93851485 -2.29914801 -2.53889777 -2.80739376\n",
      " -2.15483329 -2.88067005 -2.15483329 -2.63903518 -2.68569713 -2.18887634\n",
      " -2.7702698  -2.75950701 -2.62539479 -2.41717351 -2.63903518 -2.90389725\n",
      " -2.73338129 -2.80739376 -2.22571231 -2.48082902]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 complete. Free energy: [-2.24853498 -3.14470964 -2.95292487 -3.42655974 -3.3754568  -2.21385148\n",
      " -3.17373161 -3.17373161 -2.90374414 -3.29020792 -3.29020792 -3.48248228\n",
      " -3.20087321 -3.04049135 -2.20032075 -2.35148868 -2.44882955 -2.54035234\n",
      " -2.58548206 -3.43167431 -2.30581279 -2.98336591 -2.25789856 -3.22431538\n",
      " -2.99929723 -3.43167431 -3.15058009 -2.35148868 -2.21385148 -3.29020792\n",
      " -3.00974922 -3.23019369 -2.76098209 -2.75226712 -2.47971349 -2.59780499\n",
      " -3.18392765 -3.04049135 -2.34080007 -2.96086711 -2.54035234 -2.96086711\n",
      " -2.30581279 -3.43167431 -2.47971349 -2.54035234 -2.20032075 -2.35148868\n",
      " -3.23362687 -2.39850077 -2.27185071 -2.99929723 -3.29020792 -2.70361184\n",
      " -2.99929723 -3.48248228 -2.29348696 -2.58548206 -3.15058009 -2.07350881\n",
      " -3.42655974 -3.29020792 -3.09412047 -2.70361184 -3.18392765 -2.80933798\n",
      " -2.78595923 -2.07350881 -3.23362687 -2.99929723 -3.43167431 -2.94288928\n",
      " -3.22431538 -2.99929723 -2.27185071 -2.95292487 -2.44882955 -2.29348696\n",
      " -2.30581279 -3.24080644 -3.09412047 -3.43167431 -2.30581279 -2.58548206\n",
      " -2.98336591 -3.20087321 -2.67991183 -2.45741876 -3.08936801 -2.55026373\n",
      " -2.49251062 -2.30581279 -3.03254119 -2.96086711 -3.18392765 -2.34080007\n",
      " -2.95292487 -3.08936801 -3.3754568  -3.42655974]\n",
      "Epoch 91 complete. Free energy: [-2.23733837 -2.76747689 -1.88972447 -2.76747689 -1.97014037 -1.97014037\n",
      " -2.887441   -2.76747689 -2.35029925 -2.5102505  -2.6829828  -2.80607627\n",
      " -2.47289668 -2.41139717 -2.99561443 -2.41476473 -2.41139717 -2.87244998\n",
      " -2.23733837 -2.74015818 -2.76747689 -2.04939032 -2.887441   -1.92654237\n",
      " -2.50776777 -2.4955814  -2.91426043 -2.53452141 -2.61846307 -2.99561443\n",
      " -2.76747689 -2.49273422 -2.80607627 -2.34555245 -2.72548965 -2.03476715\n",
      " -2.41139717 -2.30653475 -2.03476715 -2.74015818 -2.39246372 -2.09277541\n",
      " -2.24204069 -2.09277541 -2.36026368 -2.61727037 -2.03476715 -2.41476473\n",
      " -2.6829828  -2.15645068 -1.98452871 -2.99561443 -2.42934516 -2.74015818\n",
      " -2.38455936 -2.76426994 -2.36464477 -2.39246372 -2.72548965 -2.47289668\n",
      " -2.41476473 -2.03476715 -2.47289668 -2.34555245 -2.15645068 -2.5375685\n",
      " -2.46847112 -2.5375685  -1.98452871 -2.65925347 -1.78146031 -2.53644355\n",
      " -2.50776777 -2.65925347 -2.04939032 -2.03476715 -2.38455936 -2.27929813\n",
      " -2.61727037 -2.91426043 -2.99561443 -2.80607627 -2.41476473 -2.284201\n",
      " -2.5102505  -2.41476473 -2.61593602 -2.34555245 -2.87244998 -2.84837082\n",
      " -2.5102505  -2.99561443 -2.50776777 -2.284201   -1.78146031 -2.53644355\n",
      " -2.3873622  -2.01228142 -2.24204069 -2.64467361]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class RBM:\n",
    "    def __init__(self, num_visible, num_hidden):\n",
    "        self.num_visible = num_visible\n",
    "        self.num_hidden = num_hidden\n",
    "        self.W = np.random.normal(0, 0.1, size=(num_visible, num_hidden))  # Weight matrix\n",
    "        self.b = np.zeros(num_visible)  # Visible biases\n",
    "        self.c = np.zeros(num_hidden)   # Hidden biases\n",
    "    def sigmoid(self, x):\n",
    "        return 1.0 / (1 + np.exp(-x))\n",
    "    def gibbs_sampling(self, visible_data, k=1):\n",
    "        num_samples = visible_data.shape[0]\n",
    "        h0_prob = self.sigmoid(np.dot(visible_data, self.W) + self.c)  # Initial hidden unit probabilities\n",
    "\n",
    "        h0_sample = np.random.binomial(1, h0_prob)  # Sample hidden units\n",
    "        h = h0_sample\n",
    "\n",
    "        for _ in range(k):\n",
    "            v_prob = self.sigmoid(np.dot(h, self.W.T) + self.b)  # Visible unit probabilities\n",
    "            v_sample = np.random.binomial(1, v_prob)  # Sample visible units\n",
    "            h_prob = self.sigmoid(np.dot(v_sample, self.W) + self.c)  # Hidden unit probabilities\n",
    "            h = np.random.binomial(1, h_prob)  # Sample hidden units\n",
    "\n",
    "        return v_sample, h_prob\n",
    "    def train(self, data, learning_rate=0.1, epochs=100, batch_size=10, k=1):\n",
    "        num_samples = data.shape[0]\n",
    "        for epoch in range(epochs):\n",
    "            np.random.shuffle(data)\n",
    "\n",
    "            for i in range(0, num_samples, batch_size):\n",
    "                batch = data[i:i+batch_size]\n",
    "                v0 = batch\n",
    "                v_sample, h_prob = self.gibbs_sampling(v0, k)\n",
    "\n",
    "                # Contrastive divergence\n",
    "                positive_grad = np.dot(v0.T, h_prob)\n",
    "                negative_grad = np.dot(v_sample.T, self.sigmoid(np.dot(v_sample, self.W) + self.c))\n",
    "                self.W += learning_rate * (positive_grad - negative_grad) / batch_size\n",
    "                self.b += learning_rate * np.mean(v0 - v_sample, axis=0)\n",
    "                self.c += learning_rate * np.mean(h_prob - self.sigmoid(np.dot(v_sample, self.W) + self.c), axis=0)\n",
    "\n",
    "            if epoch % 10 == 0:\n",
    "                print(f\"Epoch {epoch+1} complete. Free energy: {self.free_energy(data)}\")\n",
    "    def free_energy(self, v):\n",
    "        vbias_term = np.dot(v, self.b)\n",
    "        wx_b = np.dot(v, self.W) + self.c\n",
    "        hidden_term = np.sum(np.log(1 + np.exp(wx_b)), axis=1)\n",
    "        return -hidden_term - vbias_term\n",
    "# Example usage\n",
    "num_visible = 6\n",
    "num_hidden = 3\n",
    "rbm = RBM(num_visible, num_hidden)\n",
    "\n",
    "# Assuming data is your training dataset, shape (num_samples, num_visible)\n",
    "data = np.random.binomial(1, 0.5, size=(100, num_visible))  # Dummy data\n",
    "\n",
    "rbm.train(data, learning_rate=0.1, epochs=100, batch_size=10, k=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8696d062",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b31146",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
