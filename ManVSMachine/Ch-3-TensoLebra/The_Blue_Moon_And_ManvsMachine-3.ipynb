{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1004430a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " * Copyright (c) 2018 Radhamadhab Dalai\n",
    " *\n",
    " * Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    " * of this software and associated documentation files (the \"Software\"), to deal\n",
    " * in the Software without restriction, including without limitation the rights\n",
    " * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    " * copies of the Software, and to permit persons to whom the Software is\n",
    " * furnished to do so, subject to the following conditions:\n",
    " *\n",
    " * The above copyright notice and this permission notice shall be included in\n",
    " * all copies or substantial portions of the Software.\n",
    " *\n",
    " * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    " * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    " * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    " * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    " * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    " * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
    " * THE SOFTWARE.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ae9921",
   "metadata": {},
   "source": [
    "## Tensor Learning for Regression\n",
    "\n",
    "Given a set of labeled training data $\\{X_i, y_i\\}_{i=1}^N$, where $X_i \\in \\mathbb{R}^{I_1 \\times \\ldots \\times I_M}$ is an $M$-mode tensor and $y_i$ are the associated scalar targets, a classic linear predictor in the vector space is given by:\n",
    "\n",
    "$$\n",
    "y = \\langle x, w \\rangle + b\n",
    "$$\n",
    "\n",
    "This can be extended from the vector space to the tensor space as:\n",
    "\n",
    "$$\n",
    "\\hat{y}_i = \\langle X_i, W \\rangle + b\n",
    "$$\n",
    "\n",
    "where \\(W \\in \\mathbb{R}^{I_1 \\times \\ldots \\times I_M}\\) is the weight tensor and \\(b\\) is the bias.\n",
    "\n",
    "The tensor regression seeks to design a weight tensor \\(W\\) to give the regression output:\n",
    "\n",
    "$$\n",
    "\\hat{y}_i = \\langle X_i, W \\rangle + b\n",
    "$$\n",
    "\n",
    "To this end, the weight tensor \\(W\\) can be expressed as a sum of \\(R\\) rank-one tensors:\n",
    "\n",
    "$$\n",
    "W = \\sum_{r=1}^{R} u^{(1)}_r \\circ u^{(2)}_r \\circ \\cdots \\circ u^{(M)}_r\n",
    "$$\n",
    "\n",
    "Then, the tensor regression can be rewritten as:\n",
    "\n",
    "$$\n",
    "\\hat{y}_i = \\langle X_i, \\left[ [U^{(1)}, U^{(2)}, \\ldots, U^{(M)}] \\right] \\rangle + b\n",
    "$$\n",
    "\n",
    "The higher rank tensor ridge regression (hrTRR) aims to minimize the loss function:\n",
    "\n",
    "$$\n",
    "L(U^{(1)}, \\ldots, U^{(M)}; b) = \\frac{1}{2} \\sum_{i=1}^{N} \\left( y_i - \\langle X_i, \\left[ [U^{(1)}, \\ldots, U^{(M)}] \\right] \\rangle - b \\right)^2 + \\frac{\\lambda}{2} \\| [U^{(1)}, \\ldots, U^{(M)}] \\|^2_F\n",
    "$$\n",
    "\n",
    "The closed-form solution of the optimization can be derived as:\n",
    "\n",
    "1. For the bias term \\(b\\):\n",
    "\n",
    "$$\n",
    "b = \\frac{1}{N} \\sum_{i=1}^{N} \\left( y_i - \\langle X_i, \\left[ [U^{(1)}, \\ldots, U^{(M)}] \\right] \\rangle \\right)\n",
    "$$\n",
    "\n",
    "2. For the weight tensor \\(u^{(m)}\\):\n",
    "\n",
    "$$\n",
    "\\hat{u}^{(m)} = \\left( \\Phi^{(m)} \\Phi^{(m)} + \\lambda I \\right)^{-1} \\Phi^{(m)} y\n",
    "$$\n",
    "\n",
    "where $\\hat{u}^{(m)} = [\\text{vec}(\\hat{U}^{(m)})^T, b]^T$ is the vector of unknowns, $y = [y_1, \\ldots, y_N]^T$ are the targets, and $\\Phi^{(m)}$ is constructed from the unfolded tensors.\n",
    "\n",
    "The group sparsity norm regularization is defined as:\n",
    "\n",
    "$$\n",
    "\\psi(W) = \\sum_{r=1}^{R} \\sum_{m=1}^{M} \\| U^{(m)}_{:,r} \\|^2_2\n",
    "$$\n",
    "\n",
    "The optimal rank tensor ridge regression (orTRR) can be represented as:\n",
    "\n",
    "$$\n",
    "(\\hat{U}^{(m)}, b) = \\arg \\min_{U^{(m)}, b} \\sum_{i=1}^{N} \\left( y_i - \\text{tr}(U^{(m)} U^{(-m)T} X_i^{(m)}) - b \\right)^2 + \\lambda \\text{tr}(U^{(m)} U^{(m)T})\n",
    "$$\n",
    "\n",
    "The closed form solution of the orTRR is given by:\n",
    "\n",
    "1. For the bias term \\(\\hat{b}\\):\n",
    "\n",
    "$$\n",
    "\\hat{b} = \\frac{1}{N} \\sum_{i=1}^{N} \\left( y_i - \\text{tr}(U^{(m)} U^{(-m)T} X_i^{(m)}) \\right)\n",
    "$$\n",
    "\n",
    "2. For the weight tensor \\(\\hat{u}^{(m)}\\):\n",
    "\n",
    "$$\n",
    "\\hat{u}^{(m)} = \\left( \\Phi^T \\Phi + 2 \\lambda \\Theta \\right)^{-1} \\Phi^T y\n",
    "$$\n",
    "\n",
    "where $\\Theta$ is a diagonal matrix based on the sparsity.\n",
    "\n",
    "## Tensor Learning Algorithm for Regression\n",
    "\n",
    "Algorithm : Tensor Learning Algorithm for Regression\n",
    "\n",
    "1. **Input**: The set of training tensors and their corresponding targets, $\\{X_i, y_i\\}_{i=1}^N$.\n",
    "2. **Initialization**: Randomly construct $\\{U^{(0)}, \\ldots, U^{(0)}\\}$, unfolding $X_i$ to the matrix $X_i^{(m)}$, and let $t = 0$.\n",
    "3. **Repeat**:\n",
    "   1. For $k = 1$ to $M$:\n",
    "   2. For high rank tensor ridge regression (hrTRR), calculate:\n",
    "      - $U^{(t)}_{(-j)} = (U^{(M)})^T U^{(-j)} \\cdots U^{(1)}$\n",
    "      - $B^t = U^t U^{(-j)}$\n",
    "      - $X_i^{(j)} = X_i^{(j)} U^{(-j)} B^{1/2}_{(j)}$\n",
    "   3. Calculate $b$ and $\\hat{u}^{(j)}$ using the provided equations.\n",
    "   4. For optimal rank tensor ridge regression (orTRR), calculate $\\eta_r$ and update $Theta$.\n",
    "   5. Prune the columns $U_{:,r}$ of factor matrices.\n",
    "   6. Update weights $W^t$ and increment $t$.\n",
    "4. **Output**: The weights $\\{U^{(1)}, \\ldots, U^{(M)}\\}$ and the bias term $b \\in \\mathbb{R}$ that minimize the objective function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a798151d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predicted: 3.26338019921727, Target: 1.0, Error: -2.26338019921727\n",
      "Predicted: 3.26338019921727, Target: -1.0, Error: -4.26338019921727\n",
      "Predictions: [3.26338019921727, 3.26338019921727]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "class Tensor:\n",
    "    def __init__(self, data):\n",
    "        self.data = data  # Assume data is a nested list representing the tensor\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]  # Enable indexing\n",
    "\n",
    "    def unfold(self, mode):\n",
    "        # Unfold the tensor along the specified mode\n",
    "        if mode == 1:\n",
    "            return [list(x) for x in zip(*self.data)]\n",
    "        raise NotImplementedError(\"Unfolding for modes other than 1 is not implemented.\")\n",
    "\n",
    "    def tensor_dot(self, other_tensor):\n",
    "        # Dot product logic can be added here\n",
    "        return sum(a * b for a, b in zip(self.data, other_tensor.data))\n",
    "\n",
    "class TensorRegression:\n",
    "    def __init__(self, rank, lambda_reg):\n",
    "        self.rank = rank\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self.U = [self.initialize_weights() for _ in range(rank)]\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        return [[random.uniform(-1, 1) for _ in range(3)] for _ in range(3)]  # Example shape\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for _ in range(100):  # Iterations\n",
    "            for i in range(len(X)):\n",
    "                xi = X[i]\n",
    "                target = y[i]\n",
    "\n",
    "                # Simplified update logic (you need to implement your actual logic)\n",
    "                prediction = self.predict_single(xi)\n",
    "                error = target - prediction\n",
    "                # Update weights here\n",
    "                # For demonstration purposes, we'll just print the prediction and error\n",
    "                print(f\"Predicted: {prediction}, Target: {target}, Error: {error}\")\n",
    "\n",
    "    def predict_single(self, xi):\n",
    "        # Implement a simple prediction logic for a single tensor\n",
    "        prediction = 0.0\n",
    "        for r in range(self.rank):\n",
    "            prediction += sum(self.U[r][0])  # Just a placeholder logic\n",
    "        return prediction\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for xi in X:\n",
    "            pred = self.predict_single(xi)\n",
    "            predictions.append(pred)\n",
    "        return predictions\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Simulated data: 3D tensor (2 samples, 3x3 matrices)\n",
    "    X = [Tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]]), Tensor([[9, 8, 7], [6, 5, 4], [3, 2, 1]])]\n",
    "    y = [1.0, -1.0]  # Corresponding targets\n",
    "\n",
    "    model = TensorRegression(rank=2, lambda_reg=0.01)\n",
    "    model.fit(X, y)\n",
    "\n",
    "    # Predict on new data (for simplicity, using same data)\n",
    "    preds = model.predict(X)\n",
    "    print(\"Predictions:\", preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e833cac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/radha/anaconda3/envs/cv37/lib/python3.7/site-packages/ipykernel_launcher.py:39: RuntimeWarning: overflow encountered in matmul\n",
      "/home/radha/anaconda3/envs/cv37/lib/python3.7/site-packages/ipykernel_launcher.py:36: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "class Tensor:\n",
    "    def __init__(self, data):\n",
    "        self.data = data  # 2D list (flattened image)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "\n",
    "class TensorRegression:\n",
    "    def __init__(self, rank, lambda_reg):\n",
    "        self.rank = rank\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self.U = [self.initialize_weights() for _ in range(rank)]\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        return [[random.uniform(-1, 1) for _ in range(32*32)] for _ in range(self.rank)]  # Assuming 32x32 images\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for _ in range(100):  # Iterations\n",
    "            for i in range(len(X)):\n",
    "                xi = X[i].data\n",
    "                target = y[i]\n",
    "\n",
    "                # Simple prediction\n",
    "                prediction = self.predict_single(xi)\n",
    "                error = target - prediction\n",
    "\n",
    "                # Update weights (dummy update for demonstration)\n",
    "                for r in range(self.rank):\n",
    "                    for j in range(len(self.U[r])):\n",
    "                        self.U[r][j] += self.lambda_reg * error * xi[j]  # Update logic\n",
    "\n",
    "    def predict_single(self, xi):\n",
    "        prediction = sum(self.U[r][0] @ xi for r in range(self.rank))\n",
    "        return prediction\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for xi in X:\n",
    "            pred = self.predict_single(xi.data)\n",
    "            predictions.append(pred)\n",
    "        return predictions\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        img = Image.open(img_path).resize((32, 32)).convert('L')  # Resize and convert to grayscale\n",
    "        img_array = np.array(img).flatten()  # Flatten the image to a 1D array\n",
    "        images.append(Tensor(img_array))  # Create Tensor object\n",
    "        label = 1 if 'cat' in filename else 0  # Example labels\n",
    "        labels.append(label)\n",
    "    return images, labels\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Load images from dataset\n",
    "    folder = 'cat'  # Replace with your dataset path\n",
    "    X, y = load_images_from_folder(folder)\n",
    "\n",
    "    # Train the model\n",
    "    model = TensorRegression(rank=2, lambda_reg=0.01)\n",
    "    model.fit(X, y)\n",
    "\n",
    "    # Predict on the training set\n",
    "    preds = model.predict(X)\n",
    "\n",
    "    # Plot the predictions vs true labels\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(y, label='True Labels', marker='o')\n",
    "    plt.plot(preds, label='Predictions', marker='x')\n",
    "    plt.title('True Labels vs Predictions')\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('Label')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b62c448",
   "metadata": {},
   "source": [
    "## Tensor K-Means Clustering\n",
    "\n",
    "### Introduction\n",
    "\n",
    "For a multi-modal object $ x $ with three modalities—image modality, text modality, and audio modality—we can represent these features with three feature vectors: image feature vector $ a $, text feature vector $ b $, and audio feature vector $ c $. After feature learning, we can build a three-order feature tensor $ T = a \\circ b \\circ c $ for the object $ x $. Each heterogeneous object thus corresponds to a feature tensor after feature fusion.\n",
    "\n",
    "The conventional K-means algorithm clusters objects represented by vectors; hence, it is necessary to extend K-means from feature vectors to feature tensors.\n",
    "\n",
    "### Tensor Distance\n",
    "\n",
    "Given two feature tensors $ X, Y \\in \\mathbb{R}^{I_1 \\times I_2 \\times \\cdots \\times I_n} $, the tensor distance (TD) between $ X $ and $ Y $ is defined as:\n",
    "\n",
    "$$\n",
    "d_{TD}(X, Y) = (x - y)^T G (x - y)\n",
    "$$\n",
    "\n",
    "where $ x = \\text{vec}(X) $ and $ y = \\text{vec}(Y) $ are the vectorizations of $ X $ and $ Y $, respectively, and $ G $ is the coefficient matrix that reveals the correlation between $ X $ and $ Y $ in tensor space.\n",
    "\n",
    "## Tensor K-Means Algorithm\n",
    "\n",
    "The Tensor K-means clustering algorithm based on tensor distance consists of the following steps:\n",
    "\n",
    "1. Randomly select $ K $ objects as clustering centers.\n",
    "2. Use the tensor distance formula to compute the distance between each object and every clustering center, and assign each object to the nearest center.\n",
    "3. Recompute each clustering center.\n",
    "4. If the algorithm has converged, stop; otherwise, return to Step 2.\n",
    "\n",
    "The computational complexity of the Tensor K-means algorithm is $ O(tnk) $, where $ t $ is the number of iterations, $ n $ is the number of objects, and $ k $ is the number of clustering centers.\n",
    "\n",
    "## Unsupervised Clustering\n",
    "\n",
    "The main purpose of unsupervised learning methods is to extract generally useful features from unlabeled data, detect and remove input redundancies, and preserve only essential aspects of the data in robust representations. Since little to no information about the underlying distribution is available, exploring complex datasets relies on identifying \"natural\" group structures.\n",
    "\n",
    "### Clustering Criteria\n",
    "\n",
    "Clustering criteria can be broadly categorized into three fundamental types:\n",
    "\n",
    "1. **Compactness**: This concept aims to keep intra-cluster variation small. It is effective for spherical or well-separated clusters but may fail with more complex structures.\n",
    "  \n",
    "2. **Connectedness**: This principle suggests that neighboring data items should belong to the same cluster, making it suitable for detecting arbitrarily shaped clusters.\n",
    "  \n",
    "3. **Spatial Separation**: This criterion provides little guidance during clustering and can lead to trivial solutions; it is often combined with other objectives like compactness.\n",
    "\n",
    "### Applications\n",
    "\n",
    "Clustering is widely used in various fields, including statistics, computer science, biology, and psychology. Popular clustering algorithms include hierarchical clustering, spectral clustering, and K-means clustering.\n",
    "\n",
    "### Issues with Clustering\n",
    "\n",
    "A validation step is crucial due to two main issues with clustering algorithms:\n",
    "\n",
    "- **Bias**: Clustering algorithms inherently bias towards particular cluster properties due to their design.\n",
    "- **Absence of Structure**: Most algorithms will return a clustering even without actual structure, requiring users to assess the significance of the results.\n",
    "\n",
    "## Purpose of Data Clustering\n",
    "\n",
    "Data clustering serves three main purposes:\n",
    "\n",
    "1. **Understanding Underlying Structure**: It helps generate hypotheses, detect anomalies, and identify salient features.\n",
    "2. **Natural Classification**: It assesses similarity among forms or organisms (e.g., phylogenetic relationships).\n",
    "3. **Compression**: It organizes data and summarizes it through cluster prototypes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c239a1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final centroids:\n",
      "Centroid 0: [[[0.4079884458937915, 0.3881063215762476, 0.218215548725823], [0.5897675983370032, 0.7821926636614637, 0.6933497923999228], [0.5340247127260895, 0.16381104575004973, 0.5822184793129785]], [[0.2486556081538402, 0.592923110913483, 0.8227927702168165], [0.8297220891155827, 0.6421258490656663, 0.2849107439280239], [0.1694623470060561, 0.5510335133154584, 0.4921656152615874]], [[0.6805267228681877, 0.4946183745665043, 0.5572158960063436], [0.23238595514554328, 0.4469054992393985, 0.9681650777834636], [0.4385806444164257, 0.6931754706033422, 0.8156620616494585]]]\n",
      "Centroid 1: [[[0.7801556427744969, 0.37020765150962, 0.3194571291608145], [0.4392856731488668, 0.27364818920220085, 0.5556078258378272], [0.5021494824323961, 0.5861984162369315, 0.29997871949263605]], [[0.37676114819755435, 0.5961648816318103, 0.25346945002929283], [0.5556418784970091, 0.5452560429926202, 0.40129381760656996], [0.4770059972556908, 0.6172809249425653, 0.41410846377184635]], [[0.3714613202728841, 0.9423404696472099, 0.4664396723019042], [0.33003475561174495, 0.28943774852701243, 0.45707238632399916], [0.6989393205714771, 0.282164706227008, 0.6404941710797637]]]\n",
      "\n",
      "Clusters:\n",
      "Cluster 0: 2 objects\n",
      "Cluster 1: 3 objects\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "# Helper function to initialize a 3-order tensor with random values\n",
    "def initialize_tensor(dim1, dim2, dim3):\n",
    "    return [[[random.random() for _ in range(dim3)] for _ in range(dim2)] for _ in range(dim1)]\n",
    "\n",
    "# Vectorize a 3-mode tensor (flatten the tensor into a vector)\n",
    "def tensor_to_vector(tensor):\n",
    "    return [element for matrix in tensor for row in matrix for element in row]\n",
    "\n",
    "# Compute dot product between two vectors\n",
    "def dot_product(vec1, vec2):\n",
    "    return sum(v1 * v2 for v1, v2 in zip(vec1, vec2))\n",
    "\n",
    "# Compute the tensor distance between two tensors (based on vectorization)\n",
    "def tensor_distance(tensor1, tensor2, G):\n",
    "    vec1 = tensor_to_vector(tensor1)\n",
    "    vec2 = tensor_to_vector(tensor2)\n",
    "    diff_vec = [v1 - v2 for v1, v2 in zip(vec1, vec2)]\n",
    "    \n",
    "    # Compute (x - y)^T * G * (x - y)\n",
    "    return dot_product(diff_vec, diff_vec)  # Simplified G as Identity Matrix\n",
    "\n",
    "# Recompute the centroid (average tensor) of the cluster\n",
    "def recompute_centroid(cluster):\n",
    "    if len(cluster) == 0:\n",
    "        return None\n",
    "    \n",
    "    dim1 = len(cluster[0])\n",
    "    dim2 = len(cluster[0][0])\n",
    "    dim3 = len(cluster[0][0][0])\n",
    "    \n",
    "    # Initialize a new centroid tensor filled with zeros\n",
    "    new_centroid = [[[0 for _ in range(dim3)] for _ in range(dim2)] for _ in range(dim1)]\n",
    "    \n",
    "    # Sum all tensors in the cluster\n",
    "    for tensor in cluster:\n",
    "        for i in range(dim1):\n",
    "            for j in range(dim2):\n",
    "                for k in range(dim3):\n",
    "                    new_centroid[i][j][k] += tensor[i][j][k]\n",
    "    \n",
    "    # Divide by the number of tensors to get the mean\n",
    "    cluster_size = len(cluster)\n",
    "    for i in range(dim1):\n",
    "        for j in range(dim2):\n",
    "            for k in range(dim3):\n",
    "                new_centroid[i][j][k] /= cluster_size\n",
    "                \n",
    "    return new_centroid\n",
    "\n",
    "# Tensor K-Means Algorithm\n",
    "def tensor_kmeans(tensors, K, max_iterations=100):\n",
    "    # Step 1: Randomly select K tensors as initial centroids\n",
    "    centroids = random.sample(tensors, K)\n",
    "    \n",
    "    for iteration in range(max_iterations):\n",
    "        # Step 2: Assign each tensor to the nearest centroid\n",
    "        clusters = [[] for _ in range(K)]\n",
    "        for tensor in tensors:\n",
    "            distances = [tensor_distance(tensor, centroid, G=None) for centroid in centroids]\n",
    "            nearest_centroid_index = distances.index(min(distances))\n",
    "            clusters[nearest_centroid_index].append(tensor)\n",
    "        \n",
    "        # Step 3: Recompute centroids\n",
    "        new_centroids = []\n",
    "        for cluster in clusters:\n",
    "            new_centroid = recompute_centroid(cluster)\n",
    "            new_centroids.append(new_centroid)\n",
    "        \n",
    "        # Step 4: Check for convergence (if centroids don't change)\n",
    "        if new_centroids == centroids:\n",
    "            break\n",
    "        \n",
    "        centroids = new_centroids\n",
    "    \n",
    "    return centroids, clusters\n",
    "\n",
    "# Example usage\n",
    "# Generate random 3-mode tensors for 5 objects\n",
    "num_objects = 5\n",
    "tensors = [initialize_tensor(3, 3, 3) for _ in range(num_objects)]\n",
    "\n",
    "# Run Tensor K-Means with K=2 clusters\n",
    "K = 2\n",
    "centroids, clusters = tensor_kmeans(tensors, K)\n",
    "\n",
    "print(\"Final centroids:\")\n",
    "for idx, centroid in enumerate(centroids):\n",
    "    print(f\"Centroid {idx}: {centroid}\")\n",
    "    \n",
    "print(\"\\nClusters:\")\n",
    "for idx, cluster in enumerate(clusters):\n",
    "    print(f\"Cluster {idx}: {len(cluster)} objects\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1abc5668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAy0AAAGgCAYAAACnoYgpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAoMklEQVR4nO3df5TVdZ0/8NeVcS4IzCgoCjEga5Y/AEMwAzMtlA4pm6dkq5Mu/dzFMEWqNaq1H7vrWNu61rZSuEZ5OoXtJkQWGJRinaIFlANZ+SM0xlIJ0xkgHXTm8/2jL7OOwDCfYe583nd8PM75nOPc+dz5PB3HefKce+9QyrIsCwAAgEQdVnQAAACArhgtAABA0owWAAAgaUYLAACQNKMFAABImtECAAAkzWgBAACSZrQAAABJM1oAAICkGS1Uhc2bN8e73/3uGDduXAwcODCGDBkSp59+enzuc5+LP/3pTx3nnXvuuXHuuedWLMeNN94YX/va1yr28Q/knnvuifPOOy+GDBkSRx55ZLzlLW+JrVu39nkOAP7PS7mbfvrTn8b73ve+mDx5cpTL5SiVSvHII4/0aQZeWowWknfTTTfF5MmTY/369fGRj3wkVq1aFcuWLYvZs2fHl7/85Xjve9/bZ1mKKIbf/OY3ce6558aePXvi29/+dnz1q1+NBx54IM4+++z44x//2KdZAPiLl3o3/ehHP4o1a9bEmDFjYtq0aX16bV6aaooOAF35+c9/Hpdddlmcf/75sXz58iiXyx3vO//88+NDH/pQrFq1qsCEhy7Lsnj22Wdj0KBB+33/NddcE+VyOW6//faoq6uLiIjJkyfHiSeeGJ///Ofjs5/9bF/GBXjJ000R//iP/xif/OQnIyLi85//fNx11119mI6XIo+0kLRrr702SqVSLF68uFMp7FVbWxt//dd/fcD733XXXVEqlfb5ZvrII49EqVTq9JOprVu3xtvf/vYYNWpUlMvlOPbYY2P69OmxadOmiIg4/vjj47777ou1a9dGqVSKUqkUxx9/fMf9W1pa4sMf/nCMGzcuamtr42Uve1nMnz8/du/e3enapVIpLr/88vjyl78cJ598cpTL5fj617++3/zPP/983H777fHWt761Y7BERIwdOzZe//rXx7Jlyw747w5AZbzUuyki4rDD/BGSvuWRFpLV1tYWP/7xj2Py5MnR0NBQ8eu96U1vira2tvjc5z4XY8aMiR07dsTPfvazePrppyMiYtmyZXHxxRdHfX193HjjjRERHWX15z//Oc4555x49NFH42Mf+1hMnDgx7rvvvrjmmmtiy5YtsWbNmiiVSh3XWr58efzkJz+Ja665Jo477rgYMWLEfjP99re/jWeeeSYmTpy4z/smTpwYq1evjmeffTYGDhzYy58NAPZHN0ExjBaStWPHjvjzn/8c48aNq/i1nnzyybj//vvjhhtuiEsuuaTj9re85S0d/zxp0qQYNGhQ1NXVxWte85pO9//iF78Ymzdvjl/84hcxZcqUiIiYPn16vOxlL4uLL744Vq1aFTNnzuw4f9euXbFly5Y46qijDporImLYsGH7vG/YsGGRZVk89dRTMXLkyPz/0gDkppugGB7bg/jLADjhhBPiX//1X+P666+Pe++9N9rb27t9/9tvvz3Gjx8fr3rVq+L555/vON74xjfu9ykAb3jDG3KVwgt/EpbnfQBUr9S7CfqS0UKyjj766DjiiCPi4Ycfrvi1SqVS/OhHP4o3vvGN8bnPfS5OP/30OOaYY+KKK66InTt3HvT+TzzxRGzevDkOP/zwTsfQoUMjy7LYsWNHp/O7+8jI8OHDI+L/HnF5oT/96U9RKpXiyCOP7NbHAuDQ6SYohqeHkawBAwbE9OnTY+XKlfHoo4/G6NGjc3+Mva/1aG1t7XT7i79RR/zlxe0333xzREQ88MAD8e1vfzs+9alPxZ49e+LLX/5yl9c5+uijY9CgQfHVr371gO9/oe4+OnLCCSfEoEGDYsuWLfu8b8uWLfHyl7/c61kA+pBugmJ4pIWkLVy4MLIsi/e///2xZ8+efd7/3HPPxfe+970D3n/vb1DZvHlzp9tXrFjR5XVf8YpXxCc+8YmYMGFC3HPPPR23l8vleOaZZ/Y5/8ILL4zf/va3MXz48JgyZco+xwt/k0seNTU1MWvWrLjttts6/VRt27Ztceedd3Z6XjMAfeOl3k1QBI+0kLSpU6fGokWL4gMf+EBMnjw5Lrvssjj11FPjueeei3vvvTcWL14c48ePj1mzZu33/scdd1ycd9550djYGEcddVSMHTs2fvSjH8Vtt93W6bzNmzfH5ZdfHrNnz44TTzwxamtr48c//nFs3rw5PvrRj3acN2HChFi6dGnceuut8Vd/9VcxcODAmDBhQsyfPz++853vxOte97q46qqrYuLEidHe3h7btm2LH/7wh/GhD30ozjzzzB59Dj796U/HGWecERdeeGF89KMfjWeffTauueaaOProo+NDH/pQjz4mAD2nmyL++Mc/xtq1ayMiOp4NsHLlyjjmmGPimGOOiXPOOadHHxcOKIMqsGnTpmzOnDnZmDFjstra2mzw4MHZpEmTsmuuuSbbvn17x3nnnHNOds4553S672OPPZZdfPHF2bBhw7L6+vrskksuyTZs2JBFRLZkyZIsy7LsiSeeyN71rndlJ510UjZ48OBsyJAh2cSJE7N///d/z55//vmOj/XII49kM2bMyIYOHZpFRDZ27NiO9+3atSv7xCc+kb3yla/Mamtrs/r6+mzChAnZVVddlT3++OMd50VENm/evFz//hs2bMimT5+eHXHEEVldXV120UUXZQ899FCujwFA73opd9Odd96ZRcR+jxf/u0JvKGVZlhUzlwAAAA7Oa1oAAICkGS0AAEDSjBYAACBpRgsAAJA0owUAAEia0QIAACStz/9yyfb29vjDH/4QQ4cOjVKp1NeXB3jJyrIsdu7cGaNGjYrDDvMzq730EkBxuttNfT5a/vCHP0RDQ0NfXxaA/6+pqSlGjx5ddIxk6CWA4h2sm/p8tAwdOjQiIk455ZQYMGBAX1++R6ZNm1Z0hFxGjBhRdIRc/u7v/q7oCLn88pe/LDpCLuvWrSs6Qm4rVqwoOkIuy5YtKzpCt+zcuTMmTJjQ8X2Yv9j7+fjlL39ZNZ+bGTNmFB0hl+uuu67oCLm87nWvKzpCLmeddVbREXKptrwREZs2bSo6Qi4PPPBA0RG6Lcuy2LVr10G///b5aNn70PuAAQOqZrTU1tYWHSGXgQMHFh0hl7q6uqIj5DJ48OCiI+RSbV8PEVE13xv2qravYU+B6mzv52Po0KFV89+y2v4fqbbvm9XydbBXtX09VNufqyIiamr6/I/Mh6Qav88fLLMnNQMAAEkzWgAAgKQZLQAAQNKMFgAAIGlGCwAAkDSjBQAASJrRAgAAJM1oAQAAkma0AAAASTNaAACApBktAABA0owWAAAgaUYLAACQNKMFAABImtECAAAkrUej5cYbb4xx48bFwIEDY/LkyfGTn/ykt3MBQC66CaD/yj1abr311pg/f358/OMfj3vvvTfOPvvsmDlzZmzbtq0S+QDgoHQTQP+We7Rcf/318d73vjfe9773xcknnxw33HBDNDQ0xKJFiyqRDwAOSjcB9G+5RsuePXti48aNMWPGjE63z5gxI372s5/t9z6tra3R0tLS6QCA3pK3m/QSQPXJNVp27NgRbW1tceyxx3a6/dhjj43HH398v/dpbGyM+vr6jqOhoaHnaQHgRfJ2k14CqD49eiF+qVTq9HaWZfvcttfChQujubm542hqaurJJQGgS93tJr0EUH1q8px89NFHx4ABA/b5ydX27dv3+QnXXuVyOcrlcs8TAkAX8naTXgKoPrkeaamtrY3JkyfH6tWrO92+evXqmDZtWq8GA4Du0E0A/V+uR1oiIhYsWBCXXnppTJkyJaZOnRqLFy+Obdu2xdy5cyuRDwAOSjcB9G+5R8vb3va2ePLJJ+Mzn/lMPPbYYzF+/Pj4wQ9+EGPHjq1EPgA4KN0E0L/lHi0RER/4wAfiAx/4QG9nAYAe000A/VePfnsYAABAXzFaAACApBktAABA0owWAAAgaUYLAACQNKMFAABImtECAAAkzWgBAACSZrQAAABJM1oAAICkGS0AAEDSjBYAACBpRgsAAJA0owUAAEhaTVEXvuyyy2LQoEFFXT6X9vb2oiPkcv311xcdIZcrrrii6Ai5jBkzpugIuYwfP77oCLmNGzeu6Ai5LFmypOgI3fLss88WHSFpF110UQwYMKDoGN3yyCOPFB0hl7q6uqIj5DJ58uSiI+SyYMGCoiPk8qtf/aroCLnNnj276Ai5VFPenTt3duvPKh5pAQAAkma0AAAASTNaAACApBktAABA0owWAAAgaUYLAACQNKMFAABImtECAAAkzWgBAACSZrQAAABJM1oAAICkGS0AAEDSjBYAACBpRgsAAJA0owUAAEia0QIAACTNaAEAAJJmtAAAAEnLPVruvvvumDVrVowaNSpKpVIsX768ArEAoHv0EkD/l3u07N69O0477bT40pe+VIk8AJCLXgLo/2ry3mHmzJkxc+bMSmQBgNz0EkD/l3u05NXa2hqtra0db7e0tFT6kgBwQHoJoPpU/IX4jY2NUV9f33E0NDRU+pIAcEB6CaD6VHy0LFy4MJqbmzuOpqamSl8SAA5ILwFUn4o/PaxcLke5XK70ZQCgW/QSQPXx97QAAABJy/1Iy65du+Khhx7qePvhhx+OTZs2xbBhw2LMmDG9Gg4ADkYvAfR/uUfLhg0b4vWvf33H2wsWLIiIiDlz5sTXvva1XgsGAN2hlwD6v9yj5dxzz40syyqRBQBy00sA/Z/XtAAAAEkzWgAAgKQZLQAAQNKMFgAAIGlGCwAAkDSjBQAASJrRAgAAJM1oAQAAkma0AAAASTNaAACApBktAABA0owWAAAgaUYLAACQNKMFAABIWk1RFz7zzDNjyJAhRV0+lzlz5hQdIZcsy4qOkMuoUaOKjpDLm970pqIj5HLllVcWHSG3M844o+gIuWzdurXoCN3S2tpadISk1dXVRU1NYbWYy2OPPVZ0hFwefvjhoiPksmTJkqIj5HLttdcWHSGXXbt2FR0ht8bGxqIj5PLUU08VHaHbnnvuuW6d55EWAAAgaUYLAACQNKMFAABImtECAAAkzWgBAACSZrQAAABJM1oAAICkGS0AAEDSjBYAACBpRgsAAJA0owUAAEia0QIAACTNaAEAAJJmtAAAAEkzWgAAgKQZLQAAQNKMFgAAIGlGCwAAkLRco6WxsTHOOOOMGDp0aIwYMSIuuuiiuP/++yuVDQAOSjcB9H+5RsvatWtj3rx5sW7duli9enU8//zzMWPGjNi9e3el8gFAl3QTQP9Xk+fkVatWdXp7yZIlMWLEiNi4cWO87nWv69VgANAdugmg/8s1Wl6subk5IiKGDRt2wHNaW1ujtbW14+2WlpZDuSQAdOlg3aSXAKpPj1+In2VZLFiwIF772tfG+PHjD3heY2Nj1NfXdxwNDQ09vSQAdKk73aSXAKpPj0fL5ZdfHps3b45vfetbXZ63cOHCaG5u7jiampp6ekkA6FJ3ukkvAVSfHj097IMf/GCsWLEi7r777hg9enSX55bL5SiXyz0KBwDd1d1u0ksA1SfXaMmyLD74wQ/GsmXL4q677opx48ZVKhcAdItuAuj/co2WefPmxTe/+c347ne/G0OHDo3HH388IiLq6+tj0KBBFQkIAF3RTQD9X67XtCxatCiam5vj3HPPjZEjR3Yct956a6XyAUCXdBNA/5f76WEAkBLdBND/9fi3hwEAAPQFowUAAEia0QIAACTNaAEAAJJmtAAAAEkzWgAAgKQZLQAAQNKMFgAAIGlGCwAAkDSjBQAASJrRAgAAJM1oAQAAkma0AAAASTNaAACApNUUdeHW1tY4/PDDi7p8Lu94xzuKjpDLb37zm6Ij5HL22WcXHSGXavt6+OpXv1p0hNzOPPPMoiPk8h//8R9FR+iW9vb2oiMkbdSoUVFbW1t0jG6pr68vOkIumzZtKjpCLv/zP/9TdIRcHnvssaIj5HLJJZcUHSG3SZMmFR0hl8GDBxcdodva2tq6dZ5HWgAAgKQZLQAAQNKMFgAAIGlGCwAAkDSjBQAASJrRAgAAJM1oAQAAkma0AAAASTNaAACApBktAABA0owWAAAgaUYLAACQNKMFAABImtECAAAkzWgBAACSZrQAAABJM1oAAICkGS0AAEDSco2WRYsWxcSJE6Ouri7q6upi6tSpsXLlykplA4CD0k0A/V+u0TJ69Oi47rrrYsOGDbFhw4Z4wxveEG9+85vjvvvuq1Q+AOiSbgLo/2rynDxr1qxOb//Lv/xLLFq0KNatWxennnpqrwYDgO7QTQD9X67R8kJtbW3x3//937F79+6YOnXqAc9rbW2N1tbWjrdbWlp6ekkA6FJ3ukkvAVSf3C/E37JlSwwZMiTK5XLMnTs3li1bFqeccsoBz29sbIz6+vqOo6Gh4ZACA8CL5ekmvQRQfXKPlle+8pWxadOmWLduXVx22WUxZ86c+NWvfnXA8xcuXBjNzc0dR1NT0yEFBoAXy9NNegmg+uR+elhtbW28/OUvj4iIKVOmxPr16+MLX/hCfOUrX9nv+eVyOcrl8qGlBIAu5OkmvQRQfQ7572nJsqzTc4MBoGi6CaB/yfVIy8c+9rGYOXNmNDQ0xM6dO2Pp0qVx1113xapVqyqVDwC6pJsA+r9co+WJJ56ISy+9NB577LGor6+PiRMnxqpVq+L888+vVD4A6JJuAuj/co2Wm2++uVI5AKBHdBNA/3fIr2kBAACoJKMFAABImtECAAAkzWgBAACSZrQAAABJM1oAAICkGS0AAEDSjBYAACBpRgsAAJA0owUAAEia0QIAACTNaAEAAJJmtAAAAEkzWgAAgKTVFHXh3bt3F3Xp3GpqCvs09cgXvvCFoiPkcuGFFxYdIZcf/OAHRUfIZdasWUVHyO3pp58uOkIuU6ZMKTpCtzz33HOxatWqomMk64knnqia7/ff//73i46Qyyte8YqiI+Tyla98pegIuTzzzDNFR8hl8+bNRUfIra2tregIuaxZs6boCN22e/fumDFjxkHP80gLAACQNKMFAABImtECAAAkzWgBAACSZrQAAABJM1oAAICkGS0AAEDSjBYAACBpRgsAAJA0owUAAEia0QIAACTNaAEAAJJmtAAAAEkzWgAAgKQZLQAAQNKMFgAAIGlGCwAAkDSjBQAASNohjZbGxsYolUoxf/78XooDAD2nlwD6px6PlvXr18fixYtj4sSJvZkHAHpELwH0Xz0aLbt27Yp3vvOdcdNNN8VRRx3V25kAIBe9BNC/9Wi0zJs3Ly644II477zzDnpua2trtLS0dDoAoDfpJYD+rSbvHZYuXRr33HNPrF+/vlvnNzY2xqc//encwQCgO/QSQP+X65GWpqamuPLKK+Mb3/hGDBw4sFv3WbhwYTQ3N3ccTU1NPQoKAC+mlwBeGnI90rJx48bYvn17TJ48ueO2tra2uPvuu+NLX/pStLa2xoABAzrdp1wuR7lc7p20APACegngpSHXaJk+fXps2bKl023vfve746STToqrr756n2IAgErSSwAvDblGy9ChQ2P8+PGdbhs8eHAMHz58n9sBoNL0EsBLwyH95ZIAAACVlvu3h73YXXfd1QsxAKB36CWA/scjLQAAQNKMFgAAIGlGCwAAkDSjBQAASJrRAgAAJM1oAQAAkma0AAAASTNaAACApBktAABA0owWAAAgaUYLAACQNKMFAABImtECAAAkzWgBAACSZrQAAABJK2VZlvXlBVtaWqK+vj7mz58f5XK5Ly/dY1dffXXREXL59a9/XXSEXM4666yiI+SyZcuWoiPkcvTRRxcdIbdly5YVHSGXmTNnFh2hW3bu3BkTJ06M5ubmqKurKzpOMvb20o4dO6rm8/KRj3yk6Ai5jBkzpugIuQwaNKjoCLksX7686Ai5XHrppUVHyO2ZZ54pOkIu11xzTdERuq29vT22b99+0G7ySAsAAJA0owUAAEia0QIAACTNaAEAAJJmtAAAAEkzWgAAgKQZLQAAQNKMFgAAIGlGCwAAkDSjBQAASJrRAgAAJM1oAQAAkma0AAAASTNaAACApBktAABA0owWAAAgaUYLAACQtFyj5VOf+lSUSqVOx3HHHVepbABwULoJoP+ryXuHU089NdasWdPx9oABA3o1EADkpZsA+rfco6WmpsZPsABIim4C6N9yv6blwQcfjFGjRsW4cePi7W9/e2zdurXL81tbW6OlpaXTAQC9KU836SWA6pNrtJx55plxyy23xB133BE33XRTPP744zFt2rR48sknD3ifxsbGqK+v7zgaGhoOOTQA7JW3m/QSQPXJNVpmzpwZb33rW2PChAlx3nnnxfe///2IiPj6179+wPssXLgwmpubO46mpqZDSwwAL5C3m/QSQPXJ/ZqWFxo8eHBMmDAhHnzwwQOeUy6Xo1wuH8plAKDbDtZNegmg+hzS39PS2toav/71r2PkyJG9lQcADoluAuh/co2WD3/4w7F27dp4+OGH4xe/+EVcfPHF0dLSEnPmzKlUPgDokm4C6P9yPT3s0UcfjXe84x2xY8eOOOaYY+I1r3lNrFu3LsaOHVupfADQJd0E0P/lGi1Lly6tVA4A6BHdBND/HdJrWgAAACrNaAEAAJJmtAAAAEkzWgAAgKQZLQAAQNKMFgAAIGlGCwAAkDSjBQAASJrRAgAAJM1oAQAAkma0AAAASTNaAACApBktAABA0owWAAAgaUYLAACQtFKWZVlfXrClpSXq6+vjhhtuiEGDBvXlpXvsiCOOKDpCLvX19UVHyOXRRx8tOkIubW1tRUfIZciQIUVHyG3FihVFR8jlsMOq4+c/zz33XKxYsSKam5ujrq6u6DjJ2NtLF198cRx++OFFx+mW66+/vugIuaxdu7boCLncfvvtRUfI5aGHHio6Qi6nnnpq0RFya2hoKDpCLsOHDy86Qrc988wz8Q//8A8H7abqaFoAAOAly2gBAACSZrQAAABJM1oAAICkGS0AAEDSjBYAACBpRgsAAJA0owUAAEia0QIAACTNaAEAAJJmtAAAAEkzWgAAgKQZLQAAQNKMFgAAIGlGCwAAkDSjBQAASJrRAgAAJC33aPn9738fl1xySQwfPjyOOOKIeNWrXhUbN26sRDYA6BbdBNC/1eQ5+amnnoqzzjorXv/618fKlStjxIgR8dvf/jaOPPLICsUDgK7pJoD+L9do+exnPxsNDQ2xZMmSjtuOP/743s4EAN2mmwD6v1xPD1uxYkVMmTIlZs+eHSNGjIhJkybFTTfd1OV9Wltbo6WlpdMBAL0lbzfpJYDqk2u0bN26NRYtWhQnnnhi3HHHHTF37ty44oor4pZbbjngfRobG6O+vr7jaGhoOOTQALBX3m7SSwDVJ9doaW9vj9NPPz2uvfbamDRpUvz93/99vP/9749FixYd8D4LFy6M5ubmjqOpqemQQwPAXnm7SS8BVJ9co2XkyJFxyimndLrt5JNPjm3bth3wPuVyOerq6jodANBb8naTXgKoPrlGy1lnnRX3339/p9seeOCBGDt2bK+GAoDu0k0A/V+u0XLVVVfFunXr4tprr42HHnoovvnNb8bixYtj3rx5lcoHAF3STQD9X67RcsYZZ8SyZcviW9/6VowfPz7+6Z/+KW644YZ45zvfWal8ANAl3QTQ/+X6e1oiIi688MK48MILK5EFAHpENwH0b7keaQEAAOhrRgsAAJA0owUAAEia0QIAACTNaAEAAJJmtAAAAEkzWgAAgKQZLQAAQNKMFgAAIGlGCwAAkDSjBQAASJrRAgAAJM1oAQAAkma0AAAASTNaAACApNUUdeHa2tqora0t6vK5fPazny06Qi4///nPi46Qy4QJE4qOkMvw4cOLjpDL5ZdfXnSE3FauXFl0hFw2btxYdIRu2bVrV6xYsaLoGMk65ZRTYuDAgUXH6JbPfOYzRUfIZe7cuUVHyOVtb3tb0RFyufrqq4uOkMurX/3qoiPkdvPNNxcdIZd3vOMdRUfotu7uAY+0AAAASTNaAACApBktAABA0owWAAAgaUYLAACQNKMFAABImtECAAAkzWgBAACSZrQAAABJM1oAAICkGS0AAEDSjBYAACBpRgsAAJA0owUAAEia0QIAACTNaAEAAJJmtAAAAEnLNVqOP/74KJVK+xzz5s2rVD4A6JJuAuj/avKcvH79+mhra+t4+5e//GWcf/75MXv27F4PBgDdoZsA+r9co+WYY47p9PZ1110XJ5xwQpxzzjm9GgoAuks3AfR/uUbLC+3Zsye+8Y1vxIIFC6JUKh3wvNbW1mhtbe14u6WlpaeXBIAudaeb9BJA9enxC/GXL18eTz/9dLzrXe/q8rzGxsaor6/vOBoaGnp6SQDoUne6SS8BVJ8ej5abb745Zs6cGaNGjeryvIULF0Zzc3PH0dTU1NNLAkCXutNNegmg+vTo6WG/+93vYs2aNXHbbbcd9NxyuRzlcrknlwGAbutuN+klgOrTo0dalixZEiNGjIgLLrigt/MAQI/oJoD+K/doaW9vjyVLlsScOXOipqbHr+MHgF6jmwD6t9yjZc2aNbFt27Z4z3veU4k8AJCbbgLo33L/OGrGjBmRZVklsgBAj+gmgP6tx789DAAAoC8YLQAAQNKMFgAAIGlGCwAAkDSjBQAASJrRAgAAJM1oAQAAkma0AAAASTNaAACApBktAABA0owWAAAgaUYLAACQNKMFAABImtECAAAkraavL5hlWUREPPPMM3196R5ra2srOkIuLS0tRUfIpb29vegIuVTb10M1/b+2197vE9Vi165dRUfolr05q+3zW2l7Px+tra0FJ+m+PXv2FB0hl2r5f2SvauvRavrajYj485//XHSE3J577rmiI+RSTd2/N+vBuqmU9XF7Pfroo9HQ0NCXlwTgBZqammL06NFFx0iGXgIo3sG6qc9HS3t7e/zhD3+IoUOHRqlU6rWP29LSEg0NDdHU1BR1dXW99nErRd7Kkrey5K2sSuXNsix27twZo0aNisMO8+zgvfTSX8hbWfJWXrVllvcvuttNff70sMMOO6yiP+Grq6uriv/we8lbWfJWlryVVYm89fX1vfrx+gO91Jm8lSVv5VVbZnm7101+1AYAACTNaAEAAJLWb0ZLuVyOT37yk1Eul4uO0i3yVpa8lSVvZVVbXvav2v47yltZ8lZetWWWN58+fyE+AABAHv3mkRYAAKB/MloAAICkGS0AAEDSjBYAACBp/WK03HjjjTFu3LgYOHBgTJ48OX7yk58UHemA7r777pg1a1aMGjUqSqVSLF++vOhIB9TY2BhnnHFGDB06NEaMGBEXXXRR3H///UXHOqBFixbFxIkTO/7So6lTp8bKlSuLjtVtjY2NUSqVYv78+UVH2a9PfepTUSqVOh3HHXdc0bG69Pvf/z4uueSSGD58eBxxxBHxqle9KjZu3Fh0rAM6/vjj9/kcl0qlmDdvXtHR6AHdVBm6qW/ppt5XTd2UUi9V/Wi59dZbY/78+fHxj3887r333jj77LNj5syZsW3btqKj7dfu3bvjtNNOiy996UtFRzmotWvXxrx582LdunWxevXqeP7552PGjBmxe/fuoqPt1+jRo+O6666LDRs2xIYNG+INb3hDvPnNb4777ruv6GgHtX79+li8eHFMnDix6ChdOvXUU+Oxxx7rOLZs2VJ0pAN66qmn4qyzzorDDz88Vq5cGb/61a/i3/7t3+LII48sOtoBrV+/vtPnd/Xq1RERMXv27IKTkZduqhzd1Hd0U++rtm5KqpeyKvfqV786mzt3bqfbTjrppOyjH/1oQYm6LyKyZcuWFR2j27Zv355FRLZ27dqio3TbUUcdlf3Xf/1X0TG6tHPnzuzEE0/MVq9enZ1zzjnZlVdeWXSk/frkJz+ZnXbaaUXH6Larr746e+1rX1t0jENy5ZVXZieccELW3t5edBRy0k19RzdVhm6qjGrvpiJ7qaofadmzZ09s3LgxZsyY0en2GTNmxM9+9rOCUvVfzc3NERExbNiwgpMcXFtbWyxdujR2794dU6dOLTpOl+bNmxcXXHBBnHfeeUVHOagHH3wwRo0aFePGjYu3v/3tsXXr1qIjHdCKFStiypQpMXv27BgxYkRMmjQpbrrppqJjdduePXviG9/4RrznPe+JUqlUdBxy0E19SzdVhm6qjGrupqJ7qapHy44dO6KtrS2OPfbYTrcfe+yx8fjjjxeUqn/KsiwWLFgQr33ta2P8+PFFxzmgLVu2xJAhQ6JcLsfcuXNj2bJlccoppxQd64CWLl0a99xzTzQ2NhYd5aDOPPPMuOWWW+KOO+6Im266KR5//PGYNm1aPPnkk0VH26+tW7fGokWL4sQTT4w77rgj5s6dG1dccUXccsstRUfrluXLl8fTTz8d73rXu4qOQk66qe/opsrQTZVTzd1UdC/VFHLVXvbitZdlmZ9M9rLLL788Nm/eHD/96U+LjtKlV77ylbFp06Z4+umn4zvf+U7MmTMn1q5dm2Q5NDU1xZVXXhk//OEPY+DAgUXHOaiZM2d2/POECRNi6tSpccIJJ8TXv/71WLBgQYHJ9q+9vT2mTJkS1157bURETJo0Ke67775YtGhR/O3f/m3B6Q7u5ptvjpkzZ8aoUaOKjkIP6abK0029TzdVVjV3U9G9VNWPtBx99NExYMCAfX5ytX379n1+wkXPffCDH4wVK1bEnXfeGaNHjy46Tpdqa2vj5S9/eUyZMiUaGxvjtNNOiy984QtFx9qvjRs3xvbt22Py5MlRU1MTNTU1sXbt2vjiF78YNTU10dbWVnTELg0ePDgmTJgQDz74YNFR9mvkyJH7/IHg5JNPTvaF0C/0u9/9LtasWRPve9/7io5CD+imvqGbKkM3VVa1dlMKvVTVo6W2tjYmT57c8ZsM9lq9enVMmzatoFT9R5Zlcfnll8dtt90WP/7xj2PcuHFFR8oty7JobW0tOsZ+TZ8+PbZs2RKbNm3qOKZMmRLvfOc7Y9OmTTFgwICiI3aptbU1fv3rX8fIkSOLjrJfZ5111j6/BvWBBx6IsWPHFpSo+5YsWRIjRoyICy64oOgo9IBuqizdVFm6qbKqtZtS6KWqf3rYggUL4tJLL40pU6bE1KlTY/HixbFt27aYO3du0dH2a9euXfHQQw91vP3www/Hpk2bYtiwYTFmzJgCk+1r3rx58c1vfjO++93vxtChQzt+alhfXx+DBg0qON2+Pvaxj8XMmTOjoaEhdu7cGUuXLo277rorVq1aVXS0/Ro6dOg+z8EePHhwDB8+PMnnZn/4wx+OWbNmxZgxY2L79u3xz//8z9HS0hJz5swpOtp+XXXVVTFt2rS49tpr42/+5m/if//3f2Px4sWxePHioqN1qb29PZYsWRJz5syJmpqq/xb9kqWbKkc3VZZuqqxq7KZkeqnPf19ZBfznf/5nNnbs2Ky2tjY7/fTTk/61h3feeWcWEfscc+bMKTraPvaXMyKyJUuWFB1tv97znvd0fB0cc8wx2fTp07Mf/vCHRcfKJeVfK/m2t70tGzlyZHb44Ydno0aNyt7ylrdk9913X9GxuvS9730vGz9+fFYul7OTTjopW7x4cdGRDuqOO+7IIiK7//77i47CIdJNlaGb+p5u6l3V1k2p9FIpy7Ks7yYSAABAPlX9mhYAAKD/M1oAAICkGS0AAEDSjBYAACBpRgsAAJA0owUAAEia0QIAACTNaAEAAJJmtAAAAEkzWgAAgKQZLQAAQNKMFgAAIGn/D6W5yW8AzMopAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Simulate a small image dataset (10 images, each 8x8 pixels, grayscale)\n",
    "def simulate_image_dataset(num_images, height, width):\n",
    "    return [[[random.random() for _ in range(width)] for _ in range(height)] for _ in range(num_images)]\n",
    "\n",
    "# Vectorize a 2D image tensor (flatten the tensor into a vector)\n",
    "def tensor_to_vector(tensor):\n",
    "    return [element for row in tensor for element in row]\n",
    "\n",
    "# Compute dot product between two vectors\n",
    "def dot_product(vec1, vec2):\n",
    "    return sum(v1 * v2 for v1, v2 in zip(vec1, vec2))\n",
    "\n",
    "# Compute the tensor distance between two tensors (based on vectorization)\n",
    "def tensor_distance(tensor1, tensor2):\n",
    "    vec1 = tensor_to_vector(tensor1)\n",
    "    vec2 = tensor_to_vector(tensor2)\n",
    "    diff_vec = [v1 - v2 for v1, v2 in zip(vec1, vec2)]\n",
    "    return dot_product(diff_vec, diff_vec)  # Euclidean distance\n",
    "\n",
    "# Recompute the centroid (average image tensor) of the cluster\n",
    "def recompute_centroid(cluster):\n",
    "    if len(cluster) == 0:\n",
    "        return None\n",
    "    \n",
    "    height = len(cluster[0])\n",
    "    width = len(cluster[0][0])\n",
    "    \n",
    "    # Initialize a new centroid tensor filled with zeros\n",
    "    new_centroid = [[0 for _ in range(width)] for _ in range(height)]\n",
    "    \n",
    "    # Sum all tensors in the cluster\n",
    "    for tensor in cluster:\n",
    "        for i in range(height):\n",
    "            for j in range(width):\n",
    "                new_centroid[i][j] += tensor[i][j]\n",
    "    \n",
    "    # Divide by the number of tensors to get the mean\n",
    "    cluster_size = len(cluster)\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            new_centroid[i][j] /= cluster_size\n",
    "                \n",
    "    return new_centroid\n",
    "\n",
    "# Tensor K-Means Algorithm\n",
    "def tensor_kmeans(tensors, K, max_iterations=100):\n",
    "    # Step 1: Randomly select K tensors as initial centroids\n",
    "    centroids = random.sample(tensors, K)\n",
    "    \n",
    "    for iteration in range(max_iterations):\n",
    "        # Step 2: Assign each tensor to the nearest centroid\n",
    "        clusters = [[] for _ in range(K)]\n",
    "        for tensor in tensors:\n",
    "            distances = [tensor_distance(tensor, centroid) for centroid in centroids]\n",
    "            nearest_centroid_index = distances.index(min(distances))\n",
    "            clusters[nearest_centroid_index].append(tensor)\n",
    "        \n",
    "        # Step 3: Recompute centroids\n",
    "        new_centroids = []\n",
    "        for cluster in clusters:\n",
    "            new_centroid = recompute_centroid(cluster)\n",
    "            new_centroids.append(new_centroid)\n",
    "        \n",
    "        # Step 4: Check for convergence (if centroids don't change)\n",
    "        if new_centroids == centroids:\n",
    "            break\n",
    "        \n",
    "        centroids = new_centroids\n",
    "    \n",
    "    return centroids, clusters\n",
    "\n",
    "# Generate random images as tensors\n",
    "num_images = 10\n",
    "image_height = 8\n",
    "image_width = 8\n",
    "images = simulate_image_dataset(num_images, image_height, image_width)\n",
    "\n",
    "# Run Tensor K-Means with K=2 clusters\n",
    "K = 2\n",
    "centroids, clusters = tensor_kmeans(images, K)\n",
    "\n",
    "# Visualize centroids as images\n",
    "def plot_centroids(centroids):\n",
    "    fig, axs = plt.subplots(1, len(centroids), figsize=(5 * len(centroids), 5))\n",
    "    for idx, centroid in enumerate(centroids):\n",
    "        axs[idx].imshow(centroid, cmap='gray')\n",
    "        axs[idx].set_title(f'Centroid {idx}')\n",
    "    plt.show()\n",
    "\n",
    "# Visualize clustering result by plotting images grouped by clusters\n",
    "def plot_clusters(clusters):\n",
    "    fig, axs = plt.subplots(1, len(clusters), figsize=(10, 5))\n",
    "    for idx, cluster in enumerate(clusters):\n",
    "        axs[idx].imshow(cluster[0], cmap='gray')\n",
    "        axs[idx].set_title(f'Cluster {idx}')\n",
    "    plt.show()\n",
    "\n",
    "# Plot the centroids and clusters\n",
    "plot_centroids(centroids)\n",
    "plot_clusters(clusters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7f7b9c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Traditional K-means on vectorized images (without Tensor treatment)\n",
    "def kmeans_vectorized(images, K, max_iterations=100):\n",
    "    vectorized_images = [tensor_to_vector(image) for image in images]\n",
    "    centroids = random.sample(vectorized_images, K)\n",
    "    \n",
    "    for iteration in range(max_iterations):\n",
    "        clusters = [[] for _ in range(K)]\n",
    "        for vec in vectorized_images:\n",
    "            distances = [dot_product([v1 - v2 for v1, v2 in zip(vec, c)], [v1 - v2 for v1, v2 in zip(vec, c)]) for c in centroids]\n",
    "            nearest_centroid_index = distances.index(min(distances))\n",
    "            clusters[nearest_centroid_index].append(vec)\n",
    "        \n",
    "        new_centroids = []\n",
    "        for cluster in clusters:\n",
    "            centroid = [sum(vec[i] for vec in cluster) / len(cluster) for i in range(len(cluster[0]))]\n",
    "            new_centroids.append(centroid)\n",
    "        \n",
    "        if new_centroids == centroids:\n",
    "            break\n",
    "        \n",
    "        centroids = new_centroids\n",
    "    \n",
    "    return centroids, clusters\n",
    "\n",
    "# Run traditional K-Means on vectorized images\n",
    "centroids_vec, clusters_vec = kmeans_vectorized(images, K)\n",
    "\n",
    "# Visualize the centroids from traditional K-Means\n",
    "def plot_centroids_vectorized(centroids_vec, image_height, image_width):\n",
    "    fig, axs = plt.subplots(1, len(centroids_vec), figsize=(5 * len(centroids_vec), 5))\n",
    "    for idx, centroid in enumerate(centroids_vec):\n",
    "        centroid_image = [centroid[i:i + image_width] for i in range(0, len(centroid), image_width)]\n",
    "        axs[idx].imshow(centroid_image, cmap='gray')\n",
    "        axs[idx].set_title(f'Centroid {idx} (Vectorized)')\n",
    "    plt.show()\n",
    "\n",
    "plot_centroids_vectorized(centroids_vec, image_height, image_width)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316b7702",
   "metadata": {},
   "source": [
    "# Similarity Measures in Machine Learning\n",
    "\n",
    "One of the main mathematical tools for unsupervised clustering and classification is the distance measure. The distance between two vectors $ p $ and $ g $, denoted by $ D(p, g) $, is a measure if it has the following properties:\n",
    "\n",
    "1. **Nonnegativity and Positiveness**: \n",
    "   $$ \n",
    "   D(p, g) \\geq 0, \\text{ and equality holds if and only if } p = g. \n",
    "   $$\n",
    "\n",
    "2. **Symmetry**: \n",
    "   $$ \n",
    "   D(p, g) = D(g, p). \n",
    "   $$\n",
    "\n",
    "3. **Triangle Inequality**: \n",
    "   $$ \n",
    "   D(p, z) \\leq D(p, g) + D(g, z). \n",
    "   $$\n",
    "\n",
    "The basic rule of unsupervised clustering and classification is to adopt some distance metric to measure the similarity of two feature vectors. As the name suggests, this similarity is a measure of the degree of similarity between vectors.\n",
    "\n",
    "Consider a clustering problem in pattern recognition (e.g., template matching). For simplicity, suppose that there are $ N $ pattern vectors $ s_1, \\ldots, s_N $, but the number of classes is unknown. Our problem is to cluster $ N $ pattern vectors into a number of classes. For this purpose, we need to compare these pattern vectors in order to be clustered into a number of classes such that pattern vectors belonging to the same class are more similar than those belonging to other classes. On the basis of a similarity comparison, we can obtain the unsupervised pattern clustering.\n",
    "\n",
    "A quantity known as the dissimilarity is used to make a reverse measurement of the similarity between vectors: two vectors with a smaller dissimilarity are more similar. Let $ D(s_i, s_j) $ (for $ i, j = 1, \\ldots, N $, but $ j \\neq i $) be the dissimilarities between the $ i $-th and $ j $-th pattern vectors $ s_i $ and $ s_j $. If\n",
    "\n",
    "$$ \n",
    "D(s_i, s_{j_1}) < D(s_i, s_{j_2}), \n",
    "$$\n",
    "\n",
    "then we say the pattern vector $ s_{j_1} $ is more similar to $ s_i $ than $ s_{j_2} $.\n",
    "\n",
    "The simplest and most intuitive dissimilarity parameter is the Euclidean distance between vectors. The regularized Euclidean distance between the $ i $-th and the $ j $-th known pattern vectors $ (s_i, s_j) $, denoted $ D_E(s_i, s_j) $, is defined as:\n",
    "\n",
    "$$ \n",
    "D_E(s_i, s_j) = \\frac{\\|s_i - s_j\\|^2}{\\|s_i\\|^2 + \\|s_j\\|^2}. \n",
    "$$\n",
    "\n",
    "Two extreme values imply that two vectors are completely similar and completely dissimilar, respectively:\n",
    "\n",
    "$$ \n",
    "D_E(x, y) =\n",
    "\\begin{cases}\n",
    "0 & \\text{if } x \\text{ and } y \\text{ are completely similar,} \\\\\n",
    "1 & \\text{if } x \\text{ and } y \\text{ are completely dissimilar.}\n",
    "\\end{cases} \n",
    "If \n",
    "\n",
    "$$ \n",
    "D_E(s_1, s_i) = \\min_{k} D_E(s_1, s_k), \\quad k = 1, \\ldots, N, \\, i \\neq 1, \n",
    "$$ \n",
    "\n",
    "then $ s_i $ is said to be a nearest neighbor to $ s_1 $. A widely used classification method is nearest neighbor classification, which judges $ s_1 $ and $ s_i $ to belong to the same model type.\n",
    "\n",
    "All pattern vectors satisfying \n",
    "\n",
    "$$ \n",
    "D_E(s_1, s_j) \\approx D_E(s_1, s_i), \\quad j = 2, \\ldots, N, \\, j \\neq i, \n",
    "$$ \n",
    "\n",
    "are said to be the nearest neighbors to $ s_1 $ as well, and thus these pattern vectors are judged to belong to Class 1. Mimicking this process for other unclustered pattern vectors until all vectors are clustered, we can cluster all other possible classes (Class 2, Class 3, and so on) and determine the number of classes. This is the basic idea of the unsupervised clustering approach.\n",
    "\n",
    "Another frequently used distance function is the Mahalanobis distance, proposed by Mahalanobis in 1936. The Mahalanobis distance from the vector $ x $ to its mean $ \\mu $ is given by\n",
    "\n",
    "$$ \n",
    "D_M(x, \\mu) = (x - \\mu)^T C^{-1} (x - \\mu), \n",
    "$$ \n",
    "\n",
    "where $ C_x = \\text{cov}(x, x) = E\\{(x - \\mu)(x - \\mu)^T\\} $ is the autocovariance matrix of the vector $ x $.\n",
    "\n",
    "The Mahalanobis distance between vectors $ x \\in \\mathbb{R}^n $ and $ y \\in \\mathbb{R}^n $ is denoted by $ D_M(x, y) $ and is defined as\n",
    "\n",
    "$$ \n",
    "D_M(x, y) = (x - y)^T C_{xy}^{-1} (x - y), \n",
    "$$ \n",
    "\n",
    "where $ C_{xy} = \\text{cov}(x, y) = E\\{(x - \\mu_x)(y - \\mu_y)^T\\} $ is the cross-covariance matrix of $ x $ and $ y $, while $ \\mu_x $ and $ \\mu_y $ are the means of $ x $ and $ y $, respectively.\n",
    "\n",
    "Clearly, if the covariance matrix is the identity matrix, i.e., $ C = I $, then the Mahalanobis distance reduces to the Euclidean distance. If the covariance matrix takes a diagonal form, then the corresponding Mahalanobis distance is called the normalized Euclidean distance and is given by\n",
    "\n",
    "$$ \n",
    "D_M(x, y) = \\sqrt{\\sum_{i=1}^{n} \\frac{(x_i - y_i)^2}{\\sigma_i^2}}, \n",
    "$$ \n",
    "\n",
    "in which $ \\sigma_i $ is the standard deviation of $ x_i $ and $ y_i $ in the whole sample set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1f37b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class for the test vector [2.5, 3.0] is: Class A\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10302/2958317938.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m \u001b[0mcov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcovariance_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Use training data for covariance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0mmahalanobis_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmahalanobis_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_10302/2958317938.py\u001b[0m in \u001b[0;36mcovariance_matrix\u001b[0;34m(vectors)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcovariance_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;34m\"\"\"Calculate the covariance matrix of a list of vectors.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mcov_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_10302/2958317938.py\u001b[0m in \u001b[0;36mmean_vector\u001b[0;34m(vectors)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmean_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;34m\"\"\"Calculate the mean vector from a list of vectors.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Function to calculate the covariance matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_10302/2958317938.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmean_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;34m\"\"\"Calculate the mean vector from a list of vectors.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Function to calculate the covariance matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "# Function to calculate Euclidean distance\n",
    "def euclidean_distance(a, b):\n",
    "    \"\"\"Calculate the Euclidean distance between two vectors.\"\"\"\n",
    "    return sum((x - y) ** 2 for x, y in zip(a, b)) ** 0.5\n",
    "\n",
    "# Function to calculate the mean of a list of vectors\n",
    "def mean_vector(vectors):\n",
    "    \"\"\"Calculate the mean vector from a list of vectors.\"\"\"\n",
    "    return [sum(dim) / len(vectors) for dim in zip(*vectors)]\n",
    "\n",
    "# Function to calculate the covariance matrix\n",
    "def covariance_matrix(vectors):\n",
    "    \"\"\"Calculate the covariance matrix of a list of vectors.\"\"\"\n",
    "    mean = mean_vector(vectors)\n",
    "    n = len(vectors)\n",
    "    cov_matrix = [[0] * len(mean) for _ in range(len(mean))]\n",
    "\n",
    "    for vector in vectors:\n",
    "        for i in range(len(mean)):\n",
    "            for j in range(len(mean)):\n",
    "                cov_matrix[i][j] += (vector[i] - mean[i]) * (vector[j] - mean[j])\n",
    "    \n",
    "    return [[val / (n - 1) for val in row] for row in cov_matrix]\n",
    "\n",
    "# Function to calculate the inverse of a 2D matrix\n",
    "def inverse_matrix(matrix):\n",
    "    \"\"\"Calculate the inverse of a 2x2 matrix.\"\"\"\n",
    "    det = matrix[0][0] * matrix[1][1] - matrix[0][1] * matrix[1][0]\n",
    "    if det == 0:\n",
    "        raise ValueError(\"Matrix is not invertible.\")\n",
    "    return [[matrix[1][1] / det, -matrix[0][1] / det],\n",
    "            [-matrix[1][0] / det, matrix[0][0] / det]]\n",
    "\n",
    "# Function to calculate Mahalanobis distance\n",
    "def mahalanobis_distance(x, y, cov):\n",
    "    \"\"\"Calculate the Mahalanobis distance between two vectors.\"\"\"\n",
    "    diff = [a - b for a, b in zip(x, y)]\n",
    "    inv_cov = inverse_matrix(cov)\n",
    "    return sum(diff[i] * sum(inv_cov[i][j] * diff[j] for j in range(len(diff))) for i in range(len(diff)))\n",
    "\n",
    "# Nearest neighbor classification function\n",
    "def nearest_neighbor_classification(training_data, test_vector):\n",
    "    \"\"\"Classify the test_vector based on nearest neighbor classification.\"\"\"\n",
    "    min_distance = float('inf')\n",
    "    nearest_neighbor = None\n",
    "    \n",
    "    for train_vector in training_data:\n",
    "        distance = euclidean_distance(train_vector[:-1], test_vector)  # Exclude class label\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            nearest_neighbor = train_vector[-1]  # Class label\n",
    "    \n",
    "    return nearest_neighbor\n",
    "\n",
    "# Example usage\n",
    "training_data = [\n",
    "    [1.0, 2.0, 'Class A'],\n",
    "    [2.0, 3.0, 'Class A'],\n",
    "    [3.0, 3.5, 'Class B'],\n",
    "    [5.0, 4.0, 'Class B']\n",
    "]\n",
    "\n",
    "# Test vector\n",
    "test_vector = [2.5, 3.0]\n",
    "\n",
    "# Classify the test vector\n",
    "predicted_class = nearest_neighbor_classification(training_data, test_vector)\n",
    "print(f'The predicted class for the test vector {test_vector} is: {predicted_class}')\n",
    "\n",
    "# Calculate Mahalanobis distance between two points\n",
    "x = [2.0, 3.0]\n",
    "y = [3.0, 4.0]\n",
    "cov = covariance_matrix(training_data)  # Use training data for covariance\n",
    "mahalanobis_dist = mahalanobis_distance(x, y, cov)\n",
    "\n",
    "print(f'The Mahalanobis distance between {x} and {y} is: {mahalanobis_dist}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "242c1fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class for the test vector [2.5, 3.0] is: Class A\n",
      "The Mahalanobis distance between [2.0, 3.0] and [3.0, 4.0] is: 3.7941176470588296\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate Euclidean distance\n",
    "def euclidean_distance(a, b):\n",
    "    \"\"\"Calculate the Euclidean distance between two vectors.\"\"\"\n",
    "    return sum((x - y) ** 2 for x, y in zip(a, b)) ** 0.5\n",
    "\n",
    "# Function to calculate the mean of a list of vectors (excluding class labels)\n",
    "def mean_vector(vectors):\n",
    "    \"\"\"Calculate the mean vector from a list of vectors.\"\"\"\n",
    "    # Exclude the last element (class label) when calculating the mean\n",
    "    return [sum(dim) / len(vectors) for dim in zip(*[v[:-1] for v in vectors])]\n",
    "\n",
    "# Function to calculate the covariance matrix\n",
    "def covariance_matrix(vectors):\n",
    "    \"\"\"Calculate the covariance matrix of a list of vectors.\"\"\"\n",
    "    mean = mean_vector(vectors)\n",
    "    n = len(vectors)\n",
    "    cov_matrix = [[0] * (len(mean)) for _ in range(len(mean))]\n",
    "\n",
    "    for vector in vectors:\n",
    "        for i in range(len(mean)):\n",
    "            for j in range(len(mean)):\n",
    "                cov_matrix[i][j] += (vector[i] - mean[i]) * (vector[j] - mean[j])\n",
    "    \n",
    "    return [[val / (n - 1) for val in row] for row in cov_matrix]\n",
    "\n",
    "# Function to calculate the inverse of a 2D matrix (only for 2x2 matrices)\n",
    "def inverse_matrix(matrix):\n",
    "    \"\"\"Calculate the inverse of a 2x2 matrix.\"\"\"\n",
    "    det = matrix[0][0] * matrix[1][1] - matrix[0][1] * matrix[1][0]\n",
    "    if det == 0:\n",
    "        raise ValueError(\"Matrix is not invertible.\")\n",
    "    return [[matrix[1][1] / det, -matrix[0][1] / det],\n",
    "            [-matrix[1][0] / det, matrix[0][0] / det]]\n",
    "\n",
    "# Function to calculate Mahalanobis distance\n",
    "def mahalanobis_distance(x, y, cov):\n",
    "    \"\"\"Calculate the Mahalanobis distance between two vectors.\"\"\"\n",
    "    diff = [a - b for a, b in zip(x, y)]\n",
    "    inv_cov = inverse_matrix(cov)\n",
    "    return sum(diff[i] * sum(inv_cov[i][j] * diff[j] for j in range(len(diff))) for i in range(len(diff)))\n",
    "\n",
    "# Nearest neighbor classification function\n",
    "def nearest_neighbor_classification(training_data, test_vector):\n",
    "    \"\"\"Classify the test_vector based on nearest neighbor classification.\"\"\"\n",
    "    min_distance = float('inf')\n",
    "    nearest_neighbor = None\n",
    "    \n",
    "    for train_vector in training_data:\n",
    "        distance = euclidean_distance(train_vector[:-1], test_vector)  # Exclude class label\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            nearest_neighbor = train_vector[-1]  # Class label\n",
    "    \n",
    "    return nearest_neighbor\n",
    "\n",
    "# Example usage\n",
    "training_data = [\n",
    "    [1.0, 2.0, 'Class A'],\n",
    "    [2.0, 3.0, 'Class A'],\n",
    "    [3.0, 3.5, 'Class B'],\n",
    "    [5.0, 4.0, 'Class B']\n",
    "]\n",
    "\n",
    "# Test vector\n",
    "test_vector = [2.5, 3.0]\n",
    "\n",
    "# Classify the test vector\n",
    "predicted_class = nearest_neighbor_classification(training_data, test_vector)\n",
    "print(f'The predicted class for the test vector {test_vector} is: {predicted_class}')\n",
    "\n",
    "# Calculate Mahalanobis distance between two points\n",
    "x = [2.0, 3.0]\n",
    "y = [3.0, 4.0]\n",
    "cov = covariance_matrix(training_data)  # Use training data for covariance\n",
    "mahalanobis_dist = mahalanobis_distance(x, y, cov)\n",
    "\n",
    "print(f'The Mahalanobis distance between {x} and {y} is: {mahalanobis_dist}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d551385",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mnist'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10302/2185937246.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Load MNIST dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mnist'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mnist\n",
    "\n",
    "# Load MNIST dataset\n",
    "def load_mnist():\n",
    "    \"\"\"Load MNIST dataset.\"\"\"\n",
    "    train_images = mnist.train_images()\n",
    "    train_labels = mnist.train_labels()\n",
    "    test_images = mnist.test_images()\n",
    "    test_labels = mnist.test_labels()\n",
    "    \n",
    "    return train_images, train_labels, test_images, test_labels\n",
    "\n",
    "# Preprocess images: flattening\n",
    "def preprocess_images(images):\n",
    "    \"\"\"Flatten images for classification.\"\"\"\n",
    "    return images.reshape(images.shape[0], -1)\n",
    "\n",
    "# Function to calculate Euclidean distance\n",
    "def euclidean_distance(a, b):\n",
    "    return np.sqrt(np.sum((a - b) ** 2))\n",
    "\n",
    "# Nearest neighbor classification function\n",
    "def nearest_neighbor_classification(train_data, train_labels, test_data):\n",
    "    predictions = []\n",
    "    for test_vector in test_data:\n",
    "        distances = [euclidean_distance(test_vector, train_vector) for train_vector in train_data]\n",
    "        nearest_index = np.argmin(distances)\n",
    "        predictions.append(train_labels[nearest_index])\n",
    "    return np.array(predictions)\n",
    "\n",
    "# Main function to run the comparison\n",
    "def main():\n",
    "    # Load and preprocess data\n",
    "    train_images, train_labels, test_images, test_labels = load_mnist()\n",
    "    train_images = preprocess_images(train_images)\n",
    "    test_images = preprocess_images(test_images)\n",
    "\n",
    "    # Classify using nearest neighbor\n",
    "    nn_predictions = nearest_neighbor_classification(train_images, train_labels, test_images)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    nn_accuracy = np.mean(nn_predictions == test_labels)\n",
    "    print(f'Nearest Neighbor Accuracy: {nn_accuracy * 100:.2f}%')\n",
    "\n",
    "    # Plot some predictions\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for i in range(10):\n",
    "        plt.subplot(2, 5, i + 1)\n",
    "        plt.imshow(test_images[i].reshape(28, 28), cmap='gray')\n",
    "        plt.title(f'Pred: {nn_predictions[i]}, True: {test_labels[i]}')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e497beef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# Function to load images from a directory\n",
    "def load_images_from_folder(folder):\n",
    "    \"\"\"Load images and labels from a specified folder.\"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for label in os.listdir(folder):\n",
    "        label_folder = os.path.join(folder, label)\n",
    "        if os.path.isdir(label_folder):\n",
    "            for filename in os.listdir(label_folder):\n",
    "                img_path = os.path.join(label_folder, filename)\n",
    "                img = Image.open(img_path).convert('L')  # Convert to grayscale\n",
    "                img = img.resize((28, 28))  # Resize to 28x28\n",
    "                img_data = np.array(img).flatten() / 255.0  # Normalize pixel values\n",
    "                images.append(img_data)\n",
    "                labels.append(label)  # Use folder name as label\n",
    "    \n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Function to calculate Euclidean distance\n",
    "def euclidean_distance(a, b):\n",
    "    return np.sqrt(np.sum((a - b) ** 2))\n",
    "\n",
    "# Nearest neighbor classification function\n",
    "def nearest_neighbor_classification(train_data, train_labels, test_data):\n",
    "    predictions = []\n",
    "    for test_vector in test_data:\n",
    "        distances = [euclidean_distance(test_vector, train_vector) for train_vector in train_data]\n",
    "        nearest_index = np.argmin(distances)\n",
    "        predictions.append(train_labels[nearest_index])\n",
    "    return np.array(predictions)\n",
    "\n",
    "# Function to calculate the mean vector\n",
    "def mean_vector(vectors):\n",
    "    return np.mean(vectors, axis=0)\n",
    "\n",
    "# Function to calculate the covariance matrix\n",
    "def covariance_matrix(vectors):\n",
    "    return np.cov(vectors, rowvar=False)\n",
    "\n",
    "# Function to calculate the inverse of a covariance matrix\n",
    "def inverse_matrix(matrix):\n",
    "    return np.linalg.inv(matrix)\n",
    "\n",
    "# Function to calculate Mahalanobis distance\n",
    "def mahalanobis_distance(x, y, cov):\n",
    "    diff = x - y\n",
    "    inv_cov = inverse_matrix(cov)\n",
    "    return np.sqrt(np.dot(np.dot(diff.T, inv_cov), diff))\n",
    "\n",
    "# Mahalanobis classification function\n",
    "def mahalanobis_classification(train_data, train_labels, test_data):\n",
    "    predictions = []\n",
    "    cov = covariance_matrix(train_data)\n",
    "    \n",
    "    for test_vector in test_data:\n",
    "        distances = [mahalanobis_distance(test_vector, train_vector, cov) for train_vector in train_data]\n",
    "        nearest_index = np.argmin(distances)\n",
    "        predictions.append(train_labels[nearest_index])\n",
    "    \n",
    "    return np.array(predictions)\n",
    "\n",
    "# Main function to run the comparison\n",
    "def main():\n",
    "    # Load images\n",
    "    train_data, train_labels = load_images_from_folder('cd/train')\n",
    "    test_data, test_labels = load_images_from_folder('cd/validation')\n",
    "\n",
    "    # Classify using nearest neighbor\n",
    "    nn_predictions = nearest_neighbor_classification(train_data, train_labels, test_data)\n",
    "    nn_accuracy = np.mean(nn_predictions == test_labels)\n",
    "\n",
    "    # Classify using Mahalanobis distance\n",
    "    md_predictions = mahalanobis_classification(train_data, train_labels, test_data)\n",
    "    md_accuracy = np.mean(md_predictions == test_labels)\n",
    "\n",
    "    print(f'Nearest Neighbor Accuracy: {nn_accuracy * 100:.2f}%')\n",
    "    print(f'Mahalanobis Distance Accuracy: {md_accuracy * 100:.2f}%')\n",
    "\n",
    "    # Plot comparison\n",
    "    plt.bar(['Nearest Neighbor', 'Mahalanobis Distance'], [nn_accuracy, md_accuracy])\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Comparison of Classification Approaches')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd722b4e",
   "metadata": {},
   "source": [
    "Let \n",
    "$$\n",
    "\\mu = \\frac{1}{N} \\sum_{i=1}^{N} s_i, \n",
    "\\quad C = \\sum_{i=1}^{N} \\sum_{j=1}^{N} (s_i - \\mu)(s_j - \\mu)^T\n",
    "\\tag{6.12.9}\n",
    "$$\n",
    "be the sample mean vector of \\( N \\) known pattern vectors \\( s_i \\) and the sample cross-covariance matrix. \n",
    "\n",
    "Then, the Mahalanobis distance from the \\( i \\)-th pattern vector \\( s_i \\) to the \\( j \\)-th pattern vector \\( s_j \\) is defined as:\n",
    "$$\n",
    "D_M(s_i, s_j) = (s_i - s_j)^T C^{-1} (s_i - s_j)\n",
    "\\tag{6.12.10}\n",
    "$$\n",
    "\n",
    "By the nearest neighbor classification method, if:\n",
    "$$\n",
    "D_M(s_1, s_i) = \\min_{k=1, \\dots, M} D_M(s_1, s_k)\n",
    "\\tag{6.12.11}\n",
    "$$\n",
    "then the pattern vector \\( s_i \\) is recognized as belonging to the same pattern type as \\( s_1 \\).\n",
    "\n",
    "### Cosine Similarity\n",
    "\n",
    "The cosine similarity between vectors is given by:\n",
    "$$\n",
    "D(x, s_i) = \\cos \\theta_i = \\frac{x^T s_i}{\\|x\\|_2 \\|s_i\\|_2}\n",
    "\\tag{6.12.12}\n",
    "$$\n",
    "If $ \\cos \\theta_i < \\cos \\theta_j $, for all $ j \\neq i $, then the unknown pattern vector $ x $ is said to be most similar to the known pattern vector $ s_i $.\n",
    "\n",
    "### Tanimoto Measure\n",
    "\n",
    "The Tanimoto similarity measure is:\n",
    "$$\n",
    "D(x, s_i) = \\frac{x^T s_i}{x^T x + s_i^T s_i - x^T s_i}\n",
    "\\tag{6.12.13}\n",
    "$$\n",
    "This is widely used in applications such as information retrieval, disease classification, etc.\n",
    "\n",
    "### Nearest Neighbor Classification\n",
    "\n",
    "Given a test pattern vector $ x $ and $ m $ clustered classes, the mean vector of the $ i $-th class is:\n",
    "$$\n",
    "\\bar{s}^{(i)} = \\frac{1}{N_i} \\sum_{k=1}^{N_i} s_k^{(i)},\n",
    "\\tag{6.12.14}\n",
    "$$\n",
    "where $ N_i $ is the number of pattern vectors in the $ i $-th class. We decide that $ x $ belongs to Class $ i $, if:\n",
    "$$\n",
    "D(x, \\bar{s}^{(i)}) = \\min_{k=1, \\dots, m} D(x, \\bar{s}^{(k)}).\n",
    "\\tag{6.12.15}\n",
    "$$\n",
    "\n",
    "### Similarity Matrix\n",
    "\n",
    "For $ N $ objects $ x_1, \\dots, x_N $, the similarity matrix $ S = [s_{ij}]_{N,N} $ is defined as:\n",
    "$$\n",
    "s_{ij} = s(x_i, x_j), \\quad i = 1, \\dots, N; \\ j = 1, \\dots, N,\n",
    "\\tag{6.12.17}\n",
    "$$\n",
    "with $ s_{ii} = s(x_i, x_i) = 0 $.\n",
    "\n",
    "Similarly, the distance matrix $ D = [d_{ij}]_{N,N} $ is defined as:\n",
    "$$\n",
    "d_{ij} = d(x_i, x_j), \\quad i = 1, \\dots, N; \\ j = 1, \\dots, N,\n",
    "\\tag{6.12.18}\n",
    "$$\n",
    "with $ d_{ii} = d(x_i, x_i) = 0 $.\n",
    "\n",
    "Both similarity and distance matrices are symmetric and nonnegative:\n",
    "$$\n",
    "S^T = S, \\quad S \\geq 0.\n",
    "\\tag{6.12.19}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e583a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Helper functions for vector operations\n",
    "def dot_product(v1, v2):\n",
    "    return sum([v1[i] * v2[i] for i in range(len(v1))])\n",
    "\n",
    "def vector_subtraction(v1, v2):\n",
    "    return [v1[i] - v2[i] for i in range(len(v1))]\n",
    "\n",
    "def vector_magnitude(v):\n",
    "    return math.sqrt(sum([v[i] ** 2 for i in range(len(v))]))\n",
    "\n",
    "def covariance_matrix(data):\n",
    "    \"\"\"Compute the covariance matrix of the dataset.\"\"\"\n",
    "    mean_vector = [sum(col) / len(col) for col in zip(*data)]\n",
    "    n = len(data)\n",
    "    d = len(data[0])\n",
    "    cov_matrix = [[0 for _ in range(d)] for _ in range(d)]\n",
    "    \n",
    "    for i in range(d):\n",
    "        for j in range(d):\n",
    "            cov_matrix[i][j] = sum((data[k][i] - mean_vector[i]) * (data[k][j] - mean_vector[j]) for k in range(n)) / (n - 1)\n",
    "    return cov_matrix\n",
    "\n",
    "def inverse_matrix(matrix):\n",
    "    \"\"\"Find the inverse of a 2x2 matrix (for simplicity).\"\"\"\n",
    "    determinant = matrix[0][0] * matrix[1][1] - matrix[0][1] * matrix[1][0]\n",
    "    if determinant == 0:\n",
    "        raise ValueError(\"Matrix is not invertible\")\n",
    "    inv_det = 1 / determinant\n",
    "    return [[matrix[1][1] * inv_det, -matrix[0][1] * inv_det],\n",
    "            [-matrix[1][0] * inv_det, matrix[0][0] * inv_det]]\n",
    "\n",
    "def mahalanobis_distance(v1, v2, covariance_matrix):\n",
    "    \"\"\"Compute the Mahalanobis distance between two vectors.\"\"\"\n",
    "    diff = vector_subtraction(v1, v2)\n",
    "    inv_cov_matrix = inverse_matrix(covariance_matrix)\n",
    "    temp = dot_product(diff, [dot_product(row, diff) for row in inv_cov_matrix])\n",
    "    return math.sqrt(temp)\n",
    "\n",
    "# Cosine similarity\n",
    "def cosine_similarity(v1, v2):\n",
    "    return dot_product(v1, v2) / (vector_magnitude(v1) * vector_magnitude(v2))\n",
    "\n",
    "# Tanimoto measure\n",
    "def tanimoto_measure(v1, v2):\n",
    "    dot_prod = dot_product(v1, v2)\n",
    "    return dot_prod / (dot_product(v1, v1) + dot_product(v2, v2) - dot_prod)\n",
    "\n",
    "# Nearest neighbor classification\n",
    "def nearest_neighbor_classification(test_vector, data_vectors, distance_function):\n",
    "    distances = [(i, distance_function(test_vector, v)) for i, v in enumerate(data_vectors)]\n",
    "    distances.sort(key=lambda x: x[1])  # Sort by distance\n",
    "    return distances[0][0]  # Return the index of the nearest neighbor\n",
    "\n",
    "# Example dataset (replace with your actual data)\n",
    "data_vectors = [\n",
    "    [1, 2], [2, 3], [3, 4], [5, 6], [8, 9]\n",
    "]\n",
    "\n",
    "test_vector = [4, 5]\n",
    "\n",
    "# Covariance matrix for Mahalanobis distance\n",
    "cov_matrix = covariance_matrix(data_vectors)\n",
    "\n",
    "# Calculate Mahalanobis distance between two vectors\n",
    "print(\"Mahalanobis Distance:\", mahalanobis_distance(test_vector, data_vectors[0], cov_matrix))\n",
    "\n",
    "# Calculate Cosine Similarity\n",
    "print(\"Cosine Similarity:\", cosine_similarity(test_vector, data_vectors[0]))\n",
    "\n",
    "# Calculate Tanimoto Measure\n",
    "print(\"Tanimoto Measure:\", tanimoto_measure(test_vector, data_vectors[0]))\n",
    "\n",
    "# Nearest neighbor classification using cosine similarity\n",
    "nearest_neighbor = nearest_neighbor_classification(test_vector, data_vectors, cosine_similarity)\n",
    "print(\"Nearest Neighbor Index (Cosine Similarity):\", nearest_neighbor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353976f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515ea63e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
