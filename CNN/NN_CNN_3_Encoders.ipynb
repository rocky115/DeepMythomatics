{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5a5053",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " * Copyright (c) 2018 Radhamadhab Dalai\n",
    " *\n",
    " * Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    " * of this software and associated documentation files (the \"Software\"), to deal\n",
    " * in the Software without restriction, including without limitation the rights\n",
    " * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    " * copies of the Software, and to permit persons to whom the Software is\n",
    " * furnished to do so, subject to the following conditions:\n",
    " *\n",
    " * The above copyright notice and this permission notice shall be included in\n",
    " * all copies or substantial portions of the Software.\n",
    " *\n",
    " * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    " * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    " * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    " * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    " * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    " * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
    " * THE SOFTWARE.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfea30f7",
   "metadata": {},
   "source": [
    "# Multilayer Perceptrons (MLPs)\n",
    "\n",
    "## Overview\n",
    "\n",
    "Multilayer Perceptrons (MLPs) are a class of neural networks characterized by their feedforward layered structure. An MLP typically consists of an input layer, one or more hidden layers, and an output layer. \n",
    "\n",
    "## MLP with One Hidden Layer\n",
    "\n",
    "Consider a general MLP with one hidden layer. The network consists of:\n",
    "\n",
    "- **Input Layer**: Contains \\( n_i \\) units.\n",
    "- **Hidden Layer**: Contains \\( p \\) units.\n",
    "- **Output Layer**: Contains \\( n_o \\) units.\n",
    "\n",
    "In the context of auto-association, where dimension reduction is desired, the MLP is designed such that:\n",
    "\n",
    "- The number of input units and output units are the same: \\( n_i = n_o = n \\).\n",
    "- The number of hidden units \\( p \\) is less than the number of input units \\( n \\): \\( p < n \\).\n",
    "\n",
    "### Auto-Association Example\n",
    "\n",
    "In this particular application, the hidden layer acts as a limited capacity bottleneck, encoding the input vectors optimally. The structure of this MLP is often visualized as an hourglass, where the input and output layers have the same dimension, and the hidden layer has a reduced dimension.\n",
    "\n",
    "### Mathematical Representation\n",
    "\n",
    "When an \\( n \\)-dimensional real input vector \\( \\mathbf{x}_k \\) (where \\( k = 1, \\ldots, N \\)) is fed into the network, the output values of the hidden units form a \\( p \\)-vector. This is given by:\n",
    "\n",
    "$$\n",
    "\\mathbf{h}_k = F \\left( W^{(1)} \\mathbf{x}_k + \\mathbf{b}^{(1)} \\right)\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- \\( W^{(1)} \\) is the \\( p \\times n \\) weight matrix connecting the input layer to the hidden layer.\n",
    "- \\( \\mathbf{b}^{(1)} \\) is a \\( p \\)-dimensional vector of biases.\n",
    "- \\( F \\) denotes the activation function applied element-wise.\n",
    "\n",
    "### Figure: MLP with One Hidden Layer\n",
    "\n",
    "Below is a schematic representation of the MLP with one hidden layer for auto-association:\n",
    "\n",
    "![MLP with One Hidden Layer](en1.jpg)\n",
    "\n",
    "The shape of the network resembles an hourglass, with the hidden layer acting as a bottleneck.\n",
    "\n",
    "## Summary\n",
    "\n",
    "This MLP configuration is used in auto-association tasks where the goal is to reduce the dimensionality of input vectors through a hidden layer while preserving essential information for reconstruction in the output layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e13b8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-30 19:39:08.066222: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-30 19:39:20.252149: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-07-30 19:39:20.252186: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-07-30 19:39:20.899162: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-30 19:40:11.042814: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-07-30 19:40:11.064260: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-07-30 19:40:11.064284: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2024-07-30 19:40:50.453812: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2024-07-30 19:40:50.552385: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-07-30 19:40:50.607418: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (radha-Vostro-15-3568): /proc/driver/nvidia/version does not exist\n",
      "2024-07-30 19:40:51.019568: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32/32 [==============================] - 4s 11ms/step - loss: 0.6935 - accuracy: 0.0010\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6931 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6931 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6930 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.0020\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6929 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.6929 - accuracy: 0.0010\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 7ms/step - loss: 0.6928 - accuracy: 0.0010\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6928 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6928 - accuracy: 0.0020\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6927 - accuracy: 0.0020\n",
      "Loss: 0.6927, Accuracy: 0.0020\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "\n",
    "# Define the model parameters\n",
    "input_dim = 784  # Example input dimension (e.g., 28x28 images)\n",
    "hidden_units = 64  # Number of units in the hidden layer\n",
    "output_dim = 784  # Output dimension (same as input for auto-association)\n",
    "\n",
    "# Create the model\n",
    "model = Sequential([\n",
    "    Dense(hidden_units, input_dim=input_dim, activation='relu', name='hidden_layer'),\n",
    "    Dense(output_dim, activation='sigmoid', name='output_layer')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Generate some example data\n",
    "x_train = np.random.rand(1000, input_dim)  # 1000 samples, each of dimension 784\n",
    "y_train = x_train  # For auto-association, output is the same as input\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(x_train, y_train)\n",
    "print(f'Loss: {loss:.4f}, Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07e95651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.6954\n",
      "Epoch [2/10], Loss: 0.6934\n",
      "Epoch [3/10], Loss: 0.6933\n",
      "Epoch [4/10], Loss: 0.6932\n",
      "Epoch [5/10], Loss: 0.6932\n",
      "Epoch [6/10], Loss: 0.6932\n",
      "Epoch [7/10], Loss: 0.6931\n",
      "Epoch [8/10], Loss: 0.6931\n",
      "Epoch [9/10], Loss: 0.6931\n",
      "Epoch [10/10], Loss: 0.6930\n",
      "Final Loss: 0.6930\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the model parameters\n",
    "input_dim = 784  # Example input dimension (e.g., 28x28 images)\n",
    "hidden_units = 64  # Number of units in the hidden layer\n",
    "output_dim = 784  # Output dimension (same as input for auto-association)\n",
    "\n",
    "# Define the MLP model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_units)\n",
    "        self.fc2 = nn.Linear(hidden_units, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "model = MLP()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Generate some example data\n",
    "x_train = torch.rand(1000, input_dim)  # 1000 samples, each of dimension 784\n",
    "y_train = x_train  # For auto-association, output is the same as input\n",
    "\n",
    "# Training loop\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(x_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(x_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    print(f'Final Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb416def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.0834\n",
      "Epoch 2/10, Loss: 0.0875\n",
      "Epoch 3/10, Loss: 0.0846\n",
      "Epoch 4/10, Loss: 0.0834\n",
      "Epoch 5/10, Loss: 0.0833\n",
      "Epoch 6/10, Loss: 0.0832\n",
      "Epoch 7/10, Loss: 0.0832\n",
      "Epoch 8/10, Loss: 0.0832\n",
      "Epoch 9/10, Loss: 0.0832\n",
      "Epoch 10/10, Loss: 0.0832\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "#withouimport numpy as np\n",
    "\n",
    "# Activation functions and their derivatives\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "# Initialize parameters\n",
    "input_dim = 784  # Example input dimension (e.g., 28x28 images)\n",
    "hidden_units = 64  # Number of units in the hidden layer\n",
    "output_dim = 784  # Output dimension (same as input for auto-association)\n",
    "\n",
    "# Initialize weights and biases\n",
    "np.random.seed(42)\n",
    "W1 = np.random.randn(input_dim, hidden_units) * 0.01  # Input to hidden layer\n",
    "b1 = np.zeros((1, hidden_units))  # Bias for hidden layer\n",
    "W2 = np.random.randn(hidden_units, output_dim) * 0.01  # Hidden to output layer\n",
    "b2 = np.zeros((1, output_dim))  # Bias for output layer\n",
    "\n",
    "# Learning rate\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Generate example data\n",
    "x_train = np.random.rand(1000, input_dim)  # 1000 samples, each of dimension 784\n",
    "y_train = x_train  # For auto-association, output is the same as input\n",
    "\n",
    "# Training loop\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    z1 = np.dot(x_train, W1) + b1\n",
    "    a1 = sigmoid(z1)\n",
    "    z2 = np.dot(a1, W2) + b2\n",
    "    a2 = sigmoid(z2)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = mean_squared_error(y_train, a2)\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Loss: {loss:.4f}')\n",
    "\n",
    "    # Backward pass\n",
    "    error = a2 - y_train\n",
    "    d_a2 = error * sigmoid_derivative(z2)\n",
    "    \n",
    "    error_hidden_layer = np.dot(d_a2, W2.T)\n",
    "    d_a1 = error_hidden_layer * sigmoid_derivative(z1)\n",
    "    \n",
    "    # Update weights and biases\n",
    "    W2 -= learning_rate * np.dot(a1.T, d_a2)\n",
    "    b2 -= learning_rate * np.sum(d_a2, axis=0, keepdims=True)\n",
    "    W1 -= learning_rate * np.dot(x_train.T, d_a1)\n",
    "    b1 -= learning_rate * np.sum(d_a1, axis=0, keepdims=True)\n",
    "\n",
    "# Final evaluation\n",
    "print('Training completed.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dc50db",
   "metadata": {},
   "source": [
    "## Autoencoders in Object Recognition\n",
    "\n",
    "In the context of object recognition, a particularly interesting and challenging question is whether unsupervised learning can be used to learn hierarchies of invariant feature extractors. Autoencoders provide an effective way to solve this problem. The basic idea of the autoencoder, proposed by Rumelhart et al. in 1986, is the layer-by-layer training.\n",
    "\n",
    "### Invariant Features\n",
    "\n",
    "Features that are invariant to small distortions are called invariant features. The key idea to invariant feature learning is to represent an input patch with two components:\n",
    "- **Invariant Feature Vector**: Represents what is in the image.\n",
    "- **Transformation Parameters**: Encodes where each feature appears in the image.\n",
    "\n",
    "### Architecture of Autoencoders\n",
    "\n",
    "An autoencoder is an MLP with a symmetric structure, used to learn an efficient representation (encoding) for a set of data in an unsupervised manner. The aim of an autoencoder is to make the output as similar to the input as possible.\n",
    "\n",
    "Architecturally, the simplest form of an autoencoder is a feedforward, non-recurrent neural network very similar to many single-layer perceptrons in an MLP. It consists of:\n",
    "- **Input Layer**\n",
    "- **Hidden Layers**\n",
    "- **Output Layer** (also known as the reconstruction layer)\n",
    "\n",
    "The output layer has the same number of nodes as the input layer.\n",
    "\n",
    "### Purpose of Autoencoders\n",
    "\n",
    "Autoencoders are designed to reconstruct their own inputs rather than predicting a target value \\( Y \\) given inputs \\( X \\). Therefore, autoencoders are unsupervised learning models.\n",
    "\n",
    "### Components of an Autoencoder\n",
    "\n",
    "An autoencoder is composed of two main networks:\n",
    "1. **Encoder Network**: Compresses the input into a latent representation.\n",
    "2. **Decoder Network**: Reconstructs the input from the latent representation.\n",
    "\n",
    "### Symmetry in Autoencoders\n",
    "\n",
    "The autoencoder is always symmetrical:\n",
    "- The **middle layer** (comprising one or two layers, depending on whether the number of neural network layers is odd or even) acts as the bottleneck.\n",
    "- The layer **in front of the middle layer** is the encoding layer.\n",
    "- The layer **behind the middle layer** is the decoding layer.\n",
    "\n",
    "### Example Architecture\n",
    "\n",
    "The architecture of a basic autoencoder can be visualized as follows:\n",
    "\n",
    "\\[\n",
    "\\text{Input Layer} \\rightarrow \\text{Encoder Layer(s)} \\rightarrow \\text{Latent Space} \\rightarrow \\text{Decoder Layer(s)} \\rightarrow \\text{Output Layer}\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- **Input Layer** and **Output Layer** have the same number of nodes.\n",
    "- **Encoder** reduces the dimensionality of the input.\n",
    "- **Decoder** attempts to reconstruct the original input from the reduced representation.\n",
    "\n",
    "This symmetrical structure ensures that the autoencoder learns a compact representation of the input data.\n",
    "\n",
    "![Autoencoder Architecture](en2.png)  <!-- Placeholder for image visualization -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55d40eb",
   "metadata": {},
   "source": [
    "## Autoencoders: Architecture and Training\n",
    "\n",
    "### Encoder Network\n",
    "\n",
    "The encoder function \\( f(x) \\) maps the original high-dimensional inputs \\( x \\in \\mathbb{R}^n \\) to a low-dimensional feature representation \\( h \\in \\mathbb{R}^p \\):\n",
    "\n",
    "$$\n",
    "h = f(x) = s_f(W^{(1)} x + b_h) \\quad \\text{where} \\quad n > p\n",
    "$$\n",
    "\n",
    "Here:\n",
    "- \\( h \\) is the feature vector or code computed from \\( x \\),\n",
    "- \\( W^{(1)} \\in \\mathbb{R}^{p \\times n} \\) is the encoding matrix,\n",
    "- \\( s_f \\) is an elementwise nonlinear activation function, typically the logistic sigmoid function:\n",
    "\n",
    "$$\n",
    "s_f(z_i) = \\text{sigmoid}(z_i) = \\frac{1}{1 + e^{-z_i}}\n",
    "$$\n",
    "\n",
    "The encoder’s parameters include a bias vector \\( b_h \\in \\mathbb{R}^p \\).\n",
    "\n",
    "### Decoder Network\n",
    "\n",
    "The symmetric decoder \\( g(h) \\) maps \\( h \\) back to an \\( n \\)-dimensional output vector, producing a reconstruction \\( y = g(h) \\) that should be as similar as possible to the original input vector \\( x \\), i.e., \\( y = \\hat{x} \\):\n",
    "\n",
    "$$\n",
    "y = g(h) = s_g(W^{(2)} h + b_y) \\quad \\text{where} \\quad p < n\n",
    "$$\n",
    "\n",
    "Here:\n",
    "- \\( W^{(2)} \\in \\mathbb{R}^{n \\times p} \\) is the decoding matrix,\n",
    "- \\( g \\) is an elementwise nonlinear function, and \\( s_g \\) is the decoder’s activation function, typically either the identity function (for linear reconstruction) or a sigmoid function,\n",
    "- The decoder’s parameters include a bias vector \\( b_y \\in \\mathbb{R}^n \\).\n",
    "\n",
    "In general, one explores the tied weights case, where \\( W^{(2)} = (W^{(1)})^T = W^T \\).\n",
    "\n",
    "### Autoencoder Training\n",
    "\n",
    "The input layer and output layer have the same number of neurons \\( n \\), which is larger than the number \\( p \\) of neurons in the hidden layer. The middle hidden layer acts as the bottleneck of the autoencoder. The goal of training an autoencoder is to find parameters \\( \\theta = \\{W, b_h, b_y\\} \\) that minimize the reconstruction error on a training set \\( D_n \\):\n",
    "\n",
    "$$\n",
    "\\min_\\theta J_{AE}(\\theta) = \\sum_{x \\in D_n} L(x, g(f(x)))\n",
    "$$\n",
    "\n",
    "where \\( L(x, y) \\) is the reconstruction error. Typical choices for the loss function include:\n",
    "\n",
    "- **Squared Error**:\n",
    "\n",
    "$$\n",
    "L(x, y) = \\| x - y \\|^2\n",
    "$$\n",
    "\n",
    "- **Cross-Entropy Loss Function**:\n",
    "\n",
    "$$\n",
    "L(x, y) = -\\sum_{i=1}^n \\left[ x_i \\log(y_i) + (1 - x_i) \\log(1 - y_i) \\right]\n",
    "$$\n",
    "\n",
    "### Autoencoder Training Flowchart\n",
    "\n",
    "The autoencoder training process is illustrated in the following flowchart:\n",
    "\n",
    "$$\n",
    "\\begin{array}{cccc}\n",
    "\\text{Input} & \\xrightarrow{\\text{Encoder }} & \\text{Feature Vector } h = f(x) & \\xrightarrow{\\text{Decoder }} & \\text{Output } y = \\hat{x} \\\\\n",
    "& & & & \\\\\n",
    "& \\text{Reconstruction Error} & & &\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "### Hidden Layer Activations\n",
    "\n",
    "For each example \\( x_t \\) from the dataset \\( \\{x_1, \\dots, x_T\\} \\), the hidden neurons and activations of the input \\( x \\) are computed as follows:\n",
    "\n",
    "$$\n",
    "\\text{net}_j^{(2)} = \\sum_{i=1}^n w_j^{(1)} x_i + b_j^{(1)}, \\quad j = 1, \\dots, m\n",
    "$$\n",
    "\n",
    "$$\n",
    "a_j^{(2)} = f(\\text{net}_j^{(2)}), \\quad j = 1, \\dots, m\n",
    "$$\n",
    "\n",
    "Similarly, the hidden neurons and activations of the output layer are:\n",
    "\n",
    "$$\n",
    "\\text{net}_i^{(3)} = \\sum_{j=1}^m w_{ij}^{(2)} a_j^{(2)} + b_i^{(2)}, \\quad i = 1, \\dots, n\n",
    "$$\n",
    "\n",
    "$$\n",
    "a_i^{(3)} = f(\\text{net}_i^{(3)}), \\quad i = 1, \\dots, n\n",
    "$$\n",
    "\n",
    "where \\( f \\) is a nonlinear activation function, typically the sigmoid function:\n",
    "\n",
    "$$\n",
    "f(z) = \\frac{1}{1 + e^{-z}}\n",
    "$$\n",
    "\n",
    "### Energy of the System\n",
    "\n",
    "The problem of the basic autoencoder is to find optimal weight matrices \\( W^{(1)}, W^{(2)} \\) and bias vectors \\( b^{(1)}, b^{(2)} \\) for minimizing the total error energy of the system. The energy of the system is the sum of two terms:\n",
    "\n",
    "$$\n",
    "J_{AE}(\\theta) = \\frac{1}{2m} \\sum_{j=1}^m \\| a_j^{(2)} - \\text{Encode}(x, W^{(1)}) \\|^2 + \\frac{1}{2n} \\sum_{i=1}^n \\| a_i^{(3)} - \\text{Decode}(\\hat{x}, W^{(2)}) \\|^2\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- **Code Prediction Energy** \\( E_e \\):\n",
    "\n",
    "$$\n",
    "E_e(a_j^{(2)}, W^{(1)}) = \\frac{1}{2} \\| a_j^{(2)} - \\text{Encode}(x, W^{(1)}) \\|^2\n",
    "$$\n",
    "\n",
    "- **Reconstruction Energy** \\( E_d \\):\n",
    "\n",
    "$$\n",
    "E_d(a_i^{(3)}, W^{(2)}) = \\frac{1}{2} \\| a_i^{(3)} - \\text{Decode}(\\hat{x}, W^{(2)}) \\|^2\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6efb01f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/1000, Loss: 0.08647789874402455\n",
      "Epoch 200/1000, Loss: 0.08608855422787445\n",
      "Epoch 300/1000, Loss: 0.08583052523300583\n",
      "Epoch 400/1000, Loss: 0.085659436069837\n",
      "Epoch 500/1000, Loss: 0.08554594467974494\n",
      "Epoch 600/1000, Loss: 0.08547061903802536\n",
      "Epoch 700/1000, Loss: 0.0854205811257551\n",
      "Epoch 800/1000, Loss: 0.08538729480428127\n",
      "Epoch 900/1000, Loss: 0.08536510247098145\n",
      "Epoch 1000/1000, Loss: 0.08535025525493067\n",
      "Original Data: [[0.5488135  0.71518937 0.60276338 0.54488318 0.4236548  0.64589411\n",
      "  0.43758721 0.891773   0.96366276 0.38344152 0.79172504 0.52889492\n",
      "  0.56804456 0.92559664 0.07103606 0.0871293  0.0202184  0.83261985\n",
      "  0.77815675 0.87001215]]\n",
      "Decoded Data: [[0.51007112 0.54098636 0.44526398 0.49786725 0.54926883 0.54201391\n",
      "  0.51535621 0.4628755  0.56169283 0.54260375 0.46378982 0.46833193\n",
      "  0.48931598 0.46413188 0.49378504 0.48052504 0.46661399 0.48413841\n",
      "  0.53119941 0.55085537]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "class Autoencoder:\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        # Initialize weights and biases\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.W1 = np.random.randn(hidden_size, input_size) * 0.01  # Encoder weights\n",
    "        self.b1 = np.zeros((hidden_size, 1))  # Encoder biases\n",
    "        self.W2 = np.random.randn(input_size, hidden_size) * 0.01  # Decoder weights\n",
    "        self.b2 = np.zeros((input_size, 1))  # Decoder biases\n",
    "    \n",
    "    def encode(self, x):\n",
    "        \"\"\"Encode the input data.\"\"\"\n",
    "        return sigmoid(np.dot(self.W1, x.T) + self.b1)\n",
    "    \n",
    "    def decode(self, h):\n",
    "        \"\"\"Decode the feature vector.\"\"\"\n",
    "        return sigmoid(np.dot(self.W2, h) + self.b2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass through the autoencoder.\"\"\"\n",
    "        self.encoded = self.encode(x)\n",
    "        self.decoded = self.decode(self.encoded)\n",
    "        return self.decoded\n",
    "    \n",
    "    def compute_loss(self, x):\n",
    "        \"\"\"Compute the reconstruction loss.\"\"\"\n",
    "        return np.mean((x - self.decoded.T) ** 2)\n",
    "    \n",
    "    def backward(self, x, learning_rate=0.01):\n",
    "        \"\"\"Backpropagation to update weights and biases.\"\"\"\n",
    "        m = x.shape[0]\n",
    "        \n",
    "        # Compute gradients\n",
    "        d_output = (self.decoded - x.T) * sigmoid_derivative(self.decoded)\n",
    "        d_W2 = np.dot(d_output, self.encoded.T) / m\n",
    "        d_b2 = np.sum(d_output, axis=1, keepdims=True) / m\n",
    "        \n",
    "        d_hidden = np.dot(self.W2.T, d_output) * sigmoid_derivative(self.encoded)\n",
    "        d_W1 = np.dot(d_hidden, x) / m\n",
    "        d_b1 = np.sum(d_hidden, axis=1, keepdims=True) / m\n",
    "        \n",
    "        # Update weights and biases\n",
    "        self.W1 -= learning_rate * d_W1\n",
    "        self.b1 -= learning_rate * d_b1\n",
    "        self.W2 -= learning_rate * d_W2\n",
    "        self.b2 -= learning_rate * d_b2\n",
    "    \n",
    "    def train(self, x, epochs=1000, learning_rate=0.01):\n",
    "        \"\"\"Train the autoencoder using gradient descent.\"\"\"\n",
    "        for epoch in range(epochs):\n",
    "            self.forward(x)\n",
    "            loss = self.compute_loss(x)\n",
    "            self.backward(x, learning_rate)\n",
    "            if (epoch + 1) % 100 == 0:\n",
    "                print(f'Epoch {epoch + 1}/{epochs}, Loss: {loss}')\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate random data\n",
    "    np.random.seed(0)\n",
    "    data = np.random.rand(100, 20)  # 100 samples, 20 features\n",
    "\n",
    "    # Initialize and train autoencoder\n",
    "    input_size = data.shape[1]\n",
    "    hidden_size = 10\n",
    "    autoencoder = Autoencoder(input_size, hidden_size)\n",
    "    autoencoder.train(data, epochs=1000, learning_rate=0.01)\n",
    "\n",
    "    # Test encoding and decoding\n",
    "    test_data = data[0:1]  # Take the first sample\n",
    "    encoded = autoencoder.encode(test_data)\n",
    "    decoded = autoencoder.decode(encoded)\n",
    "    print(\"Original Data:\", test_data)\n",
    "    print(\"Decoded Data:\", decoded.T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46f19d9",
   "metadata": {},
   "source": [
    "## Backpropagation Algorithm for Autoencoder\n",
    "\n",
    "### Loss Function\n",
    "The loss function for the autoencoder can be represented as:\n",
    "$$\n",
    "J_{\\text{AE}}(\\theta) = \\frac{1}{2m} \\sum_{j=1}^{m} \\left( a_j^{(2)} - \\frac{1}{m} \\sum_{i=1}^n x_i \\right)^2 + \\frac{1}{2n} \\sum_{i=1}^n \\left( a_i^{(3)} - x_i \\right)^2\n",
    "$$\n",
    "where \\( a_j^{(2)} \\) is the activation in the hidden layer and \\( a_i^{(3)} \\) is the activation in the output layer.\n",
    "\n",
    "### Gradient Calculation\n",
    "\n",
    "#### Gradient with respect to Decoder Weights and Biases\n",
    "Using the chain rule, the partial derivatives of the loss function \\( J_{\\text{AE}}(\\theta) \\) with respect to the weights \\( w_{ij}^{(2)} \\) and biases \\( b_i^{(2)} \\) are given by:\n",
    "$$\n",
    "\\frac{\\partial J_{\\text{AE}}}{\\partial w_{ij}^{(2)}} = \\frac{\\partial J_{\\text{AE}}}{\\partial a_i^{(3)}} \\cdot \\frac{\\partial a_i^{(3)}}{\\partial \\text{net}_i^{(3)}} \\cdot \\frac{\\partial \\text{net}_i^{(3)}}{\\partial w_{ij}^{(2)}}\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial J_{\\text{AE}}}{\\partial b_i^{(2)}} = \\frac{\\partial J_{\\text{AE}}}{\\partial a_i^{(3)}} \\cdot \\frac{\\partial a_i^{(3)}}{\\partial \\text{net}_i^{(3)}} \\cdot \\frac{\\partial \\text{net}_i^{(3)}}{\\partial b_i^{(2)}}\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\frac{\\partial \\text{net}_i^{(3)}}{\\partial w_{ij}^{(2)}} = a_j^{(2)}\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial \\text{net}_i^{(3)}}{\\partial b_i^{(2)}} = 1\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\frac{\\partial a_i^{(3)}}{\\partial \\text{net}_i^{(3)}} = a_i^{(3)} (1 - a_i^{(3)})\n",
    "$$\n",
    "\n",
    "#### Gradient with respect to Encoder Weights and Biases\n",
    "Similarly, for the encoder weights \\( w_{ji}^{(1)} \\) and biases \\( b_j^{(1)} \\):\n",
    "$$\n",
    "\\frac{\\partial J_{\\text{AE}}}{\\partial w_{ji}^{(1)}} = \\frac{\\partial J_{\\text{AE}}}{\\partial a_j^{(2)}} \\cdot \\frac{\\partial a_j^{(2)}}{\\partial \\text{net}_j^{(2)}} \\cdot \\frac{\\partial \\text{net}_j^{(2)}}{\\partial w_{ji}^{(1)}}\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial J_{\\text{AE}}}{\\partial b_j^{(1)}} = \\frac{\\partial J_{\\text{AE}}}{\\partial a_j^{(2)}} \\cdot \\frac{\\partial a_j^{(2)}}{\\partial \\text{net}_j^{(2)}} \\cdot \\frac{\\partial \\text{net}_j^{(2)}}{\\partial b_j^{(1)}}\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\frac{\\partial \\text{net}_j^{(2)}}{\\partial w_{ji}^{(1)}} = x_i\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial \\text{net}_j^{(2)}}{\\partial b_j^{(1)}} = 1\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\frac{\\partial a_j^{(2)}}{\\partial \\text{net}_j^{(2)}} = a_j^{(2)} (1 - a_j^{(2)})\n",
    "$$\n",
    "\n",
    "### Summary of Gradient Updates\n",
    "- For decoder weights \\( W^{(2)} \\) and biases \\( b^{(2)} \\):\n",
    "$$\n",
    "W_{ij}^{(2)} \\leftarrow W_{ij}^{(2)} - \\eta \\left( a_j^{(2)} \\cdot \\sigma_i^{(3)} \\right)\n",
    "$$\n",
    "$$\n",
    "b_i^{(2)} \\leftarrow b_i^{(2)} - \\eta \\cdot \\sigma_i^{(3)}\n",
    "$$\n",
    "\n",
    "- For encoder weights \\( W^{(1)} \\) and biases \\( b^{(1)} \\):\n",
    "$$\n",
    "W_{ji}^{(1)} \\leftarrow W_{ji}^{(1)} - \\eta \\left( x_i \\cdot \\sigma_j^{(2)} \\right)\n",
    "$$\n",
    "$$\n",
    "b_j^{(1)} \\leftarrow b_j^{(1)} - \\eta \\cdot \\sigma_j^{(2)}\n",
    "$$\n",
    "\n",
    "where \\( \\eta \\) is the learning rate.\n",
    "\n",
    "### Chain Rule Derivations\n",
    "- The derivatives for \\( \\text{net}_i^{(3)} \\):\n",
    "$$\n",
    "\\frac{\\partial \\text{net}_i^{(3)}}{\\partial w_{ij}^{(2)}} = a_j^{(2)}\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial \\text{net}_i^{(3)}}{\\partial b_i^{(2)}} = 1\n",
    "$$\n",
    "\n",
    "- The derivatives for \\( \\text{net}_j^{(2)} \\):\n",
    "$$\n",
    "\\frac{\\partial \\text{net}_j^{(2)}}{\\partial w_{ji}^{(1)}} = x_i\n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial \\text{net}_j^{(2)}}{\\partial b_j^{(1)}} = 1\n",
    "$$\n",
    "\n",
    "The backpropagation algorithm updates weights and biases by computing gradients of the loss function with respect to parameters and adjusting them accordingly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea202f04",
   "metadata": {},
   "source": [
    "## Algorithm 7.4: Backpropagation Algorithm for the Basic Autoencoder\n",
    "\n",
    "### Input:\n",
    "- Data set: \\(\\{(x^{(j)}, y^{(j)})\\}_{j=1}^m\\) with \\( x^{(j)} = [x^{(j)}_1, \\ldots, x^{(j)}_n]^T \\)\n",
    "- Learning rate \\(\\eta\\)\n",
    "- Threshold \\(\\text{threshold}\\)\n",
    "\n",
    "### Steps:\n",
    "\n",
    "1. **Initialization:**\n",
    "   - Initialize weights \\(W^{(1)}, W^{(2)}\\) and biases \\(b^{(1)}, b^{(2)}\\).\n",
    "\n",
    "2. **For iteration = 1, 2, \\ldots, \\text{iter}_{\\text{max}} do:**\n",
    "\n",
    "   3. **For example = 1, 2, \\ldots, N do:**\n",
    "\n",
    "      4. **Forward Propagation:**\n",
    "\n",
    "         5. **Compute activations for the hidden layer:**\n",
    "            $$\n",
    "            \\text{net}_j^{(2)} = \\sum_{i=1}^n w_{ji}^{(1)} x_i + b_j^{(1)}\n",
    "            $$\n",
    "            $$\n",
    "            a_j^{(2)} = f(\\text{net}_j^{(2)})\n",
    "            $$\n",
    "            for \\( j = 1, 2, \\ldots, m \\)\n",
    "\n",
    "         6. **Compute activations for the output layer:**\n",
    "            $$\n",
    "            \\text{net}_i^{(3)} = \\sum_{j=1}^m w_{ij}^{(2)} a_j^{(2)} + b_i^{(2)}\n",
    "            $$\n",
    "            $$\n",
    "            a_i^{(3)} = f(\\text{net}_i^{(3)})\n",
    "            $$\n",
    "            for \\( i = 1, 2, \\ldots, n \\)\n",
    "\n",
    "      7. **Compute Gradients:**\n",
    "\n",
    "         8. **If \\( J_{\\text{AE}}(\\theta) > \\text{threshold} \\) then:**\n",
    "\n",
    "            9. **Compute error for the output layer:**\n",
    "               $$\n",
    "               \\sigma_i^{(3)} = a_i^{(3)} \\cdot (1 - a_i^{(3)}) \\cdot (a_i^{(3)} - x_i)\n",
    "               $$\n",
    "               for \\( i = 1, \\ldots, n \\)\n",
    "\n",
    "            10. **Compute error for the hidden layer:**\n",
    "                $$\n",
    "                \\sigma_j^{(2)} = \\sum_{i=1}^n w_{ji}^{(2)} \\sigma_i^{(3)} \\cdot a_j^{(2)} \\cdot (1 - a_j^{(2)})\n",
    "                $$\n",
    "                for \\( j = 1, \\ldots, m \\)\n",
    "\n",
    "            11. **Update biases and weights:**\n",
    "                - Update biases for output layer:\n",
    "                  $$\n",
    "                  b_i^{(2)} \\leftarrow b_i^{(2)} + \\sigma_i^{(3)}\n",
    "                  $$\n",
    "                  for \\( i = 1, \\ldots, n \\)\n",
    "\n",
    "                - Update weights for output layer:\n",
    "                  $$\n",
    "                  w_{ij}^{(2)} \\leftarrow w_{ij}^{(2)} + a_j^{(2)} \\cdot \\sigma_i^{(3)}\n",
    "                  $$\n",
    "                  for \\( i = 1, \\ldots, n; j = 1, \\ldots, m \\)\n",
    "\n",
    "                - Update biases for hidden layer:\n",
    "                  $$\n",
    "                  b_j^{(1)} \\leftarrow b_j^{(1)} + \\sigma_j^{(2)}\n",
    "                  $$\n",
    "                  for \\( j = 1, \\ldots, m \\)\n",
    "\n",
    "                - Update weights for hidden layer:\n",
    "                  $$\n",
    "                  w_{ji}^{(1)} \\leftarrow w_{ji}^{(1)} + x_i \\cdot \\sigma_j^{(2)}\n",
    "                  $$\n",
    "                  for \\( i = 1, \\ldots, n; j = 1, \\ldots, m \\)\n",
    "\n",
    "            12. **Apply Weight Update:**\n",
    "                - Update weights for the encoder:\n",
    "                  $$\n",
    "                  W^{(1)} = W^{(1)} - \\eta \\left( \\frac{1}{N} \\sum_{i=1}^n \\Delta W_{i}^{(1)} \\right)\n",
    "                  $$\n",
    "\n",
    "                - Update weights for the decoder:\n",
    "                  $$\n",
    "                  W^{(2)} = W^{(2)} - \\eta \\left( \\frac{1}{N} \\sum_{j=1}^m \\Delta W_{j}^{(2)} \\right)\n",
    "                  $$\n",
    "\n",
    "                - Update biases for the encoder:\n",
    "                  $$\n",
    "                  b^{(1)} = b^{(1)} - \\eta \\left( \\frac{1}{N} \\sum_{j=1}^m \\Delta b_j^{(1)} \\right)\n",
    "                  $$\n",
    "\n",
    "                - Update biases for the decoder:\n",
    "                  $$\n",
    "                  b^{(2)} = b^{(2)} - \\eta \\left( \\frac{1}{N} \\sum_{i=1}^n \\Delta b_i^{(2)} \\right)\n",
    "                  $$\n",
    "\n",
    "   13. **End For**\n",
    "\n",
    "2. **End For**\n",
    "\n",
    "### Output:\n",
    "- The learned parameters: \\( \\theta = \\{W^{(1)}, b^{(1)}; W^{(2)}, b^{(2)}\\} \\).\n",
    "\n",
    "---\n",
    "\n",
    "## Regularized Autoencoders\n",
    "\n",
    "### Regularization with Weight Decay:\n",
    "The regularized objective function with weight decay is:\n",
    "$$\n",
    "J_{\\text{AE} + \\text{wd}}(\\theta) = L(x, g(f(x))) + \\lambda \\sum_{i,j} W_{ij}^2\n",
    "$$\n",
    "where \\(\\lambda\\) is a hyperparameter controlling the strength of the regularization.\n",
    "\n",
    "### Contractive Autoencoder (CAE):\n",
    "The objective function for the contractive autoencoder is:\n",
    "$$\n",
    "J_{\\text{CAE}}(\\theta) = L(x, g(f(x))) + \\lambda \\|\\frac{\\partial h_j(x)}{\\partial x_i}\\|_F^2\n",
    "$$\n",
    "where \\(\\|\\cdot\\|_F\\) denotes the Frobenius norm and \\(\\lambda\\) is a hyperparameter controlling the strength of the regularization.\n",
    "\n",
    "The regularization term penalizes the Jacobian matrix \\(\\frac{\\partial h_j(x)}{\\partial x_i}\\), encouraging the feature mapping to be contractive in the neighborhood of the training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9ab0918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.18021408932161884\n",
      "Epoch 100, Loss: 0.1729519492406884\n",
      "Epoch 200, Loss: 0.16559672847300755\n",
      "Epoch 300, Loss: 0.15816609422465985\n",
      "Epoch 400, Loss: 0.15071575072704024\n",
      "Epoch 500, Loss: 0.14333483678353326\n",
      "Epoch 600, Loss: 0.1361335397111424\n",
      "Epoch 700, Loss: 0.12922815110318328\n",
      "Epoch 800, Loss: 0.12272663587659004\n",
      "Epoch 900, Loss: 0.11671609187222151\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Activation functions\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "class Autoencoder:\n",
    "    def __init__(self, input_size, hidden_size, learning_rate=0.01):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # Initialize weights and biases\n",
    "        self.W1 = np.random.randn(hidden_size, input_size)\n",
    "        self.b1 = np.random.randn(hidden_size, 1)\n",
    "        self.W2 = np.random.randn(input_size, hidden_size)\n",
    "        self.b2 = np.random.randn(input_size, 1)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.z1 = np.dot(self.W1, X.T) + self.b1\n",
    "        self.a1 = sigmoid(self.z1)\n",
    "        self.z2 = np.dot(self.W2, self.a1) + self.b2\n",
    "        self.a2 = sigmoid(self.z2)\n",
    "        return self.a2.T\n",
    "    \n",
    "    def backward(self, X):\n",
    "        m = X.shape[0]\n",
    "        # Compute the gradients for W2 and b2\n",
    "        d_a2 = self.a2 - X.T\n",
    "        d_z2 = d_a2 * sigmoid_derivative(self.a2)\n",
    "        d_W2 = np.dot(d_z2, self.a1.T) / m\n",
    "        d_b2 = np.sum(d_z2, axis=1, keepdims=True) / m\n",
    "        \n",
    "        # Compute the gradients for W1 and b1\n",
    "        d_a1 = np.dot(self.W2.T, d_z2)\n",
    "        d_z1 = d_a1 * sigmoid_derivative(self.a1)\n",
    "        d_W1 = np.dot(d_z1, X) / m\n",
    "        d_b1 = np.sum(d_z1, axis=1, keepdims=True) / m\n",
    "        \n",
    "        # Update weights and biases\n",
    "        self.W1 -= self.learning_rate * d_W1\n",
    "        self.b1 -= self.learning_rate * d_b1\n",
    "        self.W2 -= self.learning_rate * d_W2\n",
    "        self.b2 -= self.learning_rate * d_b2\n",
    "    \n",
    "    def train(self, X, epochs=1000):\n",
    "        for epoch in range(epochs):\n",
    "            # Forward pass\n",
    "            self.forward(X)\n",
    "            # Backward pass\n",
    "            self.backward(X)\n",
    "            # Print the cost every 100 epochs\n",
    "            if epoch % 100 == 0:\n",
    "                loss = np.mean(np.square(X - self.a2.T))\n",
    "                print(f'Epoch {epoch}, Loss: {loss}')\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate some example data\n",
    "    np.random.seed(0)\n",
    "    X = np.random.rand(100, 10)  # 100 samples, 10 features\n",
    "    \n",
    "    # Initialize and train the autoencoder\n",
    "    autoencoder = Autoencoder(input_size=10, hidden_size=5, learning_rate=0.01)\n",
    "    autoencoder.train(X, epochs=1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a91288",
   "metadata": {},
   "source": [
    " ## Stacked Sparse Autoencoder\n",
    "    $$\n",
    "\\text{Autoencoders and Their Extensions}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{A stacked autoencoder is a multilayer neural network where each layer is the hidden layer of the previous autoencoder and the input layer of the next autoencoder.}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Let } x_t^{(d)} \\text{ be the input to the } d\\text{-th stacked autoencoder, where } x_t^{(1)} = x_t.\n",
    "$$\n",
    "\n",
    "$$\n",
    "h_t^{(d)} = f\\left(W_1^{(d)} x_t^{(d)} + b_1^{(d)}\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "y_t^{(d)} = f\\left(W_2^{(d)} h_t^{(d)} + b_2^{(d)}\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "f(x) = \\frac{1}{1 + \\exp(-x)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "J\\left(W_1^{(d)}, b_1^{(d)}, W_2^{(d)}, b_2^{(d)}\\right) = \\frac{1}{2T} \\sum_{t=1}^T \\left\\| y_t^{(d)} - x_t^{(d)} \\right\\|^2 + \\frac{\\beta}{2} \\left(\\left\\| W_1^{(d)} \\right\\|^2 + \\left\\| W_2^{(d)} \\right\\|^2\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{A sparse autoencoder introduces a sparsity constraint on the hidden layer activations.}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{\\rho}_j = \\frac{1}{T} \\sum_{t=1}^T x_{t,j}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{KL}(\\rho \\parallel \\hat{\\rho}) = \\sum_{j=1}^n \\left[ \\rho \\log \\frac{\\rho}{\\hat{\\rho}_j} + (1 - \\rho) \\log \\frac{1 - \\rho}{1 - \\hat{\\rho}_j} \\right]\n",
    "$$\n",
    "\n",
    "$$\n",
    "J_{\\text{SAE}}(W, b) = J_{\\text{AE}}(W, b) + \\beta \\text{KL}(\\rho \\parallel \\hat{\\rho}) + \\frac{\\lambda}{2} \\sum_{l=1}^L \\left\\| W^{(l)} \\right\\|^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "J_{\\text{SSAE}}^{(d)} = \\frac{1}{2T} \\sum_{t=1}^T \\left\\| y_t^{(d)} - x_t^{(d)} \\right\\|^2 + \\beta \\sum_{j=1}^{K_d} \\text{KL}(\\rho \\parallel \\hat{\\rho}_j^{(d)}) + \\alpha \\left( \\left\\| W_1^{(d)} \\right\\|^2 + \\left\\| W_2^{(d)} \\right\\|^2 \\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "W_1^{(d)} \\leftarrow W_1^{(d)} - \\eta \\frac{1}{T} \\sum_{i=1}^T \\delta_i^{(d)} h_i^{(d)} + \\alpha W_1^{(d)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "W_2^{(d)} \\leftarrow W_2^{(d)} - \\eta \\frac{1}{T} \\sum_{i=1}^T \\delta_i^{(d)} h_i^{(d)} + \\alpha W_2^{(d)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "b_1^{(d)} \\leftarrow b_1^{(d)} - \\eta \\frac{1}{T} \\sum_{i=1}^T \\delta_i^{(d)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "b_2^{(d)} \\leftarrow b_2^{(d)} - \\eta \\frac{1}{T} \\sum_{i=1}^T \\delta_i^{(d)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\delta_i^{(d)} = W_2^{(d)} \\delta_i^{(d)} + \\beta \\left(- \\frac{\\rho}{\\hat{\\rho}_i^{(d)}} + \\frac{1 - \\rho}{1 - \\hat{\\rho}_i^{(d)}}\\right) f\\left(W_1^{(d)} x_i^{(d)} + b_1^{(d)}\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\delta_i^{(d)} = y_i^{(d)} - x_i^{(d)} f\\left(W_2^{(d)} h_i^{(d)} + b_2^{(d)}\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{A denoising autoencoder is trained to reconstruct clean data from noisy inputs.}\n",
    "$$\n",
    "\n",
    "$$\n",
    "J_{\\text{DAE}} = \\frac{1}{2T} \\sum_{t=1}^T \\left\\| \\hat{x}_t - x_t \\right\\|^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{A convolutional autoencoder uses convolutional layers for encoding and decoding.}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{The architecture includes convolutional layers for encoding and transposed convolutional layers for decoding.}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{A stacked denoising convolutional autoencoder combines the denoising and convolutional concepts.}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{The architecture is similar to the stacked convolutional autoencoder but with noise added to the input images.}\n",
    "$$\n",
    "\n",
    "$$\n",
    "J_{\\text{DAE}} = \\frac{1}{2T} \\sum_{t=1}^T \\left\\| \\hat{x}_t - x_t \\right\\|^2\n",
    "$$\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469d30eb",
   "metadata": {},
   "source": [
    "$$\n",
    "\\textbf{Autoencoders and Their Extensions}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Autoencoders are a type of neural network used for unsupervised learning. There are several major extensions of autoencoders, including:}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{1. Stacked Autoencoder}\n",
    "$$\n",
    "$$\n",
    "\\text{2. Sparse Autoencoder}\n",
    "$$\n",
    "$$\n",
    "\\text{3. Stacked Sparse Autoencoder}\n",
    "$$\n",
    "$$\n",
    "\\text{4. Stacked Denoising Autoencoder}\n",
    "$$\n",
    "$$\n",
    "\\text{5. Stacked Convolutional Autoencoder}\n",
    "$$\n",
    "$$\n",
    "\\text{6. Stacked Denoising Convolutional Autoencoder}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\textbf{Stacked Autoencoder}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{A stacked autoencoder is a multilayer neural network where each layer is the hidden layer of the previous autoencoder and the input layer of the next autoencoder. It can be viewed as multiple autoencoders connected successively in a greedy layer-wise fashion.}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Let } x_t^{(d)} \\text{ be the input to the } d\\text{-th stacked autoencoder, where } x_t^{(1)} = x_t.\n",
    "$$\n",
    "\n",
    "$$\n",
    "h_t^{(d)} = f\\left(W_1^{(d)} x_t^{(d)} + b_1^{(d)}\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "y_t^{(d)} = f\\left(W_2^{(d)} h_t^{(d)} + b_2^{(d)}\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{where } h_t^{(d)} \\text{ and } y_t^{(d)} \\text{ denote, respectively, the feature representation at the hidden layer and the output at the output layer of the } d\\text{-th autoencoder.}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{The activation function } f(\\cdot) \\text{ is usually the sigmoid function:}\n",
    "$$\n",
    "\n",
    "$$\n",
    "f(x) = \\frac{1}{1 + \\exp(-x)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{The objective function for the } d\\text{-th autoencoder is:}\n",
    "$$\n",
    "\n",
    "$$\n",
    "J\\left(W_1^{(d)}, b_1^{(d)}, W_2^{(d)}, b_2^{(d)}\\right) = \\frac{1}{2T} \\sum_{t=1}^T \\left\\| y_t^{(d)} - x_t^{(d)} \\right\\|^2 + \\frac{\\beta}{2} \\left(\\left\\| W_1^{(d)} \\right\\|^2 + \\left\\| W_2^{(d)} \\right\\|^2\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{where } \\beta \\text{ is a regularization parameter.}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\textbf{Sparse Autoencoder}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{A sparse autoencoder introduces a sparsity constraint on the hidden layer activations, encouraging a more efficient representation of the input data.}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{The average activation } \\hat{\\rho}_j \\text{ of the } j\\text{-th neuron is:}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{\\rho}_j = \\frac{1}{T} \\sum_{t=1}^T x_{t,j}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{To enforce sparsity, the Kullback-Leibler (KL) divergence between } \\hat{\\rho}_j \\text{ and } \\rho \\text{ is added as a regularization term:}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{KL}(\\rho \\parallel \\hat{\\rho}) = \\sum_{j=1}^n \\left[ \\rho \\log \\frac{\\rho}{\\hat{\\rho}_j} + (1 - \\rho) \\log \\frac{1 - \\rho}{1 - \\hat{\\rho}_j} \\right]\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{The final cost function of the sparse autoencoder is:}\n",
    "$$\n",
    "\n",
    "$$\n",
    "J_{\\text{SAE}}(W, b) = J_{\\text{AE}}(W, b) + \\beta \\text{KL}(\\rho \\parallel \\hat{\\rho}) + \\frac{\\lambda}{2} \\sum_{l=1}^L \\left\\| W^{(l)} \\right\\|^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{where:}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\beta \\text{ controls the sparsity penalty term}\n",
    "$$\n",
    "$$\n",
    "\\lambda \\text{ controls the weight decay}\n",
    "$$\n",
    "$$\n",
    "s_l \\text{ and } s_{l+1} \\text{ are the sizes of adjacent layers}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\textbf{Stacked Sparse Autoencoder}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{A stacked sparse autoencoder combines the stacked and sparse autoencoders. It connects multiple sparse autoencoders end-to-end, allowing for higher-level feature representations.}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{The objective function for the } d\\text{-th layer of a stacked sparse autoencoder is:}\n",
    "$$\n",
    "\n",
    "$$\n",
    "J_{\\text{SSAE}}^{(d)} = \\frac{1}{2T} \\sum_{t=1}^T \\left\\| y_t^{(d)} - x_t^{(d)} \\right\\|^2 + \\beta \\sum_{j=1}^{K_d} \\text{KL}(\\rho \\parallel \\hat{\\rho}_j^{(d)}) + \\alpha \\left( \\left\\| W_1^{(d)} \\right\\|^2 + \\left\\| W_2^{(d)} \\right\\|^2 \\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{where:}\n",
    "$$\n",
    "\n",
    "$$\n",
    "K_d \\text{ is the number of hidden units in the } d\\text{-th layer}\n",
    "$$\n",
    "$$\n",
    "\\alpha \\text{ is the weight decay parameter}\n",
    "$$\n",
    "$$\n",
    "\\beta \\text{ is the weight of the sparsity penalty}\n",
    "$$\n",
    "$$\n",
    "\\rho \\text{ is the sparsity parameter}\n",
    "$$\n",
    "$$\n",
    "\\hat{\\rho}_j^{(d)} \\text{ is the average activation of the } j\\text{-th hidden unit in the } d\\text{-th layer}\n",
    "$$\n",
    "$$\n",
    "\\text{KL}(\\rho \\parallel \\hat{\\rho}_j^{(d)}) \\text{ denotes the KL divergence between } \\rho \\text{ and } \\hat{\\rho}_j^{(d)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{The parameters are updated using stochastic gradient descent:}\n",
    "$$\n",
    "\n",
    "$$\n",
    "W_1^{(d)} \\leftarrow W_1^{(d)} - \\eta \\frac{1}{T} \\sum_{i=1}^T \\delta_i^{(d)} h_i^{(d)} + \\alpha W_1^{(d)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "W_2^{(d)} \\leftarrow W_2^{(d)} - \\eta \\frac{1}{T} \\sum_{i=1}^T \\delta_i^{(d)} h_i^{(d)} + \\alpha W_2^{(d)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "b_1^{(d)} \\leftarrow b_1^{(d)} - \\eta \\frac{1}{T} \\sum_{i=1}^T \\delta_i^{(d)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "b_2^{(d)} \\leftarrow b_2^{(d)} - \\eta \\frac{1}{T} \\sum_{i=1}^T \\delta_i^{(d)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{where } \\eta \\text{ is the learning rate, and:}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\delta_i^{(d)} = W_2^{(d)} \\delta_i^{(d)} + \\beta \\left(- \\frac{\\rho}{\\hat{\\rho}_i^{(d)}} + \\frac{1 - \\rho}{1 - \\hat{\\rho}_i^{(d)}}\\right) f\\left(W_1^{(d)} x_i^{(d)} + b_1^{(d)}\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\delta_i^{(d)} = y_i^{(d)} - x_i^{(d)} f\\left(W_2^{(d)} h_i^{(d)} + b_2^{(d)}\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\textbf{Stacked Denoising Autoencoder}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{A denoising autoencoder is trained to reconstruct clean data from noisy inputs, which makes it robust to noise.}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{The cost function is:}\n",
    "$$\n",
    "\n",
    "$$\n",
    "J_{\\text{DAE}} = \\frac{1}{2T} \\sum_{t=1}^T \\left\\| \\hat{x}_t - x_t \\right\\|^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{where } \\hat{x}_t \\text{ is the reconstruction of the clean data from the noisy input.}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\textbf{Stacked Convolutional Autoencoder}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{A convolutional autoencoder uses convolutional layers for encoding and decoding, making it suitable for image data.}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{The architecture includes:}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{1. Convolutional layers for encoding}\n",
    "$$\n",
    "$$\n",
    "\\text{2. Transposed convolutional (deconvolution) layers for decoding}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{The objective function is similar to the basic autoencoder but adapted for convolutional layers.}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\textbf{Stacked Denoising Convolutional Autoencoder}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Combines the denoising and convolutional autoencoder concepts, making it suitable for noisy image data.}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{The architecture is similar to the stacked convolutional autoencoder but with noise added to the input images.}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c457e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked Autoencoder:\n",
      "StackedAutoencoder(\n",
      "  (autoencoders): ModuleList(\n",
      "    (0): Autoencoder(\n",
      "      (encoder): Sequential(\n",
      "        (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (decoder): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=784, bias=True)\n",
      "        (1): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (1): Autoencoder(\n",
      "      (encoder): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (decoder): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (1): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (2): Autoencoder(\n",
      "      (encoder): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (decoder): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (1): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Sparse Autoencoder:\n",
      "SparseAutoencoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=784, bias=True)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      ")\n",
      "Stacked Sparse Autoencoder:\n",
      "StackedSparseAutoencoder(\n",
      "  (autoencoders): ModuleList(\n",
      "    (0): Autoencoder(\n",
      "      (encoder): Sequential(\n",
      "        (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (decoder): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=784, bias=True)\n",
      "        (1): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (1): Autoencoder(\n",
      "      (encoder): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=256, bias=True)\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (decoder): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (1): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "    (2): Autoencoder(\n",
      "      (encoder): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (1): ReLU()\n",
      "      )\n",
      "      (decoder): Sequential(\n",
      "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (1): Sigmoid()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Denoising Autoencoder:\n",
      "DenoisingAutoencoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=784, bias=True)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      ")\n",
      "Convolutional Autoencoder:\n",
      "ConvolutionalAutoencoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): ConvTranspose2d(16, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      ")\n",
      "Denoising Convolutional Autoencoder:\n",
      "DenoisingConvolutionalAutoencoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): ConvTranspose2d(16, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define a basic Autoencoder\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "# Define Stacked Autoencoder\n",
    "class StackedAutoencoder(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(StackedAutoencoder, self).__init__()\n",
    "        self.autoencoders = nn.ModuleList()\n",
    "        for i in range(len(layers) - 1):\n",
    "            self.autoencoders.append(Autoencoder(layers[i], layers[i + 1]))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for autoencoder in self.autoencoders:\n",
    "            x = autoencoder(x)\n",
    "        return x\n",
    "\n",
    "# Define Sparse Autoencoder\n",
    "class SparseAutoencoder(Autoencoder):\n",
    "    def __init__(self, input_dim, hidden_dim, rho, beta):\n",
    "        super(SparseAutoencoder, self).__init__(input_dim, hidden_dim)\n",
    "        self.rho = rho\n",
    "        self.beta = beta\n",
    "    \n",
    "    def kl_divergence(self, rho, rho_hat):\n",
    "        return rho * torch.log(rho / rho_hat) + (1 - rho) * torch.log((1 - rho) / (1 - rho_hat))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "    def loss_function(self, output, input, rho_hat):\n",
    "        mse_loss = nn.MSELoss()(output, input)\n",
    "        kl_loss = self.kl_divergence(self.rho, rho_hat)\n",
    "        return mse_loss + self.beta * kl_loss\n",
    "\n",
    "# Define Stacked Sparse Autoencoder\n",
    "class StackedSparseAutoencoder(StackedAutoencoder):\n",
    "    def __init__(self, layers, rho, beta):\n",
    "        super(StackedSparseAutoencoder, self).__init__(layers)\n",
    "        self.rho = rho\n",
    "        self.beta = beta\n",
    "    \n",
    "    def kl_divergence(self, rho, rho_hat):\n",
    "        return rho * torch.log(rho / rho_hat) + (1 - rho) * torch.log((1 - rho) / (1 - rho_hat))\n",
    "    \n",
    "    def loss_function(self, outputs, inputs, rho_hats):\n",
    "        loss = 0\n",
    "        for output, input, rho_hat in zip(outputs, inputs, rho_hats):\n",
    "            mse_loss = nn.MSELoss()(output, input)\n",
    "            kl_loss = self.kl_divergence(self.rho, rho_hat)\n",
    "            loss += mse_loss + self.beta * kl_loss\n",
    "        return loss\n",
    "\n",
    "# Define Denoising Autoencoder\n",
    "class DenoisingAutoencoder(Autoencoder):\n",
    "    def __init__(self, input_dim, hidden_dim, noise_factor=0.5):\n",
    "        super(DenoisingAutoencoder, self).__init__(input_dim, hidden_dim)\n",
    "        self.noise_factor = noise_factor\n",
    "    \n",
    "    def add_noise(self, x):\n",
    "        noise = torch.normal(mean=0, std=self.noise_factor, size=x.size())\n",
    "        return x + noise\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_noisy = self.add_noise(x)\n",
    "        encoded = self.encoder(x_noisy)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "# Define Convolutional Autoencoder\n",
    "class ConvolutionalAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvolutionalAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(16, 1, kernel_size=5, stride=1, padding=2),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# Define Denoising Convolutional Autoencoder\n",
    "class DenoisingConvolutionalAutoencoder(ConvolutionalAutoencoder):\n",
    "    def __init__(self, noise_factor=0.5):\n",
    "        super(DenoisingConvolutionalAutoencoder, self).__init__()\n",
    "        self.noise_factor = noise_factor\n",
    "    \n",
    "    def add_noise(self, x):\n",
    "        noise = torch.normal(mean=0, std=self.noise_factor, size=x.size())\n",
    "        return x + noise\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_noisy = self.add_noise(x)\n",
    "        x = self.encoder(x_noisy)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Define parameters\n",
    "    input_dim = 784\n",
    "    hidden_dim = 256\n",
    "    rho = 0.1\n",
    "    beta = 3e-3\n",
    "    noise_factor = 0.5\n",
    "    layers = [input_dim, 512, 256, hidden_dim]\n",
    "    \n",
    "    # Create models\n",
    "    stacked_autoencoder = StackedAutoencoder(layers)\n",
    "    sparse_autoencoder = SparseAutoencoder(input_dim, hidden_dim, rho, beta)\n",
    "    stacked_sparse_autoencoder = StackedSparseAutoencoder(layers, rho, beta)\n",
    "    denoising_autoencoder = DenoisingAutoencoder(input_dim, hidden_dim, noise_factor)\n",
    "    convolutional_autoencoder = ConvolutionalAutoencoder()\n",
    "    denoising_convolutional_autoencoder = DenoisingConvolutionalAutoencoder(noise_factor)\n",
    "    \n",
    "    # Print model summaries\n",
    "    print(\"Stacked Autoencoder:\")\n",
    "    print(stacked_autoencoder)\n",
    "    \n",
    "    print(\"Sparse Autoencoder:\")\n",
    "    print(sparse_autoencoder)\n",
    "    \n",
    "    print(\"Stacked Sparse Autoencoder:\")\n",
    "    print(stacked_sparse_autoencoder)\n",
    "    \n",
    "    print(\"Denoising Autoencoder:\")\n",
    "    print(denoising_autoencoder)\n",
    "    \n",
    "    print(\"Convolutional Autoencoder:\")\n",
    "    print(convolutional_autoencoder)\n",
    "    \n",
    "    print(\"Denoising Convolutional Autoencoder:\")\n",
    "    print(denoising_convolutional_autoencoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26aaa2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: ./data/MNIST/raw/train-images-idx3-ubyte.gz\n",
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz\n",
      "Using downloaded and verified file: ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Using downloaded and verified file: ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Using downloaded and verified file: ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n",
      "Training Stacked Autoencoder...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [128 x 784], m2: [512 x 256] at /opt/conda/conda-bld/pytorch-cpu_1556653114183/work/aten/src/TH/generic/THTensorMath.cpp:961",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7934/3693713441.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_7934/3693713441.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training {name}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mplot_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_7934/3693713441.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloader, num_epochs, learning_rate)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0mrho_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSparseAutoencoder\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrho_hat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrho_hat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_7934/3693713441.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mautoencoder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoencoders\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_7934/3693713441.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mdecoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecoded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv37/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv37/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv37/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1406\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1407\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1408\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [128 x 784], m2: [512 x 256] at /opt/conda/conda-bld/pytorch-cpu_1556653114183/work/aten/src/TH/generic/THTensorMath.cpp:961"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define a basic Autoencoder\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "# Define Stacked Autoencoder\n",
    "class StackedAutoencoder(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(StackedAutoencoder, self).__init__()\n",
    "        self.autoencoders = nn.ModuleList()\n",
    "        for i in range(len(layers) - 1):\n",
    "            self.autoencoders.append(Autoencoder(layers[i], layers[i + 1]))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for autoencoder in self.autoencoders:\n",
    "            x = autoencoder(x)\n",
    "        return x\n",
    "\n",
    "# Define Sparse Autoencoder\n",
    "class SparseAutoencoder(Autoencoder):\n",
    "    def __init__(self, input_dim, hidden_dim, rho, beta):\n",
    "        super(SparseAutoencoder, self).__init__(input_dim, hidden_dim)\n",
    "        self.rho = rho\n",
    "        self.beta = beta\n",
    "    \n",
    "    def kl_divergence(self, rho, rho_hat):\n",
    "        return rho * torch.log(rho / rho_hat) + (1 - rho) * torch.log((1 - rho) / (1 - rho_hat))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "    def loss_function(self, output, input, rho_hat):\n",
    "        mse_loss = nn.MSELoss()(output, input)\n",
    "        kl_loss = self.kl_divergence(self.rho, rho_hat)\n",
    "        return mse_loss + self.beta * kl_loss\n",
    "\n",
    "# Define Stacked Sparse Autoencoder\n",
    "class StackedSparseAutoencoder(StackedAutoencoder):\n",
    "    def __init__(self, layers, rho, beta):\n",
    "        super(StackedSparseAutoencoder, self).__init__(layers)\n",
    "        self.rho = rho\n",
    "        self.beta = beta\n",
    "    \n",
    "    def kl_divergence(self, rho, rho_hat):\n",
    "        return rho * torch.log(rho / rho_hat) + (1 - rho) * torch.log((1 - rho) / (1 - rho_hat))\n",
    "    \n",
    "    def loss_function(self, outputs, inputs, rho_hats):\n",
    "        loss = 0\n",
    "        for output, input, rho_hat in zip(outputs, inputs, rho_hats):\n",
    "            mse_loss = nn.MSELoss()(output, input)\n",
    "            kl_loss = self.kl_divergence(self.rho, rho_hat)\n",
    "            loss += mse_loss + self.beta * kl_loss\n",
    "        return loss\n",
    "\n",
    "# Define Denoising Autoencoder\n",
    "class DenoisingAutoencoder(Autoencoder):\n",
    "    def __init__(self, input_dim, hidden_dim, noise_factor=0.5):\n",
    "        super(DenoisingAutoencoder, self).__init__(input_dim, hidden_dim)\n",
    "        self.noise_factor = noise_factor\n",
    "    \n",
    "    def add_noise(self, x):\n",
    "        noise = torch.normal(mean=0, std=self.noise_factor, size=x.size())\n",
    "        return x + noise\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_noisy = self.add_noise(x)\n",
    "        encoded = self.encoder(x_noisy)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "# Define Convolutional Autoencoder\n",
    "class ConvolutionalAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvolutionalAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(16, 1, kernel_size=5, stride=1, padding=2),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# Define Denoising Convolutional Autoencoder\n",
    "class DenoisingConvolutionalAutoencoder(ConvolutionalAutoencoder):\n",
    "    def __init__(self, noise_factor=0.5):\n",
    "        super(DenoisingConvolutionalAutoencoder, self).__init__()\n",
    "        self.noise_factor = noise_factor\n",
    "    \n",
    "    def add_noise(self, x):\n",
    "        noise = torch.normal(mean=0, std=self.noise_factor, size=x.size())\n",
    "        return x + noise\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_noisy = self.add_noise(x)\n",
    "        x = self.encoder(x_noisy)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# Training and Testing Functions\n",
    "def train_model(model, dataloader, num_epochs=5, learning_rate=1e-3):\n",
    "    criterion = nn.MSELoss() if not isinstance(model, SparseAutoencoder) else model.loss_function\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        for data in dataloader:\n",
    "            inputs, _ = data\n",
    "            inputs = inputs.view(inputs.size(0), -1)  # Flatten the images\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            rho_hat = torch.mean(outputs, dim=0) if isinstance(model, SparseAutoencoder) else None\n",
    "            loss = criterion(outputs, inputs, rho_hat) if rho_hat is not None else criterion(outputs, inputs)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        avg_loss = epoch_loss / len(dataloader)\n",
    "        train_loss.append(avg_loss)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    return train_loss\n",
    "\n",
    "def test_model(model, dataloader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            inputs, _ = data\n",
    "            inputs = inputs.view(inputs.size(0), -1)  # Flatten the images\n",
    "            outputs = model(inputs)\n",
    "            break\n",
    "    return inputs, outputs\n",
    "\n",
    "def plot_results(train_loss, inputs, outputs):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Plot training loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_loss, label='Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot original vs. reconstructed images\n",
    "    plt.subplot(1, 2, 2)\n",
    "    num_images = 10\n",
    "    fig, axes = plt.subplots(2, num_images, figsize=(15, 2))\n",
    "    for i in range(num_images):\n",
    "        axes[0, i].imshow(inputs[i].view(28, 28).numpy(), cmap='gray')\n",
    "        axes[0, i].axis('off')\n",
    "        axes[1, i].imshow(outputs[i].view(28, 28).detach().numpy(), cmap='gray')\n",
    "        axes[1, i].axis('off')\n",
    "    \n",
    "    axes[0, 0].set_title('Original')\n",
    "    axes[1, 0].set_title('Reconstructed')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Main function to run the code\n",
    "def main():\n",
    "    # Dataset preparation\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "    train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "    test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "    \n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "    \n",
    "    # Define parameters\n",
    "    input_dim = 784\n",
    "    hidden_dim = 256\n",
    "    rho = 0.1\n",
    "    beta = 3e-3\n",
    "    noise_factor = 0.5\n",
    "    layers = [input_dim, 512, 256, hidden_dim]\n",
    "    \n",
    "    # Create models\n",
    "    models = {\n",
    "        'Stacked Autoencoder': StackedAutoencoder(layers),\n",
    "        'Sparse Autoencoder': SparseAutoencoder(input_dim, hidden_dim, rho, beta),\n",
    "        'Stacked Sparse Autoencoder': StackedSparseAutoencoder(layers, rho, beta),\n",
    "        'Denoising Autoencoder': DenoisingAutoencoder(input_dim, hidden_dim, noise_factor),\n",
    "        'Convolutional Autoencoder': ConvolutionalAutoencoder(),\n",
    "        'Denoising Convolutional Autoencoder': DenoisingConvolutionalAutoencoder(noise_factor)\n",
    "    }\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"Training {name}...\")\n",
    "        train_loss = train_model(model, train_dataloader)\n",
    "        inputs, outputs = test_model(model, test_dataloader)\n",
    "        plot_results(train_loss, inputs, outputs)\n",
    "        print(f\"Finished training {name}.\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd84f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the Autoencoder class\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(64, 32),  # Input layer size: 64, Hidden layer size: 32\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16)   # Second hidden layer size: 16\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(16, 32),  # Output layer size matches second hidden layer size: 16\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 64),  # Output size matches input size: 64\n",
    "            nn.Sigmoid()        # Apply sigmoid to ensure output is between 0 and 1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "digits = load_digits()\n",
    "data = digits.data\n",
    "scaler = StandardScaler()\n",
    "data = scaler.fit_transform(data)  # Normalize data\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "data_tensor = torch.tensor(data, dtype=torch.float32)\n",
    "\n",
    "# Split into training and test sets\n",
    "train_data, test_data = train_test_split(data_tensor, test_size=0.2, random_state=42)\n",
    "train_data = torch.tensor(train_data, dtype=torch.float32)\n",
    "test_data = torch.tensor(test_data, dtype=torch.float32)\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = Autoencoder()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training the model\n",
    "num_epochs = 50\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass\n",
    "    output = model(train_data)\n",
    "    loss = criterion(output, train_data)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    train_losses.append(loss.item())\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Plot training loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Test the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    reconstructed = model(test_data)\n",
    "    test_loss = criterion(reconstructed, test_data)\n",
    "    print(f'Test Loss: {test_loss.item():.4f}')\n",
    "\n",
    "# Function to visualize original and reconstructed data\n",
    "def visualize_results(original, reconstructed, num_samples=10):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for i in range(num_samples):\n",
    "        plt.subplot(2, num_samples, i + 1)\n",
    "        plt.imshow(original[i].reshape(8, 8), cmap='gray')\n",
    "        plt.title('Original')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(2, num_samples, i + 1 + num_samples)\n",
    "        plt.imshow(reconstructed[i].reshape(8, 8), cmap='gray')\n",
    "        plt.title('Reconstructed')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Visualize results\n",
    "visualize_results(test_data.numpy(), reconstructed.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bb9b31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
