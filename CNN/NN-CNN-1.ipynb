{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e388270c",
   "metadata": {},
   "source": [
    "'''\n",
    " * Copyright (c) 2018 Radhamadhab Dalai\n",
    " *\n",
    " * Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    " * of this software and associated documentation files (the \"Software\"), to deal\n",
    " * in the Software without restriction, including without limitation the rights\n",
    " * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    " * copies of the Software, and to permit persons to whom the Software is\n",
    " * furnished to do so, subject to the following conditions:\n",
    " *\n",
    " * The above copyright notice and this permission notice shall be included in\n",
    " * all copies or substantial portions of the Software.\n",
    " *\n",
    " * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    " * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    " * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    " * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    " * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    " * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
    " * THE SOFTWARE.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d21bc04",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks (CNNs)\n",
    "\n",
    "Convolutional Neural Networks (CNNs) have been extremely successful in image, speech, audio, and video recognition tasks due to their ability to exploit translational equivariance/invariance with respect to grid structures (in 1, 2, and 3 dimensions) [13].\n",
    "\n",
    "## Gabor Filter Banks\n",
    "\n",
    "Gabor filter banks are a powerful method for feature extraction. The method involves the following steps:\n",
    "1. **Creating Gabor Filters**: A bank of \\( N \\) Gabor filters is created.\n",
    "2. **Convolution**: Each filter is convolved with the input image to produce \\( N \\) different images.\n",
    "3. **Pooling**: Pixels from each image are pooled to extract relevant information.\n",
    "\n",
    "The process mainly consists of two steps: convolution and pooling.\n",
    "\n",
    "## Historical Background\n",
    "\n",
    "- **Neocognitron**: Proposed by Fukushima [32], the Neocognitron is generally seen as a model that inspired CNNs computationally.\n",
    "- **LeNet**: The first convolutional neural network, LeNet, was invented by Le Cun et al. [88] for handwritten digit recognition and further popularized by LeCun et al. [89].\n",
    "\n",
    "## Benefits of CNNs\n",
    "\n",
    "Compared to traditional fully connected neural networks, CNNs offer the advantage of a reduced number of parameters to be learned. The typical layers in a CNN include:\n",
    "\n",
    "1. **Input Layer**: Feeds data into the network. Inputs can be raw data (e.g., image pixels) or their transformations to highlight specific aspects of the data.\n",
    "\n",
    "2. **Convolutional Layers**: Contain a series of filters with fixed sizes used to perform convolutions on the data to generate feature maps.\n",
    "\n",
    "3. **Pooling Layers**: Focus on the most important patterns by reducing the dimensionality of the feature maps used by subsequent layers. Also known as downsampling layers.\n",
    "\n",
    "4. **Rectified Linear Unit (ReLU)**: Applies a nonlinear function to the output \\( x \\) of the previous layer, such as \\( f(x) = \\max(0, x) \\). ReLU layers contribute to faster convergence in training CNNs [84].\n",
    "\n",
    "5. **Fully Connected Layers**: Used for understanding patterns generated by the previous layers. Neurons in these layers are fully connected to all activations in the previous layer and are also called inner product layers. After training, features from these layers can be used in transfer learning to train another classifier.\n",
    "\n",
    "6. **Loss Layers**: Specify how the network training penalizes the deviation between the predicted and true labels. Various loss functions can be used, including Softmax, Sigmoid, Cross-entropy, and Euclidean loss.\n",
    "\n",
    "## Key Component: Convolutional Layers\n",
    "\n",
    "Convolutional layers are the most essential components of CNNs and are discussed first.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93cd8a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-26 19:25:00.758951: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-26 19:25:06.816579: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-07-26 19:25:06.816631: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-07-26 19:25:07.302505: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-26 19:25:18.765854: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-07-26 19:25:18.766182: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-07-26 19:25:18.766217: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2024-07-26 19:25:36.418101: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2024-07-26 19:25:36.508835: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-07-26 19:25:36.509029: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (radha-Vostro-15-3568): /proc/driver/nvidia/version does not exist\n",
      "2024-07-26 19:25:36.541432: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 29, 29, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 14, 14, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 12, 12, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 6, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4608)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               589952    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 684,490\n",
      "Trainable params: 684,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "4/4 [==============================] - 4s 248ms/step - loss: 2.3566 - accuracy: 0.0600\n",
      "Epoch 2/5\n",
      "4/4 [==============================] - 2s 458ms/step - loss: 2.3155 - accuracy: 0.0800\n",
      "Epoch 3/5\n",
      "4/4 [==============================] - 3s 653ms/step - loss: 2.3048 - accuracy: 0.1000\n",
      "Epoch 4/5\n",
      "4/4 [==============================] - 3s 788ms/step - loss: 2.2941 - accuracy: 0.1000\n",
      "Epoch 5/5\n",
      "4/4 [==============================] - 3s 624ms/step - loss: 2.2860 - accuracy: 0.1400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff2d5a4cf10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, ReLU\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Create a simple CNN model\n",
    "model = Sequential([\n",
    "    # Input layer (you can specify input shape for the first layer)\n",
    "    Conv2D(filters=32, kernel_size=(3, 3), input_shape=(64, 64, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    Conv2D(filters=128, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')  # Assume 10 classes for classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Dummy data for demonstration\n",
    "import numpy as np\n",
    "X_train = np.random.rand(100, 64, 64, 3)  # 100 samples of 64x64 RGB images\n",
    "y_train = np.random.randint(0, 10, size=(100,))  # 100 target labels\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43eeec58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 2.3837\n",
      "Epoch [2/5], Loss: 2.2323\n",
      "Epoch [3/5], Loss: 2.4041\n",
      "Epoch [4/5], Loss: 2.5652\n",
      "Epoch [5/5], Loss: 2.1216\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(128 * 8 * 8, 128)  # Assuming input images are 64x64\n",
    "        self.fc2 = nn.Linear(128, 10)  # Assuming 10 classes for classification\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(-1, 128 * 8 * 8)  # Flatten\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "model = SimpleCNN()\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Dummy data for demonstration\n",
    "X_train = torch.rand(100, 3, 64, 64)  # 100 samples of 64x64 RGB images\n",
    "y_train = torch.randint(0, 10, (100,))  # 100 target labels\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eda5de8",
   "metadata": {},
   "source": [
    "# Hankel Matrix and Convolution\n",
    "### Convolution Operations\n",
    "\n",
    "1. **One-dimensional Convolution (General Forms)**\n",
    "\n",
    "   $$ y_i = (x \\ast f)_i = \\sum_{j=1}^{n} x(j) f(i - j + 1), \\quad i = 1, \\ldots, 2d - 1 $$\n",
    "\n",
    "   $$ y_i = (x \\ast f)_i = \\sum_{j=1}^{d} x(i - j + 1) f(j), \\quad i = 1, \\ldots, 2d - 1 $$\n",
    "\n",
    "   $$ y_i = (x \\ast f)_i = \\sum_{j=1}^{d} x(i + j - 1) f(j), \\quad i = 1, \\ldots, n - d + 1 $$\n",
    "\n",
    "2. **Matrix-Vector Form of Convolution**\n",
    "\n",
    "   $$ y = (x \\ast f) = H(x) f $$\n",
    "\n",
    "   where\n",
    "\n",
    "   $$ H(x) = \\begin{bmatrix}\n",
    "   x(1) & x(2) & \\cdots & x(d) \\\\\n",
    "   x(2) & x(3) & \\cdots & x(d + 1) \\\\\n",
    "   \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "   x(n - d + 1) & x(n - d + 2) & \\cdots & x(n)\n",
    "   \\end{bmatrix} \\in \\mathbb{R}^{(n-d+1) \\times d} $$\n",
    "\n",
    "3. **Wrap-Around Hankel Matrix**\n",
    "\n",
    "   $$ H_d(x) = \\begin{bmatrix}\n",
    "   x(1) & x(2) & \\cdots & x(d) \\\\\n",
    "   x(2) & x(3) & \\cdots & x(d + 1) \\\\\n",
    "   \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "   x(n - d + 1) & x(n - d + 2) & \\cdots & x(n) \\\\\n",
    "   x(n - d + 2) & x(n - d + 3) & \\cdots & x(1) \\\\\n",
    "   \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "   x(n) & x(1) & \\cdots & x(d - 1)\n",
    "   \\end{bmatrix} $$\n",
    "\n",
    "4. **Theorem 7.1 (Rank of Hankel Matrix)**\n",
    "\n",
    "   If \\( r + 1 \\) denotes the minimum length of the annihilating filters that annihilate the signal \\( x \\), then for a given Hankel structured matrix \\( H_d(x) \\in H(n, d) \\) with \\( d > r \\), its rank is given by:\n",
    "\n",
    "   $$ \\text{rank}(H_d(x)) = r $$\n",
    "\n",
    "### Two-Dimensional Convolution\n",
    "\n",
    "1. **Two-Dimensional Convolution (General Forms)**\n",
    "\n",
    "   $$ s(t) = I(a, b) \\ast K(a, b) = \\sum_{a} \\sum_{b} I(a, b) K(m - a, n - b) $$\n",
    "\n",
    "   $$ s(t) = I(a, b) \\ast K(a, b) = \\sum_{a} \\sum_{b} I(m - a, n - b) K(a, b) $$\n",
    "\n",
    "   $$ s(t) = I(a, b) \\ast K(a, b) = \\sum_{a} \\sum_{b} I(m + a, n + b) K(a, b) $$\n",
    "\n",
    "2. **2-D Convolution with Input Image and Filter**\n",
    "\n",
    "   Given a 2-D image \\( X = [x_1, \\ldots, x_p] \\in \\mathbb{R}^{n \\times p} \\) and a 2-D filter \\( \\Phi = [\\phi_1, \\ldots, \\phi_q] \\in \\mathbb{R}^{d \\times q} \\):\n",
    "\n",
    "   $$ (X \\ast \\Phi)_{m,k} = \\sum_{i=1}^{d} \\sum_{j=1}^{q} x_{m+i-1, k+j-1} \\phi_{i,j} $$\n",
    "\n",
    "   Matrix-vector form:\n",
    "\n",
    "   $$ Y = (X \\ast \\Phi) = H_{d,q}(X) \\Phi $$\n",
    "\n",
    "   where\n",
    "\n",
    "   $$ H_{d,q}(X) = \\begin{bmatrix}\n",
    "   H_{d}(x_1) \\phi_1 & \\cdots & H_{d}(x_1) \\phi_q \\\\\n",
    "   \\vdots & \\ddots & \\vdots \\\\\n",
    "   H_{d}(x_p) \\phi_1 & \\cdots & H_{d}(x_p) \\phi_q\n",
    "   \\end{bmatrix} $$\n",
    "\n",
    "### Convolution Types\n",
    "\n",
    "1. **Single-Input Single-Output (SISO) Convolution**\n",
    "\n",
    "   $$ y = x \\ast \\phi = H_d(x) \\phi $$\n",
    "\n",
    "2. **Single-Input Multi-Output (SIMO) Convolution**\n",
    "\n",
    "   $$ Y = x \\ast \\Phi = H_d(x) \\Phi $$\n",
    "\n",
    "   where \\( \\Phi = [\\phi_1, \\ldots, \\phi_q] \\in \\mathbb{R}^{d \\times q} \\).\n",
    "\n",
    "3. **Multi-Input Multi-Output (MIMO) Convolution**\n",
    "\n",
    "   $$ y_i = \\sum_{j=1}^{p} z_j \\ast \\phi_{i,j} $$\n",
    "\n",
    "   Matrix-vector form:\n",
    "\n",
    "   $$ Y = \\sum_{j=1}^{p} H_d(z_j) \\phi_j = H_{d|p}(Z) \\Phi $$\n",
    "\n",
    "4. **Multi-Input Single-Output (MISO) Convolution**\n",
    "\n",
    "   $$ y = H_{d|p}(Z) \\phi $$\n",
    "\n",
    "   where \\( \\phi = [\\phi_1, \\ldots, \\phi_p]^T \\).\n",
    "\n",
    "### Block Hankel Matrix for 2-D Convolution\n",
    "\n",
    "1. **Block Hankel Matrix**\n",
    "\n",
    "   $$ H_{d_1, d_2}(X) = \\begin{bmatrix}\n",
    "   H_{d_1}(x_1) & H_{d_1}(x_2) & \\cdots & H_{d_1}(x_{d_2}) \\\\\n",
    "   \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "   H_{d_1}(x_{n_2}) & H_{d_1}(x_1) & \\cdots & H_{d_1}(x_{d_2 - 1})\n",
    "   \\end{bmatrix} $$\n",
    "\n",
    "2. **2-D Convolution Matrix-Vector Form**\n",
    "\n",
    "   $$ \\text{vec}(Y) = H_{d_1, d_2}(X) \\text{vec}(K) $$\n",
    "\n",
    "3. **Extended Block Hankel Matrix for Multi-Channel 2-D Convolution**\n",
    "\n",
    "   $$ H_{d_1, d_2|p}(X^{(1)}, \\ldots, X^{(p)}) = \\begin{bmatrix}\n",
    "   H_{d_1, d_2}(X^{(1)}) & \\cdots & H_{d_1, d_2}(X^{(p)})\n",
    "   \\end{bmatrix} $$\n",
    "\n",
    "   2-D MIMO Convolution:\n",
    "\n",
    "   $$ Y = H_{d_1, d_2|p}(X^{(1)}, \\ldots, X^{(p)}) K $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5f6aee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1D Convolution result: [1.8 2.7 3.6]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import convolve\n",
    "\n",
    "# Function to compute 1D convolution using a Hankel matrix\n",
    "def hankel_matrix_1d(x, d):\n",
    "    n = len(x)\n",
    "    H = np.zeros((n - d + 1, d))\n",
    "    for i in range(n - d + 1):\n",
    "        H[i, :] = x[i:i + d]\n",
    "    return H\n",
    "\n",
    "def convolve_1d(x, f):\n",
    "    d = len(f)\n",
    "    H = hankel_matrix_1d(x, d)\n",
    "    y = H @ f\n",
    "    return y\n",
    "\n",
    "# Example usage\n",
    "x = np.array([1, 2, 3, 4, 5])\n",
    "f = np.array([0.2, 0.5, 0.2])\n",
    "y = convolve_1d(x, f)\n",
    "print(\"1D Convolution result:\", y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d30099a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D Convolution result:\n",
      " [[4 4]\n",
      " [4 4]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import convolve2d\n",
    "\n",
    "# Function to compute 2D convolution\n",
    "def convolve_2d(image, kernel):\n",
    "    return convolve2d(image, kernel, mode='valid')\n",
    "\n",
    "# Example usage\n",
    "image = np.array([[1, 2, 3],\n",
    "                  [4, 5, 6],\n",
    "                  [7, 8, 9]])\n",
    "kernel = np.array([[1, 0],\n",
    "                   [0, -1]])\n",
    "result = convolve_2d(image, kernel)\n",
    "print(\"2D Convolution result:\\n\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "707d712c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D Hankel Matrix:\n",
      " [[ 1.  2.  5.  6.]\n",
      " [ 2.  3.  6.  7.]\n",
      " [ 3.  4.  7.  8.]\n",
      " [ 5.  6.  9. 10.]\n",
      " [ 6.  7. 10. 11.]\n",
      " [ 7.  8. 11. 12.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def hankel_matrix_2d(X, d1, d2):\n",
    "    n1, n2 = X.shape\n",
    "    H = np.zeros(((n1 - d1 + 1) * (n2 - d2 + 1), d1 * d2))\n",
    "    for i in range(n1 - d1 + 1):\n",
    "        for j in range(n2 - d2 + 1):\n",
    "            H[i * (n2 - d2 + 1) + j, :] = X[i:i + d1, j:j + d2].flatten()\n",
    "    return H\n",
    "\n",
    "# Example usage\n",
    "X = np.array([[1, 2, 3, 4],\n",
    "              [5, 6, 7, 8],\n",
    "              [9, 10, 11, 12]])\n",
    "d1, d2 = 2, 2\n",
    "H = hankel_matrix_2d(X, d1, d2)\n",
    "print(\"2D Hankel Matrix:\\n\", H)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39500763",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (3,1) (8,3) (3,1) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7570/2080131625.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHankelConvolutionalModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_7570/2080131625.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, y, epochs, learning_rate)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m                 \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(X)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_7570/2080131625.py\u001b[0m in \u001b[0;36mupdate_weights\u001b[0;34m(self, grad, learning_rate)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (3,1) (8,3) (3,1) "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Generate synthetic data\n",
    "def generate_synthetic_data(n_samples, n_features, n_targets):\n",
    "    X = np.random.randn(n_samples, n_features)\n",
    "    y = np.random.randn(n_samples, n_targets)\n",
    "    return X, y\n",
    "\n",
    "# Example usage\n",
    "n_samples = 100\n",
    "n_features = 10\n",
    "n_targets = 1\n",
    "X_train, y_train = generate_synthetic_data(n_samples, n_features, n_targets)\n",
    "import numpy as np\n",
    "\n",
    "class HankelConvolutionalModel:\n",
    "    def __init__(self, d):\n",
    "        self.d = d\n",
    "        self.W = np.random.randn(d, 1)  # Random initial weights\n",
    "\n",
    "    def hankel_matrix(self, x):\n",
    "        n = len(x)\n",
    "        H = np.zeros((n - self.d + 1, self.d))\n",
    "        for i in range(n - self.d + 1):\n",
    "            H[i, :] = x[i:i + self.d]\n",
    "        return H\n",
    "\n",
    "    def forward(self, x):\n",
    "        H = self.hankel_matrix(x)\n",
    "        return H @ self.W\n",
    "\n",
    "    def compute_loss(self, y_pred, y_true):\n",
    "        return np.mean((y_pred - y_true) ** 2)\n",
    "\n",
    "    def gradient(self, x, y_true):\n",
    "        y_pred = self.forward(x)\n",
    "        loss = self.compute_loss(y_pred, y_true)\n",
    "        grad = 2 * np.mean((y_pred - y_true)[:, np.newaxis] * self.hankel_matrix(x), axis=0)\n",
    "        return grad, loss\n",
    "\n",
    "    def update_weights(self, grad, learning_rate):\n",
    "        self.W -= learning_rate * grad\n",
    "\n",
    "    def train(self, X, y, epochs, learning_rate):\n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0\n",
    "            for x, y_true in zip(X, y):\n",
    "                grad, loss = self.gradient(x, y_true)\n",
    "                self.update_weights(grad, learning_rate)\n",
    "                total_loss += loss\n",
    "            print(f'Epoch {epoch + 1}/{epochs}, Loss: {total_loss / len(X)}')\n",
    "\n",
    "# Example usage\n",
    "d = 3\n",
    "model = HankelConvolutionalModel(d)\n",
    "model.train(X_train, y_train, epochs=10, learning_rate=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65435d6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
