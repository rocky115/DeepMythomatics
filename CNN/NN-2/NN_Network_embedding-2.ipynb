{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1a8c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " * Copyright (c) 2018 Radhamadhab Dalai\n",
    " *\n",
    " * Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    " * of this software and associated documentation files (the \"Software\"), to deal\n",
    " * in the Software without restriction, including without limitation the rights\n",
    " * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    " * copies of the Software, and to permit persons to whom the Software is\n",
    " * furnished to do so, subject to the following conditions:\n",
    " *\n",
    " * The above copyright notice and this permission notice shall be included in\n",
    " * all copies or substantial portions of the Software.\n",
    " *\n",
    " * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    " * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    " * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    " * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    " * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    " * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
    " * THE SOFTWARE.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995561a9",
   "metadata": {},
   "source": [
    "# GraphSAGE\n",
    "\n",
    "Most graph embedding methods require all the nodes in the graph to participate in the training process, which is a property of transductive learning, and cannot directly generalize to nodes that have not been seen before.\n",
    "\n",
    "Graph with SAmple and aggreGatE (simply called GraphSAGE), introduced by Hamilton et al. [50], uses an inductive node embedding for large-scale networks, which can generate embeddings quickly for new nodes without an additional training process. The framework of GraphSAGE is as follows [50]:\n",
    "\n",
    "- **Embedding generation**: Unlike embedding approaches that are based on matrix factorization, GraphSAGE leverages node features (e.g., text attributes, node profile information, node degrees) in order to learn an embedding function that generalizes to unseen nodes.\n",
    "  \n",
    "- **Parameter learning**: By incorporating node features in the learning of parameters, GraphSAGE simultaneously learns the topological structure of each node’s neighborhood as well as the distribution of node features in the neighborhood.\n",
    "  \n",
    "- **Aggregator architecture**: Instead of training a distinct embedding vector for each node, GraphSAGE trains a set of aggregate functions that learn to aggregate feature information from a node’s local neighborhood. Each aggregate function aggregates information from a different number of hops, or search depth, away from a given node.\n",
    "\n",
    "The aggregate functions applied in GraphSAGE must meet the following two basic requirements:\n",
    "\n",
    "1. The aggregate functions must operate over an unordered set of vectors because a node’s neighbors have no natural ordering.\n",
    "  \n",
    "2. An aggregate function should be symmetric (i.e., invariant to permutations of its inputs), but should still be trainable and maintain high representational capacity.\n",
    "\n",
    "There are three aggregate functions satisfying the above two basic requirements [50]:\n",
    "\n",
    "### 1. Mean Aggregate Function\n",
    "\n",
    "The basic operator simply takes the elementwise mean of the vectors in \\( h^{k-1}_v \\), \\( \\forall u \\in N(v) \\):\n",
    "\n",
    "$$\n",
    "\\text{AGG}_{\\text{mean}} = \\text{MEAN}(h^{k-1}_u, \\forall u \\in N(v)) = \\frac{1}{|N(v)|} \\sum_{u \\in N(v)} h^{k-1}_u \n",
    "\\quad \\text{(7.14.10)}\n",
    "$$\n",
    "\n",
    "The embedding in the \\( k \\)th layer of the node \\( v \\) is given by:\n",
    "\n",
    "$$\n",
    "h^k_v = \\sigma \\left( W_k \\cdot \\frac{1}{|N(v)|} \\sum_{u \\in N(v)} h^{k-1}_u + B_k h^{k-1}_v \\right), \\forall k > 0 \n",
    "\\quad \\text{(7.14.11)}\n",
    "$$\n",
    "\n",
    "A better choice is the Graph Convolution Network (GCN) neighborhood aggregation defined as:\n",
    "\n",
    "$$\n",
    "\\text{AGG}_{\\text{GCN}} = \\text{MEAN}\\left(h^{k-1}_v \\cup h^{k-1}_u, \\forall u \\in N(v)\\right) = \\frac{1}{\\sqrt{|N(v)| \\cdot |N(u)|}} \\sum_{u \\in N(v) \\cup v} h^{k-1}_u\n",
    "\\quad \\text{(7.14.12)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Rightarrow h^k_v = \\sigma \\left( W_k \\cdot \\sum_{u \\in N(v) \\cup v} \\frac{h^{k-1}_u}{\\sqrt{|N(v)| \\cdot |N(u)|}} \\right), \\forall k > 0 \n",
    "\\quad \\text{(7.14.13)}\n",
    "$$\n",
    "\n",
    "### 2. LSTM Aggregate Function\n",
    "\n",
    "This is a more complex aggregator based on an LSTM architecture [63]:\n",
    "\n",
    "$$\n",
    "\\text{AGG}_{\\text{LSTM}} = \\text{LSTM}(h^{k-1}_u, \\forall u \\in N(v)) \n",
    "\\quad \\text{(7.14.14)}\n",
    "$$\n",
    "\n",
    "Compared to the mean aggregate function, the advantage of LSTM aggregate functions is their larger expressive capability. However, LSTMs are not inherently symmetric, so it is necessary to adapt LSTMs for operating on an unordered set by simply applying the LSTMs to a random permutation of the node’s neighbors.\n",
    "\n",
    "### 3. Pooling Aggregate Function\n",
    "\n",
    "This aggregator is symmetric and trainable. In this pooling approach, each neighbor’s vector is independently fed through a fully connected neural network; following this transformation, an elementwise max-pooling operation is applied to aggregate information across the neighbor set:\n",
    "\n",
    "$$\n",
    "\\text{AGG}_{\\text{pool}} = \\gamma \\left( h^{k}_u + b \\right), \\forall u_i \\in N(v)\n",
    "\\quad \\text{(7.14.15)}\n",
    "$$\n",
    "\n",
    "where \\( \\gamma \\) usually takes elementwise mean/max function.\n",
    "\n",
    "### GraphSAGE Algorithm\n",
    "\n",
    "Algorithm 7.10 shows the GraphSAGE embedding generation algorithm [50]:\n",
    "\n",
    "```python\n",
    "Algorithm 7.10 GraphSAGE embedding generation algorithm [50]\n",
    "1. input: Graph G(V , E); input features {xv , ∀ v ∈ V }; depth K; weight matrices Wk^0, k = 1, . . . , K; nonlinearity σ ; neighborhood function N : v → 2V.\n",
    "2. h_v ← x_v , ∀v ∈ V ;\n",
    "3. for k = 1, . . . , K do\n",
    "4.     for v ∈ V do\n",
    "5.         h^k_v ← σ ( W_k · MEAN({h^{k-1}_u , ∀ u ∈ N(v)} ) )\n",
    "6.     end for\n",
    "7.     h^k_v ← h^k_v / ||h^k_v ||, ∀ v ∈ V .\n",
    "8. end for\n",
    "9. z_v ← h^K_v , ∀ v ∈ V .\n",
    "10. output: vector representations z_v for all v ∈ V .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abaa8823",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (3,) (5,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5881/2488201647.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;31m# Instantiate and train the GraphSAGE model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0msage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGraphSAGE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0msage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;31m# Get the node embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5881/2488201647.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mupdated_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 \u001b[0mupdated_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdated_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;31m# Normally, you'd have a loss function and backpropagation step here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5881/2488201647.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mneighbor_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mneighbor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mneighbor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0maggregated_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_aggregator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneighbor_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mcurrent_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_features\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0maggregated_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mcurrent_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_features\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# ReLU activation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcurrent_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (3,) (5,) "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# GraphSAGE Mean Aggregator Implementation\n",
    "\n",
    "class GraphSAGE:\n",
    "    def __init__(self, graph, features, output_dim, depth, learning_rate=0.01, epochs=100):\n",
    "        self.graph = graph  # Dictionary where keys are nodes and values are lists of neighbors\n",
    "        self.features = features  # Node features, a numpy array of shape (num_nodes, feature_dim)\n",
    "        self.output_dim = output_dim  # Dimension of the node embeddings\n",
    "        self.depth = depth  # Number of layers in the GraphSAGE model\n",
    "        self.learning_rate = learning_rate  # Learning rate for gradient descent\n",
    "        self.epochs = epochs  # Number of training epochs\n",
    "        self.weights = self.initialize_weights()  # Initialize weights\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        weights = []\n",
    "        input_dim = self.features.shape[1]\n",
    "        for _ in range(self.depth):\n",
    "            W = np.random.randn(input_dim, self.output_dim) * np.sqrt(2.0 / input_dim)\n",
    "            weights.append(W)\n",
    "            input_dim = self.output_dim\n",
    "        return weights\n",
    "\n",
    "    def mean_aggregator(self, node, neighbor_features):\n",
    "        if len(neighbor_features) == 0:\n",
    "            return np.zeros(self.output_dim)\n",
    "        mean_features = np.mean(neighbor_features, axis=0)\n",
    "        return mean_features\n",
    "\n",
    "    def forward(self, node):\n",
    "        current_features = self.features[node]\n",
    "        for i in range(self.depth):\n",
    "            neighbor_features = np.array([self.features[neighbor] for neighbor in self.graph[node]])\n",
    "            aggregated_features = self.mean_aggregator(node, neighbor_features)\n",
    "            current_features = np.dot(current_features + aggregated_features, self.weights[i])\n",
    "            current_features = np.maximum(0, current_features)  # ReLU activation\n",
    "        return current_features\n",
    "\n",
    "    def train(self):\n",
    "        for epoch in range(self.epochs):\n",
    "            updated_features = np.zeros_like(self.features)\n",
    "            for node in self.graph.keys():\n",
    "                updated_features[node] = self.forward(node)\n",
    "            self.features = updated_features\n",
    "            # Normally, you'd have a loss function and backpropagation step here.\n",
    "            print(f'Epoch {epoch+1}/{self.epochs} completed')\n",
    "\n",
    "    def get_embeddings(self):\n",
    "        embeddings = np.zeros((len(self.graph), self.output_dim))\n",
    "        for node in self.graph.keys():\n",
    "            embeddings[node] = self.forward(node)\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "# Example usage\n",
    "\n",
    "# Define a simple graph as a dictionary where each key is a node, and the value is a list of neighbors\n",
    "graph = {\n",
    "    0: [1, 2],\n",
    "    1: [0, 3],\n",
    "    2: [0, 3],\n",
    "    3: [1, 2]\n",
    "}\n",
    "\n",
    "# Create some random features for each node\n",
    "features = np.random.rand(4, 5)  # 4 nodes, 5-dimensional features\n",
    "\n",
    "# Instantiate and train the GraphSAGE model\n",
    "sage = GraphSAGE(graph, features, output_dim=3, depth=2, learning_rate=0.01, epochs=10)\n",
    "sage.train()\n",
    "\n",
    "# Get the node embeddings\n",
    "embeddings = sage.get_embeddings()\n",
    "print(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d423e8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 completed\n",
      "Epoch 2/10 completed\n",
      "Epoch 3/10 completed\n",
      "Epoch 4/10 completed\n",
      "Epoch 5/10 completed\n",
      "Epoch 6/10 completed\n",
      "Epoch 7/10 completed\n",
      "Epoch 8/10 completed\n",
      "Epoch 9/10 completed\n",
      "Epoch 10/10 completed\n",
      "[[0.         0.         0.         0.         0.00063144]\n",
      " [0.         0.         0.         0.         0.00286013]\n",
      " [0.         0.         0.         0.         0.00236066]\n",
      " [0.         0.         0.         0.         0.00063144]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# GraphSAGE Mean Aggregator Implementation\n",
    "\n",
    "class GraphSAGE:\n",
    "    def __init__(self, graph, features, output_dim, depth, learning_rate=0.01, epochs=100):\n",
    "        self.graph = graph  # Dictionary where keys are nodes and values are lists of neighbors\n",
    "        self.features = features  # Node features, a numpy array of shape (num_nodes, feature_dim)\n",
    "        self.output_dim = output_dim  # Dimension of the node embeddings\n",
    "        self.depth = depth  # Number of layers in the GraphSAGE model\n",
    "        self.learning_rate = learning_rate  # Learning rate for gradient descent\n",
    "        self.epochs = epochs  # Number of training epochs\n",
    "        self.weights = self.initialize_weights()  # Initialize weights\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        weights = []\n",
    "        input_dim = self.features.shape[1]\n",
    "        for _ in range(self.depth):\n",
    "            W = np.random.randn(input_dim, self.output_dim) * np.sqrt(2.0 / input_dim)\n",
    "            weights.append(W)\n",
    "            input_dim = self.output_dim  # Update input_dim to the output_dim for the next layer\n",
    "        return weights\n",
    "\n",
    "    def mean_aggregator(self, node, neighbor_features):\n",
    "        if len(neighbor_features) == 0:\n",
    "            return np.zeros(self.output_dim)\n",
    "        mean_features = np.mean(neighbor_features, axis=0)\n",
    "        return mean_features\n",
    "\n",
    "    def forward(self, node):\n",
    "        current_features = self.features[node]\n",
    "        for i in range(self.depth):\n",
    "            neighbor_features = np.array([self.features[neighbor] for neighbor in self.graph[node]])\n",
    "            aggregated_features = self.mean_aggregator(node, neighbor_features)\n",
    "            \n",
    "            # Update features with the same dimension\n",
    "            current_features = np.dot(current_features, self.weights[i]) + np.dot(aggregated_features, self.weights[i])\n",
    "            current_features = np.maximum(0, current_features)  # ReLU activation\n",
    "        return current_features\n",
    "\n",
    "    def train(self):\n",
    "        for epoch in range(self.epochs):\n",
    "            updated_features = np.zeros((len(self.graph), self.output_dim))\n",
    "            for node in self.graph.keys():\n",
    "                updated_features[node] = self.forward(node)\n",
    "            self.features = updated_features\n",
    "            print(f'Epoch {epoch+1}/{self.epochs} completed')\n",
    "\n",
    "    def get_embeddings(self):\n",
    "        embeddings = np.zeros((len(self.graph), self.output_dim))\n",
    "        for node in self.graph.keys():\n",
    "            embeddings[node] = self.forward(node)\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "# Example usage\n",
    "\n",
    "# Define a simple graph as a dictionary where each key is a node, and the value is a list of neighbors\n",
    "graph = {\n",
    "    0: [1, 2],\n",
    "    1: [0, 3],\n",
    "    2: [0, 3],\n",
    "    3: [1, 2]\n",
    "}\n",
    "\n",
    "# Create some random features for each node\n",
    "features = np.random.rand(4, 5)  # 4 nodes, 5-dimensional features\n",
    "\n",
    "# Instantiate and train the GraphSAGE model\n",
    "sage = GraphSAGE(graph, features, output_dim=5, depth=2, learning_rate=0.01, epochs=10)\n",
    "sage.train()\n",
    "\n",
    "# Get the node embeddings\n",
    "embeddings = sage.get_embeddings()\n",
    "print(embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bb0c7a",
   "metadata": {},
   "source": [
    "### 7.14.3 Graph Convolutional Networks (GCNs)\n",
    "\n",
    "There are two types of spatial information in graph data:\n",
    "\n",
    "- **Node information**: Each vertex or node has its own information or characteristics that are represented by the nodes themselves.\n",
    "- **Structural information**: Each node in the graph data has its own structural information, which is association information between nodes and is represented by edges connecting a node and other nodes.\n",
    "\n",
    "Generally speaking, graph data should consider not only node information but also structure information. A graph convolutional neural network (GCN) can automatically learn not only node information but also association information between nodes.\n",
    "\n",
    "Graph Convolutional Networks (GCNs), introduced by Kipf and Welling [82], are machine learning methods that \"learn\" graph-structured data by extracting spatial features. Because the standard convolution for image or text cannot be directly applied to graphs without a grid structure, a graph must necessarily be mapped onto another spectral domain that does have a grid structure.\n",
    "\n",
    "Unlike spatial convolution (such as GraphSAGE) which is a vertex domain (spatial domain) method based on convolutions in the vertex domain (spatial domain) defined directly by the connection relationships of each node, spectral convolution is a frequency domain method.\n",
    "\n",
    "Bruna et al. [13] first introduced a convolution for graph data from spectral domains using the graph Laplacian matrix \\( L \\). This convolution in the spectral domain of a graph is called the spectral convolution. The Laplacian matrix has many important properties. The following are the two points related to GCNs:\n",
    "\n",
    "- The Laplacian matrix is a symmetric matrix and can perform eigenvalue decomposition (spectral decomposition), which corresponds to the spectral domain of GCNs.\n",
    "- The Laplacian matrix has only nonzero elements at the center apex and the first-order connected vertices, and the rest are 0.\n",
    "\n",
    "In classical signal processing, we have the convolution theorem in the time domain:\n",
    "\n",
    "$$\n",
    "\\int_{-\\infty}^{\\infty} \\omega t f(t) \\ast h(t) = \\int_{-\\infty}^{\\infty} \\hat{f}(\\omega)\\hat{h}(\\omega)e^{-j \\omega t} \\, d\\omega,\n",
    "$$\n",
    "\n",
    "and the convolution theorem in the frequency domain:\n",
    "\n",
    "$$\n",
    "\\int_{-\\infty}^{\\infty} \\hat{f}(\\omega) \\ast \\hat{h}(\\omega) = \\int_{-\\infty}^{\\infty} f(t)h(t)e^{j \\omega t} \\, dt.\n",
    "$$\n",
    "\n",
    "Because a graph signal \\( f \\) has no grid structure, the standard convolution cannot be directly applied to \\( f \\). Compared with the graph signal \\( f \\) in the vertex domain, its spectral graph signal \\( \\hat{f} \\) in the graph spectral domain has a grid structure, and thus the convolution can be directly applied to \\( \\hat{f} \\). The spectral signals \\( \\hat{f}(\\lambda) \\) are referred to as kernels of the vertex signals \\( f(i) \\).\n",
    "\n",
    "To introduce the convolution on graph signals, we need to search for an orthonormal basis instead of the basis function \\( e^{\\pm j \\omega t} \\) in the standard convolution on Euclidean structures.\n",
    "\n",
    "Since both normalized and unnormalized Laplacians are symmetric and positive semi-definite matrices, they admit an eigenvalue decomposition \\( L = U \\Lambda U^T \\), where \\( U = [u_1, \\dots, u_n] \\) are the orthonormal eigenvectors and \\( \\Lambda = \\text{diag}(\\lambda_1, \\dots, \\lambda_n) \\) is the diagonal matrix of the corresponding nonnegative eigenvalues (spectrum) \\( \\lambda_1 \\geq \\lambda_2 \\geq \\dots \\geq \\lambda_n = 0 \\). The eigenvectors play the role of Fourier atoms in classical harmonic analysis, and the eigenvalues can be interpreted as (the square of) frequencies.\n",
    "\n",
    "Consider signals defined on an undirected, connected, weighted graph \\( G(V, E) \\), which consists of a finite set of vertices \\( V \\) with \\( |V| = N \\), a set of edges \\( E \\), and a weighted adjacency matrix \\( A \\). If there is an edge \\( e = (i, j) \\) connecting vertices \\( i \\) and \\( j \\), then the entry \\( w_{ij} \\) represents the weight of the edge; otherwise, \\( w_{ij} = 0 \\). If the graph \\( G(V, E) \\) is not connected and has \\( M \\) connected components (\\( M > 1 \\)), then \\( G(V, E) \\) is separated into \\( M \\) subgraphs \\( G_1, \\dots, G_M \\), and signals on \\( G(V, E) \\) are separated into \\( M \\) pieces corresponding to the \\( M \\) connected components, and independently process the separated signals on each of the subgraphs.\n",
    "\n",
    "A signal or function \\( f: V \\rightarrow \\mathbb{R} \\) defined on the vertices of the graph may be represented as a vector \\( f \\in \\mathbb{R}^N \\), where the \\( i \\)th component of the vector \\( f \\) represents the function value at the \\( i \\)th vertex in \\( V \\).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9358093",
   "metadata": {},
   "source": [
    "### Graph Fourier Transforms and Convolutions on Graphs\n",
    "\n",
    "Suppose we are given two signals \\( \\mathbf{f} = [f_1, \\dots, \\omega t f_N]^T \\) and \\( \\mathbf{h} = [h_1, \\dots, h_N]^T \\) on the vertices of graph \\( G(V, E) \\). By replacing \\( e^{\\pm j} \\) with eigenvectors \\( u_i \\) and \\( u_i^* \\), one can define the graph Fourier transforms and the graph convolution as follows [136]:\n",
    "\n",
    "1. **Graph Fourier Transform** \\( \\hat{\\mathbf{f}} \\) of any graph signal or function vector \\( \\mathbf{f} \\in \\mathbb{R}^N \\) on the vertices of \\( G(V, E) \\) is defined as the expansion of \\( \\mathbf{f} \\) in terms of the eigenvectors \\( u_1, \\dots, u_N \\) of the graph Laplacian \\( L \\):\n",
    "\n",
    "   $$\n",
    "   \\hat{f}(\\lambda) = \\sum_{i=1}^{N} f(i) u^*_i(i) \\quad \\text{or} \\quad \\hat{\\mathbf{f}} = U^H \\mathbf{f},\n",
    "   $$\n",
    "   $$\n",
    "   \\text{where } U = [u_1, \\dots, u_N]^T \\text{ is the eigenvector-matrix of the EVD } L = U \\Lambda U^H.\n",
    "   $$\n",
    "\n",
    "2. **Inverse Graph Fourier Transform** is given by:\n",
    "\n",
    "   $$\n",
    "   f(i) = \\sum_{k=0}^{N-1} \\hat{f}(\\lambda) u_k(i) \\quad \\text{or} \\quad \\mathbf{f} = U \\hat{\\mathbf{f}}.\n",
    "   $$\n",
    "\n",
    "3. **Convolution Theorem in the Time Domain** \\( f(t) \\ast h(t) = \\int_{-\\infty}^{\\infty} \\hat{f}(\\omega) \\hat{h}(\\omega) e^{-j \\omega t} \\, d\\omega \\) becomes the **Graph Convolution Theorem**:\n",
    "\n",
    "   $$\n",
    "   f(i) \\ast_G h(i) = \\sum_{k=0}^{N-1} \\hat{f}(\\lambda) \\hat{h}(\\lambda) u_k(i),\n",
    "   $$\n",
    "   and can be written in the **Spectral Convolution Form**:\n",
    "\n",
    "   $$\n",
    "   \\mathbf{f} \\ast_G \\mathbf{h} = U \\text{Diag}(\\hat{h}_1, \\dots, \\hat{h}_N) \\hat{\\mathbf{f}} = U \\text{Diag}(\\hat{h}_1, \\dots, \\hat{h}_N) U^T \\mathbf{f},\n",
    "   $$\n",
    "   which enforces the property that convolution in the vertex domain is equivalent to multiplication in the graph spectral domain.\n",
    "\n",
    "4. Given a signal \\( \\mathbf{x} \\in \\mathbb{R}^N \\) and a filter \\( g_\\theta = \\text{Diag}(\\theta_1, \\dots, \\theta_N) \\) parameterized by \\( \\theta = [\\theta_1, \\dots, \\theta_N]^T \\in \\mathbb{R}^N \\), the spectral convolutions on graphs in Eq. (7.14.21) become:\n",
    "\n",
    "   $$\n",
    "   \\mathbf{x} \\ast g_\\theta = U g_\\theta U^T \\mathbf{x},\n",
    "   $$\n",
    "   where \\( U \\) is the matrix of eigenvectors of the normalized graph Laplacian \\( L = I_N - D^{-1/2} A D^{-1/2} = U \\Lambda U^T \\), with a diagonal matrix of its eigenvalues \\( \\Lambda \\) and \\( U^T \\mathbf{x} \\) being the graph Fourier transform of \\( \\mathbf{x} \\). \\( g_\\theta \\) can be understood as a function of the eigenvalues of \\( L \\), i.e., \\( g_\\theta(\\Lambda) \\). This eigenvalue function can be well-approximated by a truncated expansion in terms of Chebyshev polynomials \\( T_k(x) \\) up to the \\( K \\)th order [51, 82]:\n",
    "\n",
    "   $$\n",
    "   g_\\theta(\\Lambda) \\approx \\sum_{k=0}^{K} \\theta_k T_k(\\tilde{\\Lambda}),\n",
    "   $$\n",
    "   $$\n",
    "   \\text{where } \\tilde{\\Lambda} = \\frac{2 \\Lambda}{\\lambda_{\\text{max}}} - I_N \\text{ with } \\lambda_{\\text{max}} \\text{ denoting the largest eigenvalue of } L, \\theta \\in \\mathbb{R}^K \\text{ is a vector of Chebyshev coefficients}.\n",
    "   $$\n",
    "\n",
    "   From Eqs. (7.14.22) and (7.14.23) it follows that the spectral convolution of a graph signal \\( \\mathbf{x} \\) with a filter \\( g_\\theta \\) is given by [82]:\n",
    "\n",
    "   $$\n",
    "   \\mathbf{x} \\ast g_\\theta \\approx \\sum_{k=0}^{K} \\theta_k T_k(\\tilde{L}) \\mathbf{x},\n",
    "   $$\n",
    "   $$\n",
    "   \\text{where } \\tilde{L} = \\frac{2 L}{\\lambda_{\\text{max}}} - I_N \\text{ and } T_k(\\tilde{L}) = 2 \\tilde{L} T_{k-1}(\\tilde{L}) - T_{k-2}(\\tilde{L}) \\text{ with } T_0(\\tilde{L}) = 1 \\text{ and } T_1(\\tilde{L}) = \\tilde{L}.\n",
    "   $$\n",
    "\n",
    "   Under the approximation \\( \\lambda \\approx 2 \\), Eq. (7.14.24) simplifies to:\n",
    "\n",
    "   $$\n",
    "   \\mathbf{x} \\ast g_\\theta \\approx \\theta_0 \\mathbf{x} + \\theta_1 (L - I_N) \\mathbf{x} = \\theta_0 \\mathbf{x} - D^{-1/2} A D^{-1/2} \\mathbf{x}.\n",
    "   $$\n",
    "\n",
    "   If taking a single parameter \\( \\theta = \\theta_0 = -\\theta_1 \\), then (7.14.25) gives the following expression [82]:\n",
    "\n",
    "   $$\n",
    "   \\mathbf{x} \\ast g_\\theta \\approx \\theta(I_N + D^{-1/2} A D^{-1/2}) \\mathbf{x},\n",
    "   $$\n",
    "   $$\n",
    "   \\text{where } I_N + D^{-1/2} W D^{-1/2} \\text{ has eigenvalues in the range } [0, 2].\n",
    "   $$\n",
    "\n",
    "   Direct application of the iteration in Eq. (7.14.26) will lead to numerical instability and may lead to exploding or vanishing gradients in deep neural network models. In order to alleviate this problem, the renormalization technique is necessary:\n",
    "\n",
    "   $$\n",
    "   I_N + D^{-1/2} A D^{-1/2} \\rightarrow \\tilde{D}^{-1/2} \\tilde{A} \\tilde{D}^{-1/2},\n",
    "   $$\n",
    "   $$\n",
    "   \\text{where } \\tilde{A} = A + I_N \\text{ and } \\tilde{D}_{ii} = \\sum_{j=1}^{N} \\tilde{A}_{ij}.\n",
    "   $$\n",
    "\n",
    "   The above definition can be generalized to a signal \\( X \\in \\mathbb{R}^{N \\times C} \\) with \\( C \\) input channels (i.e., a \\( C \\)-dimensional feature vector for every node) and \\( F \\) filters or feature maps, giving:\n",
    "\n",
    "   $$\n",
    "   Z = \\tilde{D}^{-1/2} \\tilde{A} \\tilde{D}^{-1/2} X \\Theta,\n",
    "   $$\n",
    "   $$\n",
    "   \\text{where } Z \\in \\mathbb{R}^{N \\times F} \\text{ is the convolved signal matrix and } \\Theta \\in \\mathbb{R}^{C \\times F} \\text{ is a matrix of filter parameters}.\n",
    "   $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39706b6",
   "metadata": {},
   "source": [
    "### Semi-Supervised Multiclass Classification and Graph Convolutional Networks (GCNs)\n",
    "\n",
    "For semi-supervised multiclass classification, the loss is defined by the cross-entropy error over all labeled examples as follows:\n",
    "\n",
    "$$\n",
    "L = -\\sum_{l \\in Y_L} \\sum_{f=1}^{F} Y_{lf} \\ln Z_{lf},\n",
    "$$\n",
    "where \\( Y_L \\) is the set of node indices that have labels.\n",
    "\n",
    "#### Two-Layer GCN for Semi-Supervised Node Classification\n",
    "\n",
    "For a two-layer Graph Convolutional Network (GCN) used for semi-supervised node classification on a graph with a symmetric adjacency matrix \\( A \\) (binary or weighted), the forward model takes the simple form:\n",
    "\n",
    "$$\n",
    "Z = f(X, A) = \\text{softmax} \\left( \\hat{A} \\, \\text{ReLU} \\left( \\hat{A} X W^{(0)} \\right) W^{(1)} \\right),\n",
    "$$\n",
    "where:\n",
    "- \\( \\hat{A} = \\tilde{D}^{-1/2} \\tilde{A} \\tilde{D}^{-1/2} \\) is calculated in the pre-processing step.\n",
    "- \\( W^{(0)} \\in \\mathbb{R}^{C \\times H} \\) is an input-to-hidden weight matrix for a hidden layer with \\( H \\) feature maps.\n",
    "- \\( W^{(1)} \\in \\mathbb{R}^{H \\times F} \\) is a hidden-to-output weight matrix.\n",
    "- The softmax activation function is defined as:\n",
    "\n",
    "$$\n",
    "\\text{softmax}(x_i) = \\frac{\\exp(x_i)}{\\sum_{i} \\exp(x_i)},\n",
    "$$\n",
    "and is applied row-wise.\n",
    "\n",
    "#### Characteristics of GCNs\n",
    "\n",
    "GCNs possess the following four characteristics:\n",
    "\n",
    "1. **Natural Extension**: GCNs are a natural extension of convolutional neural networks (CNNs) to the graph domain. Graph convolution is widely applicable to nodes and graphs of any topological structure.\n",
    "2. **Local Characteristics**: GCNs focus on information within the K-order neighborhood centered on a node, which is fundamentally different from Graph Neural Networks (GNNs).\n",
    "3. **First-Order Characteristics**: After several approximations, a GCN becomes a first-order model. A single-layer GCN processes information from first-order neighbors in graphs, while a multi-layer GCN can handle K-order neighbors.\n",
    "4. **Parameter Sharing**: The filter parameter \\( W \\) is shared across all nodes, which is one reason the graph convolution network is named as such.\n",
    "\n",
    "#### Comparison of GCN Neighborhood Aggregation with Basic Neighborhood Aggregation in GraphSAGE\n",
    "\n",
    "- **Basic Neighborhood Aggregation**:\n",
    "\n",
    "$$\n",
    "h_v^{(k)} = \\sigma \\left( W^{(k)} \\left( \\frac{1}{|\\mathcal{N}(v)|} \\sum_{u \\in \\mathcal{N}(v)} h_u^{(k-1)} \\right) + B^{(k)} h_v^{(k-1)} \\right),\n",
    "$$\n",
    "\n",
    "where:\n",
    "  - \\( h_v^{(k)} \\) is the embedding of node \\( v \\) in the \\( k \\)-th layer,\n",
    "  - \\( \\sigma(\\cdot) \\) is a nonlinear activation function,\n",
    "  - \\( \\mathcal{N}(v) \\) denotes the neighborhood of node \\( v \\),\n",
    "  - The summing term denotes the average embedding of the neighboring nodes \\( u \\in \\mathcal{N}(v) \\) in the \\( (k-1) \\)-th layer,\n",
    "  - The second term denotes the embedding of node \\( v \\) in the \\( (k-1) \\)-th layer.\n",
    "\n",
    "- **GCN Neighborhood Aggregation**:\n",
    "\n",
    "$$\n",
    "h_v^{(k)} = \\sigma \\left( W^{(k)} \\sum_{u \\in \\mathcal{N}(v) \\cup \\{v\\}} \\frac{h_u^{(k-1)}}{\\sqrt{|\\mathcal{N}(u)|} \\cdot \\sqrt{|\\mathcal{N}(v)|}} \\right),\n",
    "$$\n",
    "\n",
    "where:\n",
    "  - \\( W^{(k)} \\) denotes the same weight matrix for both node \\( v \\) and its neighboring nodes' embeddings,\n",
    "  - \\( \\sqrt{|\\mathcal{N}(u)|} \\cdot \\sqrt{|\\mathcal{N}(v)|} \\) represents the normalization per neighbor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22003544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6150, -0.7779],\n",
      "        [-0.6150, -0.7779],\n",
      "        [-0.6150, -0.7779]], grad_fn=<LogSoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GCNLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features, dropout=0.5):\n",
    "        super(GCNLayer, self).__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, A_hat, X):\n",
    "        # A_hat is the preprocessed adjacency matrix\n",
    "        # X is the input feature matrix\n",
    "        X = self.dropout(X)\n",
    "        X = torch.spmm(A_hat, X)  # Multiply with adjacency matrix\n",
    "        X = self.linear(X)\n",
    "        X = F.relu(X)\n",
    "        return X\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, n_features, n_hidden, n_classes, dropout=0.5):\n",
    "        super(GCN, self).__init__()\n",
    "        self.gcn1 = GCNLayer(n_features, n_hidden, dropout)\n",
    "        self.gcn2 = GCNLayer(n_hidden, n_classes, dropout)\n",
    "\n",
    "    def forward(self, A_hat, X):\n",
    "        X = self.gcn1(A_hat, X)\n",
    "        X = self.gcn2(A_hat, X)\n",
    "        return F.log_softmax(X, dim=1)\n",
    "\n",
    "def preprocess_adjacency_matrix(A):\n",
    "    # Add self-loops to the adjacency matrix\n",
    "    A = A + torch.eye(A.size(0))\n",
    "    \n",
    "    # Degree matrix\n",
    "    D = torch.diag(torch.pow(A.sum(1), -0.5))\n",
    "    \n",
    "    # Normalized adjacency matrix\n",
    "    A_hat = torch.mm(torch.mm(D, A), D)\n",
    "    \n",
    "    return A_hat\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "# Assume A is your adjacency matrix and X is your feature matrix\n",
    "A = torch.tensor([[0, 1, 1], [1, 0, 1], [1, 1, 0]], dtype=torch.float32)  # Example adjacency matrix\n",
    "X = torch.tensor([[1, 0], [0, 1], [1, 1]], dtype=torch.float32)  # Example feature matrix\n",
    "\n",
    "# Number of features, hidden units, and output classes\n",
    "n_features = X.size(1)\n",
    "n_hidden = 4\n",
    "n_classes = 2  # Example with binary classification\n",
    "\n",
    "# Preprocess the adjacency matrix\n",
    "A_hat = preprocess_adjacency_matrix(A)\n",
    "\n",
    "# Define the model\n",
    "model = GCN(n_features, n_hidden, n_classes)\n",
    "\n",
    "# Forward pass\n",
    "output = model(A_hat, X)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3aa9106d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:\n",
      " [[0.6858288 0.3141712]\n",
      " [0.6858288 0.3141712]\n",
      " [0.6858288 0.3141712]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))  # for numerical stability\n",
    "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "\n",
    "def normalize_adjacency_matrix(A):\n",
    "    I = np.eye(A.shape[0])  # Identity matrix\n",
    "    A_hat = A + I  # Add self-loops\n",
    "    D = np.diag(np.sum(A_hat, axis=1))  # Degree matrix\n",
    "    D_inv_sqrt = np.linalg.inv(np.sqrt(D))  # D^(-1/2)\n",
    "    return D_inv_sqrt @ A_hat @ D_inv_sqrt  # A_hat = D^(-1/2) * (A + I) * D^(-1/2)\n",
    "\n",
    "class GCNLayer:\n",
    "    def __init__(self, in_features, out_features):\n",
    "        # Initialize weights randomly\n",
    "        self.weights = np.random.randn(in_features, out_features) * np.sqrt(2.0 / in_features)\n",
    "\n",
    "    def forward(self, A_hat, X):\n",
    "        Z = A_hat @ X @ self.weights  # Graph Convolution operation\n",
    "        return relu(Z)  # Apply ReLU activation\n",
    "\n",
    "class GCN:\n",
    "    def __init__(self, n_features, n_hidden, n_classes):\n",
    "        self.layer1 = GCNLayer(n_features, n_hidden)\n",
    "        self.layer2 = GCNLayer(n_hidden, n_classes)\n",
    "\n",
    "    def forward(self, A_hat, X):\n",
    "        H = self.layer1.forward(A_hat, X)  # First GCN layer\n",
    "        Z = self.layer2.forward(A_hat, H)  # Second GCN layer\n",
    "        return softmax(Z)  # Apply softmax activation for output\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "# Example adjacency matrix (A)\n",
    "A = np.array([\n",
    "    [0, 1, 1],\n",
    "    [1, 0, 1],\n",
    "    [1, 1, 0]\n",
    "], dtype=np.float32)\n",
    "\n",
    "# Example feature matrix (X)\n",
    "X = np.array([\n",
    "    [1, 0],\n",
    "    [0, 1],\n",
    "    [1, 1]\n",
    "], dtype=np.float32)\n",
    "\n",
    "# Number of features, hidden units, and output classes\n",
    "n_features = X.shape[1]\n",
    "n_hidden = 4\n",
    "n_classes = 2  # Example with binary classification\n",
    "\n",
    "# Preprocess the adjacency matrix\n",
    "A_hat = normalize_adjacency_matrix(A)\n",
    "\n",
    "# Define the model\n",
    "gcn = GCN(n_features, n_hidden, n_classes)\n",
    "\n",
    "# Forward pass\n",
    "output = gcn.forward(A_hat, X)\n",
    "print(\"Output:\\n\", output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ccfb59",
   "metadata": {},
   "source": [
    "## Batch Normalization\n",
    "\n",
    "Batch normalization (BatchNorm) is a technique used to stabilize and accelerate the training of deep neural networks. It normalizes the output of each layer by adjusting and scaling the activations.\n",
    "\n",
    "Consider a layer with  D-dimensional input $ \\mathbf{x} = [x_1, \\dots, x_D]^T $ and a fully connected matrix $ \\mathbf{W} $ for extracting $d$-dimensional feature vectors $ \\mathbf{y} = \\mathbf{W}\\mathbf{x} = [y_1, \\dots, y_d]^T $, where $ d \\leq D $.\n",
    "\n",
    "Given a mini-batch of feature vectors $$ \\mathbf{Y} = \\{\\mathbf{y}_1, \\dots, \\mathbf{y}_N\\} $$, batch normalization is applied as follows:\n",
    "\n",
    "### Steps:\n",
    "\n",
    "1. **Compute the mean** of the mini-batch:\n",
    "   $$\n",
    "   \\mu_B = \\frac{1}{N} \\sum_{n=1}^{N} y_n\n",
    "   $$\n",
    "\n",
    "2. **Compute the variance** of the mini-batch:\n",
    "   $$\n",
    "   \\sigma_B^2 = \\frac{1}{N} \\sum_{n=1}^{N} (y_n - \\mu_B)^2\n",
    "   $$\n",
    "\n",
    "3. **Normalize the batch**:\n",
    "   $$\n",
    "   \\hat{y}_n = \\frac{y_n - \\mu_B}{\\sqrt{\\sigma_B^2 + \\epsilon}}\n",
    "   $$\n",
    "\n",
    "4. **Scale and shift** the normalized values using learnable parameters \\( \\gamma \\) (scale) and \\( \\beta \\) (shift):\n",
    "   $$\n",
    "   z_n = \\gamma \\hat{y}_n + \\beta\n",
    "   $$\n",
    "\n",
    "   where \\( \\epsilon \\) is a small constant added to the variance to prevent division by zero.\n",
    "\n",
    "### Summary:\n",
    "\n",
    "The transformation can be summarized as:\n",
    "$$\n",
    "\\text{BN}_{\\gamma, \\beta}(\\mathbf{Y}) = \\gamma \\hat{\\mathbf{Y}} + \\beta\n",
    "$$\n",
    "\n",
    "where:\n",
    "$$\n",
    "\\hat{\\mathbf{Y}} = \\frac{\\mathbf{Y} - \\mu_B}{\\sqrt{\\sigma_B^2 + \\epsilon}}\n",
    "$$\n",
    "\n",
    "Here, $ \\gamma $ and $ \\beta $ are parameters that are learned during training, allowing the network to adjust the normalized output.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9b9183",
   "metadata": {},
   "source": [
    "## Figure 7.16: Comparison of Network Architectures\n",
    "\n",
    "**(a)** Network without BatchNorm layer.\n",
    "\n",
    "**(b)** The same network with a BatchNorm layer inserted after the fully connected layer $ \\mathbf{W} $. Both networks have the same loss function $ \\hat{L} = L $.\n",
    "\n",
    "### Batch Normalization Formulas\n",
    "\n",
    "1. **Mean Calculation**:\n",
    "   $$\n",
    "   \\mu_B = \\frac{1}{N} \\sum_{n=1}^{N} y_n\n",
    "   $$\n",
    "   (Equation 7.15.7)\n",
    "\n",
    "2. **Variance Calculation**:\n",
    "   $$\n",
    "   \\sigma_B^2 = \\frac{1}{N} \\sum_{n=1}^{N} (y_n - \\mu_B)^2\n",
    "   $$\n",
    "   (Equation 7.15.8)\n",
    "\n",
    "3. **Normalized Value**:\n",
    "   $$\n",
    "   \\hat{y}_n = \\frac{y_n - \\mu_B}{\\sqrt{\\sigma_B^2 + \\epsilon}}\n",
    "   $$\n",
    "   (Equation 7.15.9)\n",
    "\n",
    "4. **BatchNorm Transformation**:\n",
    "   $$\n",
    "   z_n = \\gamma \\hat{y}_n + \\beta\n",
    "   $$\n",
    "   (Equation 7.15.10)\n",
    "\n",
    "### Loss Function and Gradients\n",
    "\n",
    "To design the loss \\( L(y, \\hat{y}, z, \\gamma, \\beta) \\) for a specific application:\n",
    "\n",
    "- **Gradient with respect to \\( \\gamma \\)**:\n",
    "  $$\n",
    "  \\frac{\\partial L}{\\partial \\gamma} = \\sum_{i=1}^{N} \\frac{\\partial L}{\\partial z_i} \\cdot \\hat{y}_i\n",
    "  $$\n",
    "  (Equation 7.15.15)\n",
    "\n",
    "- **Gradient with respect to \\( \\beta \\)**:\n",
    "  $$\n",
    "  \\frac{\\partial L}{\\partial \\beta} = \\sum_{i=1}^{N} \\frac{\\partial L}{\\partial z_i}\n",
    "  $$\n",
    "\n",
    "- **Gradient with respect to the normalized output \\( \\hat{y}_i \\)**:\n",
    "  $$\n",
    "  \\frac{\\partial L}{\\partial \\hat{y}_i} = \\frac{\\partial L}{\\partial z_i} \\cdot \\gamma\n",
    "  $$\n",
    "\n",
    "- **Gradient with respect to the variance \\( \\sigma_B^2 \\)**:\n",
    "  $$\n",
    "  \\frac{\\partial L}{\\partial \\sigma_B^2} = \\frac{1}{2} \\sum_{i=1}^{N} \\frac{\\partial L}{\\partial \\hat{y}_i} \\cdot (y_i - \\mu_B) \\cdot \\left( \\sigma_B^2 + \\epsilon \\right)^{-\\frac{3}{2}}\n",
    "  $$\n",
    "\n",
    "- **Gradient with respect to the mean \\( \\mu_B \\)**:\n",
    "  $$\n",
    "  \\frac{\\partial L}{\\partial \\mu_B} = \\frac{1}{N} \\sum_{i=1}^{N} \\frac{\\partial L}{\\partial \\hat{y}_i} \\cdot \\left( - \\frac{1}{\\sqrt{\\sigma_B^2 + \\epsilon}} \\right)\n",
    "  $$\n",
    "\n",
    "- **Gradient with respect to the input \\( y_i \\)**:\n",
    "  $$\n",
    "  \\frac{\\partial L}{\\partial y_i} = \\frac{\\partial L}{\\partial \\hat{y}_i} \\cdot \\frac{1}{\\sqrt{\\sigma_B^2 + \\epsilon}}\n",
    "  $$\n",
    "\n",
    "\n",
    "\n",
    "![Comparison of Network Architectures](en4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832a832b",
   "metadata": {},
   "source": [
    "## Comparison of Network Architectures and Batch Normalization\n",
    "\n",
    "### (a) Network Without BatchNor \n",
    "$$ x → y → \\text{Activation Function} → \\text{Output} $$\n",
    "### (b) Network With BatchNorm\n",
    "$$ x → \\text{Fully Connected Layer} \\mathbf{W} → \\text{BatchNorm} → \\text{Activation Function} → \\text{Output} $$\n",
    "### Comparison\n",
    "\n",
    "In figure 7.16, we compare two network architectures:\n",
    "\n",
    "- **(a)** The network without a BatchNorm layer.\n",
    "- **(b)** The same network as in (a) with a BatchNorm layer inserted after the fully connected layer $\\mathbf{W}$. All layer parameters are the same, and the loss function $ \\hat{L} = L $ remains unchanged.\n",
    "\n",
    "### Batch Normalization Formulas\n",
    "\n",
    "Given a mini-batch $$ \\mathbf{Y} = \\{ \\mathbf{y}_1, \\dots, \\mathbf{y}_N \\} $$, BatchNorm performs the following operations:\n",
    "\n",
    "1. **Compute the mean**:\n",
    "   $$\n",
    "   \\mu_B = \\frac{1}{N} \\sum_{n=1}^{N} y_n\n",
    "   $$\n",
    "\n",
    "2. **Compute the variance**:\n",
    "   $$\n",
    "   \\sigma_B^2 = \\frac{1}{N} \\sum_{n=1}^{N} (y_n - \\mu_B)^2\n",
    "   $$\n",
    "\n",
    "3. **Normalize the batch**:\n",
    "   $$\n",
    "   \\hat{y}_n = \\frac{y_n - \\mu_B}{\\sqrt{\\sigma_B^2 + \\epsilon}}\n",
    "   $$\n",
    "\n",
    "4. **Scale and shift**:\n",
    "   $$\n",
    "   z_n = \\gamma \\hat{y}_n + \\beta\n",
    "   $$\n",
    "\n",
    "### Gradient Computation for Learning Parameters $\\gamma$ and $\\beta$\n",
    "\n",
    "To learn the parameters $\\gamma$ and $\\beta$, we need to compute the gradients of the loss \\( L \\) with respect to these parameters. The gradients are computed as follows:\n",
    "\n",
    "1. **Gradient with respect to \\(\\gamma\\)**:\n",
    "   $$\n",
    "   \\frac{\\partial L}{\\partial \\gamma} = \\sum_{i=1}^N \\frac{\\partial L}{\\partial z_i} \\cdot \\hat{y}_i\n",
    "   $$\n",
    "\n",
    "2. **Gradient with respect to \\(\\beta\\)**:\n",
    "   $$\n",
    "   \\frac{\\partial L}{\\partial \\beta} = \\sum_{i=1}^N \\frac{\\partial L}{\\partial z_i}\n",
    "   $$\n",
    "\n",
    "3. **Gradient with respect to the normalized output \\(\\hat{y}_i\\)**:\n",
    "   $$\n",
    "   \\frac{\\partial L}{\\partial \\hat{y}_i} = \\frac{\\partial L}{\\partial z_i} \\cdot \\gamma\n",
    "   $$\n",
    "\n",
    "4. **Gradient with respect to the variance \\(\\sigma_B^2\\)**:\n",
    "   $$\n",
    "   \\frac{\\partial L}{\\partial \\sigma_B^2} = \\frac{1}{2} \\sum_{i=1}^N \\frac{\\partial L}{\\partial \\hat{y}_i} \\cdot (y_i - \\mu_B) \\cdot \\left( \\sigma_B^2 + \\epsilon \\right)^{-\\frac{3}{2}}\n",
    "   $$\n",
    "\n",
    "5. **Gradient with respect to the mean \\(\\mu_B\\)**:\n",
    "   $$\n",
    "   \\frac{\\partial L}{\\partial \\mu_B} = \\frac{1}{N} \\sum_{i=1}^N \\frac{\\partial L}{\\partial \\hat{y}_i} \\cdot \\left( - \\frac{1}{\\sqrt{\\sigma_B^2 + \\epsilon}} \\right)\n",
    "   $$\n",
    "\n",
    "6. **Gradient with respect to the input \\( y_i \\)**:\n",
    "   $$\n",
    "   \\frac{\\partial L}{\\partial y_i} = \\frac{\\partial L}{\\partial \\hat{y}_i} \\cdot \\frac{1}{\\sqrt{\\sigma_B^2 + \\epsilon}}\n",
    "   $$\n",
    "\n",
    "These gradients are used to update the parameters $\\gamma$ and $\\beta$ during the training process to minimize the loss function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06564e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward pass output:\n",
      "[[ 1.91782147  0.00695959  0.93696414  1.55587144  1.40145554]\n",
      " [-0.52081245  0.57015465 -0.33249029 -0.17450368 -0.01246507]\n",
      " [ 0.47669325  1.08650023  0.69241787 -0.00849167  0.01981701]\n",
      " [ 0.64538508  1.12726587 -0.3929259   0.13279046 -1.23979999]\n",
      " [-1.92253507  0.26653424  0.80856707 -0.64616055  1.79177121]\n",
      " [-0.94522045 -0.35598688 -0.37273495  1.03315631  1.01501921]\n",
      " [ 0.48639311 -0.01556559 -1.15973252 -1.56049272 -0.74856917]\n",
      " [ 0.48763989  0.85711514  1.1881847  -0.38422632 -0.70430708]\n",
      " [-0.58421738 -1.85711655 -2.0791495   1.34171247 -0.90553137]\n",
      " [-0.04114746 -1.68586071  0.71089938 -1.28965573 -0.6173903 ]]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'BatchNormalization' object has no attribute 'X'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5881/542677849.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;31m# Backward pass (using dummy gradient)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0md_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0md_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_beta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nBackward pass gradients:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5881/542677849.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, d_out, X)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# Gradient of variance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0md_sigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_X_hat\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigma\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;31m# Gradient of mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BatchNormalization' object has no attribute 'X'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class BatchNormalization:\n",
    "    def __init__(self, epsilon=1e-8):\n",
    "        # Initialize Batch Normalization parameters\n",
    "        self.epsilon = epsilon\n",
    "        self.gamma = None  # Scale parameter\n",
    "        self.beta = None   # Shift parameter\n",
    "        self.mu = None     # Mean\n",
    "        self.sigma = None  # Variance\n",
    "        self.mean_running = None\n",
    "        self.var_running = None\n",
    "        self.training = True  # Training mode or inference mode\n",
    "\n",
    "    def initialize_params(self, D):\n",
    "        # Initialize gamma and beta\n",
    "        self.gamma = np.ones(D)\n",
    "        self.beta = np.zeros(D)\n",
    "        self.mean_running = np.zeros(D)\n",
    "        self.var_running = np.ones(D)\n",
    "\n",
    "    def forward(self, X):\n",
    "        if self.training:\n",
    "            # Calculate mean and variance for the mini-batch\n",
    "            self.mu = np.mean(X, axis=0)\n",
    "            self.sigma = np.var(X, axis=0)\n",
    "            \n",
    "            # Normalize\n",
    "            self.X_hat = (X - self.mu) / np.sqrt(self.sigma + self.epsilon)\n",
    "            \n",
    "            # Scale and shift\n",
    "            self.out = self.gamma * self.X_hat + self.beta\n",
    "            \n",
    "            # Update running mean and variance\n",
    "            self.mean_running = 0.9 * self.mean_running + 0.1 * self.mu\n",
    "            self.var_running = 0.9 * self.var_running + 0.1 * self.sigma\n",
    "\n",
    "            return self.out\n",
    "        else:\n",
    "            # Use running mean and variance for inference\n",
    "            X_hat = (X - self.mean_running) / np.sqrt(self.var_running + self.epsilon)\n",
    "            return self.gamma * X_hat + self.beta\n",
    "\n",
    "    def backward(self, d_out, X):\n",
    "        # Gradients for gamma and beta\n",
    "        d_gamma = np.sum(d_out * self.X_hat, axis=0)\n",
    "        d_beta = np.sum(d_out, axis=0)\n",
    "        \n",
    "        # Gradient of the normalized output\n",
    "        d_X_hat = d_out * self.gamma\n",
    "        \n",
    "        # Gradient of variance\n",
    "        d_sigma = -0.5 * np.sum(d_X_hat * (self.X - self.mu) * np.power(self.sigma + self.epsilon, -1.5), axis=0)\n",
    "        \n",
    "        # Gradient of mean\n",
    "        d_mu = -np.sum(d_X_hat / np.sqrt(self.sigma + self.epsilon), axis=0) - 2 * d_sigma * np.mean(self.X - self.mu, axis=0)\n",
    "        \n",
    "        # Gradient of input\n",
    "        d_X = d_X_hat / np.sqrt(self.sigma + self.epsilon) + d_sigma * 2 * (self.X - self.mu) / X.shape[0] + d_mu / X.shape[0]\n",
    "        \n",
    "        return d_X, d_gamma, d_beta\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Define a simple network layer with BatchNorm\n",
    "    np.random.seed(0)\n",
    "    X = np.random.randn(10, 5)  # Example data: 10 samples, 5 features\n",
    "\n",
    "    bn = BatchNormalization()\n",
    "    bn.initialize_params(X.shape[1])\n",
    "    \n",
    "    # Forward pass\n",
    "    out = bn.forward(X)\n",
    "    print(\"Forward pass output:\")\n",
    "    print(out)\n",
    "    \n",
    "    # Backward pass (using dummy gradient)\n",
    "    d_out = np.random.randn(*out.shape)\n",
    "    d_X, d_gamma, d_beta = bn.backward(d_out,X)\n",
    "    \n",
    "    print(\"\\nBackward pass gradients:\")\n",
    "    print(\"d_X:\", d_X)\n",
    "    print(\"d_gamma:\", d_gamma)\n",
    "    print(\"d_beta:\", d_beta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cfafc0",
   "metadata": {},
   "source": [
    "### Theorem 7.4\n",
    "\n",
    "For a BatchNorm network with loss \\(\\hat{L}\\) and an identical non-BatchNorm network with (identical) loss \\(L\\), the following inequality is true:\n",
    "\n",
    "$$\n",
    "\\|\\nabla_{z_j} \\hat{L}\\|^2 \\leq \\frac{\\sigma^2}{\\gamma_j^2} \\left(\\|\\nabla_{z_j} L\\|^2 - \\frac{1}{N} \\left\\langle \\nabla_{z_j} L, \\hat{z}_j \\right\\rangle^2 \\right)\n",
    "$$\n",
    "\n",
    "The reduction of the gradient magnitude \\(\\|\\nabla_{z_j} \\hat{L}\\| \\leq \\frac{\\sigma}{\\gamma_j} \\|\\nabla_{z_j} L\\|\\) has an effect even when the scaling of BatchNorm is identical to the original layer scaling (i.e., even when \\(\\gamma = \\sigma_j\\)). Because the gradient magnitude \\(\\|\\nabla_{z_j} \\hat{L}\\|\\) captures the Lipschitzness of the loss \\(\\hat{L}\\), BatchNorm exhibits a better Lipschitz constant of the loss \\(L\\).\n",
    "\n",
    "### Theorem 7.5\n",
    "\n",
    "Let \\(\\hat{g}_j = \\nabla_{z_j} L\\) and \\(H_{jj} = \\frac{\\partial^2 L}{\\partial z_j^2}\\) be the gradient vector and Hessian matrix of the loss with respect to the layer outputs, respectively. Then:\n",
    "\n",
    "$$\n",
    "\\left( \\nabla_{z_j} \\hat{L} \\cdot \\frac{\\partial \\hat{L}}{\\partial z_j} \\cdot \\frac{\\partial \\gamma}{\\partial z_j} \\right)^2 \\leq \\frac{\\sigma^2}{N} \\left( \\hat{g}_j^T H_{jj} \\hat{g}_j - \\left( \\frac{\\partial \\hat{L}}{\\partial z_j} \\right)^T \\frac{\\partial L}{\\partial z_j} \\right)\n",
    "$$\n",
    "\n",
    "If the Hessian matrix \\(H_{jj}\\) preserves the relative norms of \\(\\hat{g}_j\\) and \\(\\nabla_{z_j} \\hat{L}\\), then:\n",
    "\n",
    "$$\n",
    "\\left( \\nabla_{z_j} \\hat{L} \\right)^T \\left( \\frac{\\partial^2 \\hat{L}}{\\partial z_j^2} \\cdot \\frac{\\partial L}{\\partial z_j} \\cdot \\frac{\\partial L}{\\partial z_j} \\cdot \\hat{g}_j \\right) \\leq \\frac{\\sigma^2}{N} \\left( \\hat{g}_j^T H_{jj} \\hat{g}_j - \\gamma^2 \\left( \\hat{g}_j^T \\frac{\\partial \\hat{L}}{\\partial z_j} \\right) \\right)\n",
    "$$\n",
    "\n",
    "The quadratic form of the loss Hessian matrix captures the second-order term of the Taylor expansion of the gradient around the current point. Therefore, if the quadratic forms involving the loss Hessian \\(H_{jj}\\) and the inner product \\(\\langle \\hat{y}_j, \\hat{g}_j \\rangle\\) are nonnegative (both fairly mild assumptions), Theorem 7.5 implies that the quadratic form of the loss Hessian is reduced for a BatchNorm network compared to standard networks, and thus the first-order term (gradient) is more predictive in BatchNorm networks.\n",
    "\n",
    "### Lemma 7.2\n",
    "\n",
    "Let \\(W^*\\) and \\(\\hat{W}^*\\) be the sets of local optima for the weights in the normal and BatchNorm networks, respectively. For any initialization \\(W_0\\), if \\(\\langle W^*, W_0 \\rangle > 0\\), where \\(\\hat{W}^*\\) and \\(W^*\\) are closest optima for BatchNorm and standard networks, respectively, then:\n",
    "\n",
    "$$\n",
    "\\|W_0 - \\hat{W}^*\\|^2 \\leq \\|W_0 - W^*\\|^2 - \\frac{\\|W^*\\|^2}{\\|W^*\\|} \\left\\langle W^*, W_0 \\right\\rangle\n",
    "$$\n",
    "\n",
    "This lemma shows that \\(\\|W_0 - \\hat{W}^*\\|^2 < \\|W_0 - W^*\\|^2\\). That is, the effect of any initialization \\(W_0\\) on the closest optima \\(\\hat{W}^*\\) for BatchNorm networks is smaller compared with standard networks. In other words, the initialization in optimization for BatchNorm networks is more favorable.\n",
    "\n",
    "### Variants and Extensions of Batch Normalization\n",
    "\n",
    "As pointed out by Ioffe, the dependence of the batch-normalized activations on the entire mini-batch makes BatchNorm powerful, but it also introduces some drawbacks:\n",
    "\n",
    "- When the training mini-batches are small, the estimates of the mean and variance become less accurate. These inaccuracies are compounded with depth, leading to performance degradation.\n",
    "- If the training mini-batches do not consist of independent samples, then different activations are produced between training and inference, which may lead to errors during inference.\n",
    "\n",
    "To address these issues, variants and extensions of batch normalization have been proposed, including:\n",
    "\n",
    "- **Batch Renormalization**: Uses moving averages of mini-batch statistics to normalize data. The moving averages \\((\\mu, \\sigma^2)\\) are given by:\n",
    "\n",
    "    $$\n",
    "    \\mu = \\frac{1}{m} \\sum_{i=1}^m \\mu_{B_{t-i+1}}\n",
    "    $$\n",
    "\n",
    "    $$\n",
    "    \\sigma^2 = \\frac{1}{m} \\sum_{i=1}^m \\sigma_{B_{t-i+1}}^2\n",
    "    $$\n",
    "\n",
    "    Normalization using moving averages:\n",
    "\n",
    "    $$\n",
    "    \\hat{y}_i = \\frac{y_i - \\mu}{\\sigma}\n",
    "    $$\n",
    "\n",
    "    $$\n",
    "    z_i = \\gamma \\hat{y}_i + \\beta\n",
    "    $$\n",
    "\n",
    "    However, when the source and target data have different distributions, moving average normalization statistics of the source data may not accurately represent the normalized statistics of the target (or testing) data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeec5171",
   "metadata": {},
   "source": [
    "### Algorithm 7.11: Batch Renormalization\n",
    "\n",
    "**Input:** Feature vectors \\( y \\) over a training mini-batch \\( B = \\{y_1, \\ldots, y_m\\} \\); parameters \\( \\gamma \\), \\( \\beta \\); current moving mean \\( \\mu \\) and standard deviation \\( \\sigma \\); moving average update rate \\( \\alpha \\); maximum allowed correction \\( r_{\\text{max}} \\), \\( d_{\\text{max}} \\).\n",
    "\n",
    "1. Compute the mini-batch mean:\n",
    "   $$\n",
    "   \\mu_B \\leftarrow \\frac{1}{m} \\sum_{i=1}^m y_i\n",
    "   $$\n",
    "\n",
    "2. Compute the mini-batch standard deviation:\n",
    "   $$\n",
    "   \\sigma_B \\leftarrow \\sqrt{\\frac{1}{m} \\sum_{i=1}^m (y_i - \\mu_B)^2}\n",
    "   $$\n",
    "\n",
    "3. Compute the corrected scale and shift:\n",
    "   $$\n",
    "   r \\leftarrow \\text{clip}\\left[\\frac{1}{r_{\\text{max}}}, r_{\\text{max}}\\right] \\cdot \\frac{\\sigma_B}{\\sigma}\n",
    "   $$\n",
    "   $$\n",
    "   d \\leftarrow \\text{clip}\\left[-d_{\\text{max}}, d_{\\text{max}}\\right] \\cdot \\frac{\\mu_B - \\mu}{\\sigma}\n",
    "   $$\n",
    "\n",
    "4. Normalize the activations:\n",
    "   $$\n",
    "   \\hat{y}_i \\leftarrow \\frac{y_i - \\mu_B}{\\sigma_B} \\cdot r + d\n",
    "   $$\n",
    "\n",
    "5. Apply the learned affine transformation:\n",
    "   $$\n",
    "   z_i \\leftarrow \\gamma \\hat{y}_i + \\beta\n",
    "   $$\n",
    "\n",
    "6. Update the moving averages:\n",
    "   $$\n",
    "   \\mu \\leftarrow \\mu + \\alpha (\\mu_B - \\mu)\n",
    "   $$\n",
    "   $$\n",
    "   \\sigma \\leftarrow \\sigma + \\alpha (\\sigma_B - \\sigma)\n",
    "   $$\n",
    "\n",
    "7. **Output:** \\( z_i = \\text{BatchRenorm}(y_i) \\); updated \\( \\mu \\), \\( \\sigma \\).\n",
    "\n",
    "**Inference:**\n",
    "   $$\n",
    "   z \\leftarrow \\gamma \\cdot \\frac{y - \\mu}{\\sigma} + \\beta\n",
    "   $$\n",
    "\n",
    "### Gradient Computation\n",
    "\n",
    "The gradients with respect to the loss \\(L\\) are computed as follows:\n",
    "\n",
    "1. Gradient with respect to \\(\\hat{y}_i\\):\n",
    "   $$\n",
    "   \\frac{\\partial L}{\\partial \\hat{y}_i} = \\frac{\\partial z_i}{\\partial \\hat{y}_i} \\cdot \\gamma\n",
    "   $$\n",
    "\n",
    "2. Gradient with respect to \\(\\sigma_B\\):\n",
    "   $$\n",
    "   \\frac{\\partial L}{\\partial \\sigma_B} = -\\frac{1}{\\sigma_B} \\cdot \\left(\\frac{\\partial L}{\\partial \\hat{y}_i} \\cdot \\left(\\frac{y_i - \\mu_B}{\\sigma_B}\\right)\\right)\n",
    "   $$\n",
    "\n",
    "3. Gradient with respect to \\(\\mu_B\\):\n",
    "   $$\n",
    "   \\frac{\\partial L}{\\partial \\mu_B} = -\\frac{1}{\\sigma_B} \\cdot \\left(\\frac{\\partial L}{\\partial \\hat{y}_i} \\cdot \\left(\\frac{\\partial L}{\\partial \\sigma_B}\\right)\\right)\n",
    "   $$\n",
    "\n",
    "4. Gradient with respect to \\( \\gamma \\):\n",
    "   $$\n",
    "   \\frac{\\partial L}{\\partial \\gamma} = \\sum_{i=1}^m \\frac{\\partial L}{\\partial z_i} \\cdot \\hat{y}_i\n",
    "   $$\n",
    "\n",
    "5. Gradient with respect to \\( \\beta \\):\n",
    "   $$\n",
    "   \\frac{\\partial L}{\\partial \\beta} = \\sum_{i=1}^m \\frac{\\partial L}{\\partial z_i}\n",
    "   $$\n",
    "\n",
    "### Note on BatchNorm for CNNs\n",
    "\n",
    "For convolutional neural networks, the input and output (activation) of a BatchNorm layer are four-dimensional tensors \\( Y \\), \\( Z \\in \\mathbb{R}^{N \\times C \\times H \\times W} \\) with elements \\( y_{nij}^k \\) and \\( z_{nij}^k \\), respectively. Here, \\( N \\) is the number of images in the mini-batch, \\( C \\) is the number of feature channels, \\( H \\) and \\( W \\) are the spatial height and width of the activation map, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fd4a9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch normalized and affine-transformed activations shape: (32, 64, 32, 32)\n",
      "Updated moving mean: [[[[ 3.96129474e-04]]\n",
      "\n",
      "  [[-1.17578703e-03]]\n",
      "\n",
      "  [[-1.81113646e-04]]\n",
      "\n",
      "  [[ 2.14558128e-04]]\n",
      "\n",
      "  [[ 2.69193033e-04]]\n",
      "\n",
      "  [[ 3.23901713e-04]]\n",
      "\n",
      "  [[-2.79679022e-05]]\n",
      "\n",
      "  [[ 1.84871023e-04]]\n",
      "\n",
      "  [[-2.93273967e-04]]\n",
      "\n",
      "  [[ 4.79933556e-04]]\n",
      "\n",
      "  [[ 7.63765604e-04]]\n",
      "\n",
      "  [[-6.73948618e-04]]\n",
      "\n",
      "  [[-1.27552161e-04]]\n",
      "\n",
      "  [[ 7.73047509e-04]]\n",
      "\n",
      "  [[ 1.14185056e-03]]\n",
      "\n",
      "  [[ 6.92246644e-04]]\n",
      "\n",
      "  [[ 6.46889082e-04]]\n",
      "\n",
      "  [[ 3.91375650e-04]]\n",
      "\n",
      "  [[ 4.13265528e-04]]\n",
      "\n",
      "  [[-1.60871184e-05]]\n",
      "\n",
      "  [[-7.28630664e-04]]\n",
      "\n",
      "  [[-2.83280263e-04]]\n",
      "\n",
      "  [[ 2.59267672e-04]]\n",
      "\n",
      "  [[-2.45911192e-04]]\n",
      "\n",
      "  [[-7.44960450e-04]]\n",
      "\n",
      "  [[-5.87769889e-04]]\n",
      "\n",
      "  [[ 8.31309267e-04]]\n",
      "\n",
      "  [[-2.31470418e-04]]\n",
      "\n",
      "  [[ 2.92184912e-04]]\n",
      "\n",
      "  [[-2.12327163e-04]]\n",
      "\n",
      "  [[-3.98613704e-04]]\n",
      "\n",
      "  [[-3.46699749e-04]]\n",
      "\n",
      "  [[-3.41094178e-04]]\n",
      "\n",
      "  [[ 2.05370857e-05]]\n",
      "\n",
      "  [[-3.65487148e-04]]\n",
      "\n",
      "  [[ 2.91893980e-04]]\n",
      "\n",
      "  [[ 7.21974794e-04]]\n",
      "\n",
      "  [[ 2.99460646e-04]]\n",
      "\n",
      "  [[ 7.03789828e-05]]\n",
      "\n",
      "  [[-5.26475565e-04]]\n",
      "\n",
      "  [[ 6.78582375e-05]]\n",
      "\n",
      "  [[ 1.26377869e-03]]\n",
      "\n",
      "  [[ 2.10178628e-05]]\n",
      "\n",
      "  [[ 2.69136864e-04]]\n",
      "\n",
      "  [[-2.90269250e-04]]\n",
      "\n",
      "  [[-5.36077633e-04]]\n",
      "\n",
      "  [[ 6.31557094e-04]]\n",
      "\n",
      "  [[ 7.86364812e-04]]\n",
      "\n",
      "  [[-2.42427988e-05]]\n",
      "\n",
      "  [[ 3.83825759e-04]]\n",
      "\n",
      "  [[ 1.81757835e-04]]\n",
      "\n",
      "  [[ 5.48314566e-04]]\n",
      "\n",
      "  [[ 5.65875705e-04]]\n",
      "\n",
      "  [[ 1.11621864e-03]]\n",
      "\n",
      "  [[-3.23358462e-04]]\n",
      "\n",
      "  [[-6.67469201e-04]]\n",
      "\n",
      "  [[ 9.35052528e-04]]\n",
      "\n",
      "  [[-7.56460915e-04]]\n",
      "\n",
      "  [[-1.97499343e-04]]\n",
      "\n",
      "  [[-5.19381609e-04]]\n",
      "\n",
      "  [[-6.37411518e-04]]\n",
      "\n",
      "  [[ 4.79827353e-04]]\n",
      "\n",
      "  [[-6.83493183e-04]]\n",
      "\n",
      "  [[ 3.86405403e-04]]]]\n",
      "Updated moving standard deviation: [[[[0.99967763]]\n",
      "\n",
      "  [[0.99958785]]\n",
      "\n",
      "  [[0.99989454]]\n",
      "\n",
      "  [[1.00063343]]\n",
      "\n",
      "  [[1.00001225]]\n",
      "\n",
      "  [[0.99986038]]\n",
      "\n",
      "  [[1.00029202]]\n",
      "\n",
      "  [[0.99942348]]\n",
      "\n",
      "  [[0.99989114]]\n",
      "\n",
      "  [[0.99987523]]\n",
      "\n",
      "  [[0.99952347]]\n",
      "\n",
      "  [[1.00035097]]\n",
      "\n",
      "  [[0.99980056]]\n",
      "\n",
      "  [[1.00022638]]\n",
      "\n",
      "  [[1.00031397]]\n",
      "\n",
      "  [[1.00020909]]\n",
      "\n",
      "  [[0.99973523]]\n",
      "\n",
      "  [[0.99969392]]\n",
      "\n",
      "  [[1.00015125]]\n",
      "\n",
      "  [[1.00036689]]\n",
      "\n",
      "  [[0.99988589]]\n",
      "\n",
      "  [[1.00010481]]\n",
      "\n",
      "  [[0.99965554]]\n",
      "\n",
      "  [[0.99964564]]\n",
      "\n",
      "  [[1.0004614 ]]\n",
      "\n",
      "  [[1.00034946]]\n",
      "\n",
      "  [[1.00004501]]\n",
      "\n",
      "  [[1.00028509]]\n",
      "\n",
      "  [[0.99973515]]\n",
      "\n",
      "  [[1.00026105]]\n",
      "\n",
      "  [[0.99981364]]\n",
      "\n",
      "  [[0.99984623]]\n",
      "\n",
      "  [[1.00043512]]\n",
      "\n",
      "  [[0.9999525 ]]\n",
      "\n",
      "  [[1.00002096]]\n",
      "\n",
      "  [[0.99961098]]\n",
      "\n",
      "  [[1.00052675]]\n",
      "\n",
      "  [[0.99951375]]\n",
      "\n",
      "  [[1.00014761]]\n",
      "\n",
      "  [[1.00028182]]\n",
      "\n",
      "  [[0.99981989]]\n",
      "\n",
      "  [[0.99956588]]\n",
      "\n",
      "  [[0.99973231]]\n",
      "\n",
      "  [[0.99944797]]\n",
      "\n",
      "  [[0.99973276]]\n",
      "\n",
      "  [[0.99993426]]\n",
      "\n",
      "  [[1.00042964]]\n",
      "\n",
      "  [[0.99947883]]\n",
      "\n",
      "  [[0.99972312]]\n",
      "\n",
      "  [[1.00005175]]\n",
      "\n",
      "  [[1.00009557]]\n",
      "\n",
      "  [[0.99979076]]\n",
      "\n",
      "  [[1.00069778]]\n",
      "\n",
      "  [[1.00015896]]\n",
      "\n",
      "  [[1.00026807]]\n",
      "\n",
      "  [[0.99960784]]\n",
      "\n",
      "  [[0.9995414 ]]\n",
      "\n",
      "  [[1.00011456]]\n",
      "\n",
      "  [[0.9995443 ]]\n",
      "\n",
      "  [[1.00039645]]\n",
      "\n",
      "  [[0.99958551]]\n",
      "\n",
      "  [[1.00021237]]\n",
      "\n",
      "  [[0.99989428]]\n",
      "\n",
      "  [[0.9995448 ]]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def batch_renormalization(y, gamma, beta, mu, sigma, alpha, rmax, dmax):\n",
    "    \"\"\"\n",
    "    Applies Batch Renormalization to the feature vectors y over a mini-batch.\n",
    "    \n",
    "    Parameters:\n",
    "    - y: Feature vectors of shape (N, C, H, W)\n",
    "    - gamma: Scale parameter for BatchNorm\n",
    "    - beta: Shift parameter for BatchNorm\n",
    "    - mu: Current moving mean\n",
    "    - sigma: Current moving standard deviation\n",
    "    - alpha: Moving average update rate\n",
    "    - rmax: Maximum allowed correction for the scale\n",
    "    - dmax: Maximum allowed correction for the shift\n",
    "    \n",
    "    Returns:\n",
    "    - z: Batch normalized and affine-transformed activations\n",
    "    - mu: Updated moving mean\n",
    "    - sigma: Updated moving standard deviation\n",
    "    \"\"\"\n",
    "    N, C, H, W = y.shape\n",
    "\n",
    "    # Compute mini-batch mean\n",
    "    mu_B = np.mean(y, axis=(0, 2, 3), keepdims=True)\n",
    "    \n",
    "    # Compute mini-batch standard deviation\n",
    "    sigma_B = np.sqrt(np.var(y, axis=(0, 2, 3), keepdims=True) + 1e-8)\n",
    "    \n",
    "    # Compute the correction factors\n",
    "    r = np.clip(sigma_B / sigma, 1 / rmax, rmax)\n",
    "    d = np.clip((mu_B - mu) / sigma, -dmax, dmax)\n",
    "    \n",
    "    # Normalize\n",
    "    y_hat = (y - mu_B) / sigma_B * r + d\n",
    "    \n",
    "    # Apply affine transformation\n",
    "    z = gamma * y_hat + beta\n",
    "    \n",
    "    # Update moving averages\n",
    "    mu = mu + alpha * (mu_B - mu)\n",
    "    sigma = sigma + alpha * (sigma_B - sigma)\n",
    "    \n",
    "    return z, mu, sigma\n",
    "\n",
    "# Example usage\n",
    "N, C, H, W = 32, 64, 32, 32  # Mini-batch size, number of channels, height, width\n",
    "y = np.random.randn(N, C, H, W)\n",
    "gamma = np.ones((1, C, 1, 1))\n",
    "beta = np.zeros((1, C, 1, 1))\n",
    "mu = np.zeros((1, C, 1, 1))\n",
    "sigma = np.ones((1, C, 1, 1))\n",
    "alpha = 0.1\n",
    "rmax = 3.0\n",
    "dmax = 3.0\n",
    "\n",
    "z, mu, sigma = batch_renormalization(y, gamma, beta, mu, sigma, alpha, rmax, dmax)\n",
    "print(\"Batch normalized and affine-transformed activations shape:\", z.shape)\n",
    "print(\"Updated moving mean:\", mu)\n",
    "print(\"Updated moving standard deviation:\", sigma)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bcb122",
   "metadata": {},
   "source": [
    "## Layer Normalization (LN)\n",
    "\n",
    "Layer Normalization (LN) normalizes across all hidden units within a layer. This helps to mitigate the problem of covariate shift by fixing the mean and variance of the summed inputs within each layer.\n",
    "\n",
    "### Formulas\n",
    "\n",
    "The normalization statistics for Layer Normalization are computed as follows:\n",
    "\n",
    "1. Compute the mean across all spatial locations and channels for each hidden unit:\n",
    "\n",
    "   $$ \\mu_{n,i} = \\frac{1}{H \\times W} \\sum_{j=1}^{H} \\sum_{k=1}^{W} y_{nijk} $$\n",
    "\n",
    "   where \\( H \\) is the height, \\( W \\) is the width, and \\( C \\) is the number of channels. Here, \\( i \\) is the index of the channel and \\( n \\) is the index of the image in the mini-batch.\n",
    "\n",
    "2. Compute the variance across all spatial locations and channels for each hidden unit:\n",
    "\n",
    "   $$ \\sigma_{n,i}^2 = \\frac{1}{H \\times W} \\sum_{j=1}^{H} \\sum_{k=1}^{W} (y_{nijk} - \\mu_{n,i})^2 $$\n",
    "\n",
    "   where \\( \\sigma_{n,i}^2 \\) is the variance for the \\(i\\)-th channel and \\(n\\)-th image.\n",
    "\n",
    "Layer Normalization performs normalization over \\(C\\) channels, and is named as such because it normalizes across the entire layer.\n",
    "\n",
    "## Instance Normalization (IN)\n",
    "\n",
    "Instance Normalization (IN) normalizes each image independently. This technique is useful for tasks where individual image statistics are more relevant than layer-wide statistics.\n",
    "\n",
    "### Formulas\n",
    "\n",
    "The normalization statistics for Instance Normalization are computed as follows:\n",
    "\n",
    "1. Compute the mean across all spatial locations and channels for each image:\n",
    "\n",
    "   $$ \\mu_{n} = \\frac{1}{C \\times H \\times W} \\sum_{i=1}^{C} \\sum_{j=1}^{H} \\sum_{k=1}^{W} y_{nijk} $$\n",
    "\n",
    "   where \\( C \\) is the number of channels, \\( H \\) is the height, and \\( W \\) is the width. Here, \\( n \\) is the index of the image in the mini-batch.\n",
    "\n",
    "2. Compute the variance across all spatial locations and channels for each image:\n",
    "\n",
    "   $$ \\sigma_{n}^2 = \\frac{1}{C \\times H \\times W} \\sum_{i=1}^{C} \\sum_{j=1}^{H} \\sum_{k=1}^{W} (y_{nijk} - \\mu_{n})^2 $$\n",
    "\n",
    "   where \\( \\sigma_{n}^2 \\) is the variance for the \\(n\\)-th image.\n",
    "\n",
    "Instance Normalization is also known as \"contrast normalization,\" and it normalizes each image instance independently.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f221f551",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (32) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5881/1624936513.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mlayer_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLayerNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/cv37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5881/1624936513.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maffine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mx_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_normalized\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx_normalized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (32) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LayerNormalization(nn.Module):\n",
    "    def __init__(self, num_features, eps=1e-5, affine=True):\n",
    "        super(LayerNormalization, self).__init__()\n",
    "        self.num_features = num_features\n",
    "        self.eps = eps\n",
    "        self.affine = affine\n",
    "        \n",
    "        if self.affine:\n",
    "            self.gamma = nn.Parameter(torch.ones(num_features))\n",
    "            self.beta = nn.Parameter(torch.zeros(num_features))\n",
    "        else:\n",
    "            self.gamma = None\n",
    "            self.beta = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Compute mean and variance\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        variance = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        \n",
    "        # Normalize\n",
    "        x_normalized = (x - mean) / torch.sqrt(variance + self.eps)\n",
    "        \n",
    "        if self.affine:\n",
    "            x_normalized = self.gamma * x_normalized + self.beta\n",
    "        \n",
    "        return x_normalized\n",
    "\n",
    "# Example usage\n",
    "batch_size, channels, height, width = 16, 3, 32, 32\n",
    "x = torch.randn(batch_size, channels, height, width)\n",
    "layer_norm = LayerNormalization(num_features=channels)\n",
    "output = layer_norm(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f98c257d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (3,) (16,3,32,32) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5881/2114068028.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mlayer_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLayerNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_5881/2114068028.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maffine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mx_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_normalized\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx_normalized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (3,) (16,3,32,32) "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class LayerNormalization:\n",
    "    def __init__(self, num_features, eps=1e-5, affine=True):\n",
    "        self.num_features = num_features\n",
    "        self.eps = eps\n",
    "        self.affine = affine\n",
    "        if self.affine:\n",
    "            self.gamma = np.ones(num_features)\n",
    "            self.beta = np.zeros(num_features)\n",
    "        else:\n",
    "            self.gamma = None\n",
    "            self.beta = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Compute mean and variance across the last axis (features)\n",
    "        mean = np.mean(x, axis=-1, keepdims=True)\n",
    "        variance = np.var(x, axis=-1, keepdims=True)\n",
    "        \n",
    "        # Normalize\n",
    "        x_normalized = (x - mean) / np.sqrt(variance + self.eps)\n",
    "        \n",
    "        if self.affine:\n",
    "            x_normalized = self.gamma * x_normalized + self.beta\n",
    "        \n",
    "        return x_normalized\n",
    "\n",
    "# Example usage\n",
    "batch_size, channels, height, width = 16, 3, 32, 32\n",
    "x = np.random.randn(batch_size, channels, height, width)\n",
    "layer_norm = LayerNormalization(num_features=channels)\n",
    "output = layer_norm.forward(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b7e077b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class InstanceNormalization:\n",
    "    def __init__(self, num_features, eps=1e-5, affine=False):\n",
    "        self.num_features = num_features\n",
    "        self.eps = eps\n",
    "        self.affine = affine\n",
    "        if self.affine:\n",
    "            self.gamma = np.ones(num_features)\n",
    "            self.beta = np.zeros(num_features)\n",
    "        else:\n",
    "            self.gamma = None\n",
    "            self.beta = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Compute mean and variance for each instance (over channels, height, width)\n",
    "        mean = np.mean(x, axis=(1, 2, 3), keepdims=True)\n",
    "        variance = np.var(x, axis=(1, 2, 3), keepdims=True)\n",
    "        \n",
    "        # Normalize\n",
    "        x_normalized = (x - mean) / np.sqrt(variance + self.eps)\n",
    "        \n",
    "        if self.affine:\n",
    "            x_normalized = self.gamma[:, None, None] * x_normalized + self.beta[:, None, None]\n",
    "        \n",
    "        return x_normalized\n",
    "\n",
    "# Example usage\n",
    "batch_size, channels, height, width = 16, 3, 32, 32\n",
    "x = np.random.randn(batch_size, channels, height, width)\n",
    "instance_norm = InstanceNormalization(num_features=channels)\n",
    "output = instance_norm.forward(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9f0a0b",
   "metadata": {},
   "source": [
    "## Instance Normalization (IN)\n",
    "\n",
    "Instance Normalization normalizes each instance (image) independently. The normalization statistics for each image in a mini-batch are calculated as follows:\n",
    "\n",
    "For the n-th image in the mini-batch:\n",
    "\n",
    "- **Mean** $(\\mu_n)$:\n",
    "  $$\n",
    "  \\mu_n = \\frac{1}{C \\cdot H \\cdot W} \\sum_{i=1}^{C} \\sum_{j=1}^{H} \\sum_{k=1}^{W} y_{nijk}\n",
    "  $$\n",
    "  \n",
    "- **Variance** $(\\sigma_n^2)$:\n",
    "  $$\n",
    "  \\sigma_n^2 = \\frac{1}{C \\cdot H \\cdot W} \\sum_{i=1}^{C} \\sum_{j=1}^{H} \\sum_{k=1}^{W} (y_{nijk} - \\mu_n)^2\n",
    "  $$\n",
    "\n",
    "where:\n",
    "- C is the number of channels,\n",
    "- H is the height of the image,\n",
    "- W is the width of the image,\n",
    "- $y_{nijk}$ represents the value of the pixel at position (i, j, k) in the n-th image.\n",
    "\n",
    "Instance Normalization is also known as \"contrast normalization.\"\n",
    "\n",
    "### Explanation\n",
    "\n",
    "Instance Normalization performs normalization on each image individually, ensuring that each image is normalized separately rather than across the entire batch. This technique can be especially useful in tasks like style transfer where normalization needs to be applied on a per-instance basis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd368b37",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "def instance_normalization(x, epsilon=1e-5):\n",
    "    \"\"\"\n",
    "    Apply instance normalization to the input tensor x.\n",
    "    \n",
    "    Args:\n",
    "        x (numpy.ndarray): Input tensor with shape (N, C, H, W).\n",
    "        epsilon (float): Small constant to avoid division by zero.\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Normalized tensor.\n",
    "    \"\"\"\n",
    "    # Get dimensions\n",
    "    N, C, H, W = x.shape\n",
    "    \n",
    "    # Initialize output tensor\n",
    "    normalized_x = np.zeros_like(x)\n",
    "    \n",
    "    # Compute normalization for each instance\n",
    "    for n in range(N):\n",
    "        for c in range(C):\n",
    "            # Extract the feature map for this instance and channel\n",
    "            feature_map = x[n, c, :, :]\n",
    "            \n",
    "            # Compute mean and variance\n",
    "            mean = np.mean(feature_map)\n",
    "            variance = np.var(feature_map)\n",
    "            \n",
    "            # Normalize the feature map\n",
    "            normalized_feature_map = (feature_map - mean) / np.sqrt(variance + epsilon)\n",
    "            \n",
    "            # Store the normalized feature map\n",
    "            normalized_x[n, c, :, :] = normalized_feature_map\n",
    "    \n",
    "    return normalized_x\n",
    "\n",
    "# Example usage\n",
    "N, C, H, W = 2, 3, 4, 4  # Example dimensions\n",
    "x = np.random.rand(N, C, H, W)  # Random input tensor\n",
    "normalized_x = instance_normalization(x)\n",
    "\n",
    "print(\"Input Tensor:\\n\", x)\n",
    "print(\"Normalized Tensor:\\n\", normalized_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bd283dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Tensor:\n",
      " [[[[0.04443066 0.48850864 0.57921359 0.96228825]\n",
      "   [0.16852245 0.35207429 0.27123914 0.86778994]\n",
      "   [0.48034966 0.86605724 0.84847832 0.72468133]\n",
      "   [0.81184092 0.78300024 0.32711358 0.536134  ]]\n",
      "\n",
      "  [[0.06734881 0.52961901 0.81477889 0.60507987]\n",
      "   [0.84767498 0.28545461 0.86645336 0.27534859]\n",
      "   [0.43873507 0.0380017  0.58281981 0.30684952]\n",
      "   [0.89328281 0.46400591 0.4982895  0.41524684]]\n",
      "\n",
      "  [[0.82624799 0.63863246 0.1922194  0.78312031]\n",
      "   [0.03110266 0.68066567 0.21641838 0.96076069]\n",
      "   [0.9811581  0.84264099 0.26262749 0.16667852]\n",
      "   [0.42575312 0.20685708 0.01237106 0.163002  ]]]\n",
      "\n",
      "\n",
      " [[[0.22595378 0.89277324 0.5528927  0.99532619]\n",
      "   [0.85462134 0.6041483  0.83135015 0.49747264]\n",
      "   [0.31501688 0.99417827 0.34602359 0.91422741]\n",
      "   [0.50030688 0.70146195 0.58175094 0.17018546]]\n",
      "\n",
      "  [[0.29760236 0.95853937 0.54785507 0.36530722]\n",
      "   [0.47552322 0.14332099 0.83468931 0.18605998]\n",
      "   [0.38512755 0.7257209  0.90633744 0.68388011]\n",
      "   [0.98515906 0.7659335  0.11106902 0.59877659]]\n",
      "\n",
      "  [[0.08524333 0.19031454 0.80850677 0.04640987]\n",
      "   [0.49782407 0.30387509 0.47751854 0.33352742]\n",
      "   [0.431709   0.5849544  0.68885767 0.68973522]\n",
      "   [0.62628066 0.10990205 0.85213172 0.61732888]]]]\n",
      "Normalized Tensor:\n",
      " [[[[-1.92950394 -0.29756989  0.03576008  1.44351415]\n",
      "   [-1.47348128 -0.79894999 -1.09600959  1.09624407]\n",
      "   [-0.32755315  1.08987659  1.02527614  0.57033683]\n",
      "   [ 0.89063801  0.78465194 -0.89067765 -0.12255231]]\n",
      "\n",
      "  [[-1.65262423  0.13143861  1.23197062  0.42266853]\n",
      "   [ 1.35892813 -0.81087747  1.43140049 -0.84988012]\n",
      "   [-0.21931441 -1.76588505  0.33675916 -0.728307  ]\n",
      "   [ 1.53494478 -0.12178536  0.01052703 -0.30996371]]\n",
      "\n",
      "  [[ 1.09182135  0.52961822 -0.80808989  0.96258622]\n",
      "   [-1.29088752  0.65557367 -0.73557593  1.4948981 ]\n",
      "   [ 1.55602037  1.14094413 -0.5971071  -0.88462494]\n",
      "   [-0.10828967 -0.76422705 -1.34701806 -0.89564189]]]\n",
      "\n",
      "\n",
      " [[[-1.51014678  1.0222074  -0.26854363  1.41166872]\n",
      "   [ 0.87731942 -0.07389226  0.78894333 -0.47901023]\n",
      "   [-1.17191536  1.4073093  -1.05416238  1.10368305]\n",
      "   [-0.46824677  0.29567198 -0.15894985 -1.72193595]]\n",
      "\n",
      "  [[-0.92958537  1.40582484 -0.04532146 -0.69035134]\n",
      "   [-0.30090489 -1.47473606  0.96820264 -1.32371854]\n",
      "   [-0.62031654  0.58316454  1.22137015  0.43532079]\n",
      "   [ 1.4998851   0.72525511 -1.58869788  0.13460889]]\n",
      "\n",
      "  [[-1.49637068 -1.07571639  1.39922616 -1.65184107]\n",
      "   [ 0.15540294 -0.62107492  0.07410945 -0.50236132]\n",
      "   [-0.10928981  0.50423065  0.92020907  0.92372235]\n",
      "   [ 0.66968097 -1.39764912  1.57387932  0.63384239]]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def instance_normalization(x, epsilon=1e-5):\n",
    "    \"\"\"\n",
    "    Apply instance normalization to the input tensor x.\n",
    "    \n",
    "    Args:\n",
    "        x (numpy.ndarray): Input tensor with shape (N, C, H, W).\n",
    "        epsilon (float): Small constant to avoid division by zero.\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Normalized tensor.\n",
    "    \"\"\"\n",
    "    # Get dimensions\n",
    "    N, C, H, W = x.shape\n",
    "    \n",
    "    # Initialize output tensor\n",
    "    normalized_x = np.zeros_like(x)\n",
    "    \n",
    "    # Compute normalization for each instance\n",
    "    for n in range(N):\n",
    "        for c in range(C):\n",
    "            # Extract the feature map for this instance and channel\n",
    "            feature_map = x[n, c, :, :]\n",
    "            \n",
    "            # Compute mean and variance\n",
    "            mean = np.mean(feature_map)\n",
    "            variance = np.var(feature_map)\n",
    "            \n",
    "            # Normalize the feature map\n",
    "            normalized_feature_map = (feature_map - mean) / np.sqrt(variance + epsilon)\n",
    "            \n",
    "            # Store the normalized feature map\n",
    "            normalized_x[n, c, :, :] = normalized_feature_map\n",
    "    \n",
    "    return normalized_x\n",
    "\n",
    "# Example usage\n",
    "N, C, H, W = 2, 3, 4, 4  # Example dimensions\n",
    "x = np.random.rand(N, C, H, W)  # Random input tensor\n",
    "normalized_x = instance_normalization(x)\n",
    "\n",
    "print(\"Input Tensor:\\n\", x)\n",
    "print(\"Normalized Tensor:\\n\", normalized_x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f2d2a1",
   "metadata": {},
   "source": [
    "## Group Normalization (GN) [161]\n",
    "\n",
    "Group Normalization (GN) is different from Batch Normalization (BN), Layer Normalization (LN), and Instance Normalization (IN). GN divides the \\(C\\) channels into \\(G\\) groups, where each group contains \\(\\frac{C}{G}\\) channels. GN computes the mean and variance within each group for normalization as follows:\n",
    "\n",
    "For the \\(n\\)th image in the mini-batch, the normalization statistics are:\n",
    "\n",
    "1. **Mean Calculation**:\n",
    "   $$\n",
    "   \\mu_n = \\frac{1}{\\frac{C}{G} \\cdot H \\cdot W} \\sum_{i=1}^{\\frac{C}{G}} \\sum_{j=1}^{H} \\sum_{k=1}^{W} y_{nij}^k\n",
    "   $$\n",
    "   (7.15.41)\n",
    "\n",
    "2. **Variance Calculation**:\n",
    "   $$\n",
    "   \\sigma_n^2 = \\frac{1}{\\frac{C}{G} \\cdot H \\cdot W} \\sum_{i=1}^{\\frac{C}{G}} \\sum_{j=1}^{H} \\sum_{k=1}^{W} (y_{nij}^k - \\mu_n)^2\n",
    "   $$\n",
    "   (7.15.42)\n",
    "\n",
    "In this way, GN normalizes each group of channels, and hence is named Group Normalization (GN). \n",
    "\n",
    "**Relation to LN and IN**:\n",
    "- If \\(G = 1\\), then the equations for GN reduce to those for Instance Normalization (IN):\n",
    "  $$\n",
    "  \\mu_n = \\frac{1}{C \\cdot H \\cdot W} \\sum_{i=1}^{C} \\sum_{j=1}^{H} \\sum_{k=1}^{W} y_{nij}^k\n",
    "  $$\n",
    "  (7.15.39)\n",
    "  $$\n",
    "  \\sigma_n^2 = \\frac{1}{C \\cdot H \\cdot W} \\sum_{i=1}^{C} \\sum_{j=1}^{H} \\sum_{k=1}^{W} (y_{nij}^k - \\mu_n)^2\n",
    "  $$\n",
    "  (7.15.40)\n",
    "\n",
    "- If \\(G = C\\), then the equations for GN become those for Layer Normalization (LN):\n",
    "  $$\n",
    "  \\mu_n = \\frac{1}{H \\cdot W} \\sum_{j=1}^{H} \\sum_{k=1}^{W} y_{nij}^k\n",
    "  $$\n",
    "  (7.15.37)\n",
    "  $$\n",
    "  \\sigma_n^2 = \\frac{1}{H \\cdot W} \\sum_{j=1}^{H} \\sum_{k=1}^{W} (y_{nij}^k - \\mu_n)^2\n",
    "  $$\n",
    "  (7.15.38)\n",
    "\n",
    "**Unified Normalization Statistics**:\n",
    "The normalization statistics in BN, LN, IN, and GN can be unified as follows:\n",
    "$$\n",
    "\\mu_l = \\frac{1}{m} \\sum_{p \\in S} y_{p}\n",
    "$$\n",
    "$$\n",
    "\\sigma_l^2 = \\frac{1}{m} \\sum_{p \\in S} (y_{p} - \\mu_l)^2\n",
    "$$\n",
    "(7.15.43) (7.15.44)\n",
    "\n",
    "Where \\(S\\) is a designed subset of \\(\\{n, i, j, k\\}\\) and \\(l\\) is the index of \\(\\{n, i, j, k\\} \\setminus S\\).\n",
    "\n",
    "**Cases**:\n",
    "- **Batch Normalization (BN)**:\n",
    "  $$ S = \\{p\\} = \\{1, \\ldots, N\\} $$\n",
    "  $$ m = |S| = N $$\n",
    "  $$\n",
    "  \\mu_{BN}(i, j, k) = \\frac{1}{N} \\sum_{n=1}^{N} y_{nij}^k\n",
    "  $$\n",
    "  $$\n",
    "  \\sigma_{BN}^2(i, j, k) = \\frac{1}{N} \\sum_{n=1}^{N} (y_{nij}^k - \\mu_{BN}(i, j, k))^2\n",
    "  $$\n",
    "  (7.15.45) (7.15.46)\n",
    "\n",
    "- **Layer Normalization (LN)**:\n",
    "  $$ S = \\{p\\} = \\{H, W\\} $$\n",
    "  $$ m = H \\cdot W $$\n",
    "  (7.15.37) (7.15.38)\n",
    "\n",
    "- **Instance Normalization (IN)**:\n",
    "  $$ S = \\{p\\} = \\{C, H, W\\} $$\n",
    "  $$ m = C \\cdot H \\cdot W $$\n",
    "  (7.15.39) (7.15.40)\n",
    "\n",
    "- **Group Normalization (GN)**:\n",
    "  $$ S = \\{p\\} = \\{C/G, H, W\\} $$\n",
    "  $$ m = \\frac{C}{G} \\cdot H \\cdot W $$\n",
    "  (7.15.41) (7.15.42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d719bd76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
