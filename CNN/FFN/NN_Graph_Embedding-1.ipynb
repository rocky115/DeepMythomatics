{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca53923",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " * Copyright (c) 2018 Radhamadhab Dalai\n",
    " *\n",
    " * Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    " * of this software and associated documentation files (the \"Software\"), to deal\n",
    " * in the Software without restriction, including without limitation the rights\n",
    " * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    " * copies of the Software, and to permit persons to whom the Software is\n",
    " * furnished to do so, subject to the following conditions:\n",
    " *\n",
    " * The above copyright notice and this permission notice shall be included in\n",
    " * all copies or substantial portions of the Software.\n",
    " *\n",
    " * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    " * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    " * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    " * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    " * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    " * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
    " * THE SOFTWARE.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2626e15",
   "metadata": {},
   "source": [
    "We first introduce the definition of the basic concepts in graph embedding. Suppose we are given a graph \\( G = (V, E) \\), where \\( v \\in V \\) is a vertex or node and \\( e \\in E \\) is an edge. \\( G \\) is associated with a node type mapping function \\( f_v: V \\to T_v \\) and an edge type mapping function \\( f_e: E \\to T_e \\), where \\( T_v \\) and \\( T_e \\) denote the set of node types and edge types, respectively. Each node \\( v_i \\in V \\) belongs to one particular type, i.e., \\( f_v(v_i) \\in T_v \\). Similarly, for \\( e_{ij} \\in E \\), \\( f_e(e_{ij}) \\in T_e \\).\n",
    "\n",
    "Graph learning is closely related to graph proximities and graph embedding. Graph learning tasks can be broadly abstracted into the following four categories:\n",
    "- **Node classification** aims at determining the label of nodes (a.k.a. vertices) based on other labeled nodes and the topology of the network.\n",
    "- **Link prediction** refers to the task of predicting missing links or links that are likely to occur in the future.\n",
    "- **Clustering** is used to find subsets of similar nodes and group them together.\n",
    "- **Visualization** helps in providing insights into the structure of the network.\n",
    "\n",
    "The most basic measure for both dimension reduction and structure preservation of a graph is the graph proximity. Proximity measures are usually adopted to quantify the graph property to be preserved in the embedded space.\n",
    "\n",
    "The microscopic structures of a graph can be described by its first-order proximity and second-order proximity. The first-order proximity between the vertices is their local pairwise similarity between only the nodes connected by edges.\n",
    "\n",
    "**Definition 7.10 (First-Order Proximity [144])** The first-order proximity is the observed pairwise proximity between two nodes \\( v_i \\) and \\( v_j \\), denoted as \\( S_{ij}^{(1)} = s_{ij} \\), where \\( s_{ij} \\) is the edge weight between the two nodes. If no edge is observed between nodes \\( i \\) and \\( j \\), then their first-order proximity \\( S_{ij}^{(1)} = 0 \\).\n",
    "\n",
    "The first-order proximity is the first and foremost measure of similarity between two nodes. The first-order proximity implies that two nodes in real-world networks are always similar if they are linked by an observed edge. For example, if a paper cites another paper, they should contain some common topic or keywords. However, it is not sufficient to only capture the first-order proximity, and it is also necessary to introduce the second-order proximity to capture the global network structure.\n",
    "\n",
    "**Definition 7.11 (Second-Order Proximity [144])** Let \\( \\mathbf{s}_i^{(1)} = [S_{i,1}^{(1)}, \\ldots, S_{i,n}^{(1)}]^T \\) and \\( \\mathbf{s}_i^{(2)} = [S_{i,1}^{(2)}, \\ldots, S_{i,n}^{(2)}]^T \\) be the first-order and the second-order proximity vectors between node \\( i \\) and other nodes, respectively. Then the second-order proximity \\( S_{ij}^{(2)} \\) is determined by the similarity of \\( \\mathbf{s}_i^{(1)} \\) and \\( \\mathbf{s}_j^{(1)} \\). If no vertex is linked from/to both \\( i \\) and \\( j \\), then the second-order proximity between \\( v_i \\) and \\( v_j \\) is zero, i.e., \\( S_{ij}^{(2)} = 0 \\).\n",
    "\n",
    "The second-order proximity \\( S_{ij}^{(2)} \\) is the similarity between \\( v_i \\)’s neighborhood \\( \\mathbf{s}_i^{(1)} \\) and \\( v_j \\)’s neighborhood \\( \\mathbf{s}_j^{(1)} \\).\n",
    "\n",
    "- The first-order proximity compares the similarity between the nodes \\( i \\) and \\( j \\). The more similar two nodes are, the larger the first-order proximity value between them.\n",
    "- The second-order proximity compares the similarity between the nodes’ neighborhood structures. The more similar two nodes’ neighborhoods are, the larger the second-order proximity value between them.\n",
    "\n",
    "Similarly, we can define the higher-order proximity \\( S_{ij}^{(k)} \\) (where \\( k \\geq 3 \\)) between a pair of vertices \\( (i, j) \\) in a graph.\n",
    "\n",
    "**Definition 7.12 (k-Order Proximity)** Let \\( \\mathbf{s}_i^{(k)} = [S_{i,1}^{(k)}, \\ldots, S_{i,n}^{(k)}]^T \\) be the \\( k \\)-th order proximity vector between node \\( i \\) and other nodes. Then the \\( k \\)-th order proximity \\( S_{ij}^{(k)} \\) is determined by the similarity of \\( \\mathbf{s}_i^{(k-1)} \\) and \\( \\mathbf{s}_j^{(k-1)} \\).\n",
    "\n",
    "In particular, when \\( k \\geq 3 \\), the \\( k \\)-th order proximity is generally referred to as the higher-order proximity. The matrix \\( S^{(k)} = [S_{ij}^{(k)}] \\) is known as the \\( k \\)-order proximity matrix. When \\( k \\geq 3 \\), \\( S^{(k)} \\) is called the higher-order proximity matrix. The higher-order proximity matrices are also defined using some other metrics, e.g., Katz Index, Rooted PageRank, Adamic-Adar, etc. that will be discussed in Sect. 7.13.3.\n",
    "\n",
    "By Definitions 7.10, 7.11, and 7.12, the first-order, second-order, and third-order proximity matrices \\( S^{(k)} = [S_{ij}^{(k)}] \\in \\mathbb{R}^{n \\times n} \\) (where \\( k = 1, 2, 3 \\)) are nonnegative matrices, respectively.\n",
    "\n",
    "If considering the cosine similarity as the \\( k \\)-order proximity, then for nodes \\( v_i \\) and \\( v_j \\), we have the following results:\n",
    "1. The first-order proximity\n",
    "$$\n",
    "S_{ij}^{(1)} = s_{ij}\n",
    "$$\n",
    "where \\( s_{ij} \\) is the edge weight between the two nodes.\n",
    "\n",
    "2. The second-order proximity\n",
    "$$\n",
    "S_{ij}^{(2)} = \\frac{\\mathbf{s}_i^{(1)} \\cdot \\mathbf{s}_j^{(1)}}{\\| \\mathbf{s}_i^{(1)} \\|_2 \\| \\mathbf{s}_j^{(1)} \\|_2} = \\frac{\\sum_{l=1}^{n} S_{i,l}^{(1)} S_{j,l}^{(1)}}{\\sqrt{\\sum_{l=1}^{n} (S_{i,l}^{(1)})^2} \\sqrt{\\sum_{l=1}^{n} (S_{j,l}^{(1)})^2}}\n",
    "$$\n",
    "In this way, the second-order proximity is between \\([0, 1]\\).\n",
    "\n",
    "3. The third-order proximity\n",
    "$$\n",
    "S_{ij}^{(3)} = \\frac{\\| \\mathbf{s}_i^{(2)} \\|_2 \\| \\mathbf{s}_j^{(2)} \\|_2}{\\sum_{l=1}^{n} (S_{i,l}^{(2)})^2 \\sum_{l=1}^{n} (S_{j,l}^{(2)})^2}\n",
    "$$\n",
    "\n",
    "**Definition 7.13 (Graph Embedding [14, 41])** Given the inputs of a graph \\( G = (V, E) \\), and a predefined dimensionality of the embedding \\( d \\) (\\( d \\ll |V| \\)), the graph embedding is to convert \\( G \\) into a \\( d \\)-dimensional space \\( \\mathbb{R}^d \\). In this space, the graph properties (such as the first-order, second-order, and higher-order proximities) are preserved as much as possible. The graph is represented as either a \\( d \\)-dimensional vector (for a whole graph) or a set of \\( d \\)-dimensional vectors with each vector representing the embedding of part of the graph (e.g., node, edge, substructure). Therefore, a graph embedding maps each node of graph \\( G(E, V) \\) to a low-dimensional feature vector \\( \\mathbf{y}_i \\) and tries to preserve the connection strengths between vertices. For example, a graph embedding preserving first-order proximity might be obtained by minimizing\n",
    "$$\n",
    "\\sum_{i,j} s_{ij} \\| \\mathbf{y}_i - \\mathbf{y}_j \\|^2_2\n",
    "$$\n",
    "\n",
    "Graph embedding is an important method for learning low-dimensional representations of vertices in networks, aiming to capture and preserve the network structure. Learning network representations faces the following great challenges [154]:\n",
    "1. **High nonlinearity:** The underlying structure of a graph or network is highly nonlinear. Therefore, designing a model to capture the highly nonlinear structure is rather difficult.\n",
    "2. **Topology structure-preserving:** To support applications in analyzing networks, network embedding is required to preserve the network structure. However, the underlying structure of the network is very complex. The similarity of vertices is dependent on both the local and global network structures. Therefore, how to simultaneously preserve the local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f63fa6a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "071081feadb540c690cb0f735ed15c84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 2): 100%|██████████| 50/50 [00:01<00:00, 27.45it/s]"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Key '7' not present\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8005/2180222366.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Get node embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Convert embeddings to a matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_8005/2180222366.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Get node embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Convert embeddings to a matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv37/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key_or_keys)\u001b[0m\n\u001b[1;32m    402\u001b[0m         \"\"\"\n\u001b[1;32m    403\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_or_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_KEY_TYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_or_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey_or_keys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv37/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, key, norm)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \"\"\"\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_norms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv37/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_index\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Key '{key}' not present\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Key '7' not present\""
     ]
    }
   ],
   "source": [
    "# graph_embedding.py\n",
    "\n",
    "import networkx as nx\n",
    "from node2vec import Node2Vec\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Create a graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes and edges\n",
    "G.add_edges_from([\n",
    "    (1, 2), (1, 3), (2, 4), (3, 4),\n",
    "    (4, 5), (5, 6), (6, 7), (7, 5)\n",
    "])\n",
    "\n",
    "# Optionally, add node attributes or edge weights\n",
    "nx.set_node_attributes(G, {1: 'A', 2: 'B', 3: 'C', 4: 'D', 5: 'E', 6: 'F', 7: 'G'}, 'label')\n",
    "\n",
    "# Apply Node2Vec\n",
    "node2vec = Node2Vec(G, dimensions=64, walk_length=30, num_walks=200, workers=4)\n",
    "model = node2vec.fit(window=10, min_count=1, sg=1)\n",
    "\n",
    "# Get node embeddings\n",
    "embeddings = {node: model.wv[node] for node in G.nodes()}\n",
    "\n",
    "# Convert embeddings to a matrix\n",
    "embedding_matrix = [embeddings[node] for node in G.nodes()]\n",
    "\n",
    "# Perform PCA to reduce to 2 dimensions for visualization\n",
    "pca = PCA(n_components=2)\n",
    "reduced_embeddings = pca.fit_transform(embedding_matrix)\n",
    "\n",
    "# Create a DataFrame for plotting\n",
    "df = pd.DataFrame(reduced_embeddings, index=G.nodes(), columns=['x', 'y'])\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(df['x'], df['y'])\n",
    "\n",
    "for node, (x, y) in df.iterrows():\n",
    "    plt.text(x, y, str(node), fontsize=12)\n",
    "\n",
    "plt.title('Node Embeddings Visualization')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "309c6078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "440ccb17ce184e2ea986ceb9417f7b7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating walks (CPU: 1):   0%|          | 0/50 [00:00<?, ?it/s]\n",
      "Generating walks (CPU: 2):   0%|          | 0/50 [00:00<?, ?it/s]\n",
      "Generating walks (CPU: 3):   0%|          | 0/50 [00:00<?, ?it/s]\n",
      "Generating walks (CPU: 3): 100%|██████████| 50/50 [00:01<00:00, 28.15it/s]"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# graph_embedding.py\n",
    "\n",
    "import networkx as nx\n",
    "from node2vec import Node2Vec\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Create a graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes and edges\n",
    "G.add_edges_from([\n",
    "    (1, 2), (1, 3), (2, 4), (3, 4),\n",
    "    (4, 5), (5, 6), (6, 7), (7, 5)\n",
    "])\n",
    "\n",
    "# Optionally, add node attributes or edge weights\n",
    "nx.set_node_attributes(G, {1: 'A', 2: 'B', 3: 'C', 4: 'D', 5: 'E', 6: 'F', 7: 'G'}, 'label')\n",
    "\n",
    "# Apply Node2Vec\n",
    "node2vec = Node2Vec(G, dimensions=64, walk_length=30, num_walks=200, workers=4)\n",
    "model = node2vec.fit(window=10, min_count=1, sg=1)\n",
    "\n",
    "# Check if all nodes are in the model's vocabulary\n",
    "nodes = list(G.nodes())\n",
    "missing_nodes = [node for node in nodes if str(node) not in model.wv]\n",
    "\n",
    "if missing_nodes:\n",
    "    print(f\"Warning: Nodes not in the model's vocabulary: {missing_nodes}\")\n",
    "\n",
    "# Get node embeddings, handle missing nodes\n",
    "embeddings = {node: model.wv[str(node)] for node in G.nodes() if str(node) in model.wv}\n",
    "\n",
    "# Convert embeddings to a matrix\n",
    "embedding_matrix = [embeddings[node] for node in G.nodes() if str(node) in model.wv]\n",
    "\n",
    "# Ensure all nodes are in the embedding matrix\n",
    "if not embedding_matrix:\n",
    "    raise ValueError(\"No valid embeddings found. Ensure the graph nodes are in the model's vocabulary.\")\n",
    "\n",
    "# Perform PCA to reduce to 2 dimensions for visualization\n",
    "pca = PCA(n_components=2)\n",
    "reduced_embeddings = pca.fit_transform(embedding_matrix)\n",
    "\n",
    "# Create a DataFrame for plotting\n",
    "df = pd.DataFrame(reduced_embeddings, index=[node for node in G.nodes() if str(node) in model.wv], columns=['x', 'y'])\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(df['x'], df['y'])\n",
    "\n",
    "for node, (x, y) in df.iterrows():\n",
    "    plt.text(x, y, str(node), fontsize=12)\n",
    "\n",
    "plt.title('Node Embeddings Visualization')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddbce2f",
   "metadata": {},
   "source": [
    "## Local Topology Preserving\n",
    "\n",
    "**Definition 7.14 (Local Topology Preserving [101])** Suppose we are given a symmetric undirected graph \\( G \\) with edge weights \\( s_{ij} = w_{ij} \\), and a corresponding embedding \\( (y_1, \\ldots, y_n) \\) for the \\( n \\) nodes of the graph. The embedding is said to be local topology preserving if the following condition holds:\n",
    "\n",
    "$$\n",
    "\\text{if } w_{ij} \\geq w_{pq} \\text{ then } \\| y_i - y_j \\|_2^2 \\leq \\| y_p - y_q \\|_2^2, \\forall i, j, p, q.\n",
    "$$\n",
    "\n",
    "Roughly speaking, this definition says that if two node pairs \\( (v_i, v_j) \\) and \\( (v_p, v_q) \\) are associated with connection strengths such that \\( s_{ij} \\geq s_{pq} \\), then \\( v_i \\) and \\( v_j \\) will be mapped to points in the embedding space that will be closer to each other than the mapping of \\( v_p \\) and \\( v_q \\). That is, for any pair of nodes \\( (v_i, v_j) \\), the more similar they are (the larger the edge weight \\( w_{ij} \\) or the first-order proximity \\( S_{ij}^{(1)} \\)), the closer they should be embedded together (the smaller \\( \\| y_i - y_j \\| \\) should be).\n",
    "\n",
    "To describe the topology structure of the graph or network, it is necessary to introduce the metric distance between two nodes. If \\( n \\) points \\( x_i \\in \\mathbb{R}^d \\), \\( i = 1, \\ldots, n \\), have (orthogonal) coordinates \\( (x_{i1}, \\ldots, x_{id}) \\), then the Euclidean (or Pythagorean) metric distance from \\( x_i \\) to \\( x_j \\) is given by\n",
    "\n",
    "$$\n",
    "d_{ij} = \\left( \\sum_{l=1}^d (x_{il} - x_{jl})^2 \\right)^{1/2}.\n",
    "$$\n",
    "\n",
    "Another commonly used metric distance is the Minkowski \\( p \\)-metric distance (or \\( p \\)-metric distance) given by\n",
    "\n",
    "$$\n",
    "d_{ij} = \\left( \\sum_{l=1}^d |x_{il} - x_{jl}|^p \\right)^{1/p}, \\quad p \\geq 1.\n",
    "$$\n",
    "\n",
    "Clearly, the Euclidean metric distance is a special example of the Minkowski \\( p \\)-metric distance when \\( p = 2 \\). For \\( p = 1 \\), the Minkowski metric becomes the so-called city-block distance or Manhattan metric:\n",
    "\n",
    "$$\n",
    "d_{ij} = \\sum_{l=1}^d |x_{il} - x_{jl}|.\n",
    "$$\n",
    "\n",
    "For \\( p = \\infty \\), the Minkowski metric becomes a familiar metric\n",
    "\n",
    "$$\n",
    "d_{ij} = \\max_l |x_{il} - x_{jl}|.\n",
    "$$\n",
    "\n",
    "It is well known that a local subspace of a nonlinear space can be linear. Similarly, a local structured subspace of a non-Euclidean space can be a locally Euclidean structured space as well. It should be noted that the Euclidean distance is available only for Euclidean structured space or locally Euclidean structured space in a graph or network, but the Minkowski \\( p \\)-metric distance ( \\( p \\neq 2 \\) ) can be used to describe the distance between two nodes in non-Euclidean structured spaces.\n",
    "\n",
    "## Linear Dimensionality Reduction\n",
    "\n",
    "The generic problem of linear dimensionality reduction is: given a set of points \\( x_1, \\ldots, x_n \\) in \\( \\mathbb{R}^D \\), find an \\( n \\times d \\) transformation matrix \\( W \\) that maps these \\( n \\) points to a set of points \\( y_1, \\ldots, y_n \\) in \\( \\mathbb{R}^d \\) ( \\( d \\ll D \\) ), such that \\( y_i = W^T x_i \\) “represents” \\( x_i \\).\n",
    "\n",
    "The two popular linear dimensionality reduction techniques are principal component analysis (PCA) and linear discriminant analysis (LDA).\n",
    "\n",
    "Let \\( C_x = \\frac{1}{n} \\sum_{i=1}^n x_i x_i^T \\) be the covariance matrix of the \\( n \\) data vectors \\( x_1, \\ldots, x_n \\), and \\( u_1, \\ldots, u_p \\) be \\( p \\) eigenvectors associated with principal eigenvalues of \\( C \\), where \\( p \\ll D \\). Then, the transformation matrix is given by \\( W = [u_1, \\ldots, u_p] \\in \\mathbb{R}^{n \\times p} \\) and the low-dimensional vectors \\( y_i = W^T x_i \\in \\mathbb{R}^p \\) are good representations of the high-dimensional data vectors \\( x_i \\).\n",
    "\n",
    "While PCA seeks directions that are efficient for data representation, LDA seeks directions that are efficient for data discrimination. Suppose the data points belong to \\( c \\) classes. To ensure the between-class separability and within-class compactness, the objective function of LDA is given by\n",
    "\n",
    "$$\n",
    "w_{\\text{opt}} = \\arg \\max_w \\frac{w^T S_b w}{w^T S_w w},\n",
    "$$\n",
    "\n",
    "where the between-class scatter matrix \\( S_b \\) and the within-class scatter matrix \\( S_w \\) are computed as\n",
    "\n",
    "$$\n",
    "S_b = \\sum_{i=1}^c n_i (m^{(i)} - m)(m^{(i)} - m)^T,\n",
    "$$\n",
    "\n",
    "$$\n",
    "S_w = \\sum_{i=1}^c \\sum_{j=1}^{n_i} (x_j^{(i)} - m^{(i)})(x_j^{(i)} - m^{(i)})^T,\n",
    "$$\n",
    "\n",
    "where \\( m \\) is the total sample mean vector, \\( n_i \\) is the number of samples in the \\( i \\)-th class, \\( m^{(i)} \\) is the mean vector of the \\( i \\)-th class, and \\( x_j^{(i)} \\) is the \\( j \\)-th sample vector in the \\( i \\)-th class.\n",
    "\n",
    "The LDA solution \\( w \\) is the generalized eigenvector associated with the maximum generalized eigenvalue of the matrix pencil \\( (S_b, S_w) \\). The transformation matrix \\( W \\) consists of \\( p \\) principal generalized eigenvectors associated with \\( p \\) principal generalized eigenvalues of \\( (S_b, S_w) \\).\n",
    "\n",
    "## Graph Embedding Techniques\n",
    "\n",
    "In the following, we focus on four graph embedding techniques: classical multidimensional scaling and three manifold learning techniques: isometric map, locally linear embedding, and Laplacian eigenmap.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66a491de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.82797019 -0.17511531]\n",
      " [-1.77758033  0.14285723]\n",
      " [ 0.99219749  0.38437499]\n",
      " [ 0.27421042  0.13041721]\n",
      " [ 1.67580142 -0.20949846]\n",
      " [ 0.9129491   0.17528244]\n",
      " [-0.09910944 -0.3498247 ]\n",
      " [-1.14457216  0.04641726]\n",
      " [-0.43804614  0.01776463]\n",
      " [-1.22382056 -0.16267529]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def pca(X, num_components):\n",
    "    # Center the data\n",
    "    X_centered = X - np.mean(X, axis=0)\n",
    "    \n",
    "    # Compute the covariance matrix\n",
    "    covariance_matrix = np.cov(X_centered, rowvar=False)\n",
    "    \n",
    "    # Compute the eigenvalues and eigenvectors\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(covariance_matrix)\n",
    "    \n",
    "    # Sort the eigenvalues and eigenvectors in descending order\n",
    "    sorted_index = np.argsort(eigenvalues)[::-1]\n",
    "    sorted_eigenvectors = eigenvectors[:, sorted_index]\n",
    "    \n",
    "    # Select the top num_components eigenvectors\n",
    "    eigenvector_subset = sorted_eigenvectors[:, :num_components]\n",
    "    \n",
    "    # Transform the data\n",
    "    X_reduced = np.dot(eigenvector_subset.T, X_centered.T).T\n",
    "    \n",
    "    return X_reduced\n",
    "\n",
    "# Example usage\n",
    "X = np.array([[2.5, 2.4], [0.5, 0.7], [2.2, 2.9], [1.9, 2.2], [3.1, 3.0], [2.3, 2.7], [2, 1.6], [1, 1.1], [1.5, 1.6], [1.1, 0.9]])\n",
    "num_components = 2\n",
    "X_reduced = pca(X, num_components)\n",
    "print(X_reduced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2771788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.20223353]\n",
      " [-0.93781825]\n",
      " [-0.82558442]\n",
      " [-1.40672737]\n",
      " [-1.42670118]\n",
      " [-3.32231149]\n",
      " [-2.36451943]\n",
      " [-2.76114236]\n",
      " [-2.74116854]\n",
      " [-3.34228531]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import eigh\n",
    "\n",
    "def lda(X, y, num_components):\n",
    "    class_labels = np.unique(y)\n",
    "    mean_overall = np.mean(X, axis=0)\n",
    "    \n",
    "    # Within-class scatter matrix\n",
    "    S_w = np.zeros((X.shape[1], X.shape[1]))\n",
    "    \n",
    "    # Between-class scatter matrix\n",
    "    S_b = np.zeros((X.shape[1], X.shape[1]))\n",
    "    \n",
    "    for c in class_labels:\n",
    "        X_c = X[y == c]\n",
    "        mean_c = np.mean(X_c, axis=0)\n",
    "        S_w += np.dot((X_c - mean_c).T, (X_c - mean_c))\n",
    "        n_c = X_c.shape[0]\n",
    "        mean_diff = (mean_c - mean_overall).reshape(-1, 1)\n",
    "        S_b += n_c * np.dot(mean_diff, mean_diff.T)\n",
    "    \n",
    "    # Solve the generalized eigenvalue problem\n",
    "    eigenvalues, eigenvectors = eigh(S_b, S_w)\n",
    "    \n",
    "    # Sort eigenvalues and eigenvectors in descending order\n",
    "    sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "    sorted_eigenvectors = eigenvectors[:, sorted_indices]\n",
    "    \n",
    "    # Select the top num_components eigenvectors\n",
    "    W = sorted_eigenvectors[:, :num_components]\n",
    "    \n",
    "    # Transform the data\n",
    "    X_lda = np.dot(X, W)\n",
    "    \n",
    "    return X_lda\n",
    "\n",
    "# Example usage\n",
    "X = np.array([[4.0, 2.0], [2.0, 4.0], [2.0, 3.0], [3.0, 6.0], [4.0, 4.0], [9.0, 10.0], [6.0, 8.0], [9.0, 5.0], [8.0, 7.0], [10.0, 8.0]])\n",
    "y = np.array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])\n",
    "num_components = 1\n",
    "X_lda = lda(X, y, num_components)\n",
    "print(X_lda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0923face",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.20094519  0.82111301]\n",
      " [ 0.48669236  0.44559953]\n",
      " [ 0.71425283 -1.26671255]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/radha/anaconda3/envs/cv37/lib/python3.7/site-packages/sklearn/manifold/_mds.py:518: UserWarning: The MDS API has changed. ``fit`` now constructs an dissimilarity matrix from data. To use a custom dissimilarity matrix, set ``dissimilarity='precomputed'``.\n",
      "  \"The MDS API has changed. ``fit`` now constructs an\"\n"
     ]
    }
   ],
   "source": [
    "# Classical Multidimensional Scaling (MDS)\n",
    "\n",
    "from sklearn.manifold import MDS\n",
    "\n",
    "def classical_mds(X, num_components):\n",
    "    mds = MDS(n_components=num_components, dissimilarity='euclidean')\n",
    "    X_mds = mds.fit_transform(X)\n",
    "    return X_mds\n",
    "\n",
    "# Example usage\n",
    "X = np.array([[0, 1, 2], [1, 0, 1], [2, 1, 0]])\n",
    "num_components = 2\n",
    "X_mds = classical_mds(X, num_components)\n",
    "print(X_mds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5b2876a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected n_neighbors <= n_samples,  but n_samples = 3, n_neighbors = 6",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5514/264045534.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mnum_components\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mX_isomap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misomap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_isomap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5514/264045534.py\u001b[0m in \u001b[0;36misomap\u001b[0;34m(X, num_components)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0misomap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0misomap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIsomap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mX_isomap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misomap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX_isomap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv37/lib/python3.7/site-packages/sklearn/manifold/_isomap.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mX\u001b[0m \u001b[0mtransformed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnew\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \"\"\"\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv37/lib/python3.7/site-packages/sklearn/manifold/_isomap.py\u001b[0m in \u001b[0;36m_fit_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mmetric_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"distance\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m             \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m         )\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv37/lib/python3.7/site-packages/sklearn/neighbors/_graph.py\u001b[0m in \u001b[0;36mkneighbors_graph\u001b[0;34m(X, n_neighbors, mode, metric, p, metric_params, include_self, n_jobs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_query_include_self\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv37/lib/python3.7/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors_graph\u001b[0;34m(self, X, n_neighbors, mode)\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"distance\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 886\u001b[0;31m             \u001b[0mA_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    887\u001b[0m             \u001b[0mA_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv37/lib/python3.7/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    727\u001b[0m             raise ValueError(\n\u001b[1;32m    728\u001b[0m                 \u001b[0;34m\"Expected n_neighbors <= n_samples, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0;34m\" but n_samples = %d, n_neighbors = %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_samples_fit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             )\n\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected n_neighbors <= n_samples,  but n_samples = 3, n_neighbors = 6"
     ]
    }
   ],
   "source": [
    "#Isometric Mapping (Isomap)\n",
    "from sklearn.manifold import Isomap\n",
    "\n",
    "def isomap(X, num_components):\n",
    "    isomap = Isomap(n_components=num_components)\n",
    "    X_isomap = isomap.fit_transform(X)\n",
    "    return X_isomap\n",
    "\n",
    "# Example usage\n",
    "X = np.array([[0, 1, 2], [1, 0, 1], [2, 1, 0]])\n",
    "num_components = 2\n",
    "X_isomap = isomap(X, num_components)\n",
    "print(X_isomap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74f802bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected n_neighbors <= n_samples,  but n_samples = 3, n_neighbors = 5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5514/1049766358.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mnum_components\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mX_lle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_lle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5514/1049766358.py\u001b[0m in \u001b[0;36mlle\u001b[0;34m(X, num_components)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLocallyLinearEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mX_lle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX_lle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv37/lib/python3.7/site-packages/sklearn/manifold/_locally_linear.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    765\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mitself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \"\"\"\n\u001b[0;32m--> 767\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    768\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv37/lib/python3.7/site-packages/sklearn/manifold/_locally_linear.py\u001b[0m in \u001b[0;36m_fit_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0mreg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m             \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m         )\n\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv37/lib/python3.7/site-packages/sklearn/manifold/_locally_linear.py\u001b[0m in \u001b[0;36mlocally_linear_embedding\u001b[0;34m(X, n_neighbors, n_components, reg, eigen_solver, tol, max_iter, method, hessian_tol, modified_tol, random_state, n_jobs)\u001b[0m\n\u001b[1;32m    320\u001b[0m         raise ValueError(\n\u001b[1;32m    321\u001b[0m             \u001b[0;34m\"Expected n_neighbors <= n_samples,  but n_samples = %d, n_neighbors = %d\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m             \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         )\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected n_neighbors <= n_samples,  but n_samples = 3, n_neighbors = 5"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "\n",
    "def lle(X, num_components):\n",
    "    lle = LocallyLinearEmbedding(n_components=num_components)\n",
    "    X_lle = lle.fit_transform(X)\n",
    "    return X_lle\n",
    "\n",
    "# Example usage\n",
    "X = np.array([[0, 1, 2], [1, 0, 1], [2, 1, 0]])\n",
    "num_components = 2\n",
    "X_lle = lle(X, num_components)\n",
    "print(X_lle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de338960",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module networkx has no attribute kneighbors_graph",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5514/430883180.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mnum_components\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mX_laplacian\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlaplacian_eigenmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_laplacian\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5514/430883180.py\u001b[0m in \u001b[0;36mlaplacian_eigenmap\u001b[0;34m(X, num_components, n_neighbors)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlaplacian_eigenmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Create the graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'connectivity'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_self\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaplacian_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv37/lib/python3.7/site-packages/networkx/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;34m\"This message will be removed in NetworkX 3.0.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         )\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"module {__name__} has no attribute {name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module networkx has no attribute kneighbors_graph"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "from scipy.sparse.linalg import eigsh\n",
    "\n",
    "def laplacian_eigenmap(X, num_components, n_neighbors=5):\n",
    "    # Create the graph\n",
    "    G = nx.kneighbors_graph(X, n_neighbors=n_neighbors, mode='connectivity', include_self=False)\n",
    "    L = nx.laplacian_matrix(G).astype(float)\n",
    "    \n",
    "    # Compute the eigenvalues and eigenvectors\n",
    "    eigenvalues, eigenvectors = eigsh(L, k=num_components + 1, which='SM')\n",
    "    \n",
    "    # Ignore the first eigenvector (eigenvalue=0)\n",
    "    X_laplacian = eigenvectors[:, 1:num_components + 1]\n",
    "    \n",
    "    return X_laplacian\n",
    "\n",
    "# Example usage\n",
    "X = np.array([[0, 1, 2], [1, 0, 1], [2, 1, 0]])\n",
    "num_components = 2\n",
    "X_laplacian = laplacian_eigenmap(X, num_components)\n",
    "print(X_laplacian)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2bfc2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Result:\n",
      " [[ 0.82797019 -0.17511531]\n",
      " [-1.77758033  0.14285723]\n",
      " [ 0.99219749  0.38437499]\n",
      " [ 0.27421042  0.13041721]\n",
      " [ 1.67580142 -0.20949846]\n",
      " [ 0.9129491   0.17528244]\n",
      " [-0.09910944 -0.3498247 ]\n",
      " [-1.14457216  0.04641726]\n",
      " [-0.43804614  0.01776463]\n",
      " [-1.22382056 -0.16267529]]\n",
      "LDA Result:\n",
      " [[2.]\n",
      " [4.]\n",
      " [6.]\n",
      " [4.]\n",
      " [2.]]\n",
      "Classical MDS Result:\n",
      " [[ 1.00000000e+00  7.73336626e-09]\n",
      " [ 0.00000000e+00 -5.66121702e-09]\n",
      " [-1.00000000e+00  7.73336626e-09]]\n"
     ]
    },
    {
     "ename": "OverflowError",
     "evalue": "cannot convert float infinity to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5514/2983695750.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0mnum_components_isomap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0mn_neighbors_isomap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m     \u001b[0mX_reduced_isomap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misomap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_isomap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_components_isomap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors_isomap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Isomap Result:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_reduced_isomap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5514/2983695750.py\u001b[0m in \u001b[0;36misomap\u001b[0;34m(D, num_components, n_neighbors)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m# Replace zero distances with a large number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_diagonal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m# Step 1: Construct the k-nearest neighbors graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mfill_diagonal\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/numpy/lib/index_tricks.py\u001b[0m in \u001b[0;36mfill_diagonal\u001b[0;34m(a, val, wrap)\u001b[0m\n\u001b[1;32m    907\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m     \u001b[0;31m# Write the value out into the diagonal.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m     \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOverflowError\u001b[0m: cannot convert float infinity to integer"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Principal Component Analysis (PCA)\n",
    "def pca(X, num_components):\n",
    "    X_centered = X - np.mean(X, axis=0)\n",
    "    covariance_matrix = np.cov(X_centered, rowvar=False)\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(covariance_matrix)\n",
    "    sorted_index = np.argsort(eigenvalues)[::-1]\n",
    "    sorted_eigenvectors = eigenvectors[:, sorted_index]\n",
    "    eigenvector_subset = sorted_eigenvectors[:, :num_components]\n",
    "    X_reduced = np.dot(X_centered, eigenvector_subset)\n",
    "    return X_reduced\n",
    "\n",
    "# Linear Discriminant Analysis (LDA)\n",
    "def lda(X, y, num_components):\n",
    "    class_labels = np.unique(y)\n",
    "    mean_overall = np.mean(X, axis=0)\n",
    "    S_w = np.zeros((X.shape[1], X.shape[1]))\n",
    "    S_b = np.zeros((X.shape[1], X.shape[1]))\n",
    "    for c in class_labels:\n",
    "        X_c = X[y == c]\n",
    "        mean_c = np.mean(X_c, axis=0)\n",
    "        S_w += np.dot((X_c - mean_c).T, (X_c - mean_c))\n",
    "        n_c = X_c.shape[0]\n",
    "        mean_diff = (mean_c - mean_overall).reshape(-1, 1)\n",
    "        S_b += n_c * np.dot(mean_diff, mean_diff.T)\n",
    "    eigvals, eigvecs = np.linalg.eig(np.linalg.inv(S_w).dot(S_b))\n",
    "    sorted_indices = np.argsort(eigvals)[::-1]\n",
    "    sorted_eigvecs = eigvecs[:, sorted_indices]\n",
    "    W = sorted_eigvecs[:, :num_components]\n",
    "    X_lda = np.dot(X, W)\n",
    "    return X_lda\n",
    "\n",
    "# Classical Multidimensional Scaling (MDS)\n",
    "def classical_mds(D, num_components):\n",
    "    n = D.shape[0]\n",
    "    H = np.eye(n) - np.ones((n, n)) / n\n",
    "    B = -0.5 * np.dot(H, np.dot(D ** 2, H))\n",
    "    eigvals, eigvecs = np.linalg.eigh(B)\n",
    "    sorted_indices = np.argsort(eigvals)[::-1]\n",
    "    sorted_eigvecs = eigvecs[:, sorted_indices]\n",
    "    sorted_eigvals = eigvals[sorted_indices]\n",
    "    L = np.diag(np.sqrt(sorted_eigvals[:num_components]))\n",
    "    V = sorted_eigvecs[:, :num_components]\n",
    "    Y = np.dot(V, L)\n",
    "    return Y\n",
    "\n",
    "# Isometric Mapping (Isomap)\n",
    "def isomap(D, num_components, n_neighbors):\n",
    "    n = D.shape[0]\n",
    "    \n",
    "    # Replace zero distances with a large number\n",
    "    np.fill_diagonal(D, np.inf)\n",
    "    \n",
    "    # Step 1: Construct the k-nearest neighbors graph\n",
    "    for i in range(n):\n",
    "        indices = np.argsort(D[i])[:n_neighbors + 1]\n",
    "        D[i, indices] = np.inf\n",
    "    \n",
    "    # Step 2: Compute shortest paths (Floyd-Warshall algorithm)\n",
    "    D = np.where(D == np.inf, 1e10, D)  # Replace inf with a large number\n",
    "    for k in range(n):\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                D[i, j] = min(D[i, j], D[i, k] + D[k, j])\n",
    "    \n",
    "    # Step 3: Compute the double centered matrix\n",
    "    H = np.eye(n) - np.ones((n, n)) / n\n",
    "    B = -0.5 * np.dot(H, np.dot(D ** 2, H))\n",
    "    \n",
    "    # Step 4: Compute eigenvalues and eigenvectors\n",
    "    eigvals, eigvecs = np.linalg.eigh(B)\n",
    "    sorted_indices = np.argsort(eigvals)[::-1]\n",
    "    sorted_eigvecs = eigvecs[:, sorted_indices]\n",
    "    sorted_eigvals = eigvals[sorted_indices]\n",
    "    \n",
    "    # Step 5: Construct the low-dimensional embedding\n",
    "    L = np.diag(np.sqrt(sorted_eigvals[:num_components]))\n",
    "    V = sorted_eigvecs[:, :num_components]\n",
    "    Y = np.dot(V, L)\n",
    "    return Y\n",
    "\n",
    "# Locally Linear Embedding (LLE)\n",
    "def lle(X, num_components, n_neighbors):\n",
    "    n, d = X.shape\n",
    "    W = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        distances = np.linalg.norm(X[i] - X, axis=1)\n",
    "        neighbors = np.argsort(distances)[1:n_neighbors + 1]\n",
    "        Z = X[neighbors] - X[i]\n",
    "        C = np.dot(Z, Z.T)\n",
    "        C_inv = np.linalg.inv(C)\n",
    "        w = np.sum(C_inv, axis=1) / np.sum(C_inv)\n",
    "        W[i, neighbors] = w\n",
    "    I = np.eye(n)\n",
    "    M = np.dot((I - W).T, (I - W))\n",
    "    eigvals, eigvecs = np.linalg.eigh(M)\n",
    "    sorted_indices = np.argsort(eigvals)[1:num_components + 1]\n",
    "    Y = eigvecs[:, sorted_indices]\n",
    "    return Y\n",
    "\n",
    "# Laplacian Eigenmap\n",
    "def laplacian_eigenmap(X, num_components, n_neighbors):\n",
    "    n = X.shape[0]\n",
    "    W = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        distances = np.linalg.norm(X[i] - X, axis=1)\n",
    "        neighbors = np.argsort(distances)[1:n_neighbors + 1]\n",
    "        W[i, neighbors] = np.exp(-distances[neighbors])\n",
    "    D = np.diag(np.sum(W, axis=1))\n",
    "    L = D - W\n",
    "    eigvals, eigvecs = np.linalg.eigh(L)\n",
    "    sorted_indices = np.argsort(eigvals)[1:num_components + 1]\n",
    "    Y = eigvecs[:, sorted_indices]\n",
    "    return Y\n",
    "\n",
    "# Example usage for each function\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage for PCA\n",
    "    X_pca = np.array([[2.5, 2.4], [0.5, 0.7], [2.2, 2.9], [1.9, 2.2], [3.1, 3.0], [2.3, 2.7], [2, 1.6], [1, 1.1], [1.5, 1.6], [1.1, 0.9]])\n",
    "    num_components_pca = 2\n",
    "    X_reduced_pca = pca(X_pca, num_components_pca)\n",
    "    print(\"PCA Result:\\n\", X_reduced_pca)\n",
    "\n",
    "    # Example usage for LDA\n",
    "    X_lda = np.array([[4.0, 2.0], [2.0, 4.0], [3.0, 6.0], [4.0, 4.0], [2.0, 2.0]])\n",
    "    y_lda = np.array([0, 0, 1, 1, 1])\n",
    "    num_components_lda = 1\n",
    "    X_reduced_lda = lda(X_lda, y_lda, num_components_lda)\n",
    "    print(\"LDA Result:\\n\", X_reduced_lda)\n",
    "\n",
    "    # Example usage for MDS\n",
    "    D_mds = np.array([[0, 1, 2], [1, 0, 1], [2, 1, 0]])\n",
    "    num_components_mds = 2\n",
    "    X_reduced_mds = classical_mds(D_mds, num_components_mds)\n",
    "    print(\"Classical MDS Result:\\n\", X_reduced_mds)\n",
    "\n",
    "    # Example usage for Isomap\n",
    "    D_isomap = np.array([[0, 1, 2], [1, 0, 1], [2, 1, 0]])\n",
    "    num_components_isomap = 2\n",
    "    n_neighbors_isomap = 2\n",
    "    X_reduced_isomap = isomap(D_isomap, num_components_isomap, n_neighbors_isomap)\n",
    "    print(\"Isomap Result:\\n\", X_reduced_isomap)\n",
    "\n",
    "    # Example usage for LLE\n",
    "    X_lle = np.array([[0, 0], [1, 0], [1, 1], [0, 1]])\n",
    "    num_components_lle = 1\n",
    "    n_neighbors_lle = 2\n",
    "    X_reduced_lle = lle(X_lle, num_components_lle, n_neighbors_lle)\n",
    "    print(\"LLE Result:\\n\", X_reduced_lle)\n",
    "\n",
    "    # Example usage for Laplacian Eigenmap\n",
    "    X_le = np.array([[0, 0], [1, 0], [1, 1], [0, 1]])\n",
    "    num_components_le = 1\n",
    "    n_neighbors_le = 2\n",
    "    X_reduced_le = laplacian_eigenmap(X_le, num_components_le, n_neighbors_le)\n",
    "    print(\"Laplacian Eigenmap Result:\\n\", X_reduced_le)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c772f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Result:\n",
      " [[ 0.82797019 -0.17511531]\n",
      " [-1.77758033  0.14285723]\n",
      " [ 0.99219749  0.38437499]\n",
      " [ 0.27421042  0.13041721]\n",
      " [ 1.67580142 -0.20949846]\n",
      " [ 0.9129491   0.17528244]\n",
      " [-0.09910944 -0.3498247 ]\n",
      " [-1.14457216  0.04641726]\n",
      " [-0.43804614  0.01776463]\n",
      " [-1.22382056 -0.16267529]]\n",
      "LDA Result:\n",
      " [[2.]\n",
      " [4.]\n",
      " [6.]\n",
      " [4.]\n",
      " [2.]]\n",
      "Classical MDS Result:\n",
      " [[ 1.00000000e+00  7.73336626e-09]\n",
      " [ 0.00000000e+00 -5.66121702e-09]\n",
      " [-1.00000000e+00  7.73336626e-09]]\n",
      "LLE Result:\n",
      " [[-0.40637379]\n",
      " [ 0.57867118]\n",
      " [ 0.40637379]\n",
      " [-0.57867118]]\n",
      "Laplacian Eigenmap Result:\n",
      " [[ 0.00000000e+00]\n",
      " [-7.07106781e-01]\n",
      " [ 2.13397690e-16]\n",
      " [ 7.07106781e-01]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Principal Component Analysis (PCA)\n",
    "def pca(X, num_components):\n",
    "    X_centered = X - np.mean(X, axis=0)\n",
    "    covariance_matrix = np.cov(X_centered, rowvar=False)\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(covariance_matrix)\n",
    "    sorted_index = np.argsort(eigenvalues)[::-1]\n",
    "    sorted_eigenvectors = eigenvectors[:, sorted_index]\n",
    "    eigenvector_subset = sorted_eigenvectors[:, :num_components]\n",
    "    X_reduced = np.dot(X_centered, eigenvector_subset)\n",
    "    return X_reduced\n",
    "\n",
    "# Linear Discriminant Analysis (LDA)\n",
    "def lda(X, y, num_components):\n",
    "    class_labels = np.unique(y)\n",
    "    mean_overall = np.mean(X, axis=0)\n",
    "    S_w = np.zeros((X.shape[1], X.shape[1]))\n",
    "    S_b = np.zeros((X.shape[1], X.shape[1]))\n",
    "    for c in class_labels:\n",
    "        X_c = X[y == c]\n",
    "        mean_c = np.mean(X_c, axis=0)\n",
    "        S_w += np.dot((X_c - mean_c).T, (X_c - mean_c))\n",
    "        n_c = X_c.shape[0]\n",
    "        mean_diff = (mean_c - mean_overall).reshape(-1, 1)\n",
    "        S_b += n_c * np.dot(mean_diff, mean_diff.T)\n",
    "    eigvals, eigvecs = np.linalg.eig(np.linalg.inv(S_w).dot(S_b))\n",
    "    sorted_indices = np.argsort(eigvals)[::-1]\n",
    "    sorted_eigvecs = eigvecs[:, sorted_indices]\n",
    "    W = sorted_eigvecs[:, :num_components]\n",
    "    X_lda = np.dot(X, W)\n",
    "    return X_lda\n",
    "\n",
    "# Classical Multidimensional Scaling (MDS)\n",
    "def classical_mds(D, num_components):\n",
    "    n = D.shape[0]\n",
    "    H = np.eye(n) - np.ones((n, n)) / n\n",
    "    B = -0.5 * np.dot(H, np.dot(D ** 2, H))\n",
    "    eigvals, eigvecs = np.linalg.eigh(B)\n",
    "    sorted_indices = np.argsort(eigvals)[::-1]\n",
    "    sorted_eigvecs = eigvecs[:, sorted_indices]\n",
    "    sorted_eigvals = eigvals[sorted_indices]\n",
    "    L = np.diag(np.sqrt(sorted_eigvals[:num_components]))\n",
    "    V = sorted_eigvecs[:, :num_components]\n",
    "    Y = np.dot(V, L)\n",
    "    return Y\n",
    "\n",
    "# Isometric Mapping (Isomap)\n",
    "def isomap(D, num_components, n_neighbors):\n",
    "    n = D.shape[0]\n",
    "    \n",
    "    # Replace zero distances with a large number\n",
    "    np.fill_diagonal(D, np.inf)\n",
    "    \n",
    "    # Step 1: Construct the k-nearest neighbors graph\n",
    "    for i in range(n):\n",
    "        indices = np.argsort(D[i])[:n_neighbors + 1]\n",
    "        D[i, indices] = np.inf\n",
    "    \n",
    "    # Step 2: Compute shortest paths (Floyd-Warshall algorithm)\n",
    "    D = np.where(D == np.inf, 1e10, D)  # Replace inf with a large number\n",
    "    for k in range(n):\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                if D[i, j] > D[i, k] + D[k, j]:\n",
    "                    D[i, j] = D[i, k] + D[k, j]\n",
    "    \n",
    "    # Step 3: Compute the double centered matrix\n",
    "    H = np.eye(n) - np.ones((n, n)) / n\n",
    "    B = -0.5 * np.dot(H, np.dot(D ** 2, H))\n",
    "    \n",
    "    # Step 4: Compute eigenvalues and eigenvectors\n",
    "    eigvals, eigvecs = np.linalg.eigh(B)\n",
    "    sorted_indices = np.argsort(eigvals)[::-1]\n",
    "    sorted_eigvecs = eigvecs[:, sorted_indices]\n",
    "    sorted_eigvals = eigvals[sorted_indices]\n",
    "    \n",
    "    # Step 5: Construct the low-dimensional embedding\n",
    "    L = np.diag(np.sqrt(sorted_eigvals[:num_components]))\n",
    "    V = sorted_eigvecs[:, :num_components]\n",
    "    Y = np.dot(V, L)\n",
    "    return Y\n",
    "\n",
    "# Locally Linear Embedding (LLE)\n",
    "def lle(X, num_components, n_neighbors):\n",
    "    n, d = X.shape\n",
    "    W = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        distances = np.linalg.norm(X[i] - X, axis=1)\n",
    "        neighbors = np.argsort(distances)[1:n_neighbors + 1]\n",
    "        Z = X[neighbors] - X[i]\n",
    "        C = np.dot(Z, Z.T)\n",
    "        C_inv = np.linalg.inv(C)\n",
    "        w = np.sum(C_inv, axis=1) / np.sum(C_inv)\n",
    "        W[i, neighbors] = w\n",
    "    I = np.eye(n)\n",
    "    M = np.dot((I - W).T, (I - W))\n",
    "    eigvals, eigvecs = np.linalg.eigh(M)\n",
    "    sorted_indices = np.argsort(eigvals)[1:num_components + 1]\n",
    "    Y = eigvecs[:, sorted_indices]\n",
    "    return Y\n",
    "\n",
    "# Laplacian Eigenmap\n",
    "def laplacian_eigenmap(X, num_components, n_neighbors):\n",
    "    n = X.shape[0]\n",
    "    W = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        distances = np.linalg.norm(X[i] - X, axis=1)\n",
    "        neighbors = np.argsort(distances)[1:n_neighbors + 1]\n",
    "        W[i, neighbors] = np.exp(-distances[neighbors])\n",
    "    D = np.diag(np.sum(W, axis=1))\n",
    "    L = D - W\n",
    "    eigvals, eigvecs = np.linalg.eigh(L)\n",
    "    sorted_indices = np.argsort(eigvals)[1:num_components + 1]\n",
    "    Y = eigvecs[:, sorted_indices]\n",
    "    return Y\n",
    "\n",
    "# Example usage for each function\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage for PCA\n",
    "    X_pca = np.array([[2.5, 2.4], [0.5, 0.7], [2.2, 2.9], [1.9, 2.2], [3.1, 3.0], [2.3, 2.7], [2, 1.6], [1, 1.1], [1.5, 1.6], [1.1, 0.9]])\n",
    "    num_components_pca = 2\n",
    "    X_reduced_pca = pca(X_pca, num_components_pca)\n",
    "    print(\"PCA Result:\\n\", X_reduced_pca)\n",
    "\n",
    "    # Example usage for LDA\n",
    "    X_lda = np.array([[4.0, 2.0], [2.0, 4.0], [3.0, 6.0], [4.0, 4.0], [2.0, 2.0]])\n",
    "    y_lda = np.array([0, 0, 1, 1, 1])\n",
    "    num_components_lda = 1\n",
    "    X_reduced_lda = lda(X_lda, y_lda, num_components_lda)\n",
    "    print(\"LDA Result:\\n\", X_reduced_lda)\n",
    "\n",
    "    # Example usage for MDS\n",
    "    D_mds = np.array([[0, 1, 2], [1, 0, 1], [2, 1, 0]])\n",
    "    num_components_mds = 2\n",
    "    X_reduced_mds = classical_mds(D_mds, num_components_mds)\n",
    "    print(\"Classical MDS Result:\\n\", X_reduced_mds)\n",
    "\n",
    "    # Example usage for Isomap\n",
    "#     D_isomap = np.array([[0, 1, 2], [1, 0, 1], [2, 1, 0]])\n",
    "#     num_components_isomap = 2\n",
    "#     n_neighbors_isomap = 2\n",
    "#     X_reduced_isomap = isomap(D_isomap, num_components_isomap, n_neighbors_isomap)\n",
    "#     print(\"Isomap Result:\\n\", X_reduced_isomap)\n",
    "\n",
    "    # Example usage for LLE\n",
    "    X_lle = np.array([[0, 0], [1, 0], [1, 1], [0, 1]])\n",
    "    num_components_lle = 1\n",
    "    n_neighbors_lle = 2\n",
    "    X_reduced_lle = lle(X_lle, num_components_lle, n_neighbors_lle)\n",
    "    print(\"LLE Result:\\n\", X_reduced_lle)\n",
    "\n",
    "    # Example usage for Laplacian Eigenmap\n",
    "    X_le = np.array([[0, 0], [1, 0], [1, 1], [0, 1]])\n",
    "    num_components_le = 1\n",
    "    n_neighbors_le = 2\n",
    "    X_reduced_le = laplacian_eigenmap(X_le, num_components_le, n_neighbors_le)\n",
    "    print(\"Laplacian Eigenmap Result:\\n\", X_reduced_le)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54d5d864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isomap Result:\n",
      " [[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def isomap(D, num_components, n_neighbors):\n",
    "    n = D.shape[0]\n",
    "    \n",
    "    # Replace diagonal with a large number\n",
    "    np.fill_diagonal(D, np.inf)\n",
    "    \n",
    "    # Step 1: Construct the k-nearest neighbors graph\n",
    "    for i in range(n):\n",
    "        # Get indices of the nearest neighbors\n",
    "        nearest_neighbors = np.argsort(D[i])[:n_neighbors + 1]\n",
    "        # Set non-nearest neighbors to infinity\n",
    "        D[i, nearest_neighbors] = np.inf\n",
    "    \n",
    "    # Step 2: Compute shortest paths (Floyd-Warshall algorithm)\n",
    "    D = np.where(D == np.inf, 1e10, D)  # Replace inf with a large number\n",
    "    for k in range(n):\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                if D[i, j] > D[i, k] + D[k, j]:\n",
    "                    D[i, j] = D[i, k] + D[k, j]\n",
    "    \n",
    "    # Step 3: Double center the distance matrix\n",
    "    H = np.eye(n) - np.ones((n, n)) / n\n",
    "    B = -0.5 * np.dot(H, np.dot(D ** 2, H))\n",
    "    \n",
    "    # Step 4: Compute eigenvalues and eigenvectors\n",
    "    eigvals, eigvecs = np.linalg.eigh(B)\n",
    "    sorted_indices = np.argsort(eigvals)[::-1]\n",
    "    sorted_eigvecs = eigvecs[:, sorted_indices]\n",
    "    sorted_eigvals = eigvals[sorted_indices]\n",
    "    \n",
    "    # Step 5: Construct the low-dimensional embedding\n",
    "    L = np.diag(np.sqrt(sorted_eigvals[:num_components]))\n",
    "    V = sorted_eigvecs[:, :num_components]\n",
    "    Y = np.dot(V, L)\n",
    "    \n",
    "    return Y\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Example distance matrix (replace with your actual distances)\n",
    "    D_isomap = np.array([[0, 2, 1, np.inf],\n",
    "                         [2, 0, 2, 3],\n",
    "                         [1, 2, 0, 1],\n",
    "                         [np.inf, 3, 1, 0]])\n",
    "    \n",
    "    num_components_isomap = 2\n",
    "    n_neighbors_isomap = 2\n",
    "    \n",
    "    X_reduced_isomap = isomap(D_isomap, num_components_isomap, n_neighbors_isomap)\n",
    "    print(\"Isomap Result:\\n\", X_reduced_isomap)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488e884d",
   "metadata": {},
   "source": [
    "### Multidimensional Scaling (MDS)\n",
    "\n",
    "We are given \\( n \\) points \\( \\mathbf{x}_1, \\ldots, \\mathbf{x}_n \\) with \\( \\mathbf{x}_i \\in \\mathbb{R}^D \\). While a configuration is considered as \\( n \\) points in the model space, one may with equal validity consider it as a single point\n",
    "$$\n",
    "\\left(\\mathbf{x}_{11}, \\ldots, \\mathbf{x}_{1D}, \\ldots, \\mathbf{x}_{n1}, \\ldots, \\mathbf{x}_{nD}\\right).\n",
    "$$\n",
    "\n",
    "Let \\( d_{ij} \\) denote the distance between nodes \\( i \\) and \\( j \\), and \\( s_{ij} \\) be a measure of the similarity between them. For example, a measure of the psychological similarity of two stimuli in a paired-associate experiment is given by\n",
    "$$\n",
    "s_{ij} = \\frac{p_{ij} p_{ji}}{p_{ii} p_{jj}},\n",
    "$$\n",
    "where \\( p_{ij} \\) is the empirical estimate of the conditional probability of the response assigned to stimulus \\( j \\) when stimulus \\( i \\) is presented.\n",
    "\n",
    "Another example of the similarity data \\( s \\) is\n",
    "$$\n",
    "s_{ij} = \\sum_{k=1}^{K} w_k \\cdot p_{ik} \\cdot p_{jk},\n",
    "$$\n",
    "where \\( w_k \\) are the positive psychological weights of the discrete properties that both stimuli have in common, and\n",
    "$$\n",
    "p_{ik} = \\begin{cases} \n",
    "1 & \\text{if object } i \\text{ has property } k, \\\\\n",
    "0 & \\text{otherwise}.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Define the normalized stress by\n",
    "$$\n",
    "S^* = \\frac{\\sum_{i<j} (d_{ij} - \\hat{d}_{ij})^2}{\\sum_{i<j} d_{ij}^2},\n",
    "$$\n",
    "where \\( \\hat{d}_{ij} \\) are numbers that are monotonic with the similarity data \\( s_{ij} \\) and minimize stress relative to the spatial distance \\( d_{ij} \\) at each iteration.\n",
    "\n",
    "Suppose now that the values of \\( s_{ij} \\) are given. Then for any point in configuration space, that is, for any configuration, there is a definite stress value \\( S \\). In other words,\n",
    "$$\n",
    "S = S \\left(\\mathbf{x}_{11}, \\ldots, \\mathbf{x}_{1D}, \\ldots, \\mathbf{x}_{n1}, \\ldots, \\mathbf{x}_{nD}\\right),\n",
    "$$\n",
    "defined on the points of configuration space. The multidimensional scaling (MDS) problem is to find that point which minimizes \\( S \\). This is a standard problem of numerical analysis: to minimize a function of several variables.\n",
    "\n",
    "#### Verbal Evaluation\n",
    "\n",
    "The following is the verbal evaluation suggested:\n",
    "$$\n",
    "\\begin{array}{ccc}\n",
    "\\text{Stress} & 20\\% & 10\\% & 5\\% & 2.5\\% & 0\\% \\\\\n",
    "\\text{Goodness of fit} & \\text{poor} & \\text{fair} & \\text{good} & \\text{excellent} & \\text{\"perfect\"} \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "By \"perfect\" here, it means only that there is a perfect monotone relationship between dissimilarities and the distances.\n",
    "\n",
    "#### Gradient Descent\n",
    "\n",
    "In the method of steepest descent, the (negative) gradient is given by\n",
    "$$\n",
    "-\\left(\\frac{\\partial S}{\\partial x_{11}}, \\ldots, \\frac{\\partial S}{\\partial x_{1d}}, \\ldots, \\frac{\\partial S}{\\partial x_{n1}}, \\ldots, \\frac{\\partial S}{\\partial x_{nd}}\\right).\n",
    "$$\n",
    "\n",
    "For Minkowski \\( p \\)-metric, the (negative) gradient terms \\( g_{kl} = -\\frac{\\partial S}{\\partial x_{kl}} \\) are given by\n",
    "$$\n",
    "g_{kl} = -\\frac{(\\delta_{ki} \\delta_{jk})}{S^*} \\cdot \\frac{d_{ij} - \\hat{d}_{ij}}{d_{ij}} \\cdot |x_{il} - x_{jl}|^{p-1} \\cdot \\text{sign}(x_{il} - x_{jl}),\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\text{sign}(x) = \\begin{cases} \n",
    "+1 & \\text{if } x > 0, \\\\\n",
    "-1 & \\text{if } x < 0, \\\\\n",
    "0 & \\text{if } x = 0.\n",
    "\\end{cases}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39567ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, Stress: 61.0394605024817\n",
      "Iteration 2, Stress: 46.24723172025696\n",
      "Iteration 3, Stress: 37.54232121775829\n",
      "Iteration 4, Stress: 31.742186112309685\n",
      "Iteration 5, Stress: 27.581077401037422\n",
      "Iteration 6, Stress: 24.442532253288306\n",
      "Iteration 7, Stress: 21.98727307085971\n",
      "Iteration 8, Stress: 20.012196306465306\n",
      "Iteration 9, Stress: 18.387921354192894\n",
      "Iteration 10, Stress: 17.027967749185773\n",
      "Iteration 11, Stress: 15.87226127431527\n",
      "Iteration 12, Stress: 14.877732044977009\n",
      "Iteration 13, Stress: 14.012674869270063\n",
      "Iteration 14, Stress: 13.253220789932689\n",
      "Iteration 15, Stress: 12.58104976699037\n",
      "Iteration 16, Stress: 11.981862270984315\n",
      "Iteration 17, Stress: 11.444330823204623\n",
      "Iteration 18, Stress: 10.959364065780022\n",
      "Iteration 19, Stress: 10.519579625982104\n",
      "Iteration 20, Stress: 10.11891966841622\n",
      "Iteration 21, Stress: 9.75236594789635\n",
      "Iteration 22, Stress: 9.415725515730351\n",
      "Iteration 23, Stress: 9.105467422562068\n",
      "Iteration 24, Stress: 8.818596779814111\n",
      "Iteration 25, Stress: 8.552556561523813\n",
      "Iteration 26, Stress: 8.305150261195232\n",
      "Iteration 27, Stress: 8.074480406676903\n",
      "Iteration 28, Stress: 7.858899260573983\n",
      "Iteration 29, Stress: 7.65696897555302\n",
      "Iteration 30, Stress: 7.467429152208402\n",
      "Iteration 31, Stress: 7.289170241458474\n",
      "Iteration 32, Stress: 7.121211597610539\n",
      "Iteration 33, Stress: 6.962683259286663\n",
      "Iteration 34, Stress: 6.812810739080342\n",
      "Iteration 35, Stress: 6.67090225723753\n",
      "Iteration 36, Stress: 6.536337972722142\n",
      "Iteration 37, Stress: 6.408560856009234\n",
      "Iteration 38, Stress: 6.287068918585659\n",
      "Iteration 39, Stress: 6.17140856936309\n",
      "Iteration 40, Stress: 6.061168911672658\n",
      "Iteration 41, Stress: 5.955976828933698\n",
      "Iteration 42, Stress: 5.855492734514977\n",
      "Iteration 43, Stress: 5.75940688328177\n",
      "Iteration 44, Stress: 5.66743616002449\n",
      "Iteration 45, Stress: 5.579321274298323\n",
      "Iteration 46, Stress: 5.49482430286649\n",
      "Iteration 47, Stress: 5.413726530473833\n",
      "Iteration 48, Stress: 5.3358265475066045\n",
      "Iteration 49, Stress: 5.260938569550007\n",
      "Iteration 50, Stress: 5.188890949200896\n",
      "Iteration 51, Stress: 5.119524854936394\n",
      "Iteration 52, Stress: 5.0526930955468625\n",
      "Iteration 53, Stress: 4.988259071746275\n",
      "Iteration 54, Stress: 4.926095839181862\n",
      "Iteration 55, Stress: 4.866085269264275\n",
      "Iteration 56, Stress: 4.8081172960999154\n",
      "Iteration 57, Stress: 4.752089239385122\n",
      "Iteration 58, Stress: 4.697905194465052\n",
      "Iteration 59, Stress: 4.645475481905997\n",
      "Iteration 60, Stress: 4.59471614991064\n",
      "Iteration 61, Stress: 4.545548523747178\n",
      "Iteration 62, Stress: 4.4978987970870525\n",
      "Iteration 63, Stress: 4.451697660770281\n",
      "Iteration 64, Stress: 4.406879965056984\n",
      "Iteration 65, Stress: 4.363384411891228\n",
      "Iteration 66, Stress: 4.321153274109423\n",
      "Iteration 67, Stress: 4.280132138878807\n",
      "Iteration 68, Stress: 4.240269672959901\n",
      "Iteration 69, Stress: 4.201517407656107\n",
      "Iteration 70, Stress: 4.163829541549594\n",
      "Iteration 71, Stress: 4.127162759329621\n",
      "Iteration 72, Stress: 4.091476065201335\n",
      "Iteration 73, Stress: 4.056730629523504\n",
      "Iteration 74, Stress: 4.022889647464821\n",
      "Iteration 75, Stress: 3.9899182085935845\n",
      "Iteration 76, Stress: 3.9577831764260654\n",
      "Iteration 77, Stress: 3.9264530770569777\n",
      "Iteration 78, Stress: 3.895897996082624\n",
      "Iteration 79, Stress: 3.8660894831047754\n",
      "Iteration 80, Stress: 3.837000463172359\n",
      "Iteration 81, Stress: 3.808605154579636\n",
      "Iteration 82, Stress: 3.7808789924946145\n",
      "Iteration 83, Stress: 3.7537985579405984\n",
      "Iteration 84, Stress: 3.7273415116979995\n",
      "Iteration 85, Stress: 3.7014865327330004\n",
      "Iteration 86, Stress: 3.676213260795293\n",
      "Iteration 87, Stress: 3.651502242859037\n",
      "Iteration 88, Stress: 3.627334883110012\n",
      "Iteration 89, Stress: 3.603693396207868\n",
      "Iteration 90, Stress: 3.5805607635758494\n",
      "Iteration 91, Stress: 3.557920692491516\n",
      "Iteration 92, Stress: 3.5357575777711703\n",
      "Iteration 93, Stress: 3.5140564658580264\n",
      "Iteration 94, Stress: 3.492803021139961\n",
      "Iteration 95, Stress: 3.471983494336876\n",
      "Iteration 96, Stress: 3.451584692810776\n",
      "Iteration 97, Stress: 3.4315939526634107\n",
      "Iteration 98, Stress: 3.411999112497113\n",
      "Iteration 99, Stress: 3.3927884887242366\n",
      "Iteration 100, Stress: 3.373950852319566\n",
      "Final configuration:\n",
      "[[-1.7054968   4.90987879]\n",
      " [-0.80745448 -1.11369311]\n",
      " [-7.6226792  11.81520683]\n",
      " [-0.31176503  2.00608241]\n",
      " [ 2.13182354  3.89152619]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def euclidean_distance(X):\n",
    "    \"\"\"Compute the Euclidean distance matrix.\"\"\"\n",
    "    return np.sqrt(((X[:, np.newaxis] - X) ** 2).sum(axis=2))\n",
    "\n",
    "def similarity_to_distance(sij, method='inverse'):\n",
    "    \"\"\"Convert similarity to distance based on the chosen method.\"\"\"\n",
    "    if method == 'inverse':\n",
    "        # Example conversion: distance = 1 / similarity\n",
    "        return 1 / sij\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported method for similarity to distance conversion\")\n",
    "\n",
    "def stress(dij, d_hat_ij):\n",
    "    \"\"\"Compute the stress value given the distances and their approximations.\"\"\"\n",
    "    numerator = np.sum((dij - d_hat_ij) ** 2)\n",
    "    denominator = np.sum(dij ** 2)\n",
    "    return numerator / denominator\n",
    "\n",
    "def compute_gradient(X, dij, d_hat_ij, p=2):\n",
    "    \"\"\"Compute the gradient of the stress function.\"\"\"\n",
    "    n = X.shape[0]\n",
    "    grad = np.zeros_like(X)\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i != j:\n",
    "                d = dij[i, j]\n",
    "                d_hat = d_hat_ij[i, j]\n",
    "                dist_diff = d - d_hat\n",
    "                grad[i] += 2 * dist_diff * (X[i] - X[j]) / (d ** p)\n",
    "    \n",
    "    return grad\n",
    "\n",
    "def mds(X, sij, num_components, num_iterations=1000, learning_rate=0.01, p=2):\n",
    "    \"\"\"Perform Multidimensional Scaling using gradient descent.\"\"\"\n",
    "    n = X.shape[0]\n",
    "    dij = euclidean_distance(X)\n",
    "    d_hat_ij = similarity_to_distance(sij)\n",
    "    \n",
    "    for _ in range(num_iterations):\n",
    "        current_stress = stress(dij, d_hat_ij)\n",
    "        grad = compute_gradient(X, dij, d_hat_ij, p)\n",
    "        \n",
    "        # Update the configuration\n",
    "        X -= learning_rate * grad\n",
    "        \n",
    "        # Recompute distances\n",
    "        dij = euclidean_distance(X)\n",
    "        \n",
    "        # Update stress value\n",
    "        d_hat_ij = similarity_to_distance(sij)\n",
    "        new_stress = stress(dij, d_hat_ij)\n",
    "        \n",
    "        # Debugging output\n",
    "        print(f\"Iteration {_+1}, Stress: {new_stress}\")\n",
    "        \n",
    "    return X\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Example data\n",
    "    n = 5  # number of points\n",
    "    D = 2  # dimensionality of the configuration space\n",
    "    X_initial = np.random.rand(n, D)\n",
    "    \n",
    "    # Example similarity matrix\n",
    "    sij = np.random.rand(n, n)  # Symmetric matrix of similarities\n",
    "    np.fill_diagonal(sij, 1)  # Similarity to itself is 1\n",
    "    \n",
    "    num_components = 2\n",
    "    num_iterations = 100\n",
    "    learning_rate = 0.01\n",
    "\n",
    "    X_reduced = mds(X_initial, sij, num_components, num_iterations, learning_rate)\n",
    "    print(\"Final configuration:\")\n",
    "    print(X_reduced)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbfcf52",
   "metadata": {},
   "source": [
    "# Manifold Learning: Isometric Map\n",
    "# Isomap Algorithm\n",
    "\n",
    "Given \\( n \\) points \\( x_1, \\ldots, x_n \\) in a high-dimensional vector space \\( \\mathbb{R}^D \\), our goal is to find a set of points \\( y_1, \\ldots, y_n \\) in a low-dimensional space \\( \\mathbb{R}^d \\) (where \\( d \\ll D \\)) such that each low-dimensional point \\( y_i \\) represents the corresponding high-dimensional point \\( x_i \\). This process is known as manifold learning, which aims to extract low-dimensional features from high-dimensional data.\n",
    "\n",
    "## Steps of the Isomap Algorithm\n",
    "\n",
    "### 1. Construct the Neighborhood Graph \\( G(V, E) \\)\n",
    "\n",
    "Construct the graph of observed data points \\( \\{ x_i \\} \\) as follows:\n",
    "\n",
    "- **\\( k \\)-nearest neighbor (k-Isomap)**: Include an edge \\( e = (i, j) \\) if and only if \\( x_j \\) is one of the \\( k \\)-nearest neighbors of \\( x_i \\) (and vice versa). This results in a directed graph.\n",
    "\n",
    "- **\\( \\epsilon \\)-neighborhood (\\( \\epsilon \\)-Isomap)**: Include an edge \\( e = (i, j) \\) if and only if \\( \\| x_i - x_j \\|^2 < \\epsilon \\) for some \\( \\epsilon \\). This results in an undirected graph.\n",
    "\n",
    "### 2. Compute Shortest Paths in the Graph\n",
    "\n",
    "Initialize the distance matrix \\( d_G(i, j) \\) as follows:\n",
    "\n",
    "$$\n",
    "d_G(i, j) =\n",
    "\\begin{cases}\n",
    "d_x(i, j), & \\text{if } i \\text{ and } j \\text{ are linked by an edge} \\\\\n",
    "\\infty, & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Update all entries using:\n",
    "\n",
    "$$\n",
    "d_G(i, j) = \\min \\{ d_G(i, j), d_G(i, k) + d_G(k, j) \\}\n",
    "$$\n",
    "\n",
    "for each \\( k = 1, 2, \\ldots, n \\). The matrix of final values \\( D_G = [d_G(i, j)] \\) will contain the shortest path distances between all pairs of points in \\( G(V, E) \\).\n",
    "\n",
    "### 3. Construct d-dimensional Embedding\n",
    "\n",
    "Let \\( \\lambda_p \\) be the \\( p \\)-th eigenvalue (in decreasing order) of the matrix \\( D_G \\), and \\( v_p(i) \\) be the \\( i \\)-th component of the \\( p \\)-th eigenvector \\( v_p \\). Then set the \\( p \\)-th component of the \\( d \\)-dimensional coordinate vector \\( y_i \\) equal to \\( \\lambda_p v_p(i) \\):\n",
    "\n",
    "$$\n",
    "y_i(p) = \\lambda_p v_p(i)\n",
    "$$\n",
    "\n",
    "Apply classical multidimensional scaling (MDS) to the matrix of graph distances \\( D_G \\) to construct an embedding in a \\( d \\)-dimensional Euclidean space \\( Y \\) that best preserves the manifold’s estimated intrinsic geometry. The coordinate vectors \\( y_i \\) are chosen to minimize the cost function:\n",
    "\n",
    "$$\n",
    "E = \\| D_G - D_Y \\|_F^2\n",
    "$$\n",
    "\n",
    "where \\( D_Y \\) denotes the matrix of Euclidean distances with entries \\( d_Y(i, j) = \\| y_i - y_j \\|^2 \\). The global minimum of \\( E \\) is achieved by setting the coordinates \\( y_i \\) to the top \\( d \\) eigenvectors of the matrix \\( D_G \\).\n",
    "\n",
    "# Conformal Isomap (C-Isomap)\n",
    "\n",
    "Conformal Isomap (C-Isomap) is an extension of Isomap designed to handle curved manifolds.\n",
    "\n",
    "### Modified Step 2: Compute Shortest Paths with Conformal Scaling\n",
    "\n",
    "Each edge \\( (i, j) \\) in the graph is weighted by:\n",
    "\n",
    "$$\n",
    "\\frac{\\| x_j - x_i \\|}{\\sqrt{M(i) M(j)}}\n",
    "$$\n",
    "\n",
    "where \\( M(i) \\) is the mean distance of \\( x_i \\) to its \\( k \\)-nearest neighbors. The rescaling factor \\( \\sqrt{M(i) M(j)} \\) provides an asymptotically accurate approximation to the conformal scaling factor in the neighborhood of \\( x_i \\) and \\( x_j \\).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38e3092c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low-dimensional embedding:\n",
      "[[-0.70781737  0.20215371]\n",
      " [-0.12658206 -0.48071604]\n",
      " [-0.93330675  0.08691077]\n",
      " [-0.23632343 -0.17376239]\n",
      " [ 0.23838111 -0.18078864]\n",
      " [ 0.04306687  0.16606512]\n",
      " [ 0.96407763  0.04178581]\n",
      " [ 0.49284497  0.19564813]\n",
      " [ 0.31527054  0.07839144]\n",
      " [-0.04961151  0.06431208]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from itertools import combinations\n",
    "\n",
    "def euclidean_distance(xi, xj):\n",
    "    \"\"\"Compute the Euclidean distance between two points.\"\"\"\n",
    "    return np.sqrt(np.sum((xi - xj) ** 2))\n",
    "\n",
    "def construct_graph(X, k):\n",
    "    \"\"\"Construct the k-nearest neighbor graph.\"\"\"\n",
    "    n = X.shape[0]\n",
    "    graph = np.inf * np.ones((n, n))\n",
    "    for i in range(n):\n",
    "        distances = [(j, euclidean_distance(X[i], X[j])) for j in range(n) if i != j]\n",
    "        distances.sort(key=lambda x: x[1])\n",
    "        for j, dist in distances[:k]:\n",
    "            graph[i, j] = dist\n",
    "            graph[j, i] = dist\n",
    "    return graph\n",
    "\n",
    "def compute_shortest_paths(graph):\n",
    "    \"\"\"Compute the shortest paths using Floyd-Warshall algorithm.\"\"\"\n",
    "    n = graph.shape[0]\n",
    "    dist = np.copy(graph)\n",
    "    for k in range(n):\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                if dist[i, j] > dist[i, k] + dist[k, j]:\n",
    "                    dist[i, j] = dist[i, k] + dist[k, j]\n",
    "    return dist\n",
    "\n",
    "def classical_mds(D, d):\n",
    "    \"\"\"Perform classical MDS to get the low-dimensional embedding.\"\"\"\n",
    "    n = D.shape[0]\n",
    "    H = np.eye(n) - np.ones((n, n)) / n\n",
    "    B = -0.5 * H @ (D ** 2) @ H\n",
    "    eigvals, eigvecs = np.linalg.eigh(B)\n",
    "    idx = np.argsort(eigvals)[::-1]\n",
    "    eigvals = eigvals[idx]\n",
    "    eigvecs = eigvecs[:, idx]\n",
    "    Y = eigvecs[:, :d] @ np.diag(np.sqrt(eigvals[:d]))\n",
    "    return Y\n",
    "\n",
    "def isomap(X, num_components, k):\n",
    "    \"\"\"Perform Isomap algorithm.\"\"\"\n",
    "    # Step 1: Construct the k-nearest neighbor graph\n",
    "    graph = construct_graph(X, k)\n",
    "    \n",
    "    # Step 2: Compute shortest paths\n",
    "    D = compute_shortest_paths(graph)\n",
    "    \n",
    "    # Step 3: Perform classical MDS\n",
    "    Y = classical_mds(D, num_components)\n",
    "    return Y\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate synthetic high-dimensional data\n",
    "    np.random.seed(42)\n",
    "    X = np.random.rand(10, 5)  # 10 points in 5 dimensions\n",
    "    \n",
    "    num_components = 2  # Reduce to 2 dimensions\n",
    "    k = 3  # Number of nearest neighbors\n",
    "\n",
    "    # Run Isomap\n",
    "    Y = isomap(X, num_components, k)\n",
    "    \n",
    "    print(\"Low-dimensional embedding:\")\n",
    "    print(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad897a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
