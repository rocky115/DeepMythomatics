{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ab1131",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " * Copyright (c) 2018 Radhamadhab Dalai\n",
    " *\n",
    " * Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    " * of this software and associated documentation files (the \"Software\"), to deal\n",
    " * in the Software without restriction, including without limitation the rights\n",
    " * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    " * copies of the Software, and to permit persons to whom the Software is\n",
    " * furnished to do so, subject to the following conditions:\n",
    " *\n",
    " * The above copyright notice and this permission notice shall be included in\n",
    " * all copies or substantial portions of the Software.\n",
    " *\n",
    " * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    " * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    " * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    " * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    " * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    " * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
    " * THE SOFTWARE.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f766cb54",
   "metadata": {},
   "source": [
    "## Structure and Property Preserving Network Embedding\n",
    "\n",
    "Rich structural information for network embedding from nodes and links is closely related to neighborhood structure, higher-order proximities of nodes, and community structures.\n",
    "\n",
    "### Definition 7.15 (Network Embedding)\n",
    "Given a graph denoted as \\( G = (V, E) \\), network embedding aims to learn a mapping function \\( f: v_i \\rightarrow \\mathbf{y}_i \\in \\mathbb{R}^d \\), where \\( d \\ll |V| \\). The objective of the function is to make the similarity between \\( \\mathbf{y}_i \\) and \\( \\mathbf{y}_j \\) explicitly preserve the first-order, second-order, and higher-order proximities of \\( v_i \\) and \\( v_j \\).\n",
    "\n",
    "The microscopic structures of a network can be described by its first-order proximity and second-order proximity. Network embedding usually has the following two goals:\n",
    "\n",
    "- **Network Reconstruction:** To learn low-dimensional vector representations for network nodes, the relationships among the nodes, which were originally represented by edges or other higher-order topological measures in graphs, are captured by the distances between nodes in the vector space. The topological and structural characteristics of a node are encoded into its embedding vector.\n",
    "- **Network Inference:** The learned embedding space can effectively support network inference, such as predicting unseen links, identifying important nodes, and inferring node labels.\n",
    "\n",
    "### Definition 7.16 (Information Network)\n",
    "An information network is defined as \\( G = (V, E) \\), where \\( V \\) is the set of vertices, each representing a data object and \\( E \\) is the set of edges between the vertices, each representing a relationship between two data objects. Each edge \\( e \\in E \\) is an ordered pair \\( e = (i, j) \\) and is associated with a weight \\( w_{ij} > 0 \\), which indicates the strength of the relation. If \\( G(V, E) \\) is undirected, then \\( (i, j) \\equiv (j, i) \\) and \\( w_{ij} \\equiv w_{ji} \\); and if \\( G(V, E) \\) is directed, then \\( (i, j) \\neq (j, i) \\) and \\( w_{ij} \\neq w_{ji} \\).\n",
    "\n",
    "### Definition 7.17 (Large-Scale Information Network Embedding)\n",
    "Given a large network \\( G = (V, E) \\), the problem of large-scale information network embedding aims to represent each vertex \\( v \\in V \\) in a low-dimensional space \\( \\mathbb{R}^d \\), where \\( d \\ll |V| \\). In the space \\( \\mathbb{R}^d \\), both the first-order proximity and the second-order proximity between the vertices are preserved.\n",
    "\n",
    "The first-order proximity can be measured by the joint probability distribution between two nodes \\( v_i \\) and \\( v_j \\) as\n",
    "$$\n",
    "p_1(v_i, v_j) = \\frac{1}{1 + \\exp(-\\mathbf{u}_i^T \\mathbf{u}_j)},\n",
    "$$\n",
    "where \\( \\mathbf{u}_i \\in \\mathbb{R}^d \\) is the low-dimensional vector representation of vertex \\( v_i \\). A straightforward way to preserve the first-order proximity is to minimize the following objective function:\n",
    "$$\n",
    "O_1 = -\\sum_{(i, j) \\in E} \\log p_1(v_i, v_j).\n",
    "$$\n",
    "\n",
    "The second-order proximity is modeled by the probability of the context node \\( v_j \\) being generated by node \\( v_i \\), that is,\n",
    "$$\n",
    "p_2(v_j \\mid v_i) = \\frac{\\exp(\\bar{\\mathbf{u}}_j^T \\mathbf{u}_i)}{\\sum_{k=1}^{|V|} \\exp(\\bar{\\mathbf{u}}_k^T \\mathbf{u}_i)},\n",
    "$$\n",
    "where \\( \\mathbf{u}_i \\) is the representation of \\( v_i \\) when it is treated as a vertex, while \\( \\bar{\\mathbf{u}}_i \\) is the representation of \\( v_i \\) when it is treated as a specific “context.” A straightforward way to preserve the second-order proximity is to minimize the following objective function:\n",
    "$$\n",
    "O_2 = -\\sum_{(i, j) \\in E} \\log p_2(v_j \\mid v_i).\n",
    "$$\n",
    "\n",
    "By learning \\( \\{\\mathbf{u}_i\\} \\) for \\( i = 1, \\ldots, |V| \\) and \\( \\{\\bar{\\mathbf{u}}_i\\} \\) for \\( i = 1, \\ldots, |V| \\) that minimize these objectives, we are able to represent every vertex \\( v_i \\) with a \\( d \\)-dimensional vector \\( \\mathbf{u}_i \\).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4892d8d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2ff76a4bcfd420ead43efe1e6d5000b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 2): 100%|██████████| 50/50 [00:25<00:00,  1.97it/s]"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'iter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24855/4260002217.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Generate node embeddings using Node2Vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mnode2vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNode2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimensions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdimensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwalk_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwalk_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_walks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_walks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode2vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Extract embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cv37/lib/python3.7/site-packages/node2vec/node2vec.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, **skip_gram_params)\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0mskip_gram_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sg'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mskip_gram_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'iter'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "from node2vec import Node2Vec\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a sample graph\n",
    "G = nx.erdos_renyi_graph(n=100, p=0.1, seed=42)\n",
    "\n",
    "# Node2Vec parameters\n",
    "p = 1  # Return parameter\n",
    "q = 1  # In-out parameter\n",
    "dimensions = 64  # Dimension of the embedding space\n",
    "walk_length = 30  # Length of each random walk\n",
    "num_walks = 200  # Number of random walks per node\n",
    "\n",
    "# Generate node embeddings using Node2Vec\n",
    "node2vec = Node2Vec(G, dimensions=dimensions, walk_length=walk_length, num_walks=num_walks, p=p, q=q, workers=4)\n",
    "model = node2vec.fit(window=10, min_count=1, iter=1)\n",
    "\n",
    "# Extract embeddings\n",
    "embeddings = np.array([model.wv.get_vector(str(node)) for node in G.nodes])\n",
    "\n",
    "# Dimensionality reduction for visualization\n",
    "pca = PCA(n_components=2)\n",
    "reduced_embeddings = pca.fit_transform(embeddings)\n",
    "\n",
    "# Plot the embeddings\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(reduced_embeddings[:, 0], reduced_embeddings[:, 1], alpha=0.5, edgecolors='k')\n",
    "plt.title('Node2Vec Embeddings Visualized Using PCA')\n",
    "plt.xlabel('Component 1')\n",
    "plt.ylabel('Component 2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cc6a8c",
   "metadata": {},
   "source": [
    "## Community Preserving Network Embedding\n",
    "\n",
    "Given a network \\( G(V, E) \\) with \\( |V| \\) nodes and \\( |E| \\) edges, represented by an adjacency or similarity matrix \\( S = [S_{ij}] \\in \\mathbb{R}^{|V| \\times |V|} \\), the goal is to find natural divisions of vertices into non-overlapping communities.\n",
    "\n",
    "### Modularity\n",
    "\n",
    "The **modularity** \\( Q \\) quantifies the strength of the division of a network into communities. It measures the difference between the number of edges within communities and the expected number of such edges in a random network.\n",
    "\n",
    "For a particular division of the network into two groups, where the community membership \\( h_i = 1 \\) if vertex \\( i \\) belongs to group 1 and \\( h_i = -1 \\) if it belongs to group 2, the modularity can be expressed as:\n",
    "\n",
    "$$\n",
    "Q = \\frac{1}{4m} \\sum_{i,j} \\left( A_{ij} - \\frac{k_i k_j}{2m} \\right) h_i h_j\n",
    "$$\n",
    "\n",
    "where:\n",
    "- \\( A_{ij} \\) is the number of edges between vertices \\( i \\) and \\( j \\),\n",
    "- \\( k_i \\) and \\( k_j \\) are the degrees of vertices \\( i \\) and \\( j \\),\n",
    "- \\( m = \\frac{1}{2} \\sum_{i} k_i \\) is the total number of edges in the network.\n",
    "\n",
    "In matrix-vector form:\n",
    "\n",
    "$$\n",
    "Q = \\frac{1}{4m} h^T B h\n",
    "$$\n",
    "\n",
    "where:\n",
    "- \\( h \\) is the community membership vector,\n",
    "- \\( B \\) is the modularity matrix with elements:\n",
    "\n",
    "$$\n",
    "B_{ij} = A_{ij} - \\frac{k_i k_j}{2m}\n",
    "$$\n",
    "\n",
    "### Modularity Improvement\n",
    "\n",
    "When dividing a group \\( g \\) of size \\( n_g \\) into two, the additional contribution to modularity can be expressed as:\n",
    "\n",
    "$$\n",
    "\\Delta Q = \\frac{1}{4m} \\left( \\sum_{i,j \\in g} B_{ij} (h_i h_j + 1) - \\sum_{i,j \\in g} B_{ij} \\right)\n",
    "$$\n",
    "\n",
    "or:\n",
    "\n",
    "$$\n",
    "\\Delta Q = \\frac{1}{4m} \\left( \\sum_{i,j \\in g} B_{ij} h_i h_j - \\sum_{i,j \\in g} B_{ij} \\right)\n",
    "$$\n",
    "\n",
    "which can be written as:\n",
    "\n",
    "$$\n",
    "\\Delta Q = \\frac{1}{4m} \\left( h^T B(g) h \\right)\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "$$\n",
    "B(g)_{ij} = B_{ij} - \\delta_{ij} \\sum_{k \\in g} B_{ik}\n",
    "$$\n",
    "\n",
    "### Nonnegative Matrix Factorization (NMF)\n",
    "\n",
    "To preserve both first-order and second-order proximities, the final similarity matrix is defined as:\n",
    "\n",
    "$$\n",
    "S = S^{(1)} + \\eta S^{(2)}\n",
    "$$\n",
    "\n",
    "where \\( \\eta > 0 \\) is the weight of the second-order proximity.\n",
    "\n",
    "The community-preserving network embedding finds nonnegative matrices \\( M \\) and \\( U \\) via NMF:\n",
    "\n",
    "$$\n",
    "(M, U) = \\arg \\min_{M, U} \\| S - MU \\|_F^2\n",
    "$$\n",
    "\n",
    "subject to:\n",
    "\n",
    "$$\n",
    "M \\geq 0, \\quad U \\geq 0\n",
    "$$\n",
    "\n",
    "### Community Structure Incorporation\n",
    "\n",
    "For a network with \\( k > 2 \\) communities, the community membership indicator \\( H \\) is a matrix with one column for each community. The constraint is:\n",
    "\n",
    "$$\n",
    "\\text{tr}(H^T H) = n\n",
    "$$\n",
    "\n",
    "The community-preserving embedding optimization problem is:\n",
    "\n",
    "$$\n",
    "H = \\arg \\min_H \\text{tr}(H^T B H)\n",
    "$$\n",
    "\n",
    "subject to:\n",
    "\n",
    "$$\n",
    "\\text{tr}(H^T H) = n\n",
    "$$\n",
    "\n",
    "Additionally, introduce an auxiliary nonnegative matrix \\( C \\in \\mathbb{R}^{k \\times m} \\) (community representation matrix). The matrix factorization problem is:\n",
    "\n",
    "$$\n",
    "(U, C) = \\arg \\min_{U, C} \\| H - CU \\|_F^2\n",
    "$$\n",
    "\n",
    "subject to:\n",
    "\n",
    "$$\n",
    "U \\geq 0, \\quad C \\geq 0\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3004c5ea",
   "metadata": {},
   "source": [
    "## Community Preserving Network Embedding Optimization\n",
    "\n",
    "Combining Eqs. (7.13.10), (7.13.13), and (7.13.15), the objective of the community-preserving network embedding is given by [156]:\n",
    "\n",
    "$$\n",
    "\\min_{M,U,H,C} \\ (1 - \\alpha) \\| S - MU \\|_F^2 + \\alpha \\| H - CU \\|_F^2 - \\beta \\text{tr}(H^T B H)\n",
    "$$\n",
    "\\tag{7.13.17}\n",
    "$$\n",
    "\n",
    "subject to:\n",
    "\n",
    "$$\n",
    "M \\geq 0, \\ U \\geq 0, \\ H \\geq 0, \\ C \\geq 0, \\ \\text{tr}(H^T H) = n,\n",
    "$$\n",
    "\\tag{7.13.18}\n",
    "$$\n",
    "\n",
    "where \\( \\alpha \\) and \\( \\beta \\) are positive parameters for adjusting the contribution of the corresponding terms.\n",
    "\n",
    "### H-Subproblem\n",
    "\n",
    "Updating \\( H \\) with the other parameters fixed leads to the following optimization subproblem [156]:\n",
    "\n",
    "$$\n",
    "\\min_H \\ \\alpha \\| H - UC^T \\|_F^2 - \\beta \\text{tr}(H^T B H)\n",
    "$$\n",
    "\\tag{7.13.19}\n",
    "$$\n",
    "\n",
    "subject to:\n",
    "\n",
    "$$\n",
    "\\text{tr}(H^T H) = n.\n",
    "$$\n",
    "\\tag{7.13.20}\n",
    "$$\n",
    "\n",
    "This constrained condition can be relaxed to the regularization \\( H^T H = I \\), leading to:\n",
    "\n",
    "$$\n",
    "H = \\arg \\min_H \\ \\alpha \\| H - UC^T \\|_F^2 - \\beta \\text{tr}(H^T B H) + \\lambda \\| H^T H - I \\|_F^2,\n",
    "$$\n",
    "\\tag{7.13.21}\n",
    "$$\n",
    "\n",
    "where \\( \\lambda > 0 \\) should be large enough to ensure orthogonality is satisfied. The successive updating rule for \\( H \\) is:\n",
    "\n",
    "$$\n",
    "H \\leftarrow H \\odot \\sqrt{\\frac{H \\odot (2\\beta (B_1 H))}{8\\lambda (H^T H) H} \\bigg/ \\left( \\frac{2\\beta (B_1 H) + 16\\lambda (H^T H)}{2\\beta AH + 2\\alpha UC^T + (4\\lambda - 2\\alpha)H} \\right)},\n",
    "$$\n",
    "\\tag{7.13.22-7.13.24}\n",
    "$$\n",
    "\n",
    "where \\( \\odot \\) denotes the Hadamard product and division represents element-wise operations.\n",
    "\n",
    "### Joint NMF Subproblem\n",
    "\n",
    "Updating \\( M \\), \\( U \\), and \\( C \\) with \\( H \\) fixed leads to the joint NMF problems [3]:\n",
    "\n",
    "$$\n",
    "\\min_{M,U,C} \\ (1 - \\alpha) \\| S - MU \\|_F^2 + \\alpha \\| H - CU \\|_F^2\n",
    "$$\n",
    "\\tag{7.13.25}\n",
    "$$\n",
    "\n",
    "subject to:\n",
    "\n",
    "$$\n",
    "M \\geq 0, \\ U \\geq 0, \\ C \\geq 0.\n",
    "$$\n",
    "\\tag{7.13.26}\n",
    "$$\n",
    "\n",
    "The update rules for matrices \\( M \\) and \\( C \\) are:\n",
    "\n",
    "$$\n",
    "M \\leftarrow M \\odot \\frac{S U^T}{M U U^T},\n",
    "$$\n",
    "\\tag{7.13.27}\n",
    "$$\n",
    "\n",
    "$$\n",
    "C \\leftarrow C \\odot \\frac{H U^T}{C U U^T}.\n",
    "$$\n",
    "\\tag{7.13.28}\n",
    "$$\n",
    "\n",
    "For the coefficient matrix \\( U \\), the update rule is given by:\n",
    "\n",
    "$$\n",
    "U \\leftarrow U \\odot \\frac{(1 - \\lambda) M^T S + \\lambda C^T H}{((1 - \\lambda) M^T M + \\lambda C^T C) U}.\n",
    "$$\n",
    "\\tag{7.13.29}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b01a050a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def update_H(H, U, C, B, alpha, beta, lambda_reg):\n",
    "    # Ensure dimensions align: H (n, k), U (m, k), C (k, m), B (n, n)\n",
    "    \n",
    "    # Calculate B * H (n x n) * (n x k) -> (n x k)\n",
    "    BH = B @ H\n",
    "    \n",
    "    # Calculate U @ C.T (m x k) @ (m x k) -> (n x k) => Adjust U, C if necessary\n",
    "    UCt = U @ C.T\n",
    "\n",
    "    # Update H using the formula\n",
    "    num = 2 * beta * BH\n",
    "    denom = 8 * lambda_reg * (H.T @ H) @ H + 2 * beta * BH + 16 * lambda_reg * (H.T @ H) - 2 * alpha * UCt + (4 * lambda_reg - 2 * alpha) * H\n",
    "    return H * np.sqrt(num / (denom + 1e-9))\n",
    "\n",
    "def community_preserving_embedding(S, B, alpha, beta, lambda_reg, max_iter=100, tol=1e-5):\n",
    "    n, m = S.shape\n",
    "    k = B.shape[0]  # Number of communities\n",
    "    \n",
    "    # Initialize M, U, H, C with proper dimensions\n",
    "    M = np.random.rand(n, m)\n",
    "    U = np.random.rand(m, k)  # Adjusted dimensions\n",
    "    H = np.random.rand(n, k)\n",
    "    C = np.random.rand(k, m)\n",
    "    \n",
    "    # Iterative optimization\n",
    "    for iteration in range(max_iter):\n",
    "        H_prev = H.copy()\n",
    "        \n",
    "        # Update H, M, C, U\n",
    "        H = update_H(H, U, C, B, alpha, beta, lambda_reg)\n",
    "        M = update_M(S, U, M)\n",
    "        C = update_C(H, U, C)\n",
    "        U = update_U(S, M, H, C, U, alpha, lambda_reg)\n",
    "        \n",
    "        # Compute the objective function value\n",
    "        obj_val = objective_function(S, M, U, H, C, B, alpha, beta)\n",
    "        print(f\"Iteration {iteration + 1}, Objective Function: {obj_val:.6f}\")\n",
    "        \n",
    "        # Check for convergence\n",
    "        if norm(H - H_prev) < tol:\n",
    "            print(\"Converged\")\n",
    "            break\n",
    "    \n",
    "    return M, U, H, C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86730c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, Objective Function: -5668.849384\n",
      "Iteration 2, Objective Function: -2867.772942\n",
      "Iteration 3, Objective Function: -1795.832908\n",
      "Iteration 4, Objective Function: -1283.430944\n",
      "Iteration 5, Objective Function: -1002.813208\n",
      "Iteration 6, Objective Function: -835.549885\n",
      "Iteration 7, Objective Function: -730.103340\n",
      "Iteration 8, Objective Function: -654.811796\n",
      "Iteration 9, Objective Function: 35006378773.614059\n",
      "Iteration 10, Objective Function: 237165350780293032706048.000000\n",
      "Iteration 11, Objective Function: 9833237210223619710722879219688140408094720.000000\n",
      "Iteration 12, Objective Function: 3162670638276736060502075932401614686268774816909601777908074230705029120.000000\n",
      "Iteration 13, Objective Function: 581914901938162064470495874251106936504327247795400167182607738247786106878073450607154180748071309418234295261069312.000000\n",
      "Iteration 14, Objective Function: 1452444722421497688238828061045824909658855845774925331028707607862242273144806204856282743078537253841032529926283739357198093653077518916939121279099556021991011862095578482161483776.000000\n",
      "Iteration 15, Objective Function: 5727430632749124912623386076278351649013616183123316363968194104371401561109838923150873241642531548436327960621912194933146052484753247692227790498478092500809011424367821817599022310316269034433691082048720518331140034792077086951301373775019554386055423153413084656104584020754432.000000\n",
      "Iteration 16, Objective Function: nan\n",
      "Iteration 17, Objective Function: nan\n",
      "Iteration 18, Objective Function: nan\n",
      "Iteration 19, Objective Function: nan\n",
      "Iteration 20, Objective Function: nan\n",
      "Iteration 21, Objective Function: nan\n",
      "Iteration 22, Objective Function: nan\n",
      "Iteration 23, Objective Function: nan\n",
      "Iteration 24, Objective Function: nan\n",
      "Iteration 25, Objective Function: nan\n",
      "Iteration 26, Objective Function: nan\n",
      "Iteration 27, Objective Function: nan\n",
      "Iteration 28, Objective Function: nan\n",
      "Iteration 29, Objective Function: nan\n",
      "Iteration 30, Objective Function: nan\n",
      "Iteration 31, Objective Function: nan\n",
      "Iteration 32, Objective Function: nan\n",
      "Iteration 33, Objective Function: nan\n",
      "Iteration 34, Objective Function: nan\n",
      "Iteration 35, Objective Function: nan\n",
      "Iteration 36, Objective Function: nan\n",
      "Iteration 37, Objective Function: nan\n",
      "Iteration 38, Objective Function: nan\n",
      "Iteration 39, Objective Function: nan\n",
      "Iteration 40, Objective Function: nan\n",
      "Iteration 41, Objective Function: nan\n",
      "Iteration 42, Objective Function: nan\n",
      "Iteration 43, Objective Function: nan\n",
      "Iteration 44, Objective Function: nan\n",
      "Iteration 45, Objective Function: nan\n",
      "Iteration 46, Objective Function: nan\n",
      "Iteration 47, Objective Function: nan\n",
      "Iteration 48, Objective Function: nan\n",
      "Iteration 49, Objective Function: nan\n",
      "Iteration 50, Objective Function: nan\n",
      "Iteration 51, Objective Function: nan\n",
      "Iteration 52, Objective Function: nan\n",
      "Iteration 53, Objective Function: nan\n",
      "Iteration 54, Objective Function: nan\n",
      "Iteration 55, Objective Function: nan\n",
      "Iteration 56, Objective Function: nan\n",
      "Iteration 57, Objective Function: nan\n",
      "Iteration 58, Objective Function: nan\n",
      "Iteration 59, Objective Function: nan\n",
      "Iteration 60, Objective Function: nan\n",
      "Iteration 61, Objective Function: nan\n",
      "Iteration 62, Objective Function: nan\n",
      "Iteration 63, Objective Function: nan\n",
      "Iteration 64, Objective Function: nan\n",
      "Iteration 65, Objective Function: nan\n",
      "Iteration 66, Objective Function: nan\n",
      "Iteration 67, Objective Function: nan\n",
      "Iteration 68, Objective Function: nan\n",
      "Iteration 69, Objective Function: nan\n",
      "Iteration 70, Objective Function: nan\n",
      "Iteration 71, Objective Function: nan\n",
      "Iteration 72, Objective Function: nan\n",
      "Iteration 73, Objective Function: nan\n",
      "Iteration 74, Objective Function: nan\n",
      "Iteration 75, Objective Function: nan\n",
      "Iteration 76, Objective Function: nan\n",
      "Iteration 77, Objective Function: nan\n",
      "Iteration 78, Objective Function: nan\n",
      "Iteration 79, Objective Function: nan\n",
      "Iteration 80, Objective Function: nan\n",
      "Iteration 81, Objective Function: nan\n",
      "Iteration 82, Objective Function: nan\n",
      "Iteration 83, Objective Function: nan\n",
      "Iteration 84, Objective Function: nan\n",
      "Iteration 85, Objective Function: nan\n",
      "Iteration 86, Objective Function: nan\n",
      "Iteration 87, Objective Function: nan\n",
      "Iteration 88, Objective Function: nan\n",
      "Iteration 89, Objective Function: nan\n",
      "Iteration 90, Objective Function: nan\n",
      "Iteration 91, Objective Function: nan\n",
      "Iteration 92, Objective Function: nan\n",
      "Iteration 93, Objective Function: nan\n",
      "Iteration 94, Objective Function: nan\n",
      "Iteration 95, Objective Function: nan\n",
      "Iteration 96, Objective Function: nan\n",
      "Iteration 97, Objective Function: nan\n",
      "Iteration 98, Objective Function: nan\n",
      "Iteration 99, Objective Function: nan\n",
      "Iteration 100, Objective Function: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/radha/anaconda3/envs/cv37/lib/python3.7/site-packages/ipykernel_launcher.py:47: RuntimeWarning: overflow encountered in matmul\n",
      "/home/radha/anaconda3/envs/cv37/lib/python3.7/site-packages/ipykernel_launcher.py:56: RuntimeWarning: overflow encountered in matmul\n",
      "/home/radha/anaconda3/envs/cv37/lib/python3.7/site-packages/ipykernel_launcher.py:58: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/radha/anaconda3/envs/cv37/lib/python3.7/site-packages/ipykernel_launcher.py:15: RuntimeWarning: overflow encountered in matmul\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/radha/anaconda3/envs/cv37/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: overflow encountered in multiply\n",
      "/home/radha/anaconda3/envs/cv37/lib/python3.7/site-packages/ipykernel_launcher.py:34: RuntimeWarning: invalid value encountered in matmul\n",
      "/home/radha/anaconda3/envs/cv37/lib/python3.7/site-packages/ipykernel_launcher.py:56: RuntimeWarning: invalid value encountered in matmul\n"
     ]
    }
   ],
   "source": [
    "# Example input data\n",
    "n = 50  # number of nodes\n",
    "m = 50   # dimensionality of the embedding space\n",
    "k = 10   # number of communities\n",
    "\n",
    "S = np.random.rand(n, m)  # Similarity matrix (random example)\n",
    "B = np.random.rand(n, n)  # Modularity matrix (random example)\n",
    "\n",
    "# Hyperparameters\n",
    "alpha = 0.5\n",
    "beta = 0.1\n",
    "lambda_reg = 0.01\n",
    "max_iter = 100\n",
    "\n",
    "# Run the optimization\n",
    "M, U, H, C = community_preserving_embedding(S, B, alpha, beta, lambda_reg, max_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93d22f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def update_H(H, U, C, B, alpha, beta, lambda_reg):\n",
    "    # H (n x k), U (m x k), C (k x m), B (n x n)\n",
    "    \n",
    "    # Calculate B * H (n x n) * (n x k) -> (n x k)\n",
    "    BH = B @ H\n",
    "    \n",
    "    # Calculate U @ C.T (m x k) @ (m x k) -> (n x k) => Adjust U, C if necessary\n",
    "    UCt = U @ C.T\n",
    "\n",
    "    # Update H using the formula\n",
    "    num = 2 * beta * BH + 2 * alpha * UCt\n",
    "    denom = num + 16 * lambda_reg * (H.T @ H) - 2 * alpha * UCt + (4 * lambda_reg - 2 * alpha) * H\n",
    "    \n",
    "    # Ensure dimensions align before performing Hadamard division\n",
    "    denom = np.maximum(denom, 1e-9)  # Prevent division by zero\n",
    "    H_new = H * np.sqrt(num / denom)\n",
    "    \n",
    "    return H_new\n",
    "\n",
    "def update_M(S, U, M):\n",
    "    # Update M using the formula SUT / (MUUT)\n",
    "    SUT = S @ U.T  # (n x m) * (m x k) -> (n x k)\n",
    "    MUUT = M @ (U @ U.T)  # (n x m) * (m x k) -> (n x k)\n",
    "    \n",
    "    M_new = M * (SUT / np.maximum(MUUT, 1e-9))  # Prevent division by zero\n",
    "    \n",
    "    return M_new\n",
    "\n",
    "def update_C(H, U, C):\n",
    "    # Update C using the formula HUT / (CUUT)\n",
    "    HUT = H.T @ U.T  # (k x n) * (n x m) -> (k x m)\n",
    "    CUUT = C @ (U @ U.T)  # (k x m) * (m x k) -> (k x m)\n",
    "    \n",
    "    C_new = C * (HUT / np.maximum(CUUT, 1e-9))  # Prevent division by zero\n",
    "    \n",
    "    return C_new\n",
    "\n",
    "def update_U(S, M, H, C, U, alpha, lambda_reg):\n",
    "    # Update U using the formula (1 - alpha) * MT * S + alpha * CT * H\n",
    "    MT_S = M.T @ S  # (m x n) * (n x m) -> (m x m)\n",
    "    CT_H = C.T @ H  # (m x k) * (k x n) -> (m x n)\n",
    "    \n",
    "    num = (1 - alpha) * MT_S + alpha * CT_H\n",
    "    denom = ((1 - alpha) * (M.T @ M) + alpha * (C.T @ C)) @ U\n",
    "    \n",
    "    U_new = U * (num / np.maximum(denom, 1e-9))  # Prevent division by zero\n",
    "    \n",
    "    return U_new\n",
    "\n",
    "def objective_function(S, M, U, H, C, B, alpha, beta):\n",
    "    term1 = (1 - alpha) * norm(S - M @ U, 'fro') ** 2\n",
    "    term2 = alpha * norm(H - U @ C.T, 'fro') ** 2\n",
    "    term3 = -beta * np.trace(H.T @ B @ H)\n",
    "    \n",
    "    return term1 + term2 + term3\n",
    "\n",
    "def community_preserving_embedding(S, B, alpha, beta, lambda_reg, max_iter=100, tol=1e-5):\n",
    "    n, m = S.shape\n",
    "    k = B.shape[0]  # Number of communities\n",
    "    \n",
    "    # Initialize M, U, H, C with proper dimensions\n",
    "    M = np.random.rand(n, m)\n",
    "    U = np.random.rand(m, k)  # Adjusted dimensions\n",
    "    H = np.random.rand(n, k)\n",
    "    C = np.random.rand(k, m)\n",
    "    \n",
    "    # Iterative optimization\n",
    "    for iteration in range(max_iter):\n",
    "        H_prev = H.copy()\n",
    "        \n",
    "        # Update H, M, C, U\n",
    "        H = update_H(H, U, C, B, alpha, beta, lambda_reg)\n",
    "        M = update_M(S, U, M)\n",
    "        C = update_C(H, U, C)\n",
    "        U = update_U(S, M, H, C, U, alpha, lambda_reg)\n",
    "        \n",
    "        # Compute the objective function value\n",
    "        obj_val = objective_function(S, M, U, H, C, B, alpha, beta)\n",
    "        print(f\"Iteration {iteration + 1}, Objective Function: {obj_val:.6f}\")\n",
    "        \n",
    "        # Check for convergence\n",
    "        if norm(H - H_prev) < tol:\n",
    "            print(\"Converged\")\n",
    "            break\n",
    "    \n",
    "    return M, U, H, C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adce7406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, Objective Function: -5624.462098\n",
      "Iteration 2, Objective Function: -2848.779393\n",
      "Iteration 3, Objective Function: -1783.438750\n",
      "Iteration 4, Objective Function: -1272.894975\n",
      "Iteration 5, Objective Function: -992.106087\n",
      "Iteration 6, Objective Function: -822.188698\n",
      "Iteration 7, Objective Function: -676.259977\n",
      "Iteration 8, Objective Function: 270570294627.840515\n",
      "Iteration 9, Objective Function: 19858424634688086367797248.000000\n",
      "Iteration 10, Objective Function: 14474254935549750414750908178654406701926580224.000000\n",
      "Iteration 11, Objective Function: 304314339602189369667290981950282977006897012698144286196236392582741420408832.000000\n",
      "Iteration 12, Objective Function: 29915185264741766494408675242774361494538223026060301814705592083415374787921732880017490296642352980415585241960877133922304.000000\n",
      "Iteration 13, Objective Function: 938118086758129112441358911477316057582904288246248354280870722773870944690883489855336212027838147678842482851634288385227241175838578430686103960614815191709289690236161466495742700714754834432.000000\n",
      "Iteration 14, Objective Function: 5384947862420849994180816827556099544527341731547950254232940090788863982912792678113031758214963251528839504970876072667923366633018706725691699522034657080576681835853878357984468886298743805898604587434571604173010717226510828730454784942350307085994884412620204500542432132711990510753006911225856.000000\n",
      "Iteration 15, Objective Function: nan\n",
      "Iteration 16, Objective Function: nan\n",
      "Iteration 17, Objective Function: nan\n",
      "Iteration 18, Objective Function: nan\n",
      "Iteration 19, Objective Function: nan\n",
      "Iteration 20, Objective Function: nan\n",
      "Iteration 21, Objective Function: nan\n",
      "Iteration 22, Objective Function: nan\n",
      "Iteration 23, Objective Function: nan\n",
      "Iteration 24, Objective Function: nan\n",
      "Iteration 25, Objective Function: nan\n",
      "Iteration 26, Objective Function: nan\n",
      "Iteration 27, Objective Function: nan\n",
      "Iteration 28, Objective Function: nan\n",
      "Iteration 29, Objective Function: nan\n",
      "Iteration 30, Objective Function: nan\n",
      "Iteration 31, Objective Function: nan\n",
      "Iteration 32, Objective Function: nan\n",
      "Iteration 33, Objective Function: nan\n",
      "Iteration 34, Objective Function: nan\n",
      "Iteration 35, Objective Function: nan\n",
      "Iteration 36, Objective Function: nan\n",
      "Iteration 37, Objective Function: nan\n",
      "Iteration 38, Objective Function: nan\n",
      "Iteration 39, Objective Function: nan\n",
      "Iteration 40, Objective Function: nan\n",
      "Iteration 41, Objective Function: nan\n",
      "Iteration 42, Objective Function: nan\n",
      "Iteration 43, Objective Function: nan\n",
      "Iteration 44, Objective Function: nan\n",
      "Iteration 45, Objective Function: nan\n",
      "Iteration 46, Objective Function: nan\n",
      "Iteration 47, Objective Function: nan\n",
      "Iteration 48, Objective Function: nan\n",
      "Iteration 49, Objective Function: nan\n",
      "Iteration 50, Objective Function: nan\n",
      "Iteration 51, Objective Function: nan\n",
      "Iteration 52, Objective Function: nan\n",
      "Iteration 53, Objective Function: nan\n",
      "Iteration 54, Objective Function: nan\n",
      "Iteration 55, Objective Function: nan\n",
      "Iteration 56, Objective Function: nan\n",
      "Iteration 57, Objective Function: nan\n",
      "Iteration 58, Objective Function: nan\n",
      "Iteration 59, Objective Function: nan\n",
      "Iteration 60, Objective Function: nan\n",
      "Iteration 61, Objective Function: nan\n",
      "Iteration 62, Objective Function: nan\n",
      "Iteration 63, Objective Function: nan\n",
      "Iteration 64, Objective Function: nan\n",
      "Iteration 65, Objective Function: nan\n",
      "Iteration 66, Objective Function: nan\n",
      "Iteration 67, Objective Function: nan\n",
      "Iteration 68, Objective Function: nan\n",
      "Iteration 69, Objective Function: nan\n",
      "Iteration 70, Objective Function: nan\n",
      "Iteration 71, Objective Function: nan\n",
      "Iteration 72, Objective Function: nan\n",
      "Iteration 73, Objective Function: nan\n",
      "Iteration 74, Objective Function: nan\n",
      "Iteration 75, Objective Function: nan\n",
      "Iteration 76, Objective Function: nan\n",
      "Iteration 77, Objective Function: nan\n",
      "Iteration 78, Objective Function: nan\n",
      "Iteration 79, Objective Function: nan\n",
      "Iteration 80, Objective Function: nan\n",
      "Iteration 81, Objective Function: nan\n",
      "Iteration 82, Objective Function: nan\n",
      "Iteration 83, Objective Function: nan\n",
      "Iteration 84, Objective Function: nan\n",
      "Iteration 85, Objective Function: nan\n",
      "Iteration 86, Objective Function: nan\n",
      "Iteration 87, Objective Function: nan\n",
      "Iteration 88, Objective Function: nan\n",
      "Iteration 89, Objective Function: nan\n",
      "Iteration 90, Objective Function: nan\n",
      "Iteration 91, Objective Function: nan\n",
      "Iteration 92, Objective Function: nan\n",
      "Iteration 93, Objective Function: nan\n",
      "Iteration 94, Objective Function: nan\n",
      "Iteration 95, Objective Function: nan\n",
      "Iteration 96, Objective Function: nan\n",
      "Iteration 97, Objective Function: nan\n",
      "Iteration 98, Objective Function: nan\n",
      "Iteration 99, Objective Function: nan\n",
      "Iteration 100, Objective Function: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/radha/anaconda3/envs/cv37/lib/python3.7/site-packages/ipykernel_launcher.py:56: RuntimeWarning: overflow encountered in matmul\n",
      "/home/radha/anaconda3/envs/cv37/lib/python3.7/site-packages/ipykernel_launcher.py:58: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/radha/anaconda3/envs/cv37/lib/python3.7/site-packages/ipykernel_launcher.py:15: RuntimeWarning: overflow encountered in matmul\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/radha/anaconda3/envs/cv37/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: overflow encountered in multiply\n",
      "/home/radha/anaconda3/envs/cv37/lib/python3.7/site-packages/ipykernel_launcher.py:44: RuntimeWarning: invalid value encountered in matmul\n",
      "/home/radha/anaconda3/envs/cv37/lib/python3.7/site-packages/ipykernel_launcher.py:47: RuntimeWarning: invalid value encountered in matmul\n",
      "/home/radha/anaconda3/envs/cv37/lib/python3.7/site-packages/ipykernel_launcher.py:49: RuntimeWarning: invalid value encountered in true_divide\n",
      "/home/radha/anaconda3/envs/cv37/lib/python3.7/site-packages/ipykernel_launcher.py:56: RuntimeWarning: invalid value encountered in matmul\n"
     ]
    }
   ],
   "source": [
    "# Example input data\n",
    "n = 50  # number of nodes\n",
    "m = 50   # dimensionality of the embedding space\n",
    "k = 10   # number of communities\n",
    "\n",
    "S = np.random.rand(n, m)  # Similarity matrix (random example)\n",
    "B = np.random.rand(n, n)  # Modularity matrix (random example)\n",
    "\n",
    "# Hyperparameters\n",
    "alpha = 0.5\n",
    "beta = 0.1\n",
    "lambda_reg = 0.01\n",
    "max_iter = 100\n",
    "\n",
    "# Run the optimization\n",
    "M, U, H, C = community_preserving_embedding(S, B, alpha, beta, lambda_reg, max_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0947ae45",
   "metadata": {},
   "source": [
    "###  Higher-Order Proximity Preserved Network Embedding\n",
    "\n",
    "Graph embedding algorithms aim to embed a graph into a vector space where the structure and the inherent properties of the graph are preserved without considering how to preserve its asymmetric transitivity, which is a critical property of directed graphs.\n",
    "\n",
    "Transitivity is a common characteristic of undirected and directed graphs [111, 140], and plays a key role in graph inference and analysis tasks, such as calculating similarities between nodes and measuring the importance of nodes.\n",
    "\n",
    "- **In undirected graphs**: If there is an edge between vertices \\( u \\) and \\( w \\), and another between \\( w \\) and \\( v \\), then \\( u \\) and \\( v \\) are likely connected by an edge. Transitivity is symmetric in undirected graphs.\n",
    "- **In directed graphs**: There is a directed path from \\( u \\) to \\( v \\), but not from \\( v \\) to \\( u \\). That is, transitivity is asymmetric in directed graphs.\n",
    "\n",
    "Consider a directed graph \\( G = (V , E) \\), where \\( V = \\{v_1, \\dots, v_N\\} \\) is the vertex set, and \\( N \\) is the number of vertices. \\( E \\) is the directed edge set, i.e., \\( e_{ij} = (v_i , v_j) \\in E \\) represents a directed edge from \\( v_i \\) to \\( v_j \\). The adjacency matrix is denoted by \\( A \\). If \\( S_{ij} \\) are the higher-order proximities between \\( v_i \\) and \\( v_j \\), then \\( S = [S_{ij}] \\) is known as a higher-order proximity matrix. Let \\( U = [U^s , U^t] \\) be the embedding matrix whose \\( i \\)-th row \\( u_i \\) is the embedding vector of \\( v_i \\), and let \\( U^s \\), \\( U^t \\in \\mathbb{R}^{N \\times K} \\) be the source embedding vectors and target embedding vectors, respectively, where \\( K \\) is the embedding dimension.\n",
    "\n",
    "The higher-order proximity preserved embedding (HOPE) in [111] can be stated as follows: Given a higher-order proximity matrix \\( S \\), find the source embedding matrix \\( U^s \\) and the target embedding matrix \\( U^t \\). The objective of this problem is defined as [111]:\n",
    "\n",
    "$$\n",
    "\\min \\| S - U^s (U^t)^\\top \\|_F^2 .\n",
    "\\tag{7.13.30}\n",
    "$$\n",
    "\n",
    "Let the singular value decomposition (SVD) of the higher-order proximity matrix \\( S \\) be given by\n",
    "\n",
    "$$\n",
    "S = \\sum_{i=1}^{N} \\sigma_i v^s_i (v^t_i)^\\top ,\n",
    "\\tag{7.13.31}\n",
    "$$\n",
    "\n",
    "where \\( \\sigma_1 , \\dots, \\sigma_N \\) are the singular values sorted in decreasing order, and \\( v^s_i \\) and \\( v^t_i \\) are the left- and right-singular vectors associated with \\( \\sigma_i \\) of \\( S \\).\n",
    "\n",
    "By comparison of (7.13.31) with (7.13.30), it is easily known that the source and target embedding matrices can be determined by\n",
    "\n",
    "$$\n",
    "U^s = [ \\sqrt{\\sigma_1} v^s_1, \\dots, \\sqrt{\\sigma_K} v^s_K ] ,\n",
    "\\tag{7.13.32}\n",
    "$$\n",
    "\n",
    "$$\n",
    "U^t = [ \\sqrt{\\sigma_1} v^t_1, \\dots, \\sqrt{\\sigma_K} v^t_K ] ,\n",
    "\\tag{7.13.33}\n",
    "$$\n",
    "\n",
    "where \\( K \\) is the number of the largest singular values of \\( S \\), giving the estimate of the embedding dimension.\n",
    "\n",
    "Many higher-order proximity measurements in graph can reflect the asymmetric transitivity. The higher-order proximity matrix shares a general formulation:\n",
    "\n",
    "$$\n",
    "S = M_g^{-1} M_l ,\n",
    "\\tag{7.13.34}\n",
    "$$\n",
    "\n",
    "where \\( M_g \\) and \\( M_l \\) are both polynomials of matrices.\n",
    "\n",
    "The following are a few examples of higher-order proximity matrices [111]:\n",
    "\n",
    "1. **Katz Index [76]**:\n",
    "\n",
    "$$\n",
    "S_{\\text{Katz}} = \\beta A + \\beta A S_{\\text{Katz}} ,\n",
    "\\tag{7.13.35}\n",
    "$$\n",
    "\n",
    "from which it follows that\n",
    "\n",
    "$$\n",
    "S_{\\text{Katz}} = (I - \\beta A)^{-1} \\beta A ,\n",
    "\\tag{7.13.36}\n",
    "$$\n",
    "\n",
    "where \\( \\beta \\) is a decay parameter. \\( \\beta \\) should be smaller than the spectral radius of the adjacency matrix. Clearly, for Katz index, one has\n",
    "\n",
    "$$\n",
    "M_g = (I - \\beta A) \\quad \\text{and} \\quad M_l = \\beta A .\n",
    "\\tag{7.13.37}\n",
    "$$\n",
    "\n",
    "2. **Rooted PageRank (RPR)**:\n",
    "\n",
    "$$\n",
    "S_{\\text{RPR}} = \\alpha S_{\\text{RPR}} P + (1 - \\alpha) I \\implies S_{\\text{RPR}} = (I - \\alpha P)^{-1} (1 - \\alpha) I ,\n",
    "\\tag{7.13.38}\n",
    "$$\n",
    "\n",
    "where \\( \\alpha \\in [0, 1) \\) is the probability to randomly walk to a neighbor, and \\( P \\) is the probability transition matrix satisfying the condition \\( \\sum_{i=1}^{N} P_{ij} = 1 \\). Clearly, for RPR,\n",
    "\n",
    "$$\n",
    "M_g = I - \\alpha P \\quad \\text{and} \\quad M_l = (1 - \\alpha) I .\n",
    "\\tag{7.13.39}\n",
    "$$\n",
    "\n",
    "3. **Common Neighbors (CN)**: \\( S_{ij}^{\\text{CN}} \\) counts the number of vertices connecting to both \\( v_i \\) and \\( v_j \\). For directed graphs, \\( S_{ij}^{\\text{CN}} \\) is the number of vertices which are the target of an edge from \\( v_i \\) and the source of an edge to \\( v_j \\). Formally,\n",
    "\n",
    "$$\n",
    "S^{\\text{CN}} = A^2\n",
    "\\tag{7.13.40}\n",
    "$$\n",
    "\n",
    "from which we get\n",
    "\n",
    "$$\n",
    "M_g = I \\quad \\text{and} \\quad M_l = A^2 .\n",
    "\\tag{7.13.41}\n",
    "$$\n",
    "\n",
    "4. **Adamic-Adar (AA)**: Adamic-Adar is a variant of common neighbors:\n",
    "\n",
    "$$\n",
    "S^{\\text{AA}} = A D A\n",
    "\\tag{7.13.42}\n",
    "$$\n",
    "\n",
    "which gives\n",
    "\n",
    "$$\n",
    "M_g = I \\quad \\text{and} \\quad M_l = A D A ,\n",
    "\\tag{7.13.43}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "D_{ii} = \\left( \\sum_j (A_{ij} + A_{ji}) \\right)^{-1} .\n",
    "\\tag{7.13.44}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fe37db",
   "metadata": {},
   "source": [
    "It needs the matrix inversion \\( M^{-1}_g \\) to compute the higher-order proximity matrix \\( S \\) from \\( M_g \\) and \\( M_l \\). To improve the numerical stability of the higher-order proximity preserved embedding, Ou et al. [111] suggested computing the generalized singular value decomposition (GSVD) of the matrix pair \\( (M_g , M_l) \\) instead of the SVD of \\( S \\):\n",
    "\n",
    "$$\n",
    "\\mathbf{V}^\\top_t M^\\top_l \\mathbf{X} = \\text{Diag}(\\sigma^l_1, \\dots, \\sigma^l_N) ,\n",
    "\\tag{7.13.45}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{V}^\\top_s M^\\top_g \\mathbf{X} = \\text{Diag}(\\sigma^g_1, \\dots, \\sigma^g_N) ,\n",
    "\\tag{7.13.46}\n",
    "$$\n",
    "\n",
    "where \\( \\mathbf{X} \\) is a nonsingular matrix, and\n",
    "\n",
    "$$\n",
    "\\sigma^l_1 \\geq \\sigma^l_2 \\geq \\dots \\geq \\sigma^l_N \\geq 0,\n",
    "\\tag{7.13.47}\n",
    "$$\n",
    "\n",
    "$$\n",
    "0 \\leq \\sigma^g_1 \\leq \\sigma^g_2 \\leq \\dots \\leq \\sigma^g_N,\n",
    "\\tag{7.13.48}\n",
    "$$\n",
    "\n",
    "$$\n",
    "(\\sigma^l_i)^2 + (\\sigma^g_i)^2 = 1, \\quad \\forall i.\n",
    "\\tag{7.13.49}\n",
    "$$\n",
    "\n",
    "Most existing embedding methods focus on the static network while neglecting the evolving characteristic of real-world networks. Recently, Zhu et al. [176] proposed a higher-order proximity preserved embedding for dynamic networks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa00f7ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'gsvd' from 'scipy.linalg' (/home/radha/anaconda3/envs/cv37/lib/python3.7/site-packages/scipy/linalg/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8427/3714144999.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgsvd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_gsvd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \"\"\"\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'gsvd' from 'scipy.linalg' (/home/radha/anaconda3/envs/cv37/lib/python3.7/site-packages/scipy/linalg/__init__.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import gsvd\n",
    "\n",
    "def compute_gsvd(Mg, Ml):\n",
    "    \"\"\"\n",
    "    Compute the Generalized Singular Value Decomposition (GSVD) of the matrix pair (Mg, Ml).\n",
    "\n",
    "    Parameters:\n",
    "    Mg (numpy.ndarray): Matrix Mg of shape (N, N).\n",
    "    Ml (numpy.ndarray): Matrix Ml of shape (N, N).\n",
    "\n",
    "    Returns:\n",
    "    U (numpy.ndarray): Left singular vectors.\n",
    "    V (numpy.ndarray): Right singular vectors.\n",
    "    X (numpy.ndarray): Nonsingular matrix X.\n",
    "    sigma_g (numpy.ndarray): Singular values associated with Mg.\n",
    "    sigma_l (numpy.ndarray): Singular values associated with Ml.\n",
    "    \"\"\"\n",
    "    # Compute GSVD of the matrix pair (Mg, Ml)\n",
    "    U, V, X, sigma_g, sigma_l = gsvd(Mg, Ml)\n",
    "    \n",
    "    return U, V, X, sigma_g, sigma_l\n",
    "\n",
    "def higher_order_proximity_embedding(Mg, Ml, K):\n",
    "    \"\"\"\n",
    "    Compute the higher-order proximity preserved embedding using GSVD.\n",
    "\n",
    "    Parameters:\n",
    "    Mg (numpy.ndarray): Matrix Mg of shape (N, N).\n",
    "    Ml (numpy.ndarray): Matrix Ml of shape (N, N).\n",
    "    K (int): Embedding dimension.\n",
    "\n",
    "    Returns:\n",
    "    Us (numpy.ndarray): Source embedding matrix of shape (N, K).\n",
    "    Ut (numpy.ndarray): Target embedding matrix of shape (N, K).\n",
    "    \"\"\"\n",
    "    # Compute the GSVD of the matrix pair (Mg, Ml)\n",
    "    U, V, X, sigma_g, sigma_l = compute_gsvd(Mg, Ml)\n",
    "\n",
    "    # Select the top K components for the embedding\n",
    "    Us = np.dot(np.diag(np.sqrt(sigma_l[:K])), V[:, :K])\n",
    "    Ut = np.dot(np.diag(np.sqrt(sigma_g[:K])), X[:, :K])\n",
    "    \n",
    "    return Us, Ut\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Define Mg and Ml matrices (example)\n",
    "    N = 100  # Number of nodes\n",
    "    K = 10   # Embedding dimension\n",
    "    \n",
    "    # Example matrices (Mg and Ml can be computed based on your specific higher-order proximity measure)\n",
    "    Mg = np.random.rand(N, N)\n",
    "    Ml = np.random.rand(N, N)\n",
    "    \n",
    "    # Compute the higher-order proximity preserved embedding\n",
    "    Us, Ut = higher_order_proximity_embedding(Mg, Ml, K)\n",
    "    \n",
    "    print(\"Source Embedding Matrix Us:\")\n",
    "    print(Us)\n",
    "    print(\"\\nTarget Embedding Matrix Ut:\")\n",
    "    print(Ut)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44c5a259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Embedding Matrix Us:\n",
      "[[-5.71882004e-01  7.63750807e-02  2.82158184e-03  2.11606254e-01\n",
      "   9.25585971e-02 -7.69594324e-02 -1.84000634e-01  3.30159805e-01\n",
      "   2.46215990e-01  2.17099452e-01]\n",
      " [-6.05296377e-01 -2.60366664e-01  1.80521634e-02  4.06743796e-01\n",
      "   5.27179658e-02 -1.81657828e-02 -2.03102469e-01  4.10328954e-02\n",
      "   4.01836168e-01 -2.66194396e-01]\n",
      " [-5.64220706e-01 -1.89510090e-02 -3.44030808e-02  8.98704360e-02\n",
      "   3.91677452e-02  5.87813470e-02 -9.53271815e-02  3.75936567e-01\n",
      "  -4.19153094e-02  5.41842762e-02]\n",
      " [-5.51358318e-01 -2.71564255e-01  2.20026888e-01  1.63022670e-01\n",
      "   2.73420908e-01  4.95301326e-02 -1.33590999e-01  7.65198610e-02\n",
      "  -1.44954523e-01  9.51919743e-03]\n",
      " [-5.94100737e-01  5.60785215e-02  1.46036513e-01  1.29295659e-01\n",
      "   1.92301657e-01 -3.00869154e-01  1.59082986e-01  2.31780167e-03\n",
      "  -8.07635427e-03  5.84800934e-02]\n",
      " [-6.20010066e-01  4.62067179e-02  2.11046882e-01 -5.17463628e-01\n",
      "   1.12933851e-01  3.20894436e-01  8.18208267e-04 -3.83453385e-02\n",
      "  -8.40614368e-02 -1.16381013e-01]\n",
      " [-5.71929461e-01 -4.75116369e-01 -1.34792774e-01 -1.09217133e-03\n",
      "   1.30793675e-02 -2.13189415e-01 -2.57283376e-01 -3.12778701e-02\n",
      "   4.04212596e-01  1.40505488e-01]\n",
      " [-6.61999518e-01  1.90959095e-01 -1.13162497e-01 -9.61684347e-02\n",
      "   5.13187354e-02  6.43854880e-02 -1.73450086e-02  9.91731726e-02\n",
      "  -2.41921943e-01 -5.98749860e-02]\n",
      " [-6.27681049e-01 -7.16252655e-02 -1.63984262e-01 -4.18315101e-02\n",
      "   4.48511358e-04  6.42352805e-02 -5.68610086e-03  3.37601034e-01\n",
      "  -2.56668322e-01  2.95696172e-01]\n",
      " [-6.11599882e-01 -1.86257036e-01  1.65482783e-01  1.52514289e-01\n",
      "   2.08235794e-02  3.83287360e-01 -6.15608111e-02  4.23641464e-01\n",
      "   3.24584980e-01 -2.96807428e-01]\n",
      " [-6.09721754e-01  8.25970265e-02  2.71205589e-01  4.31647143e-01\n",
      "  -3.64445015e-02  2.70723052e-01  4.13561833e-02 -1.39780196e-01\n",
      "   2.79822264e-01  5.70519161e-02]\n",
      " [-6.21334319e-01  1.75977916e-02  5.04922071e-01  1.34882623e-01\n",
      "   3.94461901e-02  1.08699732e-01 -1.94583348e-02  3.61558820e-01\n",
      "  -1.04213922e-02 -9.66588971e-03]\n",
      " [-6.31757655e-01  2.99040948e-01 -1.75820513e-02  1.90671554e-01\n",
      "  -1.05303199e-01  1.19955248e-01 -8.13650594e-02  2.90360372e-02\n",
      "  -2.35266506e-01 -1.12498264e-01]\n",
      " [-5.62478075e-01  5.80940524e-02  1.59984043e-01 -8.37584956e-03\n",
      "   3.88202524e-02 -2.67560265e-01  1.32905279e-02 -1.48075097e-01\n",
      "   1.91563604e-01 -4.19555107e-02]\n",
      " [-6.42078888e-01 -2.61295092e-01 -1.96186445e-01  1.56938680e-02\n",
      "   1.79441465e-02 -1.59175991e-01 -1.61683645e-01 -1.78984006e-01\n",
      "   8.19400083e-02 -1.01203287e-01]\n",
      " [-5.65942088e-01  1.21808275e-01 -3.55870118e-01 -9.79591448e-02\n",
      "  -1.39955322e-01  1.95679120e-02  1.78273275e-01  7.89139078e-02\n",
      "  -2.35230124e-01 -1.91637444e-01]\n",
      " [-6.17542134e-01  1.77080533e-01  1.79840222e-01 -1.32190746e-01\n",
      "  -2.63497355e-01 -8.67068429e-02  2.76281709e-01 -3.22283656e-02\n",
      "   3.34624731e-01  1.89189399e-01]\n",
      " [-5.36873874e-01 -1.64340686e-01  8.55056022e-02  2.31007617e-02\n",
      "  -1.42167191e-01  6.79174965e-02  1.66865429e-01 -8.27832574e-02\n",
      "   3.00658044e-01 -1.67586313e-01]\n",
      " [-6.10464060e-01 -1.06110450e-01 -1.31905989e-02  1.12945986e-02\n",
      "   1.49761816e-01  2.06488399e-01  1.98227870e-01  2.72256914e-02\n",
      "  -1.44614643e-01 -1.09053389e-01]\n",
      " [-5.73722093e-01  1.87982568e-02 -3.33046496e-01 -2.13039182e-02\n",
      "   2.31666381e-01  5.74936291e-02 -3.97501334e-01 -1.18784161e-01\n",
      "   5.62649083e-02  7.71738955e-02]\n",
      " [-5.98628095e-01  2.79769481e-01  2.59819093e-01 -7.97948607e-02\n",
      "   9.88342506e-02  2.74512010e-02 -3.01033933e-02 -4.43191432e-01\n",
      "  -1.18323286e-01 -1.20812035e-01]\n",
      " [-5.87811160e-01 -1.56883933e-01  1.57859410e-01  1.48903263e-01\n",
      "   2.53825272e-04 -6.06036386e-03 -1.21848128e-01  6.15946597e-02\n",
      "  -8.15986705e-02  2.13477879e-02]\n",
      " [-5.96071973e-01  5.60798506e-02 -3.15079943e-02  1.30458610e-02\n",
      "   4.31614505e-01 -1.33656296e-01  4.41934440e-02 -4.76665455e-02\n",
      "   1.09669535e-01  1.26064399e-01]\n",
      " [-5.57507669e-01 -5.01732810e-02 -6.68139599e-02 -4.27197333e-01\n",
      "   1.02201271e-01  3.78713086e-03 -1.09743604e-01 -6.01020889e-02\n",
      "   1.91326605e-01  1.45770789e-01]\n",
      " [-6.21422656e-01 -5.59561219e-02  1.80287401e-01 -4.41215754e-02\n",
      "  -7.63600327e-02  3.92005208e-01  2.73881499e-01 -3.65326000e-02\n",
      "   1.34865921e-01 -3.02267445e-02]\n",
      " [-6.27624544e-01  1.70783396e-01 -2.78500929e-01 -1.14434421e-01\n",
      "   1.03573424e-01  1.19293390e-01  3.61588698e-01 -2.36684584e-01\n",
      "  -1.42993018e-01  5.46651425e-02]\n",
      " [-5.43744176e-01  5.19994781e-02 -3.96899499e-02 -5.45945125e-03\n",
      "  -9.20216668e-02 -1.74861824e-01  1.74209240e-01 -2.69590390e-01\n",
      "   3.83627500e-04 -2.21536413e-01]\n",
      " [-5.92240749e-01  5.58424303e-03 -3.36148637e-02  2.09214843e-01\n",
      "  -1.95678013e-01 -3.56897057e-01  3.00113992e-01  9.74540308e-02\n",
      "   3.91983974e-02 -3.80958842e-02]\n",
      " [-6.65252370e-01 -6.20322250e-02  3.01606241e-02 -1.44062113e-01\n",
      "   3.04324457e-02  7.49160778e-02 -2.45968564e-01  1.16669712e-01\n",
      "  -2.02494598e-01  1.37880073e-01]\n",
      " [-5.78110614e-01  1.95934812e-01 -2.81248790e-01 -3.27038691e-01\n",
      "   1.44185918e-01 -2.11391112e-02  3.68533600e-01  4.15743667e-02\n",
      "  -1.65438927e-01 -1.66194928e-01]\n",
      " [-5.92418991e-01  4.79223662e-02  1.40113690e-01  2.69913157e-01\n",
      "   6.11689873e-02  1.61403110e-01  2.66635776e-01 -5.03707564e-02\n",
      "   4.37842149e-02  2.46643801e-01]\n",
      " [-6.41735293e-01 -1.26144593e-01  2.22021022e-01 -7.04221366e-02\n",
      "   1.66034758e-01  7.68561806e-02 -1.52365596e-01 -2.94831632e-02\n",
      "  -3.89895829e-01  2.79465778e-01]\n",
      " [-6.01418594e-01  3.56174090e-02  1.71466464e-01  2.05398598e-01\n",
      "   1.58597420e-01  2.92857618e-02  4.79209142e-02  2.15065059e-01\n",
      "  -2.29148636e-02  1.63985315e-01]\n",
      " [-5.74194631e-01 -7.02979247e-02  2.28366065e-01  2.20212354e-01\n",
      "   2.45459554e-01 -5.89929222e-03 -1.95878461e-01 -3.37439041e-01\n",
      "  -8.17494330e-02  1.61506700e-02]\n",
      " [-6.69576841e-01  1.13637202e-01  9.87368468e-02  1.67450885e-01\n",
      "  -3.66299186e-01 -1.24130184e-01 -1.20768120e-01  2.94590537e-02\n",
      "   2.04359122e-02  2.84344454e-02]\n",
      " [-5.98193738e-01  3.38850030e-01  1.70933975e-01 -2.20491249e-02\n",
      "  -2.44435366e-01 -9.22684739e-02  1.45367797e-01 -6.08662663e-02\n",
      "   1.73687828e-01  4.24739125e-02]\n",
      " [-5.70298044e-01 -1.85224182e-02  5.78561694e-02  2.25271199e-01\n",
      "   4.71354412e-03 -1.89053080e-01 -2.72117440e-02 -3.00764132e-01\n",
      "   2.21881294e-01 -1.68934864e-01]\n",
      " [-5.83327060e-01 -4.17380586e-02  5.88083143e-02  2.16904955e-01\n",
      "  -1.79697680e-01  8.42583330e-02  9.51755794e-02  2.92962103e-01\n",
      "  -5.08703909e-02 -3.65866265e-02]\n",
      " [-5.85468072e-01  9.83000581e-02 -1.52105733e-01 -3.05047600e-03\n",
      "   1.53223910e-02 -1.05268608e-01  1.20973996e-01  1.19724035e-02\n",
      "   1.29667572e-01 -4.01596270e-01]\n",
      " [-6.21207723e-01 -1.25488837e-01  2.23465039e-01 -1.04588610e-01\n",
      "  -2.04722719e-01  1.72306957e-01 -1.89921535e-01 -2.50632110e-01\n",
      "  -1.53089793e-01 -1.16125630e-01]\n",
      " [-5.84297874e-01  1.04758790e-01  1.36742855e-01 -3.78460335e-01\n",
      "  -1.42108312e-01 -7.04724570e-02  9.06552877e-02 -1.80544993e-01\n",
      "   1.04184136e-01  3.01482031e-01]\n",
      " [-6.02062653e-01 -3.62919587e-02  1.11596084e-01 -1.30942888e-01\n",
      "   1.23520936e-01  6.69408586e-02 -1.40603940e-01  2.41350699e-02\n",
      "   1.98507062e-01 -2.40306014e-01]\n",
      " [-6.22074471e-01  2.58445403e-01 -6.65203915e-02  9.16663143e-02\n",
      "   6.40168629e-02 -4.79727951e-01  1.33135881e-01  2.01762332e-01\n",
      "   5.21118399e-02 -3.41869945e-01]\n",
      " [-6.32176281e-01 -3.55814486e-01  1.20358487e-01 -8.16025925e-02\n",
      "  -1.36839795e-01  9.07205321e-02  2.93846508e-01 -1.51163505e-01\n",
      "   8.85727576e-02  4.24799036e-02]\n",
      " [-6.56303640e-01  1.06862528e-01  7.55337899e-02  3.35877178e-01\n",
      "  -9.81564292e-02 -1.08857329e-01  1.37384846e-01 -1.92522021e-01\n",
      "  -2.86820401e-01 -3.00551460e-01]\n",
      " [-5.89477505e-01 -1.26939941e-01 -2.56307634e-01 -1.03154123e-01\n",
      "  -1.85615315e-01  2.65794600e-02  4.15921657e-02  2.25378966e-01\n",
      "   1.00431845e-03  2.18303508e-02]\n",
      " [-6.70725664e-01 -1.82377364e-01  3.19493988e-01 -3.29021934e-01\n",
      "  -1.39962748e-01 -2.69527842e-01  1.54642560e-01  8.78764543e-02\n",
      "   9.97893963e-02  1.30057898e-01]\n",
      " [-5.77374940e-01  7.55379492e-02 -7.90914949e-02  1.24050394e-01\n",
      "  -1.73785813e-01  5.48314417e-02 -6.79019641e-02 -2.59637498e-01\n",
      "   4.70777753e-02  4.46289745e-03]\n",
      " [-5.51593947e-01  3.14868377e-01 -1.02331689e-01  4.10501144e-02\n",
      "  -9.94055932e-02  8.36801220e-02  1.82025780e-01  3.63052675e-02\n",
      "  -6.70444264e-02 -8.47364930e-02]\n",
      " [-6.37314539e-01  2.98484870e-01 -1.44770970e-01  1.05599447e-01\n",
      "   1.47476887e-02 -4.57622336e-02  2.41421002e-02 -6.91182929e-03\n",
      "  -7.58771037e-02 -1.01829414e-01]\n",
      " [-5.77804676e-01 -2.16503675e-01 -3.63205348e-01  4.02333318e-02\n",
      "  -1.91880561e-01  8.11470661e-02  2.79395615e-02 -1.30402141e-01\n",
      "   1.21286977e-01 -3.99449113e-02]\n",
      " [-5.89284653e-01  1.14344533e-01 -2.30442872e-01  1.46610533e-01\n",
      "   2.95825039e-01 -2.23665462e-01 -1.96350904e-01 -9.38505299e-03\n",
      "  -1.26493171e-01 -1.06670050e-01]\n",
      " [-6.13312205e-01 -6.10289799e-02 -1.46410127e-01 -4.02371341e-01\n",
      "   2.17610439e-01  1.75253412e-01 -4.40340642e-02  1.71606930e-02\n",
      "  -1.60357206e-01  4.41039044e-02]\n",
      " [-5.27348189e-01 -5.24223223e-02 -5.40506437e-02 -1.84304340e-01\n",
      "   1.15526434e-01 -1.05127993e-01  9.89642177e-02  2.36712996e-01\n",
      "  -3.01434252e-01  6.54372555e-02]\n",
      " [-5.44652516e-01 -2.72166008e-01 -1.30085606e-01  2.05848340e-01\n",
      "   1.08557756e-01 -9.28780912e-02  1.45862028e-01 -2.50630609e-01\n",
      "  -1.67085166e-02  1.93122114e-01]\n",
      " [-5.41933950e-01  4.46019257e-03  4.95333077e-02 -2.06228994e-01\n",
      "  -1.50779647e-01  1.04211351e-01 -1.20252307e-01  1.89251271e-01\n",
      "   2.13360420e-01 -3.76015366e-02]\n",
      " [-5.80636936e-01  3.13129248e-01  2.67439901e-02 -4.63479002e-02\n",
      "  -9.93804455e-03  3.53632626e-02 -4.17509373e-01 -1.34079966e-01\n",
      "   1.32762937e-01  7.99483090e-02]\n",
      " [-5.88761449e-01 -1.10742193e-01  1.16737619e-01 -1.89963970e-02\n",
      "  -1.22495064e-01  1.26080356e-01  7.16348309e-02 -1.90499170e-01\n",
      "  -4.22575893e-01  8.84077556e-02]\n",
      " [-5.64255626e-01  8.56082282e-02 -9.12965335e-03 -1.94430213e-01\n",
      "   1.98222678e-01  6.88642748e-02  1.21498021e-01 -3.44378358e-02\n",
      "  -1.68611303e-01  1.77515402e-01]\n",
      " [-6.11193208e-01 -2.22677831e-03  1.91194031e-01  3.96318418e-03\n",
      "   1.46295730e-01 -2.73570187e-01 -1.54712057e-01 -1.48952499e-01\n",
      "   6.27399152e-02  2.04838789e-01]\n",
      " [-6.15724846e-01 -2.81836815e-01 -3.44190152e-01  1.92964560e-01\n",
      "   1.55586013e-01  1.45866039e-01 -1.26095361e-01 -6.97514645e-02\n",
      "  -1.97160895e-02  1.46217941e-01]\n",
      " [-5.82829352e-01 -5.39536515e-02 -3.39280796e-01  1.00519647e-02\n",
      "  -7.02739322e-02 -1.95417475e-01  9.70861862e-02  1.99461415e-02\n",
      "   7.07233676e-02 -9.60304271e-02]\n",
      " [-5.65550002e-01 -8.24530433e-03 -1.04677526e-01  2.89707959e-01\n",
      "  -9.61516588e-03  6.75542375e-03 -2.16956277e-01 -1.63919786e-02\n",
      "  -4.21515618e-01  2.01702855e-01]\n",
      " [-6.29735586e-01  4.01946563e-03 -1.88357618e-01  2.37788182e-01\n",
      "  -2.46627983e-01 -2.28201042e-01 -3.35475389e-02 -1.36945537e-02\n",
      "   4.07464687e-01 -1.59996495e-01]\n",
      " [-5.91653220e-01  2.61690170e-01  2.20162496e-01 -3.45980213e-01\n",
      "   2.02030968e-01  1.11333852e-01 -1.74853959e-01 -2.33257385e-01\n",
      "  -1.62950247e-02 -4.84748252e-02]\n",
      " [-6.08704839e-01  1.95834089e-01 -2.17467723e-01 -9.34530501e-02\n",
      "  -1.46884256e-02  1.40647779e-01 -1.22428722e-02 -1.41661802e-01\n",
      "  -8.83698261e-02 -3.37811908e-01]\n",
      " [-6.32768570e-01  1.05641813e-02  3.73491189e-02  8.55057671e-02\n",
      "   9.39639787e-02 -2.98503486e-01  8.55713659e-02  2.01607424e-01\n",
      "  -2.72894734e-03 -6.56324118e-02]\n",
      " [-6.00777793e-01  1.28155102e-01  1.25795628e-01  1.42194607e-02\n",
      "  -1.81661240e-01  3.25908220e-01  3.97216576e-06  1.37159594e-01\n",
      "   1.05989069e-01  2.09968621e-01]\n",
      " [-5.83802912e-01 -2.18906684e-01  1.07760234e-01  1.37642691e-02\n",
      "  -3.10605778e-01 -8.08177559e-02  2.01293042e-01  2.35633948e-01\n",
      "   1.00965214e-01 -8.66341745e-03]\n",
      " [-6.24172504e-01 -6.85027919e-02  2.05459787e-01  1.84684491e-03\n",
      "   2.23306639e-01  7.55288109e-02  1.64986888e-02  1.32798181e-01\n",
      "  -2.53154143e-01  7.92990308e-02]\n",
      " [-5.69723181e-01  9.91457758e-02 -1.89619387e-01 -6.38710732e-02\n",
      "  -4.51957408e-01 -4.51164605e-02  2.39062765e-01 -1.22912921e-01\n",
      "   1.39326933e-01  2.64794633e-01]\n",
      " [-6.09814369e-01 -1.11184744e-01 -9.17394264e-02 -2.06079170e-02\n",
      "   3.16831220e-01 -6.27832048e-03  3.58119345e-03  9.59123242e-02\n",
      "  -2.12474755e-01 -1.35440516e-02]\n",
      " [-6.64609498e-01 -9.14083346e-02 -1.93901519e-01 -1.67415773e-01\n",
      "  -2.06283530e-01  3.02846332e-01 -2.76410318e-01 -5.69810681e-02\n",
      "  -2.00298075e-01 -1.86187092e-01]\n",
      " [-5.94503158e-01  3.46967664e-01 -1.72299256e-01 -1.20675386e-02\n",
      "  -4.60819530e-02  2.53474366e-01  5.30267720e-02  1.91575348e-01\n",
      "  -1.99754442e-01  2.03388957e-01]\n",
      " [-5.80309899e-01 -1.27919237e-01  7.33717610e-02 -2.45739748e-01\n",
      "   1.25289570e-01  2.61783042e-02 -1.52413012e-01 -1.03795504e-02\n",
      "  -2.32283076e-02 -3.99169489e-01]\n",
      " [-5.75682349e-01  4.28681192e-01  5.97221285e-03  1.01116951e-01\n",
      "  -5.80504193e-02 -2.04113118e-01 -2.32419122e-01 -1.19008173e-01\n",
      "  -7.81253360e-02 -2.40307502e-01]\n",
      " [-5.59955858e-01  8.40339665e-02  3.80252410e-01 -3.02249383e-01\n",
      "   1.29951115e-03  4.34541242e-02 -4.69609172e-02  1.23097055e-01\n",
      "  -1.63520611e-01 -1.50727429e-01]\n",
      " [-6.56536522e-01 -2.91195530e-01  1.48253359e-01  2.15290016e-01\n",
      "  -3.93815675e-02 -2.32852235e-01  2.47180910e-01 -1.53895994e-02\n",
      "   3.14948004e-01 -1.77069879e-01]\n",
      " [-5.49427504e-01  2.15057548e-01 -4.39716144e-02  2.69212573e-01\n",
      "   1.41491648e-01  1.48712630e-01  2.28333616e-01  1.70134933e-01\n",
      "  -1.56513833e-01 -1.63802665e-01]\n",
      " [-6.32879547e-01 -1.13659665e-01 -6.52150397e-02 -1.83057332e-02\n",
      "   1.21323344e-01 -1.47259874e-02  7.51239740e-02  7.73340355e-02\n",
      "   1.58216629e-02  9.61034672e-02]\n",
      " [-6.31972611e-01  1.61361696e-01  2.17360541e-01 -2.48272080e-01\n",
      "   1.65663295e-01  8.52465571e-02  3.95507584e-02 -4.02124261e-02\n",
      "   4.34897902e-01  2.50405964e-01]\n",
      " [-5.78484612e-01  2.17233387e-01 -1.25350128e-01  2.40550283e-01\n",
      "   3.22122956e-01 -2.08709620e-01  8.92294766e-02  2.03060906e-01\n",
      "  -1.99229152e-01  2.65311470e-01]\n",
      " [-6.35394226e-01 -1.93247833e-01 -2.22224895e-01  1.72790328e-01\n",
      "   9.71831431e-02  1.77074762e-01  1.78639192e-01  2.35480141e-01\n",
      "  -9.53574703e-02 -8.10674766e-02]\n",
      " [-6.08513082e-01 -4.04115930e-02  1.08171719e-01 -2.13264226e-01\n",
      "   2.14674807e-01 -3.44615905e-01 -1.05960347e-02  6.44383869e-02\n",
      "   1.57749899e-02 -2.08235948e-01]\n",
      " [-5.67472642e-01  6.75736122e-02 -2.79682285e-01  4.02439815e-01\n",
      "  -3.29454237e-01  2.34404811e-01 -3.97382539e-02 -1.31655838e-01\n",
      "  -2.90167625e-01  7.52118434e-03]\n",
      " [-6.55509729e-01 -1.75970005e-01  6.18069229e-02 -2.14028904e-01\n",
      "  -1.78639920e-01 -2.26454351e-01  2.92985776e-01  1.43280434e-01\n",
      "  -1.27492571e-01 -2.22753630e-01]\n",
      " [-5.81092490e-01  2.42329252e-01  1.62567148e-01  4.94609221e-02\n",
      "   1.92171481e-01 -2.98835269e-01  1.29256799e-01 -2.18271320e-01\n",
      "  -2.18409144e-01  1.62663825e-01]\n",
      " [-6.31428969e-01 -9.81560273e-02 -1.59382868e-01 -1.77800945e-01\n",
      "   1.98337312e-01 -1.60631388e-01 -4.57908074e-02  2.08232001e-01\n",
      "   2.30190243e-01  1.60237807e-02]\n",
      " [-6.18576053e-01 -1.55099055e-01  1.70949250e-01 -9.53001449e-02\n",
      "  -5.88846774e-02 -4.69146801e-02 -6.29205034e-03 -7.03129449e-02\n",
      "   1.89469861e-01 -4.85695480e-02]\n",
      " [-5.60207039e-01  3.18476047e-01 -1.50667187e-01 -1.15547305e-01\n",
      "   3.35294190e-02 -1.90936239e-02 -2.50498196e-01  3.42143490e-02\n",
      "   1.75128590e-01  7.50264354e-02]\n",
      " [-4.97898557e-01 -4.21708841e-02 -4.06821618e-02 -2.36081722e-02\n",
      "   1.93079424e-01  2.19356763e-01  3.35327258e-01  1.21487829e-01\n",
      "   6.53274913e-02 -1.15194785e-01]\n",
      " [-5.92288740e-01  1.09589343e-01  1.00336975e-02 -2.04618382e-01\n",
      "   1.49193621e-01  1.35349850e-01  4.85807142e-02 -4.41456984e-02\n",
      "   1.93066797e-01  9.09820608e-02]\n",
      " [-6.13757974e-01 -2.70298100e-01  2.91169644e-01 -3.16272757e-02\n",
      "  -1.56861394e-01  1.90980184e-02  1.51745765e-01 -3.97428355e-01\n",
      "  -4.63047766e-02  1.93078286e-01]\n",
      " [-6.26542818e-01  5.05667248e-03  3.72679881e-01  2.13444822e-02\n",
      "  -1.13601491e-01  1.84816269e-01  1.65372903e-02 -1.85375371e-01\n",
      "  -2.53087739e-02  4.12060014e-02]\n",
      " [-5.97172014e-01 -1.18240719e-01  2.77574890e-02 -1.24031070e-01\n",
      "  -8.26687943e-02  4.15111378e-02  1.02539172e-01  2.89546395e-01\n",
      "  -9.49068640e-02  8.28383469e-02]\n",
      " [-6.17728587e-01 -3.72152648e-02 -8.80690654e-02  3.64520953e-01\n",
      "  -2.64855702e-01  1.45900068e-01 -3.47089511e-02 -2.13235960e-01\n",
      "  -3.17010102e-01  2.27474500e-01]\n",
      " [-5.90340690e-01 -7.67521784e-02  2.97420217e-01  1.83965822e-01\n",
      "   1.87885250e-03 -1.30722459e-01 -9.93058727e-02  3.85771417e-02\n",
      "  -2.03402121e-01  2.18909446e-01]\n",
      " [-6.33886445e-01 -2.40134771e-01 -2.17178541e-01 -8.03262221e-02\n",
      "   1.98005500e-01  1.45194360e-01  4.41155529e-02 -7.37273054e-02\n",
      "  -2.15849232e-02 -5.13350053e-01]\n",
      " [-6.51502816e-01  1.69120695e-01 -1.87905631e-01  3.03251240e-01\n",
      "  -7.56370646e-02  3.12741195e-01 -1.61505656e-02 -7.69656763e-02\n",
      "   2.51222247e-01  1.10690229e-01]\n",
      " [-5.62141902e-01  5.65047347e-01  7.87111277e-02  1.76887068e-01\n",
      "   3.95683345e-02  1.09253057e-01 -3.80767669e-01  3.56383357e-02\n",
      "   1.28112523e-01 -2.25460167e-01]]\n",
      "\n",
      "Target Embedding Matrix Ut:\n",
      "[[-8.10562013e-01 -7.70550810e-02  9.94342512e-02  7.42090649e-02\n",
      "  -5.51763306e-02  7.27939868e-02 -2.39019769e-01  3.40690125e-02\n",
      "  -3.66976359e-01  1.72587959e-01]\n",
      " [-8.01085764e-01  4.18462416e-01  2.51049290e-01 -2.18149841e-01\n",
      "  -4.15056752e-02 -2.79255737e-01 -8.18839145e-03 -1.48405638e-01\n",
      "   1.02180833e-01 -2.01735433e-02]\n",
      " [-8.49229965e-01  3.50608560e-01  1.15393862e-01  2.04753995e-02\n",
      "  -2.70240539e-02  3.99059475e-01 -1.58237156e-01 -2.79620420e-01\n",
      "   1.83013218e-01 -3.04796784e-01]\n",
      " [-8.56625837e-01 -4.53653579e-03  3.36295539e-02  5.04204562e-01\n",
      "  -1.16165449e-01 -1.10258293e-01 -1.64737185e-01 -1.10770634e-01\n",
      "   1.67584829e-01  6.28259074e-02]\n",
      " [-8.26554419e-01  6.15233703e-02 -2.70303560e-01  1.47667206e-01\n",
      "  -3.21714916e-01 -2.40891361e-01 -2.50608336e-01 -2.44464415e-01\n",
      "  -1.84155196e-01 -2.72831902e-02]\n",
      " [-8.11169571e-01 -1.14739155e-01  3.81614164e-01  2.78763833e-01\n",
      "  -7.91542316e-03  4.79598339e-01 -1.01147432e-01  1.68252836e-01\n",
      "   8.19648986e-03 -9.31576218e-02]\n",
      " [-8.34580114e-01  2.68869572e-02  2.69168184e-01 -1.02901778e-01\n",
      "   1.55476305e-01  4.52547778e-01 -6.79937730e-02  1.06306280e-01\n",
      "  -2.13505953e-01  3.34599583e-02]\n",
      " [-8.65099174e-01  3.86424016e-01  9.79294133e-02 -1.01985311e-01\n",
      "  -4.33057787e-03  1.59050797e-01  2.44696331e-01  2.62636065e-01\n",
      "  -2.46704368e-02  4.18584351e-02]\n",
      " [-8.36499882e-01  1.39961262e-01  3.53254212e-01 -2.74651982e-01\n",
      "   3.32498439e-01 -1.45239397e-01 -1.25728942e-01 -4.43410161e-01\n",
      "   1.44324250e-01  1.69782377e-01]\n",
      " [-8.25456033e-01 -1.76061440e-02  9.46856480e-02 -4.42542895e-01\n",
      "  -1.50661353e-01  4.23096914e-01  1.74245734e-01  1.65266659e-01\n",
      "   7.68510563e-02 -2.61773140e-01]\n",
      " [-8.43650907e-01 -2.61162496e-01  1.07669260e-01 -1.24434274e-01\n",
      "  -7.18618429e-02  2.32223602e-01 -8.84563698e-02 -2.34808642e-01\n",
      "  -2.34998748e-01 -1.35244412e-01]\n",
      " [-8.72480477e-01 -1.80933073e-02  1.39231603e-01 -2.92591406e-01\n",
      "   1.31924282e-01 -2.70641933e-01 -4.21513145e-01  3.19983875e-01\n",
      "  -2.37787206e-01 -4.42403646e-01]\n",
      " [-9.11301071e-01  3.27014394e-01 -5.10369013e-01  1.78716024e-01\n",
      "   2.05608167e-01  5.40347979e-01  2.71089941e-02  4.56712581e-02\n",
      "   3.14058736e-01  3.16819230e-01]\n",
      " [-8.76919638e-01  2.15840519e-01 -1.34513327e-01  1.84475628e-01\n",
      "  -2.51053945e-02 -1.24262775e-01 -6.30144831e-02  7.11262231e-02\n",
      "  -1.85291603e-01  1.36566868e-01]\n",
      " [-8.67423265e-01 -1.76034005e-01 -1.36224702e-01 -1.46686316e-01\n",
      "   2.24897711e-01 -3.50312507e-01 -6.42141335e-01  3.13386503e-01\n",
      "   3.71882346e-02  8.06601722e-02]\n",
      " [-9.16837131e-01 -2.55521690e-01 -3.60432880e-02  8.91970529e-03\n",
      "  -4.65514958e-01  4.16734007e-02  1.92400239e-01 -2.37398805e-01\n",
      "   1.89992701e-01 -8.66712800e-03]\n",
      " [-8.46176469e-01 -3.74052852e-01  2.40672569e-01  1.42105472e-02\n",
      "  -1.95221248e-01 -1.91228168e-02 -1.27513845e-01  5.26028947e-01\n",
      "   2.45793611e-01 -3.99010207e-01]\n",
      " [-8.03618188e-01 -8.91723236e-02 -4.08171895e-01 -3.21883971e-01\n",
      "  -4.27216546e-02 -1.90897615e-01  3.04223242e-01  1.06184573e-01\n",
      "  -8.80414230e-02  2.11464906e-01]\n",
      " [-8.29434694e-01 -7.71826050e-03  9.38928055e-02  3.12642976e-01\n",
      "  -2.60673003e-02 -9.08628712e-02 -5.83532571e-02  1.75607867e-01\n",
      "   5.29533386e-02  2.44088666e-01]\n",
      " [-8.18303333e-01 -3.42230505e-01  1.10297991e-01 -1.78427937e-02\n",
      "  -1.10807810e-01  2.76978120e-01 -1.46989904e-01  6.85005498e-02\n",
      "   7.22223389e-02 -3.44343260e-01]\n",
      " [-8.15934294e-01  3.35007332e-01 -7.03488070e-02  1.72165398e-01\n",
      "  -1.22670030e-01  9.45822741e-02  3.03307285e-01 -2.99241280e-01\n",
      "   3.21471592e-01 -2.58106518e-01]\n",
      " [-8.04153861e-01 -4.31649648e-01 -1.88015006e-01  1.16997143e-01\n",
      "  -2.93740700e-01  2.47056185e-01 -1.48758000e-01 -2.38060539e-01\n",
      "   1.76469501e-01  1.33662903e-01]\n",
      " [-8.18328977e-01 -1.08251274e-01  3.31952334e-01  3.83812904e-01\n",
      "  -3.45485584e-01 -4.17603636e-01  8.90676668e-02 -4.19801922e-01\n",
      "   1.78924281e-01  1.17391979e-02]\n",
      " [-8.34790148e-01 -2.37681139e-01 -1.66390321e-01 -3.55236965e-01\n",
      "   2.53768354e-01  3.32006167e-02  1.70164863e-01 -1.90442721e-01\n",
      "  -1.31534241e-01  4.19658163e-01]\n",
      " [-8.43762020e-01  9.40324862e-02 -2.22527677e-01  3.07851858e-01\n",
      "   2.30114765e-01  5.71136380e-03  3.14028681e-02  2.11069661e-01\n",
      "   2.42986875e-01 -1.39970735e-03]\n",
      " [-8.24151302e-01  1.46857920e-01  1.87680505e-01  1.79298789e-01\n",
      "  -6.39754811e-02 -2.96921846e-01  2.59316687e-01  2.95056080e-01\n",
      "  -4.60007960e-01  1.44096985e-01]\n",
      " [-8.67553544e-01 -1.58515237e-01 -1.43768763e-01  7.36657545e-02\n",
      "  -1.67310771e-02  2.10515010e-01  8.69695465e-01  7.63392994e-02\n",
      "   1.48792145e-01  5.81583433e-01]\n",
      " [-8.31714098e-01  7.41396724e-02 -1.30304987e-01 -1.27040910e-01\n",
      "  -2.45994620e-01  5.21357458e-01  3.21502937e-01  2.11819841e-01\n",
      "  -8.79547974e-02 -1.70424931e-01]\n",
      " [-8.29163299e-01  3.97702163e-01  2.94309477e-01  1.88976359e-01\n",
      "  -1.33014164e-01  1.20757012e-01  2.26071640e-02 -2.03965653e-01\n",
      "  -4.74675448e-01  9.30270230e-02]\n",
      " [-8.07015895e-01 -7.79468638e-02  5.41497661e-01 -2.15823638e-01\n",
      "   2.56930873e-02  1.04278311e-01 -1.44376801e-01  1.67611577e-01\n",
      "  -3.10618565e-02 -2.47444183e-01]\n",
      " [-8.15631112e-01  9.82637880e-02  1.28920944e-01 -1.04267838e-01\n",
      "  -1.61365424e-01 -1.82482358e-02  1.35489450e-01  1.40154248e-01\n",
      "   5.54777810e-02 -4.17090340e-01]\n",
      " [-8.58936405e-01  3.26172610e-01  2.59163491e-01  5.10531318e-02\n",
      "  -4.13277181e-01  4.67551847e-01 -2.81985767e-01 -1.20203572e-01\n",
      "   2.37145243e-01  4.22038585e-01]\n",
      " [-8.62560450e-01 -2.43557662e-01 -4.38333371e-01 -2.45558671e-01\n",
      "   3.51160555e-01  1.58652035e-01 -2.61214761e-01 -2.27144433e-01\n",
      "  -1.33419793e-01 -1.22528286e-01]\n",
      " [-8.76651960e-01 -7.39647788e-02 -8.06337570e-02 -1.13264792e-01\n",
      "  -5.08742937e-01  7.34716762e-02  2.86887828e-01  9.82236371e-02\n",
      "  -1.06849220e-01  2.97445287e-01]\n",
      " [-8.86958956e-01 -4.79595437e-01  8.85857472e-02 -2.41074965e-02\n",
      "   2.10798221e-01 -1.76147702e-01  5.79071472e-01 -1.70375376e-01\n",
      "   3.70988728e-01 -1.37448356e-01]\n",
      " [-8.61247478e-01  1.59912810e-01 -7.17879017e-02  3.27038660e-03\n",
      "  -2.22804450e-01 -2.12023781e-01 -8.98119583e-02 -2.14410460e-01\n",
      "  -1.85602767e-01 -9.42980055e-02]\n",
      " [-7.86538652e-01 -5.80354100e-02  7.21544119e-02  8.58782590e-02\n",
      "   6.69486869e-02  1.15037368e-02 -1.24697995e-01 -1.87481175e-01\n",
      "   2.23403453e-01 -1.89985864e-01]\n",
      " [-8.31217145e-01  9.62959652e-02  4.07539847e-01 -1.63850488e-01\n",
      "   3.82405256e-01 -2.22942842e-01  8.87889019e-02 -1.88304630e-01\n",
      "  -4.75642578e-02  2.34249988e-01]\n",
      " [-8.19566302e-01  1.60076632e-01 -6.52125323e-01 -1.35583540e-01\n",
      "   3.82241477e-02  9.81869192e-02 -3.28936530e-01 -3.60626507e-01\n",
      "  -3.48221734e-01  2.80477905e-01]\n",
      " [-8.20624941e-01  1.53070368e-01 -2.40270864e-01  1.17164868e-01\n",
      "  -7.03990841e-02 -1.80635193e-01 -5.81893978e-01  1.05352793e-01\n",
      "   3.83874755e-01  2.54330699e-01]\n",
      " [-8.50189702e-01  5.18924370e-01 -2.67530613e-01 -5.01992806e-01\n",
      "   6.54574331e-02  6.15953809e-02 -5.46952034e-03  2.48026221e-01\n",
      "   4.68337398e-02 -1.73820617e-01]\n",
      " [-8.73864740e-01 -5.48651461e-01  9.52301801e-02 -4.04264817e-02\n",
      "  -2.01937735e-03 -5.08207491e-01 -6.74615895e-02 -2.17350429e-01\n",
      "  -8.39544762e-02  2.26576103e-01]\n",
      " [-8.64920381e-01  2.71904273e-01 -3.42819833e-01  1.77936593e-01\n",
      "  -2.64860615e-01  2.05782268e-01  3.07743315e-01 -7.86015042e-02\n",
      "   1.70463580e-01 -1.18940902e-01]\n",
      " [-8.10982912e-01 -6.79923416e-02  8.89825531e-02  3.89173286e-02\n",
      "  -2.84648487e-01  3.48727042e-02 -1.14483897e-02 -6.30169812e-03\n",
      "   2.94459362e-01  1.74105494e-01]\n",
      " [-8.43839070e-01 -6.79313204e-01  5.09855327e-01 -3.55885862e-02\n",
      "   1.49420663e-01 -1.83310615e-01 -8.49113952e-02 -1.86702397e-01\n",
      "   8.68988614e-02  7.86839090e-02]\n",
      " [-8.46383342e-01 -1.97822802e-01 -3.21048200e-01 -4.40160149e-02\n",
      "   7.93463222e-02  1.93269723e-01 -1.32844611e-01 -2.47230361e-01\n",
      "  -7.34902073e-02 -5.14540766e-01]\n",
      " [-7.91875952e-01  2.57572681e-01  3.58777908e-01 -1.04857486e-01\n",
      "  -1.56398698e-01  1.05987087e-01  2.09486148e-01 -4.66929466e-02\n",
      "  -3.43625121e-01 -1.77076774e-01]\n",
      " [-8.82780894e-01 -5.83614495e-01 -2.27796100e-01 -1.98587384e-02\n",
      "  -3.51106377e-01  1.33754285e-03 -2.44376863e-01  2.72215814e-01\n",
      "   2.82181457e-01 -3.14226596e-01]\n",
      " [-8.34115489e-01  3.35258557e-01 -1.01964282e-01  1.14554700e-01\n",
      "  -4.45486250e-01 -1.38805009e-01 -2.07030637e-01  1.33643025e-01\n",
      "  -2.46374730e-01  2.80137365e-01]\n",
      " [-8.75110654e-01 -4.64661911e-01 -1.09320977e-01  4.77174549e-01\n",
      "   2.96889223e-01 -8.89674279e-02 -2.57854399e-02 -2.74654959e-01\n",
      "  -5.32905285e-02 -4.80289878e-01]\n",
      " [-7.57621622e-01 -2.03593634e-01  3.78087301e-01 -2.24631849e-01\n",
      "   1.23506504e-01  2.55908857e-01  4.84340674e-02  2.27246001e-01\n",
      "   5.28519430e-02 -1.16635628e-01]\n",
      " [-8.49891736e-01  2.47884047e-01 -7.47699543e-02  1.47714456e-01\n",
      "  -3.83280252e-01 -2.58525757e-01 -3.69846656e-01  2.27123041e-01\n",
      "   2.98274088e-01  6.45728720e-02]\n",
      " [-8.39698482e-01  1.61638725e-01 -2.16571198e-01  2.83448011e-01\n",
      "   3.80169413e-01 -1.08144381e-01  1.00855760e-01  6.16059098e-01\n",
      "  -3.26786747e-01  1.25342821e-01]\n",
      " [-8.90388596e-01 -1.77949855e-01  9.20268299e-02  5.88011305e-02\n",
      "   5.65693849e-02  2.09586262e-02  1.42948904e-01  4.63567522e-01\n",
      "  -4.82974977e-01 -2.35545602e-02]\n",
      " [-8.76760576e-01 -2.94413608e-01  3.63145833e-01  6.06002852e-02\n",
      "   3.11820064e-01 -1.59932348e-01  3.49775429e-01 -4.00638558e-02\n",
      "   3.04553557e-01  3.91968399e-01]\n",
      " [-8.35656794e-01 -1.97358214e-01 -1.59623774e-02  1.70561930e-01\n",
      "   8.37908856e-02 -1.22489594e-01 -3.12525386e-02  4.93942181e-01\n",
      "  -3.88547463e-01  2.18978758e-01]\n",
      " [-8.61178183e-01 -2.78497991e-01  1.56347393e-01  3.36248365e-01\n",
      "   8.61925214e-02  1.06477241e-01 -3.57116505e-02  1.12265010e-01\n",
      "  -5.02821858e-01  4.16349582e-03]\n",
      " [-8.56741340e-01  1.53527203e-01 -7.76528870e-02  2.24158814e-01\n",
      "  -1.33543426e-01 -4.37009534e-01  1.45673896e-01 -1.11405548e-02\n",
      "  -1.45797153e-01 -8.19542637e-01]\n",
      " [-8.59310553e-01  2.15913875e-01 -1.14560243e-01 -1.75376596e-01\n",
      "  -5.59618467e-01 -2.48288650e-01  1.52080197e-01 -3.50292532e-01\n",
      "  -3.66409422e-01 -1.11548168e-02]\n",
      " [-8.25529151e-01 -4.83946806e-01  3.59328065e-01 -1.54346413e-02\n",
      "  -4.88069367e-03 -2.00465892e-01  2.33659204e-01 -1.62247784e-01\n",
      "  -1.30418599e-02 -2.46805144e-01]\n",
      " [-8.26973514e-01 -3.92786618e-01 -2.41470573e-01 -4.47956073e-01\n",
      "   1.69766817e-01 -4.09194058e-01 -2.18636768e-01  1.47401404e-01\n",
      "   2.57961364e-01  1.29009222e-01]\n",
      " [-8.70900217e-01 -2.86197842e-01 -1.32104725e-01 -9.41422566e-02\n",
      "  -3.64806025e-02  5.38165315e-02 -2.97618526e-01 -4.65900873e-02\n",
      "  -2.70252668e-01  5.25438689e-01]\n",
      " [-8.28231704e-01 -3.94613867e-01 -3.74499020e-01 -6.44969380e-02\n",
      "   2.44280028e-02  2.66633608e-01  2.37176318e-02  2.42284732e-02\n",
      "  -1.72101039e-02 -8.88819925e-02]\n",
      " [-8.02725852e-01  5.51066167e-01 -2.08865022e-02  7.36310146e-02\n",
      "   4.90340626e-01 -2.31190412e-01  1.20199720e-01  2.86002173e-01\n",
      "   3.98807119e-02 -2.09172441e-01]\n",
      " [-7.72364497e-01  2.04292717e-01 -9.48114953e-02  1.64151733e-01\n",
      "   6.80670276e-01  2.93549744e-01 -1.30105549e-01 -1.09974768e-01\n",
      "   4.31324182e-02 -7.75574775e-03]\n",
      " [-8.34213502e-01  1.15125880e-01 -9.55188113e-02 -1.44285891e-02\n",
      "   8.76700333e-02 -2.59341949e-01 -1.63923400e-01  2.36382015e-01\n",
      "   5.85185182e-01  2.14149426e-01]\n",
      " [-8.77327823e-01 -3.77831687e-01  1.55555962e-02  2.71168633e-01\n",
      "   8.93124550e-02  5.90330383e-02 -1.07125894e-02 -4.46522775e-02\n",
      "  -2.08927912e-01  2.76414540e-01]\n",
      " [-8.18422525e-01  1.35942149e-01 -1.08310059e-01 -1.02079991e-01\n",
      "   7.79860528e-02 -1.58238058e-01  1.33953710e-01 -2.65884928e-02\n",
      "   4.01964426e-01 -2.61228491e-01]\n",
      " [-8.57682778e-01  1.62788991e-01 -2.45535117e-01 -2.81038801e-01\n",
      "  -2.20148337e-01  5.88957274e-03  3.78109576e-01  1.72257176e-01\n",
      "   6.09327188e-02 -1.01992762e-01]\n",
      " [-8.51349250e-01 -7.55447237e-02 -3.94570795e-02  3.28945775e-03\n",
      "   1.05305970e-01  4.60327711e-01 -1.75588963e-02 -1.36255384e-01\n",
      "   2.32955453e-01  2.02384655e-01]\n",
      " [-8.33228686e-01 -2.90483113e-01 -1.74378580e-01  1.32150563e-01\n",
      "  -3.73272628e-01  2.46896442e-01  7.44917304e-02  4.10120632e-01\n",
      "  -3.89872193e-01 -1.10634014e-01]\n",
      " [-8.63932302e-01  2.43624222e-02  1.94697555e-01 -4.50361058e-02\n",
      "  -4.14950000e-01  3.02564234e-01 -8.28851717e-02  2.31324551e-02\n",
      "   1.91427142e-01  3.12779384e-02]\n",
      " [-7.94230963e-01 -1.37577335e-01 -6.42219942e-01 -2.14085122e-01\n",
      "   3.64226338e-01 -5.68626817e-01  3.87326998e-01 -3.18168589e-03\n",
      "   1.97628596e-02  3.84546878e-02]\n",
      " [-8.68986261e-01  3.51649646e-01  1.17791683e-01 -6.96380732e-02\n",
      "  -1.65241597e-02 -3.57117368e-01  5.63137326e-01  2.44141594e-01\n",
      "   5.53049122e-01 -2.81675292e-02]\n",
      " [-8.84573694e-01 -1.01966694e-01  3.06664755e-01 -2.50803832e-01\n",
      "   5.50454330e-01  5.73939034e-01 -1.68788433e-01 -7.33114010e-02\n",
      "   2.95138685e-01  2.14276357e-01]\n",
      " [-7.86570388e-01 -2.57079300e-01 -2.24775433e-01  1.82301345e-01\n",
      "  -3.54376695e-01 -1.13647505e-01 -7.19178109e-03  5.68060965e-01\n",
      "  -8.16764831e-02  2.65802010e-01]\n",
      " [-8.72749698e-01  1.63235262e-01 -5.68533844e-01  3.18782403e-01\n",
      "   2.01863656e-01 -2.31239078e-01 -1.01012241e-01 -9.83257409e-02\n",
      "   1.82515587e-01 -6.13271516e-01]\n",
      " [-8.48425564e-01 -3.38569460e-03 -2.54560793e-01  4.06492111e-01\n",
      "   4.01972558e-01  1.36546903e-01  3.74184008e-01  1.49613358e-01\n",
      "  -2.86813333e-01 -2.38968134e-01]\n",
      " [-8.54091079e-01  2.89785725e-01  7.24236416e-01 -1.72842181e-01\n",
      "  -1.12797892e-01 -4.36830830e-01 -6.25864300e-03  2.18168163e-01\n",
      "  -1.03812129e-01  2.82835085e-01]\n",
      " [-9.12675464e-01  5.41889381e-02  2.89608924e-01  5.84027714e-01\n",
      "   2.32339042e-01 -2.12705923e-01 -2.67424475e-02 -3.55260073e-01\n",
      "   2.16778313e-03  2.56679295e-01]\n",
      " [-7.45030379e-01  4.40271861e-02  1.86044780e-01 -1.08415231e-01\n",
      "  -7.11139033e-02 -1.07660182e-01 -1.98953696e-01 -2.71949482e-01\n",
      "   1.10118773e-02 -3.14196531e-01]\n",
      " [-8.43632714e-01 -3.40388944e-02  1.26417679e-01  3.64622998e-01\n",
      "   2.68629561e-01  2.54104414e-01 -2.72866915e-01  9.24509838e-02\n",
      "   2.20511065e-02  1.11792398e-01]\n",
      " [-8.13620551e-01  5.08318074e-01  2.18747551e-01 -7.43719928e-02\n",
      "  -1.75404615e-01 -5.07990594e-02 -4.90688890e-01 -1.80148029e-01\n",
      "  -4.04676667e-01 -1.29364121e-01]\n",
      " [-8.79216112e-01  1.52420758e-01 -1.32584297e-01  4.06465545e-01\n",
      "  -4.28672911e-01  2.07085945e-01 -4.67646731e-01  2.29550118e-01\n",
      "   3.55839607e-01  1.13605737e-01]\n",
      " [-8.49164925e-01 -6.25410824e-02 -3.65663215e-01 -8.12313716e-01\n",
      "  -6.77715254e-02  1.40301408e-01 -2.33715006e-01 -4.49044749e-01\n",
      "   2.32806356e-03  9.11847362e-02]\n",
      " [-8.27107647e-01  5.08595552e-02  1.02020222e-02  6.50925765e-01\n",
      "   3.55557061e-01  2.32139260e-01  3.86148499e-02 -6.06841869e-01\n",
      "  -1.24557506e-01 -9.78118247e-02]\n",
      " [-8.73124908e-01  1.63567812e-01  3.26531696e-02 -1.36389160e-01\n",
      "  -2.17999945e-01 -1.76348420e-01  5.03259117e-01 -2.16293775e-01\n",
      "   2.69181681e-02  9.44975610e-02]\n",
      " [-8.63704884e-01  1.13451985e-01 -1.21795908e-02  2.67741976e-01\n",
      "   1.75791106e-01 -1.53630792e-01 -2.14402369e-01 -5.85678099e-02\n",
      "   6.32018129e-02 -1.85173369e-01]\n",
      " [-8.08102440e-01  4.85870820e-01 -7.19554632e-03 -2.99773097e-01\n",
      "   4.92343175e-01  1.35360791e-01 -1.18719748e-01  7.98512637e-02\n",
      "   1.44496208e-01  2.68187769e-04]\n",
      " [-7.90163182e-01  7.57609204e-02  3.26200848e-01 -8.49420392e-02\n",
      "  -1.04082892e-01 -8.62254687e-02 -2.51500653e-02  2.68547797e-01\n",
      "   4.23029781e-01 -5.36308333e-02]\n",
      " [-8.42103881e-01 -7.82060523e-02  2.55800528e-01 -2.89293826e-01\n",
      "  -2.53795793e-01  3.28819431e-01  2.44282390e-01 -2.71727255e-01\n",
      "  -1.38361903e-01 -3.01800263e-01]\n",
      " [-8.54849767e-01 -7.66629193e-02 -3.62503199e-01  1.54796477e-01\n",
      "  -1.12580320e-01 -2.05692997e-01 -7.49879292e-02  2.87874901e-02\n",
      "   6.33683746e-02  1.13654412e-01]\n",
      " [-8.23751044e-01  2.70974573e-01  2.65258217e-02 -3.11478724e-01\n",
      "   1.22378576e-01 -1.83058882e-01 -8.72795928e-02 -2.68530768e-01\n",
      "  -4.35741064e-01  1.75597822e-01]\n",
      " [-8.63268342e-01  7.22139955e-03 -2.13234825e-01 -9.06513210e-02\n",
      "  -2.80814360e-01 -2.40056118e-01  1.23249001e-01 -6.46396212e-01\n",
      "   7.67687514e-02  2.47218668e-01]\n",
      " [-8.91771286e-01 -7.89937791e-02  8.14645553e-02 -3.65442896e-01\n",
      "   1.01215948e-01  1.11404110e-01  9.64461231e-02  2.11536045e-01\n",
      "   1.81700614e-01  1.41670750e-02]\n",
      " [-8.38533726e-01 -1.18134116e-01 -1.40384608e-01 -5.54254223e-01\n",
      "   9.20101706e-03  3.83871606e-02  4.60636367e-02  9.89839122e-03\n",
      "  -3.84084061e-01 -1.80349807e-01]\n",
      " [-8.69655138e-01  5.25749094e-02  2.13558447e-01 -4.12203877e-01\n",
      "   2.97144640e-01 -3.32581799e-01 -3.07890075e-01  9.17107583e-02\n",
      "  -7.43872230e-02 -5.62176270e-02]\n",
      " [-8.90563825e-01  1.36330192e-01 -1.11589657e-01 -4.73596262e-02\n",
      "   2.81984389e-01  2.91539811e-01  1.63837423e-01  1.69368272e-01\n",
      "  -1.56996795e-01  1.97847554e-01]\n",
      " [-8.35641523e-01  2.62252298e-01  1.88457548e-01  1.23051542e-01\n",
      "   1.44189976e-01 -5.10979616e-02  1.51549022e-02  2.97705888e-02\n",
      "   2.49035372e-01  7.44662187e-02]\n",
      " [-7.99665111e-01  1.71764494e-01  4.02293193e-02  3.42022064e-01\n",
      "   1.61700135e-01  1.43709586e-03  4.23640723e-01 -1.40716045e-01\n",
      "  -3.83067518e-01 -7.21707842e-02]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import svd\n",
    "\n",
    "def compute_svd(M):\n",
    "    \"\"\"\n",
    "    Compute the Singular Value Decomposition (SVD) of a matrix M.\n",
    "\n",
    "    Parameters:\n",
    "    M (numpy.ndarray): Matrix M of shape (2N, N).\n",
    "\n",
    "    Returns:\n",
    "    U (numpy.ndarray): Left singular vectors.\n",
    "    Sigma (numpy.ndarray): Singular values.\n",
    "    Vt (numpy.ndarray): Right singular vectors transposed.\n",
    "    \"\"\"\n",
    "    U, Sigma, Vt = svd(M, full_matrices=False)\n",
    "    return U, Sigma, Vt\n",
    "\n",
    "def higher_order_proximity_embedding(Mg, Ml, K):\n",
    "    \"\"\"\n",
    "    Compute the higher-order proximity preserved embedding using SVD.\n",
    "\n",
    "    Parameters:\n",
    "    Mg (numpy.ndarray): Matrix Mg of shape (N, N).\n",
    "    Ml (numpy.ndarray): Matrix Ml of shape (N, N).\n",
    "    K (int): Embedding dimension.\n",
    "\n",
    "    Returns:\n",
    "    Us (numpy.ndarray): Source embedding matrix of shape (N, K).\n",
    "    Ut (numpy.ndarray): Target embedding matrix of shape (N, K).\n",
    "    \"\"\"\n",
    "    # Create the combined matrix for SVD\n",
    "    M_combined = np.vstack((Mg, Ml))\n",
    "    \n",
    "    # Compute the SVD of the combined matrix\n",
    "    U, Sigma, Vt = compute_svd(M_combined)\n",
    "    \n",
    "    # Select the top K components for the embedding\n",
    "    Us = np.dot(U[:len(Mg), :K], np.diag(np.sqrt(Sigma[:K])))\n",
    "    Ut = np.dot(Vt.T[:, :K], np.diag(np.sqrt(Sigma[:K])))\n",
    "    \n",
    "    return Us, Ut\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Define Mg and Ml matrices (example)\n",
    "    N = 100  # Number of nodes\n",
    "    K = 10   # Embedding dimension\n",
    "    \n",
    "    # Example matrices (Mg and Ml can be computed based on your specific higher-order proximity measure)\n",
    "    Mg = np.random.rand(N, N)\n",
    "    Ml = np.random.rand(N, N)\n",
    "    \n",
    "    # Compute the higher-order proximity preserved embedding\n",
    "    Us, Ut = higher_order_proximity_embedding(Mg, Ml, K)\n",
    "    \n",
    "    print(\"Source Embedding Matrix Us:\")\n",
    "    print(Us)\n",
    "    print(\"\\nTarget Embedding Matrix Ut:\")\n",
    "    print(Ut)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1955505c",
   "metadata": {},
   "source": [
    "GNN is a kind of neural network which processes directly the data represented in a graph domain. A typical application of GNN is node classification. Essentially, each node in the graph is associated with a label. Our goal is to predict the label of a node without an associated ground-truth.\n",
    "\n",
    "Let the vertex or node \\( x_i \\) (i = 1, \\dots, n) represent the ith data point (feature). The goal of GNNs is to learn a state embedding \\( h_i \\in \\mathbb{R}^s \\) which contains the information of the neighborhood for the \\( i \\)th node \\( x_i \\).\n",
    "\n",
    "GNNs are a general neural network architecture defined according to a graph structure \\( G = (V, E) \\). Nodes \\( j \\in V \\) take unique values from \\(\\{1, \\dots, |V|\\}\\), and edges are pairs \\( e = (i, j) \\in V \\times V \\). In directed graphs, \\( (i, j) \\) represents a directed edge \\( i \\rightarrow j \\). The node vector, also called node representation or node embedding, for node \\( j \\) is denoted by \\( x_j \\in \\mathbb{R}^D \\). Graphs may also contain node labels \\( l_j \\in \\{1, \\dots, L_{|V|}\\} \\) for each node \\( j \\) and edge labels or edge types \\( l_e \\in \\{1, \\dots, L_{|E|}\\} \\) for each edge. Let \\( x_S = \\{x_j \\ |\\ j \\in S\\} \\) when \\( S \\) is a set of nodes, and \\( l_E = \\{l_e \\ |\\ e \\in E\\} \\) when \\( E \\) is a set of edges.\n",
    "\n",
    "Let \\( f_i \\) be a parametric function (for the node \\( i \\)), called the local transition function, that expresses the dependence of node \\( i \\) on its neighborhood, and let \\( g_i \\) be the local output function (for the node \\( i \\)) that describes how the output is produced.\n",
    "\n",
    "The set \\( \\text{ne}[n] \\) stands for the neighbors of the vertex \\( n \\), i.e., the nodes connected to \\( n \\) by an arc, while \\( \\text{co}[n] \\) denotes the set of arcs having \\( n \\) as a vertex.\n",
    "\n",
    "The state vector or state embedding \\( h_i \\) and the output \\( o_i \\) can be represented by:\n",
    "\n",
    "$$\n",
    "h_i = f_i\\left(x_i, x_{\\text{co}[i]}, h_{\\text{ne}[i]}, x_{\\text{ne}[i]}\\right),\n",
    "$$\n",
    "$$\n",
    "o_i = g_i\\left(h_i, x_i\\right),\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- \\( x_i \\): the features of the node \\( i \\),\n",
    "- \\( x_{\\text{co}[i]} \\): the features of edges connecting with \\( i \\),\n",
    "- \\( h_{\\text{ne}[i]} \\): the embedding of the nodes in the neighborhood of \\( i \\),\n",
    "- \\( x_{\\text{ne}[i]} \\): the features of the nodes in the neighborhood of \\( i \\),\n",
    "- \\( f_i \\): a transition function that maps the above four inputs to d-dimensional space,\n",
    "- \\( g_i \\): an output function when the input is \\( x_i \\) and the transited state is \\( h_i \\).\n",
    "\n",
    "**Example 7.2** Let \\( x_1, \\dots, x_8 \\) be eight data points, where \\( x_2, x_3, x_4, x_6 \\) are the neighbors of \\( x_1 \\). Then, \\( x_{\\text{co}[1]} = \\left(e(1,2), e(3,1), e(1,4), e(6,1)\\right) \\), where \\( e(ij) \\) denotes the edge label connecting node \\( i \\) to node \\( j \\), \\( x_{\\text{ne}[1]} = \\left(x_2, x_3, x_4, x_6\\right) \\), and \\( h_{\\text{ne}[1]} = \\) ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38dcd5e",
   "metadata": {},
   "source": [
    "(h_2, h_3, h_4, h_6). In other words,\n",
    "\n",
    "$$\n",
    "h_1 = f\\left( x_1, x_{\\text{co}[1]} = \\left(e(1,2), e(3,1), e(1,4), e(6,1)\\right), h_{\\text{ne}[1]} = \\left(h_2, h_3, h_4, h_6\\right), x_{\\text{ne}[1]} = \\left(x_2, x_3, x_4, x_6\\right)\\right),\n",
    "$$\n",
    "\n",
    "which contains information on the neighborhood for the first node \\( x_1 \\).\n",
    "\n",
    "Let \\( h \\), \\( o \\), \\( x \\), and \\( x_N \\) be the vectors constructed by stacking all the states, all the outputs, all the features, and all the node features, respectively. Equations (7.14.1) and (7.14.2) can be rewritten in a compact form as [129]:\n",
    "\n",
    "$$\n",
    "h = f(h, x),\n",
    "$$\n",
    "$$\n",
    "o = g(h, x_N),\n",
    "$$\n",
    "\n",
    "where \\( f = [f_1, \\dots, f_N]^T \\) and \\( g = [g_1, \\dots, g_N]^T \\) are stacked versions of local transition functions and local output functions corresponding to all \\( N \\) nodes, respectively; and are known as the global transition function and global output function for all nodes in a graph, respectively. The aim of GNNs is to learn the global transition function \\( f \\) and the global output function \\( g \\).\n",
    "\n",
    "Let \\( t_i = Wh_i \\) be the target information (for a specific node \\( i \\)) for the supervision, the loss can be written as follows:\n",
    "\n",
    "$$\n",
    "L(W) = \\frac{1}{2} \\sum_{i=1}^{p} \\|t_i - o_i\\|_2^2,\n",
    "$$\n",
    "\n",
    "where \\( p \\) is the number of supervised nodes.\n",
    "\n",
    "By Banach’s fixed point theorem [78], GNN uses the following classic iterative scheme for updating the state:\n",
    "\n",
    "$$\n",
    "h^{(t+1)} = f\\left(h^{(t)}, x\\right),\n",
    "$$\n",
    "\n",
    "where \\( h^{(t)} \\) denotes the \\( t \\)th iteration of \\( h \\). This updating converges exponentially fast to the solution of Eq. (7.14.3) for any initial value \\( h^{(0)} \\).\n",
    "\n",
    "The dynamical systems based on the computations of \\( f \\) and \\( g \\) can be interpreted as feedforward neural networks. To learn the parameters of \\( f \\) and \\( g \\), given the target information \\( t \\) for the supervision, the loss in (7.14.5) can be rewritten as follows:\n",
    "\n",
    "$$\n",
    "L(W) = \\frac{1}{2} \\|t - o\\|_2^2 = \\frac{1}{2} \\|Wh - o\\|_2^2.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac1ff59",
   "metadata": {},
   "source": [
    "The learning algorithm is based on a gradient descent strategy composed of the following steps [129]:\n",
    "\n",
    "1. The states \\( h_i^{(t)} \\) are iteratively updated by Eq. (7.14.1) until a time \\( T \\). They approach the fixed point solution to Eq. (7.14.3): \n",
    "   $$\n",
    "   h^{(T)} \\approx h.\n",
    "   $$\n",
    "\n",
    "2. Compute the gradient of weights:\n",
    "   $$\n",
    "   \\nabla L(W^t) = \\frac{\\partial L}{\\partial W^t} = (W^t h - o^t) h^T.\n",
    "   $$\n",
    "\n",
    "3. The weights are updated as:\n",
    "   $$\n",
    "   W^{t+1} = W^t - \\mu_t \\nabla L(W^t).\n",
    "   $$\n",
    "\n",
    "4. Return to Step 1 and repeat the above steps until \\( W \\) is converged.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77ce3da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 0.29036661982536316\n",
      "Epoch 2/100, Loss: 0.17837175726890564\n",
      "Epoch 3/100, Loss: 0.11794856190681458\n",
      "Epoch 4/100, Loss: 0.10147053748369217\n",
      "Epoch 5/100, Loss: 0.11370628327131271\n",
      "Epoch 6/100, Loss: 0.13271023333072662\n",
      "Epoch 7/100, Loss: 0.14212076365947723\n",
      "Epoch 8/100, Loss: 0.13877928256988525\n",
      "Epoch 9/100, Loss: 0.12701861560344696\n",
      "Epoch 10/100, Loss: 0.11275219917297363\n",
      "Epoch 11/100, Loss: 0.10054752230644226\n",
      "Epoch 12/100, Loss: 0.09286817163228989\n",
      "Epoch 13/100, Loss: 0.09019728004932404\n",
      "Epoch 14/100, Loss: 0.09137881547212601\n",
      "Epoch 15/100, Loss: 0.09436710178852081\n",
      "Epoch 16/100, Loss: 0.09707813709974289\n",
      "Epoch 17/100, Loss: 0.09805217385292053\n",
      "Epoch 18/100, Loss: 0.09674113988876343\n",
      "Epoch 19/100, Loss: 0.09343274682760239\n",
      "Epoch 20/100, Loss: 0.08895740658044815\n",
      "Epoch 21/100, Loss: 0.0843329131603241\n",
      "Epoch 22/100, Loss: 0.08045006543397903\n",
      "Epoch 23/100, Loss: 0.07785101979970932\n",
      "Epoch 24/100, Loss: 0.07662783563137054\n",
      "Epoch 25/100, Loss: 0.0764523595571518\n",
      "Epoch 26/100, Loss: 0.07672816514968872\n",
      "Epoch 27/100, Loss: 0.07681632041931152\n",
      "Epoch 28/100, Loss: 0.0762542113661766\n",
      "Epoch 29/100, Loss: 0.07488521933555603\n",
      "Epoch 30/100, Loss: 0.07286105304956436\n",
      "Epoch 31/100, Loss: 0.07053609192371368\n",
      "Epoch 32/100, Loss: 0.0683111846446991\n",
      "Epoch 33/100, Loss: 0.06649035960435867\n",
      "Epoch 34/100, Loss: 0.06519496440887451\n",
      "Epoch 35/100, Loss: 0.06435318291187286\n",
      "Epoch 36/100, Loss: 0.0637553334236145\n",
      "Epoch 37/100, Loss: 0.06314705312252045\n",
      "Epoch 38/100, Loss: 0.062322910875082016\n",
      "Epoch 39/100, Loss: 0.06118977069854736\n",
      "Epoch 40/100, Loss: 0.05978231504559517\n",
      "Epoch 41/100, Loss: 0.058232296258211136\n",
      "Epoch 42/100, Loss: 0.056707873940467834\n",
      "Epoch 43/100, Loss: 0.055346786975860596\n",
      "Epoch 44/100, Loss: 0.05420786887407303\n",
      "Epoch 45/100, Loss: 0.05325688049197197\n",
      "Epoch 46/100, Loss: 0.05239064246416092\n",
      "Epoch 47/100, Loss: 0.05148688331246376\n",
      "Epoch 48/100, Loss: 0.05045803263783455\n",
      "Epoch 49/100, Loss: 0.049284569919109344\n",
      "Epoch 50/100, Loss: 0.048015423119068146\n",
      "Epoch 51/100, Loss: 0.046737827360630035\n",
      "Epoch 52/100, Loss: 0.04553365334868431\n",
      "Epoch 53/100, Loss: 0.0444430336356163\n",
      "Epoch 54/100, Loss: 0.04345124959945679\n",
      "Epoch 55/100, Loss: 0.04250260069966316\n",
      "Epoch 56/100, Loss: 0.04153233766555786\n",
      "Epoch 57/100, Loss: 0.040499456226825714\n",
      "Epoch 58/100, Loss: 0.039404645562171936\n",
      "Epoch 59/100, Loss: 0.03828541561961174\n",
      "Epoch 60/100, Loss: 0.037192996591329575\n",
      "Epoch 61/100, Loss: 0.03616424277424812\n",
      "Epoch 62/100, Loss: 0.03520383685827255\n",
      "Epoch 63/100, Loss: 0.03428594768047333\n",
      "Epoch 64/100, Loss: 0.03337313234806061\n",
      "Epoch 65/100, Loss: 0.032440148293972015\n",
      "Epoch 66/100, Loss: 0.031488437205553055\n",
      "Epoch 67/100, Loss: 0.030543019995093346\n",
      "Epoch 68/100, Loss: 0.029634928330779076\n",
      "Epoch 69/100, Loss: 0.02878156118094921\n",
      "Epoch 70/100, Loss: 0.02797759883105755\n",
      "Epoch 71/100, Loss: 0.027201538905501366\n",
      "Epoch 72/100, Loss: 0.026432547718286514\n",
      "Epoch 73/100, Loss: 0.0256650410592556\n",
      "Epoch 74/100, Loss: 0.02491137757897377\n",
      "Epoch 75/100, Loss: 0.024191590026021004\n",
      "Epoch 76/100, Loss: 0.023518403992056847\n",
      "Epoch 77/100, Loss: 0.022889206185936928\n",
      "Epoch 78/100, Loss: 0.022290177643299103\n",
      "Epoch 79/100, Loss: 0.021708576008677483\n",
      "Epoch 80/100, Loss: 0.02114279568195343\n",
      "Epoch 81/100, Loss: 0.0206022709608078\n",
      "Epoch 82/100, Loss: 0.02009834349155426\n",
      "Epoch 83/100, Loss: 0.019634254276752472\n",
      "Epoch 84/100, Loss: 0.019203051924705505\n",
      "Epoch 85/100, Loss: 0.018794231116771698\n",
      "Epoch 86/100, Loss: 0.018402790650725365\n",
      "Epoch 87/100, Loss: 0.018032226711511612\n",
      "Epoch 88/100, Loss: 0.017689576372504234\n",
      "Epoch 89/100, Loss: 0.01740265265107155\n",
      "Epoch 90/100, Loss: 0.01711150072515011\n",
      "Epoch 91/100, Loss: 0.016823163256049156\n",
      "Epoch 92/100, Loss: 0.016585418954491615\n",
      "Epoch 93/100, Loss: 0.01636207103729248\n",
      "Epoch 94/100, Loss: 0.016145866364240646\n",
      "Epoch 95/100, Loss: 0.015939895063638687\n",
      "Epoch 96/100, Loss: 0.01575186476111412\n",
      "Epoch 97/100, Loss: 0.015584388747811317\n",
      "Epoch 98/100, Loss: 0.015431791543960571\n",
      "Epoch 99/100, Loss: 0.015286020934581757\n",
      "Epoch 100/100, Loss: 0.015144393779337406\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the GNN model\n",
    "class GNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GNNModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim * 2, hidden_dim)  # Transition function\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)     # Output function\n",
    "\n",
    "    def forward(self, x, adjacency_matrix):\n",
    "        # x: node features\n",
    "        # adjacency_matrix: adjacency matrix of the graph\n",
    "\n",
    "        # Update states based on neighborhood and self features\n",
    "        h = torch.relu(self.fc1(torch.cat([x, torch.matmul(adjacency_matrix, x)], dim=1)))\n",
    "\n",
    "        # Compute outputs\n",
    "        o = self.fc2(h)\n",
    "        return h, o\n",
    "\n",
    "# Define the loss function\n",
    "def compute_loss(outputs, targets):\n",
    "    return nn.MSELoss()(outputs, targets)\n",
    "\n",
    "# Training function\n",
    "def train_gnn(model, adjacency_matrix, node_features, targets, num_epochs, learning_rate):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        \n",
    "        # Forward pass\n",
    "        h, outputs = model(node_features, adjacency_matrix)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = compute_loss(outputs, targets)\n",
    "        \n",
    "        # Zero gradients, backward pass, optimizer step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n",
    "\n",
    "# Example usage\n",
    "num_nodes = 8\n",
    "input_dim = 5\n",
    "hidden_dim = 16\n",
    "output_dim = 1\n",
    "num_epochs = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Dummy data\n",
    "node_features = torch.rand(num_nodes, input_dim)  # Random node features\n",
    "adjacency_matrix = torch.rand(num_nodes, num_nodes)  # Random adjacency matrix\n",
    "targets = torch.rand(num_nodes, output_dim)  # Random targets\n",
    "\n",
    "model = GNNModel(input_dim, hidden_dim, output_dim)\n",
    "train_gnn(model, adjacency_matrix, node_features, targets, num_epochs, learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "729d318d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 963.8184548060966\n",
      "Epoch 2/100, Loss: 72167.33222532854\n",
      "Epoch 3/100, Loss: 26.00344496518261\n",
      "Epoch 4/100, Loss: 24.977228963022203\n",
      "Epoch 5/100, Loss: 23.991651114547345\n",
      "Epoch 6/100, Loss: 23.0451021488721\n",
      "Epoch 7/100, Loss: 22.136036522237585\n",
      "Epoch 8/100, Loss: 21.2629698944178\n",
      "Epoch 9/100, Loss: 20.424476705059686\n",
      "Epoch 10/100, Loss: 19.619187846000145\n",
      "Epoch 11/100, Loss: 18.845788425759366\n",
      "Epoch 12/100, Loss: 18.10301562256012\n",
      "Epoch 13/100, Loss: 17.389656622367564\n",
      "Epoch 14/100, Loss: 16.704546638582634\n",
      "Epoch 15/100, Loss: 16.046567010155588\n",
      "Epoch 16/100, Loss: 15.41464337501425\n",
      "Epoch 17/100, Loss: 14.80774391582451\n",
      "Epoch 18/100, Loss: 14.224877675218686\n",
      "Epoch 19/100, Loss: 13.665092937740852\n",
      "Epoch 20/100, Loss: 13.127475675867139\n",
      "Epoch 21/100, Loss: 12.611148057563625\n",
      "Epoch 22/100, Loss: 12.115267012944933\n",
      "Epoch 23/100, Loss: 11.639022857693138\n",
      "Epoch 24/100, Loss: 11.181637970989314\n",
      "Epoch 25/100, Loss: 10.742365525798963\n",
      "Epoch 26/100, Loss: 10.320488269438147\n",
      "Epoch 27/100, Loss: 9.915317352429224\n",
      "Epoch 28/100, Loss: 9.526191203733848\n",
      "Epoch 29/100, Loss: 9.152474450526814\n",
      "Epoch 30/100, Loss: 8.793556880746776\n",
      "Epoch 31/100, Loss: 8.44885244673003\n",
      "Epoch 32/100, Loss: 8.117798308300342\n",
      "Epoch 33/100, Loss: 7.799853913752473\n",
      "Epoch 34/100, Loss: 7.494500117228699\n",
      "Epoch 35/100, Loss: 7.201238331047268\n",
      "Epoch 36/100, Loss: 6.91958971159862\n",
      "Epoch 37/100, Loss: 6.649094377480139\n",
      "Epoch 38/100, Loss: 6.38931065859275\n",
      "Epoch 39/100, Loss: 6.139814374973302\n",
      "Epoch 40/100, Loss: 5.900198144185184\n",
      "Epoch 41/100, Loss: 5.670070716136275\n",
      "Epoch 42/100, Loss: 5.449056334238103\n",
      "Epoch 43/100, Loss: 5.236794121863098\n",
      "Epoch 44/100, Loss: 5.032937493098144\n",
      "Epoch 45/100, Loss: 4.837153586832281\n",
      "Epoch 46/100, Loss: 4.649122723254548\n",
      "Epoch 47/100, Loss: 4.468537881874493\n",
      "Epoch 48/100, Loss: 4.295104200213087\n",
      "Epoch 49/100, Loss: 4.128538492345473\n",
      "Epoch 50/100, Loss: 3.968568786509416\n",
      "Epoch 51/100, Loss: 3.8149338810244684\n",
      "Epoch 52/100, Loss: 3.6673829177967234\n",
      "Epoch 53/100, Loss: 3.525674972712798\n",
      "Epoch 54/100, Loss: 3.3895786622541957\n",
      "Epoch 55/100, Loss: 3.2588717656897543\n",
      "Epoch 56/100, Loss: 3.1333408622292653\n",
      "Epoch 57/100, Loss: 3.0127809825458103\n",
      "Epoch 58/100, Loss: 2.8969952740978204\n",
      "Epoch 59/100, Loss: 2.7857946797043716\n",
      "Epoch 60/100, Loss: 2.6789976288489035\n",
      "Epoch 61/100, Loss: 2.576429741207311\n",
      "Epoch 62/100, Loss: 2.4779235419163257\n",
      "Epoch 63/100, Loss: 2.3833181881172636\n",
      "Epoch 64/100, Loss: 2.292459206328645\n",
      "Epoch 65/100, Loss: 2.205198240218855\n",
      "Epoch 66/100, Loss: 2.1213928083670126\n",
      "Epoch 67/100, Loss: 2.040906071616503\n",
      "Epoch 68/100, Loss: 1.9636066096413145\n",
      "Epoch 69/100, Loss: 1.8893682063603432\n",
      "Epoch 70/100, Loss: 1.8180696438492983\n",
      "Epoch 71/100, Loss: 1.7495945044136902\n",
      "Epoch 72/100, Loss: 1.683830980499733\n",
      "Epoch 73/100, Loss: 1.6206716921327682\n",
      "Epoch 74/100, Loss: 1.560013511585135\n",
      "Epoch 75/100, Loss: 1.5017573949871883\n",
      "Epoch 76/100, Loss: 1.4458082206065201\n",
      "Epoch 77/100, Loss: 1.3920746335313265\n",
      "Epoch 78/100, Loss: 1.340468896504311\n",
      "Epoch 79/100, Loss: 1.2909067466635649\n",
      "Epoch 80/100, Loss: 1.2433072579565123\n",
      "Epoch 81/100, Loss: 1.197592709002259\n",
      "Epoch 82/100, Loss: 1.153688456186594\n",
      "Epoch 83/100, Loss: 1.1115228117824294\n",
      "Epoch 84/100, Loss: 1.07102692689667\n",
      "Epoch 85/100, Loss: 1.0321346790523864\n",
      "Epoch 86/100, Loss: 0.9947825642227364\n",
      "Epoch 87/100, Loss: 0.9589095931403405\n",
      "Epoch 88/100, Loss: 0.9244571917128077\n",
      "Epoch 89/100, Loss: 0.891369105381805\n",
      "Epoch 90/100, Loss: 0.85959130726951\n",
      "Epoch 91/100, Loss: 0.829071909962462\n",
      "Epoch 92/100, Loss: 0.7997610807887733\n",
      "Epoch 93/100, Loss: 0.7716109604503624\n",
      "Epoch 94/100, Loss: 0.7445755848773526\n",
      "Epoch 95/100, Loss: 0.7186108101770341\n",
      "Epoch 96/100, Loss: 0.6936742405548482\n",
      "Epoch 97/100, Loss: 0.6697251590897009\n",
      "Epoch 98/100, Loss: 0.6467244612505731\n",
      "Epoch 99/100, Loss: 0.624634591045875\n",
      "Epoch 100/100, Loss: 0.6034194797012831\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class GNNModel:\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        # Initialize weights\n",
    "        self.W1 = np.random.randn(input_dim * 2, hidden_dim)\n",
    "        self.W2 = np.random.randn(hidden_dim, output_dim)\n",
    "        self.b1 = np.zeros(hidden_dim)\n",
    "        self.b2 = np.zeros(output_dim)\n",
    "    \n",
    "    def forward(self, X, adjacency_matrix):\n",
    "        # X: node features (num_nodes x input_dim)\n",
    "        # adjacency_matrix: adjacency matrix (num_nodes x num_nodes)\n",
    "        \n",
    "        # Compute neighborhood aggregation\n",
    "        aggregated_neigh = np.dot(adjacency_matrix, X)\n",
    "        \n",
    "        # Combine self features and neighborhood features\n",
    "        combined = np.hstack([X, aggregated_neigh])\n",
    "        \n",
    "        # Transition function\n",
    "        self.hidden = np.maximum(0, np.dot(combined, self.W1) + self.b1)  # ReLU activation\n",
    "        \n",
    "        # Output function\n",
    "        self.outputs = np.dot(self.hidden, self.W2) + self.b2\n",
    "        return self.outputs\n",
    "    \n",
    "    def compute_loss(self, outputs, targets):\n",
    "        return np.mean((outputs - targets) ** 2)\n",
    "    \n",
    "    def backward(self, X, adjacency_matrix, targets, learning_rate):\n",
    "        num_nodes = X.shape[0]\n",
    "        \n",
    "        # Compute gradients using the chain rule\n",
    "        dL_doutputs = 2 * (self.outputs - targets) / num_nodes\n",
    "        dL_dW2 = np.dot(self.hidden.T, dL_doutputs)\n",
    "        dL_db2 = np.sum(dL_doutputs, axis=0)\n",
    "        \n",
    "        dL_dhidden = np.dot(dL_doutputs, self.W2.T)\n",
    "        dL_dhidden[self.hidden <= 0] = 0  # ReLU derivative\n",
    "        \n",
    "        dL_dW1 = np.dot(np.hstack([X, np.dot(adjacency_matrix, X)]).T, dL_dhidden)\n",
    "        dL_db1 = np.sum(dL_dhidden, axis=0)\n",
    "        \n",
    "        # Update weights and biases\n",
    "        self.W2 -= learning_rate * dL_dW2\n",
    "        self.b2 -= learning_rate * dL_db2\n",
    "        self.W1 -= learning_rate * dL_dW1\n",
    "        self.b1 -= learning_rate * dL_db1\n",
    "    \n",
    "    def train(self, X, adjacency_matrix, targets, num_epochs, learning_rate):\n",
    "        for epoch in range(num_epochs):\n",
    "            # Forward pass\n",
    "            outputs = self.forward(X, adjacency_matrix)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = self.compute_loss(outputs, targets)\n",
    "            \n",
    "            # Backward pass and weight update\n",
    "            self.backward(X, adjacency_matrix, targets, learning_rate)\n",
    "            \n",
    "            print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss}')\n",
    "\n",
    "# Example usage\n",
    "num_nodes = 8\n",
    "input_dim = 5\n",
    "hidden_dim = 16\n",
    "output_dim = 1\n",
    "num_epochs = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Dummy data\n",
    "X = np.random.rand(num_nodes, input_dim)  # Node features\n",
    "adjacency_matrix = np.random.rand(num_nodes, num_nodes)  # Adjacency matrix\n",
    "targets = np.random.rand(num_nodes, output_dim)  # Target values\n",
    "\n",
    "model = GNNModel(input_dim, hidden_dim, output_dim)\n",
    "model.train(X, adjacency_matrix, targets, num_epochs, learning_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f52c28",
   "metadata": {},
   "source": [
    "## DeepWalk and GraphSAGE\n",
    "\n",
    "The original GNN has three main limitations:\n",
    "\n",
    "1. **Fixed Point Hypothesis:**\n",
    "   - If the “fixed point” hypothesis is relaxed, a more stable representation can be learned using multilayer perceptrons, and the iterative update process can be deleted.\n",
    "\n",
    "2. **Edge Information Handling:**\n",
    "   - It does not handle edge information (for example, different edges in a knowledge graph may represent different relationships between nodes).\n",
    "\n",
    "3. **Node Representation Diversity:**\n",
    "   - Fixed points hinder the diversity of node distribution and are not suitable for learning good representations of nodes.\n",
    "\n",
    "In view of the above limitations of the original GNN, many variants have been proposed. Two typical variants are **DeepWalk** and **GraphSAGE**.\n",
    "\n",
    "### DeepWalk\n",
    "\n",
    "Social representations are expected to have the following characteristics:\n",
    "\n",
    "- **Adaptable:** Real social networks are constantly evolving; new social relations should not require repeating the learning process all over again.\n",
    "\n",
    "- **Community Aware:** The distance between latent dimensions should represent a metric for evaluating social similarity between the corresponding members of the network. This allows generalization in networks with homophily.\n",
    "\n",
    "- **Low Dimensional:** When labeled data is scarce, low-dimensional models generalize better and speed up convergence and inference.\n",
    "\n",
    "- **Continuous:** Latent representations are required to model partial community membership in continuous space. In addition to providing a nuanced view of community membership, a continuous representation has smooth decision boundaries between communities, which allows more robust classification.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0480ad",
   "metadata": {},
   "source": [
    "### DeepWalk\n",
    "\n",
    "DeepWalk, introduced by Perozzi et al. [114], satisfies these requirements by learning representations for vertices from a stream of short random walks, using optimization techniques originally designed for language modeling.\n",
    "\n",
    "#### 1. Random Walks\n",
    "\n",
    "Random walks are executed on nodes in a graph to generate a sequence of nodes. A random walk rooted at vertex \\( v_i \\) is denoted as \\( W_{v_i} \\), which is a stochastic process with random variables \\( W_{v_i}, \\ldots, W_{v_{i+k}} \\) such that \\( W_{v_{i+k}} \\) is a vertex chosen at random from the neighbors of vertex \\( v_i \\). Due to the local structure, a stream of short random walks can be used as a basic tool for extracting information from a network. Moreover, using random walks has two other desirable properties [114]:\n",
    "\n",
    "- **Local Exploration:** Local exploration is easy to parallelize. Several random walkers (in different threads, processes, or machines) can simultaneously explore different parts of the same graph.\n",
    "\n",
    "- **Adaptability:** Relying on information obtained from short random walks makes it possible to accommodate small changes in the graph structure without the need for global recomputation. The learned model can be iteratively updated with new random walks from the changed region in time sub-linear to the entire graph.\n",
    "\n",
    "#### 2. Language Modeling\n",
    "\n",
    "Run skip-gram to learn the embedding of each node according to the sequence of nodes generated in random walks. Language modeling can be generalized to explore the graph through a stream of short random walks. These random walks can be thought of as short sentences and phrases in a special language; the direct analog is to estimate the likelihood of observing vertex \\( v_i \\) given all the previous vertices visited so far in the random walk, i.e.,\n",
    "\n",
    "$$\n",
    "\\text{Pr}(v_i | (v_1, v_2, \\ldots, v_{i-1}))\n",
    "$$\n",
    "\n",
    "#### Algorithm 7.8: DeepWalk(G, w, d, γ, t) [114]\n",
    "\n",
    "```python\n",
    "1. input: Graph G(V, E); window size w; embedding size d; walks per vertex γ; walk length t.\n",
    "2. initialization: Sample matrix \\( \\Theta \\) from \\( U^{|V| \\times d} \\).\n",
    "3. Build a binary Tree T from V.\n",
    "4. for i = 0 to γ do\n",
    "5.     O = Shuffle(V).\n",
    "6.     for each \\( v_i \\) ∈ O do\n",
    "7.         \\( W_{v_i} = \\text{RandomWalk}(G, v_i, t) \\).\n",
    "8.         \\text{SkipGram}( \\Theta, W_{v_i}, w).\n",
    "9.     end for\n",
    "10. end for\n",
    "11. output: matrix of vertex representations \\( \\Theta \\in \\mathbb{R}^{|V| \\times d} \\)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9df8a96f",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8427/778667206.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;31m# Run DeepWalk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_walks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwalk_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Node embeddings:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_8427/778667206.py\u001b[0m in \u001b[0;36mdeepwalk\u001b[0;34m(graph, num_walks, walk_length, window_size, embedding_dim, epochs)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# 2. Train skip-gram model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSkipGramModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedding_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwalks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_8427/778667206.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, walks, window_size, epochs)\u001b[0m\n\u001b[1;32m     31\u001b[0m                     \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mwindow_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcenter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_8427/778667206.py\u001b[0m in \u001b[0;36m_update\u001b[0;34m(self, center, context)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m# Compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# Compute gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Function to generate a random walk\n",
    "def random_walk(graph, start_node, walk_length):\n",
    "    walk = [start_node]\n",
    "    for _ in range(walk_length - 1):\n",
    "        cur_node = walk[-1]\n",
    "        neighbors = list(graph.get(cur_node, []))\n",
    "        if not neighbors:\n",
    "            break\n",
    "        walk.append(random.choice(neighbors))\n",
    "    return walk\n",
    "\n",
    "# Skip-gram model class\n",
    "class SkipGramModel:\n",
    "    def __init__(self, vocab_size, embedding_dim, learning_rate=0.01):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # Initialize weights\n",
    "        self.W = np.random.randn(vocab_size, embedding_dim)  # Embedding matrix for input words\n",
    "        self.W_out = np.random.randn(embedding_dim, vocab_size)  # Embedding matrix for output words\n",
    "    \n",
    "    def train(self, walks, window_size, epochs):\n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0\n",
    "            for walk in walks:\n",
    "                for i, center in enumerate(walk):\n",
    "                    context = [walk[j] for j in range(max(0, i - window_size), min(len(walk), i + window_size + 1)) if j != i]\n",
    "                    for word in context:\n",
    "                        loss = self._update(center, word)\n",
    "                        total_loss += loss\n",
    "            print(f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss:.4f}\")\n",
    "    \n",
    "    def _update(self, center, context):\n",
    "        center_vector = self.W[center]\n",
    "        context_vector = self.W_out[:, context]\n",
    "        scores = np.dot(center_vector, context_vector)\n",
    "        probs = self._softmax(scores)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = -np.log(probs[context])\n",
    "        \n",
    "        # Compute gradients\n",
    "        grad = probs\n",
    "        grad[context] -= 1\n",
    "        \n",
    "        # Update weights\n",
    "        self.W[center] -= self.learning_rate * np.dot(grad, context_vector.T)\n",
    "        self.W_out[:, context] -= self.learning_rate * np.outer(center_vector, grad)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def _softmax(self, x):\n",
    "        e_x = np.exp(x - np.max(x))\n",
    "        return e_x / e_x.sum(axis=0)\n",
    "\n",
    "# DeepWalk algorithm\n",
    "def deepwalk(graph, num_walks, walk_length, window_size, embedding_dim, epochs):\n",
    "    # 1. Generate random walks\n",
    "    walks = []\n",
    "    nodes = list(graph.keys())\n",
    "    for _ in range(num_walks):\n",
    "        random.shuffle(nodes)\n",
    "        for node in nodes:\n",
    "            walks.append(random_walk(graph, node, walk_length))\n",
    "    \n",
    "    # 2. Train skip-gram model\n",
    "    model = SkipGramModel(vocab_size=len(graph), embedding_dim=embedding_dim)\n",
    "    model.train(walks, window_size, epochs)\n",
    "    \n",
    "    return model.W\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Example graph as an adjacency list\n",
    "    graph = {\n",
    "        0: [1, 2],\n",
    "        1: [0, 2, 3],\n",
    "        2: [0, 1, 3],\n",
    "        3: [1, 2]\n",
    "    }\n",
    "\n",
    "    # Parameters\n",
    "    num_walks = 10\n",
    "    walk_length = 5\n",
    "    window_size = 2\n",
    "    embedding_dim = 2\n",
    "    epochs = 10\n",
    "\n",
    "    # Run DeepWalk\n",
    "    embeddings = deepwalk(graph, num_walks, walk_length, window_size, embedding_dim, epochs)\n",
    "    print(\"Node embeddings:\")\n",
    "    print(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49ac4594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 0 embedding: [-0.29050043  1.26720343]\n",
      "Neighbor 1 embedding: [0.36383828 1.31667723]\n",
      "Neighbor 2 embedding: [-2.29991282 -1.43031955]\n",
      "Node 5 not found in the graph.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example function that may cause IndexError\n",
    "def example_function():\n",
    "    # Create a dictionary with nodes and their neighbors\n",
    "    graph = {\n",
    "        0: [1, 2],\n",
    "        1: [0, 2, 3],\n",
    "        2: [0, 1, 3],\n",
    "        3: [1, 2]\n",
    "    }\n",
    "    \n",
    "    # Initialize the embedding matrix\n",
    "    num_nodes = len(graph)\n",
    "    embedding_dim = 2\n",
    "    embeddings = np.random.randn(num_nodes, embedding_dim)\n",
    "    \n",
    "    # Function to perform a simple operation\n",
    "    def process_node(node):\n",
    "        if node in graph:\n",
    "            neighbors = graph[node]\n",
    "            # Avoid IndexError: Ensure we index into arrays properly\n",
    "            node_embedding = embeddings[node]  # This should be a valid row from the embeddings matrix\n",
    "            print(f\"Node {node} embedding: {node_embedding}\")\n",
    "            for neighbor in neighbors:\n",
    "                if neighbor < num_nodes:  # Ensure neighbor index is valid\n",
    "                    neighbor_embedding = embeddings[neighbor]\n",
    "                    print(f\"Neighbor {neighbor} embedding: {neighbor_embedding}\")\n",
    "                else:\n",
    "                    print(f\"Neighbor index {neighbor} is out of bounds.\")\n",
    "        else:\n",
    "            print(f\"Node {node} not found in the graph.\")\n",
    "    \n",
    "    # Example usage\n",
    "    process_node(0)\n",
    "    process_node(5)  # Example of a node that is not in the graph\n",
    "\n",
    "# Call the function\n",
    "example_function()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b311208d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
