{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed51c88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " * Copyright (c) 2008 Radhamadhab Dalai\n",
    " *\n",
    " * Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    " * of this software and associated documentation files (the \"Software\"), to deal\n",
    " * in the Software without restriction, including without limitation the rights\n",
    " * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    " * copies of the Software, and to permit persons to whom the Software is\n",
    " * furnished to do so, subject to the following conditions:\n",
    " *\n",
    " * The above copyright notice and this permission notice shall be included in\n",
    " * all copies or substantial portions of the Software.\n",
    " *\n",
    " * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    " * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    " * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    " * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    " * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    " * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
    " * THE SOFTWARE.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31cecea",
   "metadata": {},
   "source": [
    "# MCMC and Particle Systems - Mathematical Analysis\n",
    "\n",
    "## Importance Sampling and Resampling\n",
    "\n",
    "The importance sampling approach ensures that the distribution of the final sample is empirically distributed from the target $\\pi$. The distribution of the final sample is close to being (empirically) agreement with $\\pi$, and is thus a valid importance sampling methodology. In other words, the importance sampling weight does not need to be adjusted after the MCMC step, as already seen in Lemma 14.1.\n",
    "\n",
    "As above, reduced variance resampling strategies can also be implemented at the resampling stage. Note that the proposed kernel $g$ needs not to be known numerically, as long as simulations from $g$ are possible. Gilks and Berzuini (2001) also extend this algorithm to a model choice setting with sequentially observed data, as in Section 11.2, and they use a reversible jump algorithm as part of the evolution step 3. Obviously, the success of this additional step in fighting degeneracy depends on the setup and several iterations of the MCMC step could be necessary to reach regions of acceptable values of $\\pi$.\n",
    "\n",
    "As noted in Chapp and Goutall (2001), the **Augmentation step 1** in Algorithm 14.60 can itself be supplemented by an importance sampling step where the entire vector $\\mathbf{x}_i^{(t-1)}$ may be modified through an importance distribution $g$ (and a corresponding modification of the weight). These authors also suggested **tempering schemes** to smooth the bridge between $g$ and the target distribution $\\pi$. As the authors propose to use a sequence of geometric averages:\n",
    "\n",
    "$$\\pi^{(m)}(\\mathbf{x}) \\propto g^{am}(\\mathbf{x}) \\pi^{1-am}(\\mathbf{x})$$\n",
    "\n",
    "where $0 < a_m < 1$ increases from $0$ to $1$ (see Note 13.6.2 for an introduction to tempering).\n",
    "\n",
    "## 14.3.7 Convergence of Particle Systems\n",
    "\n",
    "So far, the sequential Monte Carlo methods have been discussed from a rather practical point of view, in that the convergence properties of the various estimators or approximations have been derived from those of regular importance sampling techniques, that is, mostly from the Law of Large Numbers. We must, however, take into account an additional dimension, when compared with importance sampling (as in Chapter 3), due to the iterative nature of the method. Each resampling step uses of Gilks and Berzuini (2001) assures that the speed gain goes to infinity at each iteration, but this is unrealistic and contradicts the speed requirement which is at the core of the method.\n",
    "\n",
    "More recent results, as those of Kunsch (2005), give a better understanding of how these algorithms converge and make explicit the intuition that \"there isn't so much thing as a free lunch,\" namely, that it does not seem possible to consider a sequence of target distributions without incurring an increase in the computational expense.\n",
    "\n",
    "Although the proofs are too advanced for the level of this book, let us point out here that Kunsch (2004) shows, for state-space models, that the variance of the estimator $\\hat{\\mu}_t$ does not increase exponentially fast with $t$, to achieve convergence in total variation for the sequential importance sampling/particle filter method. (This result is not surprising in light of the intuitive development of Section 14.3.1.) Chopin (2004) also establishes Central Limit Theorems for both the multinomial and the residual sampling schemes, with the side result that the asymptotic variance is smaller for the residual sampling approach, again a rather comforting result. Note that for the basic sequential sampling in a fixed dimensional setting where\n",
    "\n",
    "$$\\omega_t^{(i)} \\propto \\omega_{t-1}^{(i)} \\frac{\\pi_t(\\mathbf{Z}_i)}{\\pi_{t-1}(\\mathbf{Z}_i)}$$\n",
    "\n",
    "## Central Limit Theorem\n",
    "\n",
    "A Central Limit Theorem also holds:\n",
    "\n",
    "$$\\sqrt{N} \\left\\{ \\frac{\\sum_{i=1}^N \\omega_t^{(i)} h(\\mathbf{Z}_i)}{\\sum_{i=1}^N \\omega_t^{(i)}} - \\mathbb{E}_{\\pi_t}[h(\\mathbf{Z})] \\right\\} \\stackrel{d}{\\to} \\mathcal{N}(0, V_t^{(h)})$$\n",
    "\n",
    "where\n",
    "\n",
    "$$V_t^{(h)} = \\mathbb{E}_{\\pi_t} \\left[ \\frac{\\pi_t(\\mathbf{Z})}{\\pi_0(\\mathbf{Z})} \\left\\{ h(\\mathbf{Z}) - \\mathbb{E}_{\\pi_t}[h(\\mathbf{Z})] \\right\\}^2 \\right]$$\n",
    "\n",
    "by an application of the usual Central Limit Theorem, since the $\\mathbf{Z}_i$'s are independent. (Establishing the Central Limit Theorems for the two other sampling schemes of Section 14.3.5 is beyond our scope.)\n",
    "\n",
    "## Comparison with Three Sampling Schemes\n",
    "\n",
    "In comparing the three sampling schemes, Chopin (2004) obtained the important comparison that, for a fixed state space of dimension $p$, and under the assumption that the likelihood ratio $L_t$ has finite variance for all $t$, the three corresponding asymptotic variances satisfy:\n",
    "\n",
    "$$V_t^{(h)} = O(p^{2^{-1}}), \\quad V_t^{(m)} = O(p^{2/3}), \\quad \\text{and} \\quad V_t^{(r)} = O(p^{2/3})$$\n",
    "\n",
    "where $V_t^{(m)}$ and $V_t^{(r)}$ denote the asymptotic variances for the estimators of $\\mathbb{E}_{\\pi_t}[h(\\mathbf{Z})]$ based on the multinomial and the residual resampling schemes, respectively. Therefore, resampling is more expensive in terms of the mere reweighting scheme. This is not a factor because the extra computational cost is less than the gain in reduction of variance.\n",
    "\n",
    "In all cases, to fight degeneracy, that is, to keep the effective sample size from decreasing as a power of $t$, Crisan et al. (1999), Del Moral and Miclo (2000) and Chopin (2004) stress that the number of particles must increase as a power of $t$. Related entries to the study of the convergence of particle filters.\n",
    "\n",
    "---\n",
    "\n",
    "## Mathematical Notation Summary\n",
    "\n",
    "- $\\pi$: Target distribution\n",
    "- $g$: Proposal kernel\n",
    "- $\\mathbf{x}_i^{(t)}$: Particle $i$ at time $t$\n",
    "- $\\omega_t^{(i)}$: Weight of particle $i$ at time $t$\n",
    "- $N$: Number of particles\n",
    "- $V_t^{(h)}$: Asymptotic variance for function $h$\n",
    "- $\\mathbb{E}_{\\pi_t}[\\cdot]$: Expectation under distribution $\\pi_t$\n",
    "- $\\mathcal{N}(0, V)$: Normal distribution with mean 0 and variance $V$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5de988a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Particle Filter Demo ===\n",
      "Final estimate: -0.669\n",
      "True final state: -0.679\n",
      "Average ESS: 693.0\n",
      "\n",
      "=== Tempering Demo ===\n",
      "Alpha\tMean\tVariance\tESS\n",
      "0.10\t-0.004\t3.593\t937.8\n",
      "0.20\t-0.027\t3.660\t832.7\n",
      "0.30\t-0.043\t3.765\t733.5\n",
      "0.40\t-0.055\t3.861\t652.4\n",
      "0.50\t-0.065\t3.941\t588.4\n",
      "0.60\t-0.072\t4.006\t537.7\n",
      "0.70\t-0.078\t4.058\t496.7\n",
      "0.80\t-0.082\t4.101\t462.9\n",
      "0.90\t-0.085\t4.136\t434.4\n",
      "1.00\t-0.087\t4.166\t410.1\n",
      "\n",
      "=== Convergence Analysis ===\n",
      "Method\t\tN=100\tN=500\tN=1000\tN=2000\n",
      "multinomial\t0.0095\t0.0097\t0.0099\t0.0099\n",
      "residual\t0.0101\t0.0101\t0.0101\t0.0098\n",
      "systematic\t0.0096\t0.0100\t0.0101\t0.0100\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy.special import logsumexp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class ParticleFilter:\n",
    "    \"\"\"\n",
    "    Sequential Monte Carlo (Particle Filter) implementation with multiple resampling schemes\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_particles=1000, resampling_method='multinomial'):\n",
    "        self.n_particles = n_particles\n",
    "        self.resampling_method = resampling_method\n",
    "        self.particles = None\n",
    "        self.weights = None\n",
    "        self.log_weights = None\n",
    "        self.effective_sample_size = None\n",
    "        \n",
    "    def initialize_particles(self, initial_dist):\n",
    "        \"\"\"Initialize particles from initial distribution\"\"\"\n",
    "        self.particles = initial_dist.rvs(size=self.n_particles)\n",
    "        self.weights = np.ones(self.n_particles) / self.n_particles\n",
    "        self.log_weights = np.log(self.weights)\n",
    "        \n",
    "    def predict(self, transition_kernel, *args):\n",
    "        \"\"\"Prediction step - propagate particles through transition kernel\"\"\"\n",
    "        for i in range(self.n_particles):\n",
    "            self.particles[i] = transition_kernel(self.particles[i], *args)\n",
    "    \n",
    "    def update_weights(self, likelihood_func, observation, *args):\n",
    "        \"\"\"Update particle weights based on likelihood of observation\"\"\"\n",
    "        for i in range(self.n_particles):\n",
    "            log_likelihood = likelihood_func(observation, self.particles[i], *args)\n",
    "            self.log_weights[i] += log_likelihood\n",
    "        \n",
    "        # Normalize weights\n",
    "        self.log_weights -= logsumexp(self.log_weights)\n",
    "        self.weights = np.exp(self.log_weights)\n",
    "        \n",
    "        # Calculate effective sample size\n",
    "        self.effective_sample_size = 1.0 / np.sum(self.weights**2)\n",
    "    \n",
    "    def resample(self, threshold=0.5):\n",
    "        \"\"\"Resample particles if ESS falls below threshold\"\"\"\n",
    "        if self.effective_sample_size < threshold * self.n_particles:\n",
    "            if self.resampling_method == 'multinomial':\n",
    "                indices = self._multinomial_resample()\n",
    "            elif self.resampling_method == 'residual':\n",
    "                indices = self._residual_resample()\n",
    "            elif self.resampling_method == 'systematic':\n",
    "                indices = self._systematic_resample()\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown resampling method: {self.resampling_method}\")\n",
    "            \n",
    "            self.particles = self.particles[indices]\n",
    "            self.weights = np.ones(self.n_particles) / self.n_particles\n",
    "            self.log_weights = np.log(self.weights)\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def _multinomial_resample(self):\n",
    "        \"\"\"Multinomial resampling\"\"\"\n",
    "        return np.random.choice(self.n_particles, size=self.n_particles, p=self.weights)\n",
    "    \n",
    "    def _residual_resample(self):\n",
    "        \"\"\"Residual resampling - more efficient than multinomial\"\"\"\n",
    "        n_copies = np.floor(self.n_particles * self.weights).astype(int)\n",
    "        residual = self.n_particles * self.weights - n_copies\n",
    "        \n",
    "        indices = []\n",
    "        for i in range(self.n_particles):\n",
    "            indices.extend([i] * n_copies[i])\n",
    "        \n",
    "        n_remaining = self.n_particles - len(indices)\n",
    "        if n_remaining > 0:\n",
    "            residual_weights = residual / np.sum(residual)\n",
    "            additional_indices = np.random.choice(\n",
    "                self.n_particles, size=n_remaining, p=residual_weights\n",
    "            )\n",
    "            indices.extend(additional_indices)\n",
    "        \n",
    "        return np.array(indices)\n",
    "    \n",
    "    def _systematic_resample(self):\n",
    "        \"\"\"Systematic resampling\"\"\"\n",
    "        cumsum = np.cumsum(self.weights)\n",
    "        u = (np.arange(self.n_particles) + np.random.random()) / self.n_particles\n",
    "        indices = np.searchsorted(cumsum, u)\n",
    "        return indices\n",
    "    \n",
    "    def estimate_mean(self):\n",
    "        \"\"\"Weighted mean estimate\"\"\"\n",
    "        return np.average(self.particles, weights=self.weights)\n",
    "    \n",
    "    def estimate_variance(self):\n",
    "        \"\"\"Weighted variance estimate\"\"\"\n",
    "        mean = self.estimate_mean()\n",
    "        return np.average((self.particles - mean)**2, weights=self.weights)\n",
    "\n",
    "\n",
    "class SequentialMonteCarlo:\n",
    "    \"\"\"\n",
    "    Sequential Monte Carlo with importance sampling and tempering\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_particles=1000):\n",
    "        self.n_particles = n_particles\n",
    "        self.particles = None\n",
    "        self.weights = None\n",
    "        self.log_weights = None\n",
    "        \n",
    "    def importance_sampling_step(self, target_log_pdf, proposal_sampler, proposal_log_pdf):\n",
    "        \"\"\"Standard importance sampling step\"\"\"\n",
    "        # Sample from proposal\n",
    "        self.particles = proposal_sampler(self.n_particles)\n",
    "        \n",
    "        # Calculate importance weights\n",
    "        self.log_weights = np.zeros(self.n_particles)\n",
    "        for i in range(self.n_particles):\n",
    "            log_target = target_log_pdf(self.particles[i])\n",
    "            log_proposal = proposal_log_pdf(self.particles[i])\n",
    "            self.log_weights[i] = log_target - log_proposal\n",
    "        \n",
    "        # Normalize weights\n",
    "        self.log_weights -= logsumexp(self.log_weights)\n",
    "        self.weights = np.exp(self.log_weights)\n",
    "    \n",
    "    def tempering_sequence(self, target_log_pdf, proposal_log_pdf, n_steps=10):\n",
    "        \"\"\"\n",
    "        Geometric tempering sequence: π^(m)(x) ∝ g^(a_m)(x) * π^(1-a_m)(x)\n",
    "        \"\"\"\n",
    "        if self.particles is None:\n",
    "            raise ValueError(\"Particles not initialized. Run importance_sampling_step first.\")\n",
    "        \n",
    "        # Create tempering schedule\n",
    "        alphas = np.linspace(0, 1, n_steps + 1)[1:]  # Skip alpha=0\n",
    "        \n",
    "        results = []\n",
    "        for alpha in alphas:\n",
    "            # Update weights with tempered distribution\n",
    "            for i in range(self.n_particles):\n",
    "                log_target = target_log_pdf(self.particles[i])\n",
    "                log_proposal = proposal_log_pdf(self.particles[i])\n",
    "                # Tempered log-density: (1-α)*log(g) + α*log(π)\n",
    "                tempered_log_density = (1 - alpha) * log_proposal + alpha * log_target\n",
    "                self.log_weights[i] = tempered_log_density - log_proposal\n",
    "            \n",
    "            # Normalize weights\n",
    "            self.log_weights -= logsumexp(self.log_weights)\n",
    "            self.weights = np.exp(self.log_weights)\n",
    "            \n",
    "            # Store results\n",
    "            mean_estimate = np.average(self.particles, weights=self.weights)\n",
    "            var_estimate = np.average((self.particles - mean_estimate)**2, weights=self.weights)\n",
    "            ess = 1.0 / np.sum(self.weights**2)\n",
    "            \n",
    "            results.append({\n",
    "                'alpha': alpha,\n",
    "                'mean': mean_estimate,\n",
    "                'variance': var_estimate,\n",
    "                'ess': ess\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "\n",
    "\n",
    "class MCMCParticleFilter:\n",
    "    \"\"\"\n",
    "    MCMC-enhanced Particle Filter with augmentation steps\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_particles=1000, mcmc_steps=5):\n",
    "        self.n_particles = n_particles\n",
    "        self.mcmc_steps = mcmc_steps\n",
    "        self.particles = None\n",
    "        self.weights = None\n",
    "        self.log_weights = None\n",
    "    \n",
    "    def initialize(self, initial_sampler):\n",
    "        \"\"\"Initialize particles\"\"\"\n",
    "        self.particles = initial_sampler(self.n_particles)\n",
    "        self.weights = np.ones(self.n_particles) / self.n_particles\n",
    "        self.log_weights = np.log(self.weights)\n",
    "    \n",
    "    def mcmc_augmentation_step(self, log_target_pdf, proposal_std=0.1):\n",
    "        \"\"\"\n",
    "        MCMC augmentation step - improve particle diversity\n",
    "        \"\"\"\n",
    "        for i in range(self.n_particles):\n",
    "            current_particle = self.particles[i].copy()\n",
    "            current_log_prob = log_target_pdf(current_particle)\n",
    "            \n",
    "            for _ in range(self.mcmc_steps):\n",
    "                # Propose new state\n",
    "                proposal = current_particle + np.random.normal(0, proposal_std, size=current_particle.shape)\n",
    "                proposal_log_prob = log_target_pdf(proposal)\n",
    "                \n",
    "                # Metropolis-Hastings acceptance\n",
    "                log_alpha = proposal_log_prob - current_log_prob\n",
    "                if np.log(np.random.random()) < log_alpha:\n",
    "                    current_particle = proposal\n",
    "                    current_log_prob = proposal_log_prob\n",
    "            \n",
    "            self.particles[i] = current_particle\n",
    "    \n",
    "    def particle_filter_step(self, observation, likelihood_func, transition_kernel):\n",
    "        \"\"\"Combined particle filter step with MCMC augmentation\"\"\"\n",
    "        # Prediction\n",
    "        for i in range(self.n_particles):\n",
    "            self.particles[i] = transition_kernel(self.particles[i])\n",
    "        \n",
    "        # Weight update\n",
    "        for i in range(self.n_particles):\n",
    "            log_likelihood = likelihood_func(observation, self.particles[i])\n",
    "            self.log_weights[i] += log_likelihood\n",
    "        \n",
    "        # Normalize weights\n",
    "        self.log_weights -= logsumexp(self.log_weights)\n",
    "        self.weights = np.exp(self.log_weights)\n",
    "        \n",
    "        # MCMC augmentation\n",
    "        def log_target(x):\n",
    "            return likelihood_func(observation, x)\n",
    "        \n",
    "        self.mcmc_augmentation_step(log_target)\n",
    "        \n",
    "        # Resample if needed\n",
    "        ess = 1.0 / np.sum(self.weights**2)\n",
    "        if ess < self.n_particles / 2:\n",
    "            indices = np.random.choice(self.n_particles, size=self.n_particles, p=self.weights)\n",
    "            self.particles = self.particles[indices]\n",
    "            self.weights = np.ones(self.n_particles) / self.n_particles\n",
    "            self.log_weights = np.log(self.weights)\n",
    "\n",
    "\n",
    "# Example usage and demonstration\n",
    "def demo_particle_filter():\n",
    "    \"\"\"Demonstrate particle filter on a simple state-space model\"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # True state evolution (random walk)\n",
    "    n_timesteps = 50\n",
    "    true_states = np.zeros(n_timesteps)\n",
    "    observations = np.zeros(n_timesteps)\n",
    "    \n",
    "    # Generate true trajectory\n",
    "    for t in range(1, n_timesteps):\n",
    "        true_states[t] = true_states[t-1] + np.random.normal(0, 0.1)\n",
    "        observations[t] = true_states[t] + np.random.normal(0, 0.5)\n",
    "    \n",
    "    # Define model functions\n",
    "    def transition_kernel(x):\n",
    "        return x + np.random.normal(0, 0.1)\n",
    "    \n",
    "    def log_likelihood(obs, state):\n",
    "        return stats.norm.logpdf(obs, loc=state, scale=0.5)\n",
    "    \n",
    "    # Initialize particle filter\n",
    "    pf = ParticleFilter(n_particles=1000, resampling_method='systematic')\n",
    "    pf.initialize_particles(stats.norm(0, 1))\n",
    "    \n",
    "    # Run particle filter\n",
    "    estimates = []\n",
    "    variances = []\n",
    "    ess_history = []\n",
    "    \n",
    "    for t in range(1, n_timesteps):\n",
    "        # Predict\n",
    "        pf.predict(transition_kernel)\n",
    "        \n",
    "        # Update\n",
    "        pf.update_weights(log_likelihood, observations[t])\n",
    "        \n",
    "        # Resample\n",
    "        resampled = pf.resample()\n",
    "        \n",
    "        # Store estimates\n",
    "        estimates.append(pf.estimate_mean())\n",
    "        variances.append(pf.estimate_variance())\n",
    "        ess_history.append(pf.effective_sample_size)\n",
    "    \n",
    "    return true_states[1:], observations[1:], estimates, variances, ess_history\n",
    "\n",
    "\n",
    "def demo_tempering():\n",
    "    \"\"\"Demonstrate tempering for bridging proposal and target\"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Define target (mixture of Gaussians)\n",
    "    def target_log_pdf(x):\n",
    "        return logsumexp([stats.norm.logpdf(x, -2, 0.5), stats.norm.logpdf(x, 2, 0.5)]) + np.log(0.5)\n",
    "    \n",
    "    # Define proposal (single Gaussian)\n",
    "    def proposal_sampler(n):\n",
    "        return np.random.normal(0, 2, n)\n",
    "    \n",
    "    def proposal_log_pdf(x):\n",
    "        return stats.norm.logpdf(x, 0, 2)\n",
    "    \n",
    "    # Run tempering\n",
    "    smc = SequentialMonteCarlo(n_particles=1000)\n",
    "    smc.importance_sampling_step(target_log_pdf, proposal_sampler, proposal_log_pdf)\n",
    "    \n",
    "    results = smc.tempering_sequence(target_log_pdf, proposal_log_pdf, n_steps=10)\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def convergence_analysis():\n",
    "    \"\"\"Analyze convergence properties of different resampling schemes\"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    methods = ['multinomial', 'residual', 'systematic']\n",
    "    n_runs = 50\n",
    "    n_particles_list = [100, 500, 1000, 2000]\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for method in methods:\n",
    "        results[method] = {}\n",
    "        for n_particles in n_particles_list:\n",
    "            mse_list = []\n",
    "            \n",
    "            for run in range(n_runs):\n",
    "                # Simple target: N(0,1)\n",
    "                true_mean = 0\n",
    "                \n",
    "                pf = ParticleFilter(n_particles=n_particles, resampling_method=method)\n",
    "                pf.initialize_particles(stats.norm(0, 1))\n",
    "                \n",
    "                # Single update step\n",
    "                def dummy_likelihood(obs, state):\n",
    "                    return stats.norm.logpdf(obs, state, 0.1)\n",
    "                \n",
    "                pf.update_weights(dummy_likelihood, 0.1)\n",
    "                pf.resample()\n",
    "                \n",
    "                estimate = pf.estimate_mean()\n",
    "                mse_list.append((estimate - true_mean)**2)\n",
    "            \n",
    "            results[method][n_particles] = {\n",
    "                'mse': np.mean(mse_list),\n",
    "                'std': np.std(mse_list)\n",
    "            }\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== Particle Filter Demo ===\")\n",
    "    true_states, observations, estimates, variances, ess = demo_particle_filter()\n",
    "    print(f\"Final estimate: {estimates[-1]:.3f}\")\n",
    "    print(f\"True final state: {true_states[-1]:.3f}\")\n",
    "    print(f\"Average ESS: {np.mean(ess):.1f}\")\n",
    "    \n",
    "    print(\"\\n=== Tempering Demo ===\")\n",
    "    tempering_results = demo_tempering()\n",
    "    print(\"Alpha\\tMean\\tVariance\\tESS\")\n",
    "    for result in tempering_results:\n",
    "        print(f\"{result['alpha']:.2f}\\t{result['mean']:.3f}\\t{result['variance']:.3f}\\t{result['ess']:.1f}\")\n",
    "    \n",
    "    print(\"\\n=== Convergence Analysis ===\")\n",
    "    conv_results = convergence_analysis()\n",
    "    print(\"Method\\t\\tN=100\\tN=500\\tN=1000\\tN=2000\")\n",
    "    for method in conv_results:\n",
    "        mse_values = [conv_results[method][n]['mse'] for n in [100, 500, 1000, 2000]]\n",
    "        print(f\"{method}\\t{mse_values[0]:.4f}\\t{mse_values[1]:.4f}\\t{mse_values[2]:.4f}\\t{mse_values[3]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c766e4a",
   "metadata": {},
   "source": [
    "# Population Monte Carlo (PMC) - Mathematical Analysis\n",
    "\n",
    "## 14.4 Population Monte Carlo\n",
    "\n",
    "The Population Monte Carlo (PMC) algorithm, introduced in this section, is simultaneously an iterated importance sampling scheme that produces, at each iteration, a sample (eventually) simulated from a target distribution and an **adaptive algorithm** that calibrates the proposal distribution to the target distribution over iterations. Its theoretical roots are thus within importance sampling and not within MCMC, despite its iterated features. In that, the approximation to the target is valid (that is, unbiased at least to the order $O(1/n)$) at each iteration and does not require convergence time nor stopping rules.\n",
    "\n",
    "## 14.4.1 Sample Simulation\n",
    "\n",
    "In the previous chapters about MCMC, the stationary distribution has always been considered to be the limiting distribution of a Markov sequence $(Z_i)$ with the practical expectation that $Z_t$ is approximately distributed from $\\pi$ for $t$ large enough. A rather straightforward extension of this perspective is to go from simulating a point distributed from $\\pi$ to simulating a sample of size $n$ distributed from $\\pi$ or, rather, from\n",
    "\n",
    "$$\\boldsymbol{\\omega}^{(n)}(z_1, \\ldots, z_n) = \\prod_{i=1}^n \\pi(z_i)$$\n",
    "\n",
    "Implementations of this possible extension can be found in Warnes (2001) and Mengersen and Robert (2003), with improvements over a naïve programming of a parallel MCMC runs. Indeed, the entire sample at iteration $t$ can be used to design a proposal at iteration $t + 1$. In Warnes (2001), for instance, a kernel estimation of the target distribution based on the sample $(z_1^{(t)}, \\ldots, z_n^{(t)})$ is the proposal distribution. The difficulty with such a proposal is that non-parametric dimensional kernel estimators are notoriously poor. In Mengersen and Robert (2003), one point of the sample is chosen using different criteria to avoid the other points of the sample by delayed rejection (Tierney and Mira 1998). Note that, for simulation purposes, a kernel estimator is not different from a random walk proposal. In both cases, it is more efficient to move around one point of the sample separately, as the average acceptance probability of the entire sample decreases with the sample size, no matter what the proposal distribution is, using the same Kullback-Leibler argument as in Section 14.3.3. However, as we will see next, the recourse to the theory of a valid approximation leads to justify the convergence to $\\pi^{\\otimes n}$ if not necessary to obtain a valid approximation of an iid sample from $\\pi$.\n",
    "\n",
    "## 14.4.2 General Iterative Importance Sampling\n",
    "\n",
    "The PMC algorithm can be described in a very general framework: it is indeed possible to consider different proposal distributions at each iteration and for each particle with this algorithm. That is, the $Z_i^{(t)}$'s can be simulated from distributions $g_i$ that may depend on past samples,\n",
    "\n",
    "$$Z_i^{(t)} \\sim g_i(z_i)$$\n",
    "\n",
    "## Mathematical Framework\n",
    "\n",
    "### Sample Distribution\n",
    "\n",
    "The target joint distribution for $n$ samples is:\n",
    "\n",
    "$$\\boldsymbol{\\omega}^{(n)}(z_1, \\ldots, z_n) = \\prod_{i=1}^n \\pi(z_i)$$\n",
    "\n",
    "where:\n",
    "- $\\pi(z_i)$ is the target distribution for each sample point\n",
    "- $n$ is the sample size\n",
    "- The joint distribution represents $n$ independent samples from $\\pi$\n",
    "\n",
    "### Iterative Proposal Adaptation\n",
    "\n",
    "At iteration $t$, particles are generated from adaptive proposals:\n",
    "\n",
    "$$Z_i^{(t)} \\sim g_i^{(t)}(z_i | \\text{past samples})$$\n",
    "\n",
    "where:\n",
    "- $g_i^{(t)}$ is the proposal distribution for particle $i$ at iteration $t$\n",
    "- The proposal can depend on the history of past samples\n",
    "- Each particle can have its own adapted proposal distribution\n",
    "\n",
    "### Key Properties\n",
    "\n",
    "1. **Unbiased Estimation**: The approximation to the target is valid (unbiased to order $O(1/n)$) at each iteration\n",
    "2. **No Convergence Requirements**: Unlike MCMC, PMC doesn't require convergence time or stopping rules\n",
    "3. **Adaptive Proposals**: The proposal distributions are calibrated to the target over iterations\n",
    "4. **Parallel Structure**: Can utilize parallel computation more effectively than standard MCMC\n",
    "\n",
    "### Theoretical Foundation\n",
    "\n",
    "The PMC algorithm builds on:\n",
    "- **Importance Sampling Theory**: Each iteration provides valid importance sampling estimates\n",
    "- **Adaptive Design**: Proposals improve based on accumulated information\n",
    "- **Sample-Based Calibration**: Uses entire sample history to design better proposals\n",
    "\n",
    "### Challenges and Solutions\n",
    "\n",
    "**Challenge**: High-dimensional kernel estimators perform poorly\n",
    "- **Solution**: Use delayed rejection or alternative proposal mechanisms\n",
    "\n",
    "**Challenge**: Acceptance probability decreases with sample size\n",
    "- **Solution**: Move particles individually rather than updating entire sample simultaneously\n",
    "\n",
    "**Challenge**: Maintaining validity across iterations\n",
    "- **Solution**: Ensure each iteration provides proper importance sampling weights\n",
    "\n",
    "---\n",
    "\n",
    "## Implementation Notes\n",
    "\n",
    "The PMC algorithm represents a significant advance over traditional MCMC by:\n",
    "1. Maintaining validity at each iteration\n",
    "2. Allowing parallel computation\n",
    "3. Adapting proposals based on sample history\n",
    "4. Not requiring burn-in or convergence diagnostics\n",
    "\n",
    "The mathematical foundation ensures that each iteration provides a valid approximation to the target distribution $\\pi^{\\otimes n}$, making it particularly suitable for applications requiring reliable estimates without the computational overhead of MCMC convergence analysis.\n",
    "\n",
    "# Population Monte Carlo - Implementation and Variance Analysis\n",
    "\n",
    "## Importance Weight Calculation\n",
    "\n",
    "In PMC, each simulated point $z_i^{(t)}$ is allocated an importance weight independently of one another (conditional on the past samples). Thus, each simulated point $z_i^{(t)}$ is allocated an importance weight:\n",
    "\n",
    "$$\\omega_i^{(t)} = \\frac{\\pi(z_i^{(t)})}{q_t(z_i^{(t)})}, \\quad i = 1, \\ldots, n$$\n",
    "\n",
    "and approximations of the form\n",
    "\n",
    "$$\\hat{I}_t = \\frac{1}{n} \\sum_{i=1}^n \\omega_i^{(t)} h(z_i^{(t)})$$\n",
    "\n",
    "are then unbiased estimators of $\\mathbb{E}^{\\pi}[h(Z)]$, even when the importance distribution $q_t$ depends on the entire past of the experiment. Indeed, we have\n",
    "\n",
    "$$\\mathbb{E}\\left[\\omega_i^{(t)} h(z_i^{(t)})\\right] = \\int \\int \\frac{\\pi(z)}{q_t(z)} h(z) q_t(z) dz \\, g(\\zeta) d\\zeta$$\n",
    "\n",
    "$$(14.9) \\quad = \\int h(z) \\pi(z) dz \\, g(\\zeta) d\\zeta = \\mathbb{E}^\\pi[h(X)]$$\n",
    "\n",
    "where $\\zeta$ denotes the vector of past random variates that contribute to $q_t$, and $g(\\zeta)$ its arbitrary distribution. Furthermore, assuming that the variances\n",
    "\n",
    "$$\\text{var}\\left(\\omega_i^{(t)} h(z_i^{(t)})\\right)$$\n",
    "\n",
    "exist for every $1 \\leq i \\leq n$, which means that the proposals $q_t$ should have heavier tails than $\\pi$, we have\n",
    "\n",
    "$$(14.10) \\quad \\text{var}(\\hat{I}_t) = \\frac{1}{n^2} \\sum_{i=1}^n \\text{var}\\left(\\omega_i^{(t)} h(z_i^{(t)})\\right)$$\n",
    "\n",
    "due to the cancelling effect of the weights $\\omega_i^{(t)}$ (Problem 14.16). In fact, even if the $Z_i^{(t)}$ are correlated, the importance-weighted terms will always be uncorrelated (Lemma 12.11). So, for importance sampling estimators, the variance of the sum will equal the sum of the variances of the individual terms.\n",
    "\n",
    "Note that resampling may take place at some or even all iterations of the algorithm but that, contrary to the particle systems, there is no propagation of the weights across iterations.\n",
    "\n",
    "## Normalizing Constant Estimation\n",
    "\n",
    "As in most settings the distribution of interest $\\pi$ is unnormalized, we instead use\n",
    "\n",
    "$$\\omega_i^{(t)} \\propto \\frac{\\pi(z_i^{(t)})}{q_t(z_i^{(t)})}, \\quad i = 1, \\ldots, n$$\n",
    "\n",
    "scaled so that the weights $\\omega_i^{(t)}$ sum up to 1. In this case, the above unbiasedness property and the variance decomposition are both lost, although they still approximately hold. In fact, the estimation of the normalizing constant of $\\pi$ improves with each iteration $t$, since the overall average\n",
    "\n",
    "$$(14.11) \\quad \\hat{\\omega}_t = \\frac{1}{tn} \\sum_{s=1}^t \\sum_{i=1}^n \\frac{\\pi(z_i^{(s)})}{q_s(z_i^{(s)})}$$\n",
    "\n",
    "is a convergent estimator of the inverse of the normalizing constant. Therefore, as $t$ increases, $\\hat{I}_t$ contains less and less to the bias and variability of $\\hat{I}_t$, and the above properties can be considered as holding for $t$ large enough. In addition, in the IID case instead of $\\omega_{t-1}$ Eq. (t), if\n",
    "\n",
    "$$(14.12) \\quad \\omega_i^{(t)} = \\frac{\\pi(z_i^{(t)})}{\\hat{\\omega}_{t-1} q_t(z_i^{(t)})}$$\n",
    "\n",
    "the variance decomposition (14.10) can be approximately recovered, via the same conditioning argument (Problem 14.16).\n",
    "\n",
    "## 14.4.3 Population Monte Carlo\n",
    "\n",
    "Following Iba (2000), Cappé et al. (2004) called their iterative approach **population Monte Carlo** (coining the idea that it is simulating an entire population rather than iteratively simulating the points of an approximate sample). Since the above section establishes that the iterative importance sampling scheme based on sample dependent proposals is fundamentally a specific kind of importance sampling, we can suppose the following algorithm, which is validated by the same principles as regular importance sampling.\n",
    "\n",
    "### Algorithm 14.4.3 - Population Monte Carlo\n",
    "\n",
    "For $t = 1, \\ldots, T$:\n",
    "\n",
    "1. **For $i = 1, \\ldots, n$:**\n",
    "   - (i) Select the generating distribution $q_t^{(i)}$\n",
    "   - (ii) Generate $Z_i^{(t)} \\sim q_t^{(i)}(z)$\n",
    "   - (iii) Compute $\\omega_i^{(t)} = \\pi(Z_i^{(t)})/q_t^{(i)}(Z_i^{(t)})$\n",
    "\n",
    "2. **Normalize** the $\\omega_i^{(t)}$'s to sum to 1.\n",
    "\n",
    "3. **Resample** a values from the $Z_i^{(t)}$'s with replacement, using the weights $\\omega_i^{(t)}$, to create the sample $(Z_1^{(t)}, Z_2^{(t)}, \\ldots, Z_n^{(t)})$.\n",
    "\n",
    "### Key Algorithm Features\n",
    "\n",
    "**Step 1.(i)** is singled out because it is an essential feature of the PMC algorithm as demonstrated in the previous Section, the proposal distributions can be individualized without each particle and can depend on the past iterations (including the validity of the method). The proposals $q_t$ can therefore be plotted according to the individuals and to the past values. Indeed, if storage is an issue, the algorithm can be implemented, for instance, so that the $q_t$'s are determined by the estimates of the past, or else the $q_t$'s are built through the $q_{t-1}$'s (possibly by moving the parameters, by using **Rao-Blackwellization** (Chapter 4) or by adapting the number of components.\n",
    "\n",
    "For instance, the $q_t$'s can be estimated by mixture of normals based on all the previously simulated samples, if storage allows). For instance, the $q_t$'s are determined by the estimators of the past, or the $q_t$'s are built through the tails from the $q_{t-1}$'s (**Rao-Blackwellization** according to (Section 14.4.2) to increase the variance.\n",
    "\n",
    "## Mathematical Properties\n",
    "\n",
    "### Unbiased Estimation\n",
    "\n",
    "For any iteration $t$, the estimator:\n",
    "\n",
    "$$\\hat{I}_t = \\frac{1}{n} \\sum_{i=1}^n \\omega_i^{(t)} h(z_i^{(t)})$$\n",
    "\n",
    "is an unbiased estimator of $\\mathbb{E}^\\pi[h(Z)]$, where:\n",
    "\n",
    "$$\\mathbb{E}\\left[\\omega_i^{(t)} h(z_i^{(t)})\\right] = \\mathbb{E}^\\pi[h(X)]$$\n",
    "\n",
    "### Variance Decomposition\n",
    "\n",
    "When weights are independent, the variance decomposes as:\n",
    "\n",
    "$$\\text{var}(\\hat{I}_t) = \\frac{1}{n^2} \\sum_{i=1}^n \\text{var}\\left(\\omega_i^{(t)} h(z_i^{(t)})\\right)$$\n",
    "\n",
    "### Convergent Normalizing Constant\n",
    "\n",
    "The average weight across all iterations:\n",
    "\n",
    "$$\\hat{\\omega}_t = \\frac{1}{tn} \\sum_{s=1}^t \\sum_{i=1}^n \\frac{\\pi(z_i^{(s)})}{q_s(z_i^{(s)})}$$\n",
    "\n",
    "converges to the inverse of the normalizing constant as $t \\to \\infty$.\n",
    "\n",
    "### Adaptive Proposals\n",
    "\n",
    "The proposal distributions $q_t^{(i)}$ can be:\n",
    "- **Individual**: Each particle $i$ can have its own proposal\n",
    "- **Adaptive**: Based on past samples and iterations\n",
    "- **Mixture-based**: Using mixture of normals from previous samples\n",
    "- **Parameter-driven**: Updated through Rao-Blackwellization\n",
    "\n",
    "## Advantages over Standard Methods\n",
    "\n",
    "1. **No Burn-in**: Each iteration provides valid estimates\n",
    "2. **Parallel Structure**: Natural parallelization across particles\n",
    "3. **Adaptive Learning**: Proposals improve over iterations\n",
    "4. **Flexible Design**: Individual proposals per particle\n",
    "5. **Theoretical Validity**: Maintains importance sampling guarantees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea0649a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy.special import logsumexp\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class PopulationMonteCarlo:\n",
    "    \"\"\"\n",
    "    Population Monte Carlo (PMC) implementation with adaptive proposals\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_particles=1000, max_iterations=50, \n",
    "                 proposal_adaptation='mixture', resample_every=1):\n",
    "        self.n_particles = n_particles\n",
    "        self.max_iterations = max_iterations\n",
    "        self.proposal_adaptation = proposal_adaptation\n",
    "        self.resample_every = resample_every\n",
    "        \n",
    "        # Storage for particles and weights\n",
    "        self.particles_history = []\n",
    "        self.weights_history = []\n",
    "        self.log_weights_history = []\n",
    "        self.proposals_history = []\n",
    "        \n",
    "        # Convergence tracking\n",
    "        self.normalizing_constant_estimates = []\n",
    "        self.ess_history = []\n",
    "        self.variance_estimates = []\n",
    "        \n",
    "    def target_log_pdf(self, x):\n",
    "        \"\"\"Target log-probability density function (to be overridden)\"\"\"\n",
    "        raise NotImplementedError(\"Must implement target_log_pdf\")\n",
    "    \n",
    "    def target_pdf(self, x):\n",
    "        \"\"\"Target probability density function\"\"\"\n",
    "        return np.exp(self.target_log_pdf(x))\n",
    "    \n",
    "    def initial_proposal(self, size):\n",
    "        \"\"\"Initial proposal distribution (to be overridden)\"\"\"\n",
    "        raise NotImplementedError(\"Must implement initial_proposal\")\n",
    "    \n",
    "    def initial_proposal_log_pdf(self, x):\n",
    "        \"\"\"Initial proposal log-pdf (to be overridden)\"\"\"\n",
    "        raise NotImplementedError(\"Must implement initial_proposal_log_pdf\")\n",
    "    \n",
    "    def adaptive_proposal_mixture(self, iteration):\n",
    "        \"\"\"\n",
    "        Create mixture of Gaussians based on past samples\n",
    "        \"\"\"\n",
    "        if iteration == 0:\n",
    "            return self.initial_proposal, self.initial_proposal_log_pdf\n",
    "        \n",
    "        # Collect all past weighted samples\n",
    "        all_particles = []\n",
    "        all_weights = []\n",
    "        \n",
    "        for t in range(iteration):\n",
    "            particles = self.particles_history[t]\n",
    "            weights = self.weights_history[t]\n",
    "            all_particles.extend(particles)\n",
    "            all_weights.extend(weights)\n",
    "        \n",
    "        all_particles = np.array(all_particles)\n",
    "        all_weights = np.array(all_weights)\n",
    "        \n",
    "        # Normalize weights\n",
    "        all_weights = all_weights / np.sum(all_weights)\n",
    "        \n",
    "        # Fit Gaussian mixture to weighted samples\n",
    "        n_components = min(5, len(all_particles) // 10)  # Adaptive number of components\n",
    "        \n",
    "        if len(all_particles.shape) == 1:\n",
    "            all_particles = all_particles.reshape(-1, 1)\n",
    "        \n",
    "        try:\n",
    "            gmm = GaussianMixture(n_components=n_components, random_state=42)\n",
    "            gmm.fit(all_particles, sample_weight=all_weights)\n",
    "            \n",
    "            def mixture_sampler(size):\n",
    "                samples, _ = gmm.sample(size)\n",
    "                return samples.flatten() if samples.shape[1] == 1 else samples\n",
    "            \n",
    "            def mixture_log_pdf(x):\n",
    "                if len(x.shape) == 0:\n",
    "                    x = x.reshape(1, -1)\n",
    "                elif len(x.shape) == 1 and len(all_particles.shape) > 1:\n",
    "                    x = x.reshape(1, -1)\n",
    "                return gmm.score_samples(x.reshape(-1, 1) if x.ndim == 1 else x)\n",
    "            \n",
    "            return mixture_sampler, mixture_log_pdf\n",
    "            \n",
    "        except:\n",
    "            # Fallback to simple Gaussian\n",
    "            mean = np.average(all_particles, weights=all_weights, axis=0)\n",
    "            if len(all_particles.shape) == 1:\n",
    "                var = np.average((all_particles - mean)**2, weights=all_weights)\n",
    "                std = np.sqrt(var)\n",
    "                \n",
    "                def gaussian_sampler(size):\n",
    "                    return np.random.normal(mean, std, size)\n",
    "                \n",
    "                def gaussian_log_pdf(x):\n",
    "                    return stats.norm.logpdf(x, mean, std)\n",
    "                \n",
    "                return gaussian_sampler, gaussian_log_pdf\n",
    "            else:\n",
    "                cov = np.cov(all_particles.T, aweights=all_weights)\n",
    "                \n",
    "                def multivariate_sampler(size):\n",
    "                    return np.random.multivariate_normal(mean, cov, size)\n",
    "                \n",
    "                def multivariate_log_pdf(x):\n",
    "                    return stats.multivariate_normal.logpdf(x, mean, cov)\n",
    "                \n",
    "                return multivariate_sampler, multivariate_log_pdf\n",
    "    \n",
    "    def adaptive_proposal_kernel(self, iteration):\n",
    "        \"\"\"\n",
    "        Create proposal based on kernel density estimation\n",
    "        \"\"\"\n",
    "        if iteration == 0:\n",
    "            return self.initial_proposal, self.initial_proposal_log_pdf\n",
    "        \n",
    "        # Use last iteration's particles with their weights\n",
    "        last_particles = np.array(self.particles_history[-1])\n",
    "        last_weights = np.array(self.weights_history[-1])\n",
    "        \n",
    "        # Normalize weights\n",
    "        last_weights = last_weights / np.sum(last_weights)\n",
    "        \n",
    "        # Adaptive bandwidth\n",
    "        n_eff = 1.0 / np.sum(last_weights**2)\n",
    "        bandwidth = 1.06 * np.std(last_particles) * (n_eff ** (-1/5))\n",
    "        \n",
    "        def kernel_sampler(size):\n",
    "            # Sample indices according to weights\n",
    "            indices = np.random.choice(len(last_particles), size=size, p=last_weights)\n",
    "            # Add Gaussian noise\n",
    "            samples = last_particles[indices] + np.random.normal(0, bandwidth, size)\n",
    "            return samples\n",
    "        \n",
    "        def kernel_log_pdf(x):\n",
    "            # Mixture of Gaussians centered at past particles\n",
    "            log_probs = []\n",
    "            for i, particle in enumerate(last_particles):\n",
    "                log_prob = stats.norm.logpdf(x, particle, bandwidth) + np.log(last_weights[i])\n",
    "                log_probs.append(log_prob)\n",
    "            return logsumexp(log_probs)\n",
    "        \n",
    "        return kernel_sampler, kernel_log_pdf\n",
    "    \n",
    "    def get_proposal(self, iteration, particle_idx=None):\n",
    "        \"\"\"\n",
    "        Get proposal distribution for current iteration\n",
    "        \"\"\"\n",
    "        if self.proposal_adaptation == 'mixture':\n",
    "            return self.adaptive_proposal_mixture(iteration)\n",
    "        elif self.proposal_adaptation == 'kernel':\n",
    "            return self.adaptive_proposal_kernel(iteration)\n",
    "        else:\n",
    "            return self.initial_proposal, self.initial_proposal_log_pdf\n",
    "    \n",
    "    def compute_importance_weights(self, particles, proposal_log_pdf_func):\n",
    "        \"\"\"\n",
    "        Compute importance weights: ω_i = π(z_i) / q_t(z_i)\n",
    "        \"\"\"\n",
    "        n = len(particles)\n",
    "        log_weights = np.zeros(n)\n",
    "        \n",
    "        for i, particle in enumerate(particles):\n",
    "            log_target = self.target_log_pdf(particle)\n",
    "            log_proposal = proposal_log_pdf_func(particle)\n",
    "            log_weights[i] = log_target - log_proposal\n",
    "        \n",
    "        # Normalize to avoid numerical issues\n",
    "        log_weights = log_weights - logsumexp(log_weights)\n",
    "        weights = np.exp(log_weights)\n",
    "        \n",
    "        return weights, log_weights\n",
    "    \n",
    "    def resample(self, particles, weights):\n",
    "        \"\"\"\n",
    "        Resample particles according to weights\n",
    "        \"\"\"\n",
    "        n = len(particles)\n",
    "        indices = np.random.choice(n, size=n, p=weights)\n",
    "        return particles[indices]\n",
    "    \n",
    "    def estimate_integral(self, func, particles, weights):\n",
    "        \"\"\"\n",
    "        Estimate E[h(X)] using importance sampling: Î_t = (1/n) Σ ω_i h(z_i)\n",
    "        \"\"\"\n",
    "        weighted_values = []\n",
    "        for i, particle in enumerate(particles):\n",
    "            weighted_values.append(weights[i] * func(particle))\n",
    "        \n",
    "        return np.mean(weighted_values)\n",
    "    \n",
    "    def compute_variance_estimate(self, func, particles, weights):\n",
    "        \"\"\"\n",
    "        Estimate variance of the importance sampling estimator\n",
    "        \"\"\"\n",
    "        n = len(particles)\n",
    "        weighted_values = []\n",
    "        \n",
    "        for i, particle in enumerate(particles):\n",
    "            value = weights[i] * func(particle)\n",
    "            weighted_values.append(value)\n",
    "        \n",
    "        # Variance decomposition: var(Î_t) = (1/n²) Σ var(ω_i h(z_i))\n",
    "        sample_var = np.var(weighted_values)\n",
    "        return sample_var / n\n",
    "    \n",
    "    def run_pmc(self, verbose=True):\n",
    "        \"\"\"\n",
    "        Run Population Monte Carlo algorithm\n",
    "        \"\"\"\n",
    "        if verbose:\n",
    "            print(\"Starting Population Monte Carlo...\")\n",
    "        \n",
    "        for t in range(self.max_iterations):\n",
    "            if verbose and t % 10 == 0:\n",
    "                print(f\"Iteration {t+1}/{self.max_iterations}\")\n",
    "            \n",
    "            # Step 1: Get proposal distribution for this iteration\n",
    "            proposal_sampler, proposal_log_pdf = self.get_proposal(t)\n",
    "            \n",
    "            # Step 2: Generate particles\n",
    "            particles = proposal_sampler(self.n_particles)\n",
    "            \n",
    "            # Step 3: Compute importance weights\n",
    "            weights, log_weights = self.compute_importance_weights(particles, proposal_log_pdf)\n",
    "            \n",
    "            # Step 4: Normalize weights to sum to 1\n",
    "            weights = weights / np.sum(weights)\n",
    "            \n",
    "            # Step 5: Optional resampling\n",
    "            if t % self.resample_every == 0 and t > 0:\n",
    "                particles = self.resample(particles, weights)\n",
    "                weights = np.ones(self.n_particles) / self.n_particles\n",
    "                log_weights = np.log(weights)\n",
    "            \n",
    "            # Store results\n",
    "            self.particles_history.append(particles)\n",
    "            self.weights_history.append(weights)\n",
    "            self.log_weights_history.append(log_weights)\n",
    "            \n",
    "            # Compute diagnostics\n",
    "            ess = 1.0 / np.sum(weights**2)\n",
    "            self.ess_history.append(ess)\n",
    "            \n",
    "            # Estimate normalizing constant (Equation 14.11)\n",
    "            if t == 0:\n",
    "                self.normalizing_constant_estimates.append(np.mean(np.exp(log_weights)))\n",
    "            else:\n",
    "                # ω̂_t = (1/tn) Σ_{s=1}^t Σ_{i=1}^n π(z_i^(s))/q_s(z_i^(s))\n",
    "                total_weight = 0\n",
    "                total_samples = 0\n",
    "                for s in range(t+1):\n",
    "                    total_weight += np.sum(np.exp(self.log_weights_history[s]))\n",
    "                    total_samples += len(self.log_weights_history[s])\n",
    "                \n",
    "                self.normalizing_constant_estimates.append(total_weight / total_samples)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"PMC completed!\")\n",
    "        \n",
    "        return self.particles_history, self.weights_history\n",
    "    \n",
    "    def get_final_sample(self):\n",
    "        \"\"\"\n",
    "        Get final weighted sample\n",
    "        \"\"\"\n",
    "        if not self.particles_history:\n",
    "            raise ValueError(\"No samples generated. Run PMC first.\")\n",
    "        \n",
    "        return self.particles_history[-1], self.weights_history[-1]\n",
    "    \n",
    "    def estimate_expectation(self, func):\n",
    "        \"\"\"\n",
    "        Estimate E[h(X)] using final sample\n",
    "        \"\"\"\n",
    "        particles, weights = self.get_final_sample()\n",
    "        return self.estimate_integral(func, particles, weights)\n",
    "\n",
    "\n",
    "class GaussianMixturePMC(PopulationMonteCarlo):\n",
    "    \"\"\"\n",
    "    PMC for Gaussian mixture target distribution\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, mixture_weights, means, stds, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.mixture_weights = np.array(mixture_weights)\n",
    "        self.means = np.array(means)\n",
    "        self.stds = np.array(stds)\n",
    "        \n",
    "    def target_log_pdf(self, x):\n",
    "        \"\"\"Mixture of Gaussians log-pdf\"\"\"\n",
    "        log_probs = []\n",
    "        for i, (weight, mean, std) in enumerate(zip(self.mixture_weights, self.means, self.stds)):\n",
    "            log_prob = np.log(weight) + stats.norm.logpdf(x, mean, std)\n",
    "            log_probs.append(log_prob)\n",
    "        return logsumexp(log_probs)\n",
    "    \n",
    "    def initial_proposal(self, size):\n",
    "        \"\"\"Initial proposal: broad Gaussian\"\"\"\n",
    "        return np.random.normal(0, 3, size)\n",
    "    \n",
    "    def initial_proposal_log_pdf(self, x):\n",
    "        \"\"\"Initial proposal log-pdf\"\"\"\n",
    "        return stats.norm.logpdf(x, 0, 3)\n",
    "\n",
    "\n",
    "class BayesianRegressionPMC(PopulationMonteCarlo):\n",
    "    \"\"\"\n",
    "    PMC for Bayesian linear regression\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, X, y, prior_mean=0, prior_std=1, noise_std=1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.prior_mean = prior_mean\n",
    "        self.prior_std = prior_std\n",
    "        self.noise_std = noise_std\n",
    "        self.n_params = X.shape[1]\n",
    "        \n",
    "    def target_log_pdf(self, beta):\n",
    "        \"\"\"Posterior log-pdf for Bayesian regression\"\"\"\n",
    "        # Prior: N(prior_mean, prior_std²)\n",
    "        log_prior = np.sum(stats.norm.logpdf(beta, self.prior_mean, self.prior_std))\n",
    "        \n",
    "        # Likelihood: N(Xβ, σ²)\n",
    "        pred = self.X @ beta\n",
    "        log_likelihood = np.sum(stats.norm.logpdf(self.y, pred, self.noise_std))\n",
    "        \n",
    "        return log_prior + log_likelihood\n",
    "    \n",
    "    def initial_proposal(self, size):\n",
    "        \"\"\"Initial proposal: prior distribution\"\"\"\n",
    "        return np.random.normal(self.prior_mean, self.prior_std, (size, self.n_params))\n",
    "    \n",
    "    def initial_proposal_log_pdf(self, beta):\n",
    "        \"\"\"Initial proposal log-pdf\"\"\"\n",
    "        return np.sum(stats.norm.logpdf(beta, self.prior_mean, self.prior_std))\n",
    "\n",
    "\n",
    "def demo_gaussian_mixture():\n",
    "    \"\"\"Demonstrate PMC on Gaussian mixture\"\"\"\n",
    "    print(\"=== Gaussian Mixture PMC Demo ===\")\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Define mixture: 0.3*N(-2,0.5) + 0.7*N(2,1)\n",
    "    mixture_weights = [0.3, 0.7]\n",
    "    means = [-2, 2]\n",
    "    stds = [0.5, 1.0]\n",
    "    \n",
    "    # True expectation\n",
    "    true_mean = sum(w * m for w, m in zip(mixture_weights, means))\n",
    "    \n",
    "    # Run PMC\n",
    "    pmc = GaussianMixturePMC(\n",
    "        mixture_weights, means, stds,\n",
    "        n_particles=1000, max_iterations=30,\n",
    "        proposal_adaptation='mixture'\n",
    "    )\n",
    "    \n",
    "    pmc.run_pmc(verbose=True)\n",
    "    \n",
    "    # Estimate mean\n",
    "    estimated_mean = pmc.estimate_expectation(lambda x: x)\n",
    "    \n",
    "    print(f\"True mean: {true_mean:.3f}\")\n",
    "    print(f\"Estimated mean: {estimated_mean:.3f}\")\n",
    "    print(f\"Error: {abs(estimated_mean - true_mean):.3f}\")\n",
    "    print(f\"Final ESS: {pmc.ess_history[-1]:.1f}\")\n",
    "    \n",
    "    return pmc\n",
    "\n",
    "\n",
    "def demo_bayesian_regression():\n",
    "    \"\"\"Demonstrate PMC on Bayesian regression\"\"\"\n",
    "    print(\"\\n=== Bayesian Regression PMC Demo ===\")\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Generate synthetic data\n",
    "    n_samples, n_features = 100, 3\n",
    "    true_beta = np.array([1.5, -0.8, 2.1])\n",
    "    \n",
    "    X = np.random.randn(n_samples, n_features)\n",
    "    y = X @ true_beta + np.random.normal(0, 0.5, n_samples)\n",
    "    \n",
    "    # Run PMC\n",
    "    pmc = BayesianRegressionPMC(\n",
    "        X, y, prior_mean=0, prior_std=2, noise_std=0.5,\n",
    "        n_particles=500, max_iterations=25,\n",
    "        proposal_adaptation='mixture'\n",
    "    )\n",
    "    \n",
    "    pmc.run_pmc(verbose=True)\n",
    "    \n",
    "    # Estimate posterior means\n",
    "    estimated_beta = pmc.estimate_expectation(lambda beta: beta)\n",
    "    \n",
    "    print(f\"True beta: {true_beta}\")\n",
    "    print(f\"Estimated beta: {estimated_beta}\")\n",
    "    print(f\"Error: {np.linalg.norm(estimated_beta - true_beta):.3f}\")\n",
    "    print(f\"Final ESS: {pmc.ess_history[-1]:.1f}\")\n",
    "    \n",
    "    return pmc\n",
    "\n",
    "\n",
    "def convergence_analysis():\n",
    "    \"\"\"Analyze PMC convergence properties\"\"\"\n",
    "    print(\"\\n=== Convergence Analysis ===\")\n",
    "    \n",
    "    # Run multiple PMC experiments\n",
    "    n_runs = 10\n",
    "    results = {'mixture': [], 'kernel': [], 'fixed': []}\n",
    "    \n",
    "    for adaptation in ['mixture', 'kernel', 'fixed']:\n",
    "        errors = []\n",
    "        \n",
    "        for run in range(n_runs):\n",
    "            np.random.seed(run)\n",
    "            \n",
    "            pmc = GaussianMixturePMC(\n",
    "                [0.5, 0.5], [-1, 1], [0.5, 0.5],\n",
    "                n_particles=500, max_iterations=20,\n",
    "                proposal_adaptation=adaptation\n",
    "            )\n",
    "            \n",
    "            pmc.run_pmc(verbose=False)\n",
    "            \n",
    "            true_mean = 0.0  # By symmetry\n",
    "            estimated_mean = pmc.estimate_expectation(lambda x: x)\n",
    "            error = abs(estimated_mean - true_mean)\n",
    "            errors.append(error)\n",
    "        \n",
    "        results[adaptation] = errors\n",
    "        print(f\"{adaptation:8}: Mean error = {np.mean(errors):.4f} ± {np.std(errors):.4f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def plot_pmc_evolution(pmc):\n",
    "    \"\"\"Plot PMC evolution over iterations\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "    \n",
    "    # ESS evolution\n",
    "    axes[0,0].plot(pmc.ess_history)\n",
    "    axes[0,0].set_title('Effective Sample Size')\n",
    "    axes[0,0].set_xlabel('Iteration')\n",
    "    axes[0,0].set_ylabel('ESS')\n",
    "    \n",
    "    # Normalizing constant\n",
    "    axes[0,1].plot(pmc.normalizing_constant_estimates)\n",
    "    axes[0,1].set_title('Normalizing Constant Estimate')\n",
    "    axes[0,1].set_xlabel('Iteration')\n",
    "    axes[0,1].set_ylabel('Estimate')\n",
    "    \n",
    "    # Final sample distribution\n",
    "    particles, weights = pmc.get_final_sample()\n",
    "    axes[1,0].hist(particles, bins=50, weights=weights, alpha=0.7, density=True)\n",
    "    axes[1,0].set_title('Final Weighted Sample')\n",
    "    axes[1,0].set_xlabel('Value')\n",
    "    axes[1,0].set_ylabel('Density')\n",
    "    \n",
    "    # Weight distribution\n",
    "    axes[1,1].hist(weights, bins=50, alpha=0.7)\n",
    "    axes[1,1].set_title('Final Weight Distribution')\n",
    "    axes[1,1].set_xlabel('Weight')\n",
    "    axes[1,1].set_ylabel('Frequency')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run demonstrations\n",
    "    pmc1 = demo_gaussian_mixture()\n",
    "    pmc2 = demo_bayesian_regression()\n",
    "    \n",
    "    # Convergence analysis\n",
    "    conv_results = convergence_analysis()\n",
    "    \n",
    "    # Show final normalizing constant convergence\n",
    "    print(f\"\\nNormalizing constant evolution (Gaussian mixture):\")\n",
    "    for i, estimate in enumerate(pmc1.normalizing_constant_estimates[::5]):\n",
    "        print(f\"Iteration {i*5:2d}: {estimate:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd007953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Gaussian Mixture PMC Demo (Core Python) ===\n",
      "Starting Population Monte Carlo (Core Python)...\n",
      "Iteration 1/30\n",
      "Iteration 6/30\n",
      "Iteration 11/30\n",
      "Iteration 16/30\n",
      "Iteration 21/30\n",
      "Iteration 26/30\n",
      "PMC completed!\n",
      "True mean: 0.800\n",
      "Estimated mean: 0.001\n",
      "Error: 0.799\n",
      "Final ESS: 1000.0\n",
      "\n",
      "=== Bayesian Regression PMC Demo (Core Python - Univariate) ===\n",
      "Starting Population Monte Carlo (Core Python)...\n",
      "Iteration 1/25\n",
      "Iteration 6/25\n",
      "Iteration 11/25\n",
      "Iteration 16/25\n",
      "Iteration 21/25\n",
      "PMC completed!\n",
      "True beta: 1.5\n",
      "Estimated beta: 0.003\n",
      "Error: 1.497\n",
      "Final ESS: 500.0\n",
      "\n",
      "=== Convergence Analysis (Core Python) ===\n",
      "mixture : Mean error = 0.0001 ± 0.0000\n",
      "kernel  : Mean error = 0.0001 ± 0.0001\n",
      "fixed   : Mean error = 0.0001 ± 0.0001\n",
      "\n",
      "Normalizing constant evolution (Gaussian mixture demo):\n",
      "Iteration  1: 1.0049\n",
      "Iteration  6: 1.6081\n",
      "Iteration 11: 1.6116\n",
      "Iteration 16: 1.6521\n",
      "Iteration 21: 1.6666\n",
      "Iteration 26: 1.6062\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random # For basic random number generation\n",
    "\n",
    "# --- Replacements for common NumPy/SciPy functions ---\n",
    "\n",
    "# Custom logsumexp for numerical stability\n",
    "def custom_logsumexp(log_x_list):\n",
    "    \"\"\"\n",
    "    Computes log(sum(exp(x))) for a list of log-values.\n",
    "    Handles potential overflow/underflow by subtracting the maximum value.\n",
    "    \"\"\"\n",
    "    if not log_x_list:\n",
    "        return -float('inf') # log(0)\n",
    "    \n",
    "    max_log_x = log_x_list[0]\n",
    "    for x_val in log_x_list:\n",
    "        if x_val > max_log_x:\n",
    "            max_log_x = x_val\n",
    "            \n",
    "    # If all values are -inf (e.g., empty or very small numbers), result is -inf\n",
    "    if max_log_x == -float('inf'):\n",
    "        return -float('inf')\n",
    "\n",
    "    sum_exp = 0.0\n",
    "    for x_val in log_x_list:\n",
    "        sum_exp += math.exp(x_val - max_log_x)\n",
    "    \n",
    "    return max_log_x + math.log(sum_exp)\n",
    "\n",
    "# Custom univariate normal log PDF (replacement for stats.norm.logpdf)\n",
    "def custom_norm_logpdf(x, mean, std):\n",
    "    \"\"\"\n",
    "    Calculates the log PDF of a univariate normal distribution.\n",
    "    Assumes x is a scalar or a list of scalars.\n",
    "    \"\"\"\n",
    "    if std <= 0:\n",
    "        return -float('inf') # Invalid standard deviation\n",
    "    \n",
    "    # Handle scalar x\n",
    "    if not isinstance(x, (list, tuple)):\n",
    "        x = [x]\n",
    "        \n",
    "    log_pdf_vals = []\n",
    "    for val in x:\n",
    "        exponent = -0.5 * ((val - mean) / std)**2\n",
    "        log_normalization = -0.5 * math.log(2 * math.pi) - math.log(std)\n",
    "        log_pdf_vals.append(log_normalization + exponent)\n",
    "        \n",
    "    # If input x was a scalar, return scalar log_pdf\n",
    "    if len(x) == 1:\n",
    "        return log_pdf_vals[0]\n",
    "    return log_pdf_vals\n",
    "\n",
    "\n",
    "# Custom normal random number generator (replacement for np.random.normal)\n",
    "# Uses Box-Muller transform for standard normal, then scales/shifts.\n",
    "def custom_normal_sampler(mean, std, size=1):\n",
    "    \"\"\"\n",
    "    Generates random numbers from a univariate normal distribution.\n",
    "    Uses Box-Muller transform.\n",
    "    \"\"\"\n",
    "    if std < 0:\n",
    "        raise ValueError(\"Standard deviation cannot be negative.\")\n",
    "    \n",
    "    samples = []\n",
    "    i = 0\n",
    "    while i < size:\n",
    "        u1 = random.random() # Uniform between 0 and 1\n",
    "        u2 = random.random()\n",
    "        \n",
    "        # Apply Box-Muller transform for standard normal\n",
    "        z0 = math.sqrt(-2 * math.log(u1)) * math.cos(2 * math.pi * u2)\n",
    "        # z1 = math.sqrt(-2 * math.log(u1)) * math.sin(2 * math.pi * u2) # We only need one at a time for size=1\n",
    "\n",
    "        # Scale and shift to desired mean and std\n",
    "        samples.append(z0 * std + mean)\n",
    "        i += 1\n",
    "        \n",
    "        # If size is odd, and we've generated a pair, we only take one.\n",
    "        # For simplicity, we just generate one at a time until size is met.\n",
    "        # A more optimized Box-Muller would store z1 for the next call.\n",
    "    \n",
    "    if size == 1:\n",
    "        return samples[0]\n",
    "    return samples\n",
    "\n",
    "# Custom mean (replacement for np.mean)\n",
    "def custom_mean(data):\n",
    "    if not data:\n",
    "        return 0.0 # Or raise error depending on context\n",
    "    return sum(data) / len(data)\n",
    "\n",
    "# Custom sum (replacement for np.sum)\n",
    "def custom_sum(data):\n",
    "    return sum(data)\n",
    "\n",
    "# Custom variance (replacement for np.var)\n",
    "def custom_variance(data, weights=None):\n",
    "    if not data:\n",
    "        return 0.0\n",
    "    \n",
    "    if weights:\n",
    "        # Weighted mean\n",
    "        weighted_sum = sum(data[i] * weights[i] for i in range(len(data)))\n",
    "        total_weights = sum(weights)\n",
    "        if total_weights == 0:\n",
    "            return 0.0 # Avoid division by zero\n",
    "        mean = weighted_sum / total_weights\n",
    "        \n",
    "        # Weighted variance\n",
    "        sum_sq_diff_weighted = sum(weights[i] * (data[i] - mean)**2 for i in range(len(data)))\n",
    "        return sum_sq_diff_weighted / total_weights # Or sum_sq_diff_weighted / (total_weights - 1) for sample variance\n",
    "    else:\n",
    "        mean = custom_mean(data)\n",
    "        sum_sq_diff = sum((x - mean)**2 for x in data)\n",
    "        return sum_sq_diff / len(data)\n",
    "\n",
    "# Custom standard deviation (replacement for np.std)\n",
    "def custom_std(data, weights=None):\n",
    "    return math.sqrt(custom_variance(data, weights))\n",
    "\n",
    "# Custom weighted average (replacement for np.average)\n",
    "def custom_average(data, weights):\n",
    "    if not data or not weights or len(data) != len(weights):\n",
    "        raise ValueError(\"Data and weights must be non-empty and of same length.\")\n",
    "    \n",
    "    weighted_sum = sum(data[i] * weights[i] for i in range(len(data)))\n",
    "    total_weights = sum(weights)\n",
    "    if total_weights == 0:\n",
    "        return 0.0 # Or handle as error\n",
    "    return weighted_sum / total_weights\n",
    "\n",
    "# Custom random choice (replacement for np.random.choice)\n",
    "def custom_random_choice(items, size, p=None):\n",
    "    \"\"\"\n",
    "    Randomly chooses items from a list with replacement, given probabilities.\n",
    "    \"\"\"\n",
    "    if p is None:\n",
    "        return random.choices(items, k=size) # Python 3.6+\n",
    "    else:\n",
    "        # Manual weighted choice for older Python or clarity\n",
    "        chosen = []\n",
    "        cumulative_probs = [0.0] * len(p)\n",
    "        current_sum = 0.0\n",
    "        for i, prob in enumerate(p):\n",
    "            current_sum += prob\n",
    "            cumulative_probs[i] = current_sum\n",
    "\n",
    "        for _ in range(size):\n",
    "            r = random.random()\n",
    "            for i, cum_prob in enumerate(cumulative_probs):\n",
    "                if r <= cum_prob:\n",
    "                    chosen.append(items[i])\n",
    "                    break\n",
    "        return chosen\n",
    "\n",
    "# --- PMC Classes (re-written without NumPy/SciPy/Sklearn) ---\n",
    "\n",
    "class PopulationMonteCarlo:\n",
    "    \"\"\"\n",
    "    Population Monte Carlo (PMC) implementation with adaptive proposals (core Python).\n",
    "    Simplified: multivariate support is removed.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_particles=1000, max_iterations=50, \n",
    "                 proposal_adaptation='mixture', resample_every=1):\n",
    "        self.n_particles = n_particles\n",
    "        self.max_iterations = max_iterations\n",
    "        self.proposal_adaptation = proposal_adaptation\n",
    "        self.resample_every = resample_every\n",
    "        \n",
    "        # Storage for particles and weights\n",
    "        self.particles_history = []\n",
    "        self.weights_history = []\n",
    "        self.log_weights_history = []\n",
    "        self.proposals_history = [] # Store proposal sampler and log_pdf functions\n",
    "        \n",
    "        # Convergence tracking\n",
    "        self.normalizing_constant_estimates = []\n",
    "        self.ess_history = []\n",
    "        self.variance_estimates = [] # Note: Variance estimation needs more work without np.var\n",
    "        \n",
    "    def target_log_pdf(self, x):\n",
    "        \"\"\"Target log-probability density function (to be overridden)\"\"\"\n",
    "        raise NotImplementedError(\"Must implement target_log_pdf\")\n",
    "    \n",
    "    def target_pdf(self, x):\n",
    "        \"\"\"Target probability density function\"\"\"\n",
    "        return math.exp(self.target_log_pdf(x))\n",
    "    \n",
    "    def initial_proposal(self, size):\n",
    "        \"\"\"Initial proposal distribution (to be overridden)\"\"\"\n",
    "        raise NotImplementedError(\"Must implement initial_proposal\")\n",
    "    \n",
    "    def initial_proposal_log_pdf(self, x):\n",
    "        \"\"\"Initial proposal log-pdf (to be overridden)\"\"\"\n",
    "        raise NotImplementedError(\"Must implement initial_proposal_log_pdf\")\n",
    "    \n",
    "    # Simplified adaptive proposal: fits a single Gaussian, not a mixture\n",
    "    def adaptive_proposal_single_gaussian(self, iteration):\n",
    "        \"\"\"\n",
    "        Create a single Gaussian proposal based on past samples' weighted mean and std.\n",
    "        This replaces the GMM fitting (sklearn.mixture.GaussianMixture).\n",
    "        \"\"\"\n",
    "        if iteration == 0:\n",
    "            return self.initial_proposal, self.initial_proposal_log_pdf\n",
    "        \n",
    "        # Collect all past weighted samples (flat list)\n",
    "        all_particles = []\n",
    "        all_weights = []\n",
    "        \n",
    "        for t in range(iteration):\n",
    "            particles = self.particles_history[t]\n",
    "            weights = self.weights_history[t]\n",
    "            all_particles.extend(particles)\n",
    "            all_weights.extend(weights)\n",
    "            \n",
    "        # Normalize weights\n",
    "        sum_all_weights = custom_sum(all_weights)\n",
    "        if sum_all_weights == 0: # Avoid division by zero if weights are all very small\n",
    "            normalized_weights = [1.0 / len(all_weights)] * len(all_weights)\n",
    "        else:\n",
    "            normalized_weights = [w / sum_all_weights for w in all_weights]\n",
    "        \n",
    "        # Calculate weighted mean and std\n",
    "        mean = custom_average(all_particles, normalized_weights)\n",
    "        std = custom_std(all_particles, normalized_weights)\n",
    "        \n",
    "        # Ensure std is not zero (add a small epsilon if needed for numerical stability)\n",
    "        if std < 1e-6:\n",
    "            std = 1e-6\n",
    "\n",
    "        def gaussian_sampler(size):\n",
    "            return custom_normal_sampler(mean, std, size)\n",
    "            \n",
    "        def gaussian_log_pdf(x_val): # x_val could be a single float or a list\n",
    "            return custom_norm_logpdf(x_val, mean, std)\n",
    "            \n",
    "        return gaussian_sampler, gaussian_log_pdf\n",
    "    \n",
    "    def adaptive_proposal_kernel(self, iteration):\n",
    "        \"\"\"\n",
    "        Create proposal based on kernel density estimation.\n",
    "        Simplified to use last iteration's particles and weights.\n",
    "        \"\"\"\n",
    "        if iteration == 0:\n",
    "            return self.initial_proposal, self.initial_proposal_log_pdf\n",
    "            \n",
    "        last_particles = self.particles_history[-1]\n",
    "        last_weights = self.weights_history[-1]\n",
    "        \n",
    "        # Normalize weights\n",
    "        sum_last_weights = custom_sum(last_weights)\n",
    "        if sum_last_weights == 0:\n",
    "            normalized_last_weights = [1.0 / len(last_weights)] * len(last_weights)\n",
    "        else:\n",
    "            normalized_last_weights = [w / sum_last_weights for w in last_weights]\n",
    "        \n",
    "        # Adaptive bandwidth (simplified for univariate case)\n",
    "        # n_eff = 1.0 / np.sum(last_weights**2)\n",
    "        ess = 1.0 / custom_sum([w**2 for w in normalized_last_weights])\n",
    "        \n",
    "        # Requires std calculation on all particles (or sampled particles)\n",
    "        # Using the standard deviation of all collected particles from the last step\n",
    "        # This formula is often used for Silverman's rule for KDE bandwidth\n",
    "        # Need to ensure last_particles is not empty to calculate std\n",
    "        if not last_particles:\n",
    "            bandwidth = 1.0 # Default fallback\n",
    "        else:\n",
    "            std_particles = custom_std(last_particles)\n",
    "            # Avoid negative power if ess is very small or 0\n",
    "            bandwidth = 1.06 * std_particles * (ess ** (-1/5.0) if ess > 0 else 1.0) \n",
    "            if bandwidth < 1e-6: # Prevent tiny bandwidths\n",
    "                bandwidth = 1e-6\n",
    "        \n",
    "        def kernel_sampler(size):\n",
    "            # Sample indices according to weights\n",
    "            indices = custom_random_choice(list(range(len(last_particles))), size=size, p=normalized_last_weights)\n",
    "            # Add Gaussian noise\n",
    "            samples = []\n",
    "            for idx in indices:\n",
    "                samples.append(last_particles[idx] + custom_normal_sampler(0, bandwidth))\n",
    "            return samples\n",
    "            \n",
    "        def kernel_log_pdf(x_val):\n",
    "            # Mixture of Gaussians centered at past particles\n",
    "            # Ensure x_val is a scalar for custom_norm_logpdf\n",
    "            if isinstance(x_val, (list, tuple)):\n",
    "                if len(x_val) > 1: # This implementation is for univariate x_val\n",
    "                    raise ValueError(\"Kernel log PDF expects a scalar x for this simplified implementation.\")\n",
    "                x_val = x_val[0]\n",
    "\n",
    "            log_probs_components = []\n",
    "            for i, particle in enumerate(last_particles):\n",
    "                # log(weight) + logpdf(x | particle_mean, bandwidth_std)\n",
    "                log_prob = math.log(normalized_last_weights[i]) + custom_norm_logpdf(x_val, particle, bandwidth)\n",
    "                log_probs_components.append(log_prob)\n",
    "            return custom_logsumexp(log_probs_components)\n",
    "            \n",
    "        return kernel_sampler, kernel_log_pdf\n",
    "        \n",
    "    def get_proposal(self, iteration):\n",
    "        \"\"\"\n",
    "        Get proposal distribution for current iteration\n",
    "        \"\"\"\n",
    "        if self.proposal_adaptation == 'mixture': # This is simplified to single Gaussian\n",
    "            return self.adaptive_proposal_single_gaussian(iteration)\n",
    "        elif self.proposal_adaptation == 'kernel':\n",
    "            return self.adaptive_proposal_kernel(iteration)\n",
    "        else:\n",
    "            return self.initial_proposal, self.initial_proposal_log_pdf\n",
    "            \n",
    "    def compute_importance_weights(self, particles, proposal_log_pdf_func):\n",
    "        \"\"\"\n",
    "        Compute importance weights: ω_i = π(z_i) / q_t(z_i)\n",
    "        \"\"\"\n",
    "        n = len(particles)\n",
    "        log_weights = [0.0] * n # Initialize list\n",
    "        \n",
    "        for i, particle in enumerate(particles):\n",
    "            log_target = self.target_log_pdf(particle)\n",
    "            log_proposal = proposal_log_pdf_func(particle)\n",
    "            log_weights[i] = log_target - log_proposal\n",
    "            \n",
    "        # Normalize to avoid numerical issues (using custom_logsumexp)\n",
    "        log_weights_normalized = [lw - custom_logsumexp(log_weights) for lw in log_weights]\n",
    "        weights = [math.exp(lw) for lw in log_weights_normalized]\n",
    "        \n",
    "        return weights, log_weights_normalized\n",
    "        \n",
    "    def resample(self, particles, weights):\n",
    "        \"\"\"\n",
    "        Resample particles according to weights\n",
    "        \"\"\"\n",
    "        n = len(particles)\n",
    "        # Use custom_random_choice for weighted sampling\n",
    "        resampled_particles = custom_random_choice(particles, size=n, p=weights)\n",
    "        return resampled_particles\n",
    "        \n",
    "    def estimate_integral(self, func, particles, weights):\n",
    "        \"\"\"\n",
    "        Estimate E[h(X)] using importance sampling: Î_t = (1/n) Σ ω_i h(z_i)\n",
    "        \"\"\"\n",
    "        weighted_values = []\n",
    "        for i, particle in enumerate(particles):\n",
    "            # Ensure func handles the particle type correctly (scalar vs list)\n",
    "            weighted_values.append(weights[i] * func(particle))\n",
    "            \n",
    "        return custom_mean(weighted_values) # Use custom_mean\n",
    "        \n",
    "    def compute_variance_estimate(self, func, particles, weights):\n",
    "        \"\"\"\n",
    "        Estimate variance of the importance sampling estimator (simplified).\n",
    "        \"\"\"\n",
    "        n = len(particles)\n",
    "        weighted_values = []\n",
    "        \n",
    "        for i, particle in enumerate(particles):\n",
    "            value = weights[i] * func(particle)\n",
    "            weighted_values.append(value)\n",
    "            \n",
    "        # Simplified variance calculation for a list\n",
    "        # This is (1/n) * sample_variance_of_weighted_values\n",
    "        if n == 0: return 0.0\n",
    "        sample_var = custom_variance(weighted_values) # Using custom_variance\n",
    "        return sample_var / n\n",
    "        \n",
    "    def run_pmc(self, verbose=True):\n",
    "        \"\"\"\n",
    "        Run Population Monte Carlo algorithm\n",
    "        \"\"\"\n",
    "        if verbose:\n",
    "            print(\"Starting Population Monte Carlo (Core Python)...\")\n",
    "        \n",
    "        for t in range(self.max_iterations):\n",
    "            if verbose and t % 5 == 0: # Adjusted verbose frequency\n",
    "                print(f\"Iteration {t+1}/{self.max_iterations}\")\n",
    "            \n",
    "            # Step 1: Get proposal distribution for this iteration\n",
    "            proposal_sampler, proposal_log_pdf = self.get_proposal(t)\n",
    "            self.proposals_history.append((proposal_sampler, proposal_log_pdf)) # Store proposal\n",
    "            \n",
    "            # Step 2: Generate particles\n",
    "            particles = proposal_sampler(self.n_particles)\n",
    "            \n",
    "            # Step 3: Compute importance weights\n",
    "            weights, log_weights = self.compute_importance_weights(particles, proposal_log_pdf)\n",
    "            \n",
    "            # Step 4: Normalize weights to sum to 1 (already done by custom_compute_importance_weights)\n",
    "            # Ensure they sum to 1.0 (or very close)\n",
    "            sum_weights = custom_sum(weights)\n",
    "            if abs(sum_weights - 1.0) > 1e-9 and sum_weights != 0:\n",
    "                weights = [w / sum_weights for w in weights] # Re-normalize if floating point drift\n",
    "            \n",
    "            # Step 5: Optional resampling\n",
    "            if self.resample_every > 0 and t % self.resample_every == 0 and t > 0:\n",
    "                particles = self.resample(particles, weights)\n",
    "                weights = [1.0 / self.n_particles] * self.n_particles # Reset weights after resampling\n",
    "                log_weights = [math.log(w) for w in weights]\n",
    "            \n",
    "            # Store results\n",
    "            self.particles_history.append(particles)\n",
    "            self.weights_history.append(weights)\n",
    "            self.log_weights_history.append(log_weights)\n",
    "            \n",
    "            # Compute diagnostics\n",
    "            # ess = 1.0 / np.sum(weights**2)\n",
    "            sum_sq_weights = custom_sum([w**2 for w in weights])\n",
    "            ess = 1.0 / sum_sq_weights if sum_sq_weights != 0 else 0.0\n",
    "            self.ess_history.append(ess)\n",
    "            \n",
    "            # Estimate normalizing constant (Equation 14.11 from typical PMC texts)\n",
    "            # This is sum(exp(log_weights)) / n_particles from current iteration,\n",
    "            # or cumulative average from all iterations.\n",
    "            # The original code's cumulative sum: (1/tn) sum_{s=1}^t sum_{i=1}^n pi(z_i^(s))/q_s(z_i^(s))\n",
    "            # which is (1/tn) * sum of all raw (unnormalized) importance ratios.\n",
    "            # My current log_weights are already normalized.\n",
    "            # Let's adjust the normalizing constant to match the usual definition for PMC:\n",
    "            # log(Z_hat) approx log( (1/N) * sum_i (target_pdf(particle_i) / proposal_pdf(particle_i)) )\n",
    "            # = log( (1/N) * sum_i exp(log_target_i - log_proposal_i) )\n",
    "            # = log( (1/N) * sum_i exp(log_raw_weights_i) )\n",
    "            # = log(sum_i exp(log_raw_weights_i)) - log(N)\n",
    "            # We need to re-compute raw log weights for this\n",
    "            \n",
    "            # To estimate the normalizing constant accurately without raw_log_weights storage:\n",
    "            # Z_hat = mean(weights_t) if weights_t are defined as pi(z)/q(z) for a large N,\n",
    "            # NOT if they are normalized.\n",
    "            # The original code was using 'np.mean(np.exp(log_weights))' where log_weights\n",
    "            # were already normalized, which is confusing for Z.\n",
    "            # If log_weights are normalized (sum to 1), then exp(log_weights) are also normalized.\n",
    "            # Let's re-align with standard PMC Z estimation:\n",
    "            # Z_hat = (1/N) * sum(pi(zi)/q(zi)) = (1/N) * sum(exp(log_target - log_proposal))\n",
    "            \n",
    "            # For each iteration, recompute raw weights\n",
    "            current_raw_log_weights = []\n",
    "            for i, particle in enumerate(particles):\n",
    "                log_target = self.target_log_pdf(particle)\n",
    "                log_proposal = self.proposals_history[t][1](particle) # Use the stored proposal log_pdf\n",
    "                current_raw_log_weights.append(log_target - log_proposal)\n",
    "            \n",
    "            # current_raw_weights = [math.exp(lw) for lw in current_raw_log_weights]\n",
    "            # estimate for current iteration = custom_mean(current_raw_weights)\n",
    "            \n",
    "            # Cumulative average of raw importance ratios\n",
    "            # This is what the original code seems to be doing more robustly\n",
    "            if t == 0:\n",
    "                self.normalizing_constant_estimates.append(custom_mean([math.exp(lw) for lw in current_raw_log_weights]))\n",
    "            else:\n",
    "                total_raw_weight_sum = 0.0\n",
    "                total_particle_count = 0\n",
    "                for s in range(t + 1):\n",
    "                    # Need original raw log weights to do this precisely, which we don't store by default.\n",
    "                    # As a simplification, we'll average the 'mean(exp(log_weights))' from each iteration\n",
    "                    # This is an approximation for cumulative average, but conceptually follows the text.\n",
    "                    \n",
    "                    # For a truly \"cumulative\" Z estimate, one would need to store all raw unnormalized weights\n",
    "                    # from all previous iterations. The current `self.log_weights_history` is for normalized log_weights.\n",
    "                    # So, I'll stick to a simpler iteration-wise average for demo.\n",
    "                    \n",
    "                    # The original formula was: (1/tn) Σ_{s=1}^t Σ_{i=1}^n π(z_i^(s))/q_s(z_i^(s))\n",
    "                    # which implies we need the sum of *raw* importance ratios over all history.\n",
    "                    # This means we need to re-evaluate or store raw log weights.\n",
    "                    # Re-evaluating would be slow. Storing needs modification of `compute_importance_weights`.\n",
    "                    \n",
    "                    # Let's simplify the Z estimate to just be the mean of exp(raw weights) from current iteration\n",
    "                    # (This is Z_hat = (1/N) * sum(w_raw))\n",
    "                    if s == t: # Only process current iteration's raw weights\n",
    "                        total_raw_weight_sum += custom_sum([math.exp(lw) for lw in current_raw_log_weights])\n",
    "                        total_particle_count += self.n_particles\n",
    "                    \n",
    "                self.normalizing_constant_estimates.append(total_raw_weight_sum / total_particle_count)\n",
    "            \n",
    "        if verbose:\n",
    "            print(\"PMC completed!\")\n",
    "        \n",
    "        return self.particles_history, self.weights_history\n",
    "        \n",
    "    def get_final_sample(self):\n",
    "        \"\"\"\n",
    "        Get final weighted sample\n",
    "        \"\"\"\n",
    "        if not self.particles_history:\n",
    "            raise ValueError(\"No samples generated. Run PMC first.\")\n",
    "            \n",
    "        return self.particles_history[-1], self.weights_history[-1]\n",
    "        \n",
    "    def estimate_expectation(self, func):\n",
    "        \"\"\"\n",
    "        Estimate E[h(X)] using final sample\n",
    "        \"\"\"\n",
    "        particles, weights = self.get_final_sample()\n",
    "        return self.estimate_integral(func, particles, weights)\n",
    "\n",
    "\n",
    "class GaussianMixturePMC(PopulationMonteCarlo):\n",
    "    \"\"\"\n",
    "    PMC for Gaussian mixture target distribution (Simplified to univariate target).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, mixture_weights, means, stds, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        # Ensure these are flat lists, not NumPy arrays\n",
    "        self.mixture_weights = list(mixture_weights)\n",
    "        self.means = list(means)\n",
    "        self.stds = list(stds)\n",
    "        \n",
    "    def target_log_pdf(self, x):\n",
    "        \"\"\"Mixture of Univariate Gaussians log-pdf\"\"\"\n",
    "        # x is assumed to be a scalar here, as this is a univariate target.\n",
    "        # If x could be a list of particles, then custom_norm_logpdf needs to handle it.\n",
    "        # We'll assume a single x for this function's input.\n",
    "        log_probs = []\n",
    "        for i in range(len(self.mixture_weights)):\n",
    "            weight = self.mixture_weights[i]\n",
    "            mean = self.means[i]\n",
    "            std = self.stds[i]\n",
    "            if weight <= 0: # Handle zero weights to avoid log(0)\n",
    "                log_probs.append(-float('inf'))\n",
    "                continue\n",
    "            # log(weight) + logpdf(x | mean, std)\n",
    "            log_prob = math.log(weight) + custom_norm_logpdf(x, mean, std)\n",
    "            log_probs.append(log_prob)\n",
    "        return custom_logsumexp(log_probs)\n",
    "        \n",
    "    def initial_proposal(self, size):\n",
    "        \"\"\"Initial proposal: broad Gaussian (univariate)\"\"\"\n",
    "        return custom_normal_sampler(0, 3, size) # Uses custom normal sampler\n",
    "        \n",
    "    def initial_proposal_log_pdf(self, x):\n",
    "        \"\"\"Initial proposal log-pdf (univariate)\"\"\"\n",
    "        return custom_norm_logpdf(x, 0, 3)\n",
    "\n",
    "\n",
    "class BayesianRegressionPMC(PopulationMonteCarlo):\n",
    "    \"\"\"\n",
    "    PMC for Bayesian linear regression.\n",
    "    ***SIMPLIFIED TO UNIVARIATE LINEAR REGRESSION (1 feature, scalar beta)***\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, X, y, prior_mean=0, prior_std=1, noise_std=1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        # X and y are lists of numbers for univariate regression\n",
    "        self.X = list(X)\n",
    "        self.y = list(y)\n",
    "        self.prior_mean = prior_mean\n",
    "        self.prior_std = prior_std\n",
    "        self.noise_std = noise_std\n",
    "        # n_params is 1 for univariate regression\n",
    "        self.n_params = 1 # Crucial simplification: beta is a scalar\n",
    "        \n",
    "    def target_log_pdf(self, beta):\n",
    "        \"\"\"\n",
    "        Posterior log-pdf for Bayesian regression (univariate beta assumed).\n",
    "        beta is assumed to be a scalar or a single-element list.\n",
    "        \"\"\"\n",
    "        if isinstance(beta, (list, tuple)):\n",
    "            if len(beta) != 1:\n",
    "                raise ValueError(\"BayesianRegressionPMC (simplified) expects scalar beta.\")\n",
    "            beta_val = beta[0]\n",
    "        else:\n",
    "            beta_val = beta\n",
    "\n",
    "        # Prior: N(prior_mean, prior_std²)\n",
    "        log_prior = custom_norm_logpdf(beta_val, self.prior_mean, self.prior_std)\n",
    "        \n",
    "        # Likelihood: N(Xβ, σ²)\n",
    "        # pred = X @ beta becomes pred = X_i * beta_val\n",
    "        log_likelihood_terms = []\n",
    "        for i in range(len(self.X)):\n",
    "            pred = self.X[i] * beta_val # Scalar multiplication\n",
    "            log_likelihood_terms.append(custom_norm_logpdf(self.y[i], pred, self.noise_std))\n",
    "        \n",
    "        log_likelihood = custom_sum(log_likelihood_terms) # Sum of log likelihoods\n",
    "\n",
    "        return log_prior + log_likelihood\n",
    "        \n",
    "    def initial_proposal(self, size):\n",
    "        \"\"\"Initial proposal: prior distribution (univariate)\"\"\"\n",
    "        # Returns a list of scalars (beta values)\n",
    "        return custom_normal_sampler(self.prior_mean, self.prior_std, size)\n",
    "        \n",
    "    def initial_proposal_log_pdf(self, beta):\n",
    "        \"\"\"Initial proposal log-pdf (univariate)\"\"\"\n",
    "        # Beta is a scalar for this simplified implementation\n",
    "        if isinstance(beta, (list, tuple)):\n",
    "            if len(beta) != 1:\n",
    "                raise ValueError(\"Initial proposal log-pdf expects scalar beta.\")\n",
    "            beta_val = beta[0]\n",
    "        else:\n",
    "            beta_val = beta\n",
    "        return custom_norm_logpdf(beta_val, self.prior_mean, self.prior_std)\n",
    "\n",
    "# --- Demo Functions (adapted for core Python) ---\n",
    "\n",
    "def demo_gaussian_mixture():\n",
    "    \"\"\"Demonstrate PMC on Gaussian mixture (univariate)\"\"\"\n",
    "    print(\"=== Gaussian Mixture PMC Demo (Core Python) ===\")\n",
    "    random.seed(42) # Set seed for reproducibility\n",
    "    \n",
    "    # Define mixture: 0.3*N(-2,0.5) + 0.7*N(2,1)\n",
    "    mixture_weights = [0.3, 0.7]\n",
    "    means = [-2.0, 2.0]\n",
    "    stds = [0.5, 1.0]\n",
    "    \n",
    "    # True expectation\n",
    "    true_mean = custom_sum([w * m for w, m in zip(mixture_weights, means)])\n",
    "    \n",
    "    # Run PMC\n",
    "    pmc = GaussianMixturePMC(\n",
    "        mixture_weights, means, stds,\n",
    "        n_particles=1000, max_iterations=30,\n",
    "        proposal_adaptation='mixture' # This now implies adaptive_proposal_single_gaussian\n",
    "    )\n",
    "    \n",
    "    pmc.run_pmc(verbose=True)\n",
    "    \n",
    "    # Estimate mean (h(x) = x)\n",
    "    # Ensure lambda function returns scalar if particle is scalar\n",
    "    estimated_mean = pmc.estimate_expectation(lambda x: x)\n",
    "    \n",
    "    print(f\"True mean: {true_mean:.3f}\")\n",
    "    print(f\"Estimated mean: {estimated_mean:.3f}\")\n",
    "    print(f\"Error: {abs(estimated_mean - true_mean):.3f}\")\n",
    "    print(f\"Final ESS: {pmc.ess_history[-1]:.1f}\")\n",
    "    \n",
    "    return pmc\n",
    "\n",
    "\n",
    "def demo_bayesian_regression():\n",
    "    \"\"\"\n",
    "    Demonstrate PMC on Bayesian regression.\n",
    "    ***SIMPLIFIED TO UNIVARIATE LINEAR REGRESSION***\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Bayesian Regression PMC Demo (Core Python - Univariate) ===\")\n",
    "    random.seed(42) # Set seed for reproducibility\n",
    "    \n",
    "    # Generate synthetic data for univariate regression (y = beta*X + noise)\n",
    "    n_samples = 100\n",
    "    true_beta = 1.5 # Scalar beta\n",
    "    \n",
    "    # X values (1D list of features for each sample)\n",
    "    X_data = [random.gauss(0, 1) for _ in range(n_samples)] # X from standard normal\n",
    "    \n",
    "    # y values\n",
    "    y_data = []\n",
    "    for x_val in X_data:\n",
    "        y_data.append(x_val * true_beta + random.gauss(0, 0.5)) # Noise std = 0.5\n",
    "    \n",
    "    # Run PMC\n",
    "    pmc = BayesianRegressionPMC(\n",
    "        X_data, y_data, prior_mean=0, prior_std=2, noise_std=0.5,\n",
    "        n_particles=500, max_iterations=25,\n",
    "        proposal_adaptation='mixture' # This implies adaptive_proposal_single_gaussian\n",
    "    )\n",
    "    \n",
    "    pmc.run_pmc(verbose=True)\n",
    "    \n",
    "    # Estimate posterior mean of beta\n",
    "    # Pass lambda that assumes beta is a scalar (or takes 1st element of list if particles are lists)\n",
    "    estimated_beta = pmc.estimate_expectation(lambda beta_val: beta_val if not isinstance(beta_val, list) else beta_val[0])\n",
    "    \n",
    "    print(f\"True beta: {true_beta}\")\n",
    "    print(f\"Estimated beta: {estimated_beta:.3f}\")\n",
    "    print(f\"Error: {abs(estimated_beta - true_beta):.3f}\") # For scalar beta\n",
    "    print(f\"Final ESS: {pmc.ess_history[-1]:.1f}\")\n",
    "    \n",
    "    return pmc\n",
    "\n",
    "\n",
    "def convergence_analysis():\n",
    "    \"\"\"Analyze PMC convergence properties (univariate Gaussian target)\"\"\"\n",
    "    print(\"\\n=== Convergence Analysis (Core Python) ===\")\n",
    "    \n",
    "    # Run multiple PMC experiments\n",
    "    n_runs = 5 # Reduced runs due to slower execution\n",
    "    results = {'mixture': [], 'kernel': [], 'fixed': []}\n",
    "    \n",
    "    for adaptation in ['mixture', 'kernel', 'fixed']:\n",
    "        errors = []\n",
    "        \n",
    "        for run in range(n_runs):\n",
    "            random.seed(run) # Set seed per run\n",
    "            \n",
    "            # Simple Gaussian mixture target: 0.5*N(-1,0.5) + 0.5*N(1,0.5)\n",
    "            # True mean is 0.0\n",
    "            pmc = GaussianMixturePMC(\n",
    "                [0.5, 0.5], [-1.0, 1.0], [0.5, 0.5],\n",
    "                n_particles=500, max_iterations=20,\n",
    "                proposal_adaptation=adaptation\n",
    "            )\n",
    "            \n",
    "            pmc.run_pmc(verbose=False)\n",
    "            \n",
    "            true_mean = 0.0  # By symmetry\n",
    "            estimated_mean = pmc.estimate_expectation(lambda x: x)\n",
    "            error = abs(estimated_mean - true_mean)\n",
    "            errors.append(error)\n",
    "            \n",
    "        # Using custom_mean and custom_std for results\n",
    "        mean_error = custom_mean(errors)\n",
    "        std_error = custom_std(errors)\n",
    "        print(f\"{adaptation:8}: Mean error = {mean_error:.4f} \\u00B1 {std_error:.4f}\") # \\u00B1 is plus/minus symbol\n",
    "        \n",
    "        results[adaptation] = errors\n",
    "        \n",
    "    return results\n",
    "\n",
    "\n",
    "# --- Main execution block ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Run demonstrations\n",
    "    pmc1 = demo_gaussian_mixture()\n",
    "    pmc2 = demo_bayesian_regression()\n",
    "    \n",
    "    # Convergence analysis\n",
    "    conv_results = convergence_analysis()\n",
    "    \n",
    "    # Show final normalizing constant convergence for Gaussian mixture demo\n",
    "    print(f\"\\nNormalizing constant evolution (Gaussian mixture demo):\")\n",
    "    for i, estimate in enumerate(pmc1.normalizing_constant_estimates[::5]):\n",
    "        print(f\"Iteration {i*5+1:2d}: {estimate:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6868f51a",
   "metadata": {},
   "source": [
    "**Note the formal similarity with Warnes’s (2001) use of the previous sample to build a nonparametric kernel approximation to $\\pi$. The main difference is that the proposal does not aim at a good approximation of $\\pi$ using standard nonparametric results like bandwidth selection, but may remain multiscaled over the iterations, as illustrated in Section 14.4.4 The main feature of the PMC algorithm is indeed that several scenarios can be tested in parallel and tuned along iterations, a feature that can hardly be achieved within the domain of MCMC algorithms (Section 7.6.3).**\n",
    "\n",
    "**There also are similarities between the PMC algorithm and earlier proposals in the particle system literature, in particular with Algorithm [A.60], since the latter also considers iterated samples with (SIR) resampling steps based on importance weights. A major difference, though (besides the dynamic setting of moving target distributions), is that [A.60] remains an MCMC algorithm and thus needs to use Markov transition kernels with a given stationary distribution. There is also a connection with Chopin (2002), who considers iterated importance sampling with changing proposals. His setting is a special case of the PMC algorithm in a Bayesian framework, where the proposals $q_t$ are the posterior distributions associated with a portion $k_t$ of the observed dataset (and are thus independent of $x$ and of the previous samples). As detailed in the following sections, the range of possible choices for the $q_t$’s is actually much wider.**\n",
    "\n",
    "---\n",
    "\n",
    "### 14.4.4 An Illustration for the Mixture Model\n",
    "\n",
    "Consider the normal mixture model of Example 5.19, that is, $pN(\\mu_1, 1) + (1 - p)N(\\mu_2, 1)$, where $p \\ne 1/2$ is known, and the corresponding simulation from $\\pi(\\mu_1, \\mu_2|\\mathbf{x})$, the posterior distribution for an i.i.d sample $\\mathbf{x} = (x_1, \\dots, x_n)$ and an arbitrary proper prior on $(\\mu_1, \\mu_2)$. While we presented in Chapter 9 a Gibbs sampler based on a data augmentation step via the indicator variables, Celeux et al. (2003) show that a PMC sampler can be efficiently implemented without this augmentation step.\n",
    "\n",
    "Given the posterior distribution\n",
    "$$\\pi(\\mu_1, \\mu_2|\\mathbf{x}) \\propto \\exp(-\\lambda(\\theta - \\mu_1)^2 / 2\\sigma^2) \\exp(-\\lambda(\\theta - \\mu_2)^2 / 2\\sigma^2)$$\n",
    "$$\\prod_{i=1}^n \\left\\{ p \\exp(-(x_i - \\mu_1)^2 / 2\\sigma^2) + (1 - p) \\exp(-(x_i - \\mu_2)^2 / 2\\sigma^2) \\right\\},$$\n",
    "a natural possibility is to choose a random walk for the proposal distribution (see Section 7.5). That is, starting from a sample of values of $\\mu = (\\mu_1, \\mu_2)$, generate random isotropic perturbations of the points of this sample.\n",
    "\n",
    "The difficult issue of selecting the scale of the random walk (see Section 7.6), found in MCMC settings, can be bypassed by virtue of the adaptivity of the PMC algorithm. Indeed, if we take as proposals $q_t$ normal distributions centered at the points of the current sample, $N_2(\\mu_t^{(i)}, \\sigma^2 \\mathbf{I}_2)$, the variance factors $\\sigma_k$ can be chosen at random from a set of $K$ scales $\\nu_k$ ($1 \\le k \\le K$) ranging from, e.g., $10^0$ down to $10^{-3}$ if this range is compatible with the range of the observations. At each iteration $t$ of the PMC algorithm, the probability of choosing a particular scale $\\nu_k$ can be calibrated accordingly to the performance of the different scales over the previous iterations. For instance, possible criterion is to select a scale proportional to its non-degeneracy rate on the previous iterations, that is, the percentage of points associated with $\\nu_k$ that survived past the resampling step 3. The reasoning behind this scheme is that, if most $\\mu_t^{(i)}$s associated with a given scale $\\nu_k$ are not resampled, the scale is not appropriate and thus should not be much used in the next iterations. However, when the survival rate is null, in order to avoid a definitive removal of the corresponding scale, the next probability $\\zeta_k$ is set to a positive value $\\epsilon$.\n",
    "\n",
    "In order to smooth the selection of the scales, Rao-Blackwellization should also be used in the computation of the importance weights, using as the denominator\n",
    "$$\\sum_k \\zeta_k \\varphi \\left( \\mu_t^{(i)}; \\mu_t^{(i')}, \\nu_k \\right),$$\n",
    "where $\\varphi(\\mu; \\xi, \\nu)$ here denotes the density of the two-dimensional normal distribution with mean $\\xi$ and variance $\\nu \\mathbf{I}_2$ at the vector $\\mu$.\n",
    "\n",
    "The corresponding PMC algorithm thus looks as follows.\n",
    "\n",
    "**Algorithm A.62 —Mixture PMC algorithm—**\n",
    "\n",
    "**Step 0: Initialization**\n",
    "For $i = 1, \\dots, n$, generate $\\mu_1^{(i)}$ from an arbitrary distribution.\n",
    "For $k = 1, \\dots, K$, set $\\nu_k$ and $\\zeta_k = 1/K$.\n",
    "\n",
    "**Step 1: Update**\n",
    "For $i = 1, \\dots, n$,\n",
    "a. with probability $\\zeta_k$, take $\\sigma_{t+1}^{(i)} = \\nu_k$\n",
    "b. generate\n",
    "$$\\mu_{t+1}^{(i)} \\sim N_2 \\left( \\mu_t^{(i')}, \\sigma_{t+1}^{(i)} \\mathbf{I}_2 \\right)$$\n",
    "c. compute the weights\n",
    "$$\\frac{\\pi \\left( \\mu_{t+1}^{(i)} | \\mathbf{x} \\right)}{\\sum_k \\zeta_k \\varphi \\left( \\mu_{t+1}^{(i)}; \\mu_t^{(i')}, \\nu_k \\right)}$$\n",
    "\n",
    "Resample the $\\mu_{t+1}^{(i)}$'s using the weights.\n",
    "Update the $\\zeta_k$'s as $\\zeta_k \\propto r_k + \\epsilon$ where $r_k$ is the number of $\\mu_t$'s generated with variance $\\nu_k$ that have been resampled in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0e2e3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Mixture PMC Algorithm A.62 Demo (Core Python) ===\n",
      "Generated 200 data points from a mixture with true (mu1, mu2) = (0.0, 5.0)\n",
      "Starting Mixture PMC Algorithm A.62 (Core Python)...\n",
      "Iteration 1/50 (Initialization complete)\n",
      "  ESS: 1.4, Z_hat: 0.0000\n",
      "  ESS: 39.1, Z_hat: 0.0000\n",
      "  ESS: 139.4, Z_hat: 0.0000\n",
      "  ESS: 180.5, Z_hat: 0.0000\n",
      "  ESS: 186.9, Z_hat: 0.0000\n",
      "Iteration 6/50\n",
      "  ESS: 197.3, Z_hat: 0.0000\n",
      "  ESS: 190.7, Z_hat: 0.0000\n",
      "  ESS: 192.1, Z_hat: 0.0000\n",
      "  ESS: 176.6, Z_hat: 0.0000\n",
      "  ESS: 201.4, Z_hat: 0.0000\n",
      "Iteration 11/50\n",
      "  ESS: 188.1, Z_hat: 0.0000\n",
      "  ESS: 171.8, Z_hat: 0.0000\n",
      "  ESS: 187.0, Z_hat: 0.0000\n",
      "  ESS: 189.6, Z_hat: 0.0000\n",
      "  ESS: 193.1, Z_hat: 0.0000\n",
      "Iteration 16/50\n",
      "  ESS: 189.1, Z_hat: 0.0000\n",
      "  ESS: 194.1, Z_hat: 0.0000\n",
      "  ESS: 182.3, Z_hat: 0.0000\n",
      "  ESS: 186.0, Z_hat: 0.0000\n",
      "  ESS: 191.7, Z_hat: 0.0000\n",
      "Iteration 21/50\n",
      "  ESS: 188.0, Z_hat: 0.0000\n",
      "  ESS: 186.7, Z_hat: 0.0000\n",
      "  ESS: 183.3, Z_hat: 0.0000\n",
      "  ESS: 188.5, Z_hat: 0.0000\n",
      "  ESS: 183.4, Z_hat: 0.0000\n",
      "Iteration 26/50\n",
      "  ESS: 190.4, Z_hat: 0.0000\n",
      "  ESS: 196.9, Z_hat: 0.0000\n",
      "  ESS: 171.1, Z_hat: 0.0000\n",
      "  ESS: 199.1, Z_hat: 0.0000\n",
      "  ESS: 188.9, Z_hat: 0.0000\n",
      "Iteration 31/50\n",
      "  ESS: 192.8, Z_hat: 0.0000\n",
      "  ESS: 188.4, Z_hat: 0.0000\n",
      "  ESS: 168.5, Z_hat: 0.0000\n",
      "  ESS: 167.6, Z_hat: 0.0000\n",
      "  ESS: 210.9, Z_hat: 0.0000\n",
      "Iteration 36/50\n",
      "  ESS: 181.3, Z_hat: 0.0000\n",
      "  ESS: 200.5, Z_hat: 0.0000\n",
      "  ESS: 194.7, Z_hat: 0.0000\n",
      "  ESS: 193.1, Z_hat: 0.0000\n",
      "  ESS: 193.0, Z_hat: 0.0000\n",
      "Iteration 41/50\n",
      "  ESS: 170.0, Z_hat: 0.0000\n",
      "  ESS: 190.3, Z_hat: 0.0000\n",
      "  ESS: 173.5, Z_hat: 0.0000\n",
      "  ESS: 186.8, Z_hat: 0.0000\n",
      "  ESS: 183.3, Z_hat: 0.0000\n",
      "Iteration 46/50\n",
      "  ESS: 168.2, Z_hat: 0.0000\n",
      "  ESS: 183.2, Z_hat: 0.0000\n",
      "  ESS: 170.6, Z_hat: 0.0000\n",
      "  ESS: 178.3, Z_hat: 0.0000\n",
      "  ESS: 175.4, Z_hat: 0.0000\n",
      "PMC completed!\n",
      "\n",
      "True (mu1, mu2): (0.0, 5.0)\n",
      "Estimated (mu1, mu2): (-0.000, 0.005)\n",
      "Final ESS: 175.4\n",
      "Final Normalizing Constant Estimate: 0.0000\n",
      "Final zeta_k distribution for scales [0.1, 0.5, 1.0, 5.0, 10.0]:\n",
      "  nu_1=0.1: 1.0000\n",
      "  nu_2=0.5: 0.0000\n",
      "  nu_3=1.0: 0.0000\n",
      "  nu_4=5.0: 0.0000\n",
      "  nu_5=10.0: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "# --- Basic Vector Operations for 2D (Core Python) ---\n",
    "def vector_add(v1, v2):\n",
    "    return [v1[i] + v2[i] for i in range(len(v1))]\n",
    "\n",
    "def vector_sub(v1, v2):\n",
    "    return [v1[i] - v2[i] for i in range(len(v1))]\n",
    "\n",
    "def scalar_mul_vector(scalar, v):\n",
    "    return [scalar * v_i for v_i in v]\n",
    "\n",
    "def vector_dot_product(v1, v2):\n",
    "    return sum(v1[i] * v2[i] for i in range(len(v1)))\n",
    "\n",
    "def squared_euclidean_distance(v1, v2):\n",
    "    diff = vector_sub(v1, v2)\n",
    "    return vector_dot_product(diff, diff)\n",
    "\n",
    "# --- Replacements for common NumPy/SciPy functions (from previous implementation) ---\n",
    "\n",
    "def custom_logsumexp(log_x_list):\n",
    "    if not log_x_list:\n",
    "        return -float('inf')\n",
    "    max_log_x = log_x_list[0]\n",
    "    for x_val in log_x_list:\n",
    "        if x_val > max_log_x:\n",
    "            max_log_x = x_val\n",
    "    if max_log_x == -float('inf'):\n",
    "        return -float('inf')\n",
    "    sum_exp = 0.0\n",
    "    for x_val in log_x_list:\n",
    "        sum_exp += math.exp(x_val - max_log_x)\n",
    "    return max_log_x + math.log(sum_exp)\n",
    "\n",
    "def custom_normal_sampler(mean, std, size=1):\n",
    "    if std < 0:\n",
    "        raise ValueError(\"Standard deviation cannot be negative.\")\n",
    "    samples = []\n",
    "    i = 0\n",
    "    while i < size:\n",
    "        u1 = random.random()\n",
    "        u2 = random.random()\n",
    "        z0 = math.sqrt(-2 * math.log(u1)) * math.cos(2 * math.pi * u2)\n",
    "        samples.append(z0 * std + mean)\n",
    "        i += 1\n",
    "    if size == 1:\n",
    "        return samples[0]\n",
    "    return samples\n",
    "\n",
    "def custom_mean(data):\n",
    "    if not data:\n",
    "        return 0.0\n",
    "    return sum(data) / len(data)\n",
    "\n",
    "def custom_sum(data):\n",
    "    return sum(data)\n",
    "\n",
    "def custom_variance(data, weights=None):\n",
    "    if not data:\n",
    "        return 0.0\n",
    "    if weights:\n",
    "        weighted_sum = sum(data[i] * weights[i] for i in range(len(data)))\n",
    "        total_weights = sum(weights)\n",
    "        if total_weights == 0: return 0.0\n",
    "        mean = weighted_sum / total_weights\n",
    "        sum_sq_diff_weighted = sum(weights[i] * (data[i] - mean)**2 for i in range(len(data)))\n",
    "        return sum_sq_diff_weighted / total_weights\n",
    "    else:\n",
    "        mean = custom_mean(data)\n",
    "        sum_sq_diff = sum((x - mean)**2 for x in data)\n",
    "        return sum_sq_diff / len(data)\n",
    "\n",
    "def custom_std(data, weights=None):\n",
    "    return math.sqrt(custom_variance(data, weights))\n",
    "\n",
    "def custom_average(data, weights):\n",
    "    if not data or not weights or len(data) != len(weights):\n",
    "        raise ValueError(\"Data and weights must be non-empty and of same length.\")\n",
    "    weighted_sum = sum(data[i] * weights[i] for i in range(len(data)))\n",
    "    total_weights = sum(weights)\n",
    "    if total_weights == 0: return 0.0\n",
    "    return weighted_sum / total_weights\n",
    "\n",
    "def custom_random_choice(items, size, p=None):\n",
    "    if p is None:\n",
    "        return random.choices(items, k=size)\n",
    "    else:\n",
    "        chosen = []\n",
    "        cumulative_probs = [0.0] * len(p)\n",
    "        current_sum = 0.0\n",
    "        for i, prob in enumerate(p):\n",
    "            current_sum += prob\n",
    "            cumulative_probs[i] = current_sum\n",
    "        for _ in range(size):\n",
    "            r = random.random()\n",
    "            for i, cum_prob in enumerate(cumulative_probs):\n",
    "                if r <= cum_prob:\n",
    "                    chosen.append(items[i])\n",
    "                    break\n",
    "        return chosen\n",
    "\n",
    "# --- New 2D Multivariate Normal PDF and Sampler (Spherical Covariance) ---\n",
    "\n",
    "def multivariate_normal_log_pdf_2D_spherical(x_vec, mean_vec, variance):\n",
    "    \"\"\"\n",
    "    Calculates the log PDF of a 2D spherical multivariate normal distribution.\n",
    "    phi(mu; xi, nu) where x_vec=mu, mean_vec=xi, variance=nu.\n",
    "    Assumes covariance matrix is diag(variance, variance).\n",
    "    \"\"\"\n",
    "    if variance <= 0:\n",
    "        return -float('inf')\n",
    "    \n",
    "    D = 2 # Dimension is fixed at 2\n",
    "    \n",
    "    # log( (1 / ( (2*pi)^D * det(Sigma) )^0.5 ) )\n",
    "    # det(Sigma) = (variance)^D\n",
    "    log_normalization = -0.5 * D * math.log(2 * math.pi) - 0.5 * D * math.log(variance)\n",
    "    \n",
    "    # -0.5 * (x - mu).T @ Sigma_inv @ (x - mu)\n",
    "    # Sigma_inv = (1/variance) * I_2\n",
    "    sq_dist = squared_euclidean_distance(x_vec, mean_vec)\n",
    "    exponent = -0.5 * (1.0 / variance) * sq_dist\n",
    "    \n",
    "    return log_normalization + exponent\n",
    "\n",
    "def multivariate_normal_sampler_2D_spherical(mean_vec, variance, size=1):\n",
    "    \"\"\"\n",
    "    Generates samples from a 2D spherical multivariate normal distribution.\n",
    "    Assumes covariance matrix is diag(variance, variance).\n",
    "    \"\"\"\n",
    "    if variance < 0:\n",
    "        raise ValueError(\"Variance cannot be negative.\")\n",
    "    \n",
    "    std = math.sqrt(variance)\n",
    "    samples = []\n",
    "    for _ in range(size):\n",
    "        # Sample two independent univariate normals\n",
    "        z1 = custom_normal_sampler(0, 1)\n",
    "        z2 = custom_normal_sampler(0, 1)\n",
    "        \n",
    "        sample_x = mean_vec[0] + z1 * std\n",
    "        sample_y = mean_vec[1] + z2 * std\n",
    "        samples.append([sample_x, sample_y])\n",
    "        \n",
    "    if size == 1:\n",
    "        return samples[0]\n",
    "    return samples\n",
    "\n",
    "# --- Algorithm A.62 Mixture PMC Implementation ---\n",
    "\n",
    "class MixturePMC:\n",
    "    \"\"\"\n",
    "    Implementation of Algorithm A.62 (Mixture PMC Algorithm) in core Python.\n",
    "    Designed for a 2D parameter space (mu1, mu2) and 1D data x.\n",
    "    Assumes spherical covariance for proposals.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_x, p_mixture, K_scales, epsilon=1e-6, n_particles=1000, max_iterations=50):\n",
    "        self.data_x = list(data_x) # Observed data (1D list)\n",
    "        self.p_mixture = p_mixture # Known mixture weight (p)\n",
    "        \n",
    "        self.K_scales = list(K_scales) # List of K possible variances (nu_k)\n",
    "        self.epsilon = epsilon # Small constant for zeta_k update\n",
    "        self.n_particles = n_particles\n",
    "        self.max_iterations = max_iterations\n",
    "        \n",
    "        # Step 0: Initialization\n",
    "        self.zeta_k = [1.0 / len(self.K_scales)] * len(self.K_scales) # Initialize zeta_k to 1/K\n",
    "        \n",
    "        # History storage\n",
    "        self.particles_history = [] # Stores lists of 2-element lists [mu1, mu2]\n",
    "        self.weights_history = [] # Normalized weights\n",
    "        self.log_weights_history = [] # Log of normalized weights\n",
    "        self.raw_log_weights_history = [] # Log of UNNORMALIZED weights (for Z estimate)\n",
    "        self.scale_choices_history = [] # To track which nu_k was used for each particle\n",
    "        self.normalizing_constant_estimates = []\n",
    "        self.ess_history = []\n",
    "        \n",
    "        # Parameters for the target posterior (Example 5.19 normal mixture model)\n",
    "        # pi(mu1, mu2 | x) proportional to prior * likelihood\n",
    "        # Assuming prior is N(theta, sigma_prior_sq / lambda) for each mu\n",
    "        # For Example 5.19, the standard deviation of components is 1.0 (sigma_noise_sq = 1.0)\n",
    "        self.prior_theta = 0.0 # Placeholder for prior mean\n",
    "        self.prior_lambda = 1.0 # Placeholder for prior precision/strength\n",
    "        self.prior_sigma_sq = 100.0 # Placeholder for prior variance (large for diffuse prior)\n",
    "        self.noise_sigma_sq = 1.0 # From Example 5.19: N(mu, 1) means variance is 1\n",
    "\n",
    "    def target_log_pdf(self, mu_vec):\n",
    "        \"\"\"\n",
    "        Calculates the log-posterior density pi(mu1, mu2 | x) for the mixture model.\n",
    "        Assumes mu_vec = [mu1, mu2]\n",
    "        \"\"\"\n",
    "        mu1, mu2 = mu_vec[0], mu_vec[1]\n",
    "\n",
    "        # Prior term: exp(-lambda(theta - mu1)^2 / 2*sigma_prior_sq) * exp(-lambda(theta - mu2)^2 / 2*sigma_prior_sq)\n",
    "        # Log prior for N(prior_theta, prior_sigma_sq / prior_lambda)\n",
    "        log_prior_mu1 = multivariate_normal_log_pdf_2D_spherical([mu1], [self.prior_theta], self.prior_sigma_sq / self.prior_lambda)\n",
    "        log_prior_mu2 = multivariate_normal_log_pdf_2D_spherical([mu2], [self.prior_theta], self.prior_sigma_sq / self.prior_lambda)\n",
    "        log_prior = log_prior_mu1 + log_prior_mu2\n",
    "        \n",
    "        # Likelihood term: Product_i { p * N(xi | mu1, noise_sigma_sq) + (1-p) * N(xi | mu2, noise_sigma_sq) }\n",
    "        log_likelihood_sum_terms = []\n",
    "        for x_i in self.data_x:\n",
    "            # log( p * N(x_i | mu1, 1) + (1-p) * N(x_i | mu2, 1) )\n",
    "            \n",
    "            # log(p) + log(N(x_i | mu1, 1))\n",
    "            log_comp1 = math.log(self.p_mixture) + multivariate_normal_log_pdf_2D_spherical([x_i], [mu1], self.noise_sigma_sq)\n",
    "            \n",
    "            # log(1-p) + log(N(x_i | mu2, 1))\n",
    "            log_comp2 = math.log(1.0 - self.p_mixture) + multivariate_normal_log_pdf_2D_spherical([x_i], [mu2], self.noise_sigma_sq)\n",
    "            \n",
    "            log_likelihood_sum_terms.append(custom_logsumexp([log_comp1, log_comp2]))\n",
    "            \n",
    "        log_likelihood = custom_sum(log_likelihood_sum_terms) # Sum of log-terms for product\n",
    "        \n",
    "        return log_prior + log_likelihood\n",
    "\n",
    "    def initial_proposal(self, size):\n",
    "        \"\"\"\n",
    "        Generates initial particles from an arbitrary distribution.\n",
    "        Here, a broad 2D spherical normal.\n",
    "        \"\"\"\n",
    "        return multivariate_normal_sampler_2D_spherical([0.0, 0.0], 10.0, size) # Mean 0, Variance 10\n",
    "\n",
    "    def initial_proposal_log_pdf(self, mu_vec):\n",
    "        \"\"\"\n",
    "        Log PDF of the initial proposal.\n",
    "        \"\"\"\n",
    "        return multivariate_normal_log_pdf_2D_spherical(mu_vec, [0.0, 0.0], 10.0)\n",
    "\n",
    "    def compute_weighted_proposal_log_pdf(self, mu_vec, parent_mu_vec):\n",
    "        \"\"\"\n",
    "        Computes the denominator in the weight calculation (Step 1.c):\n",
    "        sum_k { zeta_k * phi(mu_vec; parent_mu_vec, nu_k) }\n",
    "        This is log(sum_k { zeta_k * phi(...) })\n",
    "        \"\"\"\n",
    "        log_terms = []\n",
    "        for k in range(len(self.K_scales)):\n",
    "            zeta = self.zeta_k[k]\n",
    "            nu_k = self.K_scales[k]\n",
    "            \n",
    "            if zeta <= 0: # Avoid log(0)\n",
    "                log_terms.append(-float('inf'))\n",
    "                continue\n",
    "\n",
    "            # log(zeta_k) + log(phi(mu_vec; parent_mu_vec, nu_k))\n",
    "            log_phi = multivariate_normal_log_pdf_2D_spherical(mu_vec, parent_mu_vec, nu_k)\n",
    "            log_terms.append(math.log(zeta) + log_phi)\n",
    "            \n",
    "        return custom_logsumexp(log_terms)\n",
    "\n",
    "    def compute_importance_weights(self, particles, parent_particles_for_each_new_particle, scales_used_for_each_new_particle):\n",
    "        \"\"\"\n",
    "        Compute importance weights: ω_i = π(z_i) / q_t(z_i)\n",
    "        Here, q_t(z_i) = sum_k { zeta_k * phi(z_i; z_i_parent, nu_k) }\n",
    "        z_i_parent is the parent particle from which z_i was drawn.\n",
    "        \"\"\"\n",
    "        n = len(particles)\n",
    "        log_weights = [0.0] * n\n",
    "        raw_log_weights = [0.0] * n # Store unnormalized for Z estimate\n",
    "\n",
    "        for i in range(n):\n",
    "            current_particle = particles[i]\n",
    "            parent_particle = parent_particles_for_each_new_particle[i]\n",
    "            \n",
    "            log_target = self.target_log_pdf(current_particle)\n",
    "            log_proposal_denominator = self.compute_weighted_proposal_log_pdf(current_particle, parent_particle)\n",
    "            \n",
    "            raw_log_weights[i] = log_target - log_proposal_denominator\n",
    "        \n",
    "        # Normalize log_weights\n",
    "        log_sum_raw_weights = custom_logsumexp(raw_log_weights)\n",
    "        normalized_log_weights = [lw - log_sum_raw_weights for lw in raw_log_weights]\n",
    "        \n",
    "        weights = [math.exp(lw) for lw in normalized_log_weights]\n",
    "        \n",
    "        return weights, normalized_log_weights, raw_log_weights\n",
    "\n",
    "    def resample(self, particles, weights):\n",
    "        \"\"\"\n",
    "        Resample particles according to weights, and keep track of parent indices.\n",
    "        Returns resampled particles and their original indices.\n",
    "        \"\"\"\n",
    "        n = len(particles)\n",
    "        # Items to choose from are the indices of the particles\n",
    "        original_indices = list(range(n))\n",
    "        \n",
    "        # Use custom_random_choice for weighted sampling of indices\n",
    "        resampled_indices = custom_random_choice(original_indices, size=n, p=weights)\n",
    "        \n",
    "        resampled_particles = []\n",
    "        for idx in resampled_indices:\n",
    "            resampled_particles.append(particles[idx])\n",
    "            \n",
    "        return resampled_particles, resampled_indices\n",
    "        \n",
    "    def estimate_integral(self, func, particles, weights):\n",
    "        \"\"\"\n",
    "        Estimate E[h(X)] using importance sampling.\n",
    "        h(X) is a function of the 2D particle vector.\n",
    "        \"\"\"\n",
    "        weighted_values = []\n",
    "        for i in range(len(particles)):\n",
    "            weighted_values.append(weights[i] * func(particles[i]))\n",
    "            \n",
    "        return custom_mean(weighted_values)\n",
    "        \n",
    "    def run_pmc(self, verbose=True):\n",
    "        \"\"\"\n",
    "        Run Population Monte Carlo Algorithm A.62\n",
    "        \"\"\"\n",
    "        if verbose:\n",
    "            print(\"Starting Mixture PMC Algorithm A.62 (Core Python)...\")\n",
    "        \n",
    "        # Step 0: Initialization is done in __init__ for zeta_k\n",
    "        \n",
    "        # Initialize particles for t=0 from initial proposal (arbitrary distribution)\n",
    "        current_particles = self.initial_proposal(self.n_particles)\n",
    "        # For t=0, parent particles are just themselves, and scales are not yet chosen\n",
    "        # For initial weights, use initial proposal's log_pdf directly\n",
    "        initial_log_target = [self.target_log_pdf(p) for p in current_particles]\n",
    "        initial_log_proposal = [self.initial_proposal_log_pdf(p) for p in current_particles]\n",
    "        \n",
    "        initial_raw_log_weights = [initial_log_target[i] - initial_log_proposal[i] for i in range(self.n_particles)]\n",
    "        log_sum_initial_raw = custom_logsumexp(initial_raw_log_weights)\n",
    "        initial_normalized_log_weights = [lw - log_sum_initial_raw for lw in initial_raw_log_weights]\n",
    "        initial_weights = [math.exp(lw) for lw in initial_normalized_log_weights]\n",
    "\n",
    "        self.particles_history.append(current_particles)\n",
    "        self.weights_history.append(initial_weights)\n",
    "        self.log_weights_history.append(initial_normalized_log_weights)\n",
    "        self.raw_log_weights_history.append(initial_raw_log_weights) # Store raw weights\n",
    "        \n",
    "        # For t=0, ESS and Z estimate\n",
    "        sum_sq_weights_t0 = custom_sum([w**2 for w in initial_weights])\n",
    "        ess_t0 = 1.0 / sum_sq_weights_t0 if sum_sq_weights_t0 != 0 else 0.0\n",
    "        self.ess_history.append(ess_t0)\n",
    "        \n",
    "        # Z estimate for t=0 is mean of raw (unnormalized) importance ratios\n",
    "        self.normalizing_constant_estimates.append(custom_mean([math.exp(lw) for lw in initial_raw_log_weights]))\n",
    "\n",
    "        # Track which nu_k was used for each particle in current_particles to update zeta_k later\n",
    "        # For t=0, there's no \"parent\" choice based on zeta_k, so we'll just assign a dummy or average\n",
    "        self.scale_choices_history.append([0] * self.n_particles) # Store index of nu_k used\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Iteration 1/{self.max_iterations} (Initialization complete)\")\n",
    "            print(f\"  ESS: {self.ess_history[-1]:.1f}, Z_hat: {self.normalizing_constant_estimates[-1]:.4f}\")\n",
    "        \n",
    "        # Loop for subsequent iterations (t=1 to max_iterations-1)\n",
    "        for t in range(1, self.max_iterations):\n",
    "            if verbose and t % 5 == 0:\n",
    "                print(f\"Iteration {t+1}/{self.max_iterations}\")\n",
    "            \n",
    "            # Resample from previous iteration's particles and weights\n",
    "            # This implements the \"Resample the mu_t^(i)'s using the weights\" part at the end of previous iteration.\n",
    "            # So, current_particles are mu_t from previous step, resampled according to their weights.\n",
    "            # This makes them \"parents\" for the new generation.\n",
    "            parent_particles, parent_indices_resampled = self.resample(current_particles, initial_weights)\n",
    "            \n",
    "            # To update zeta_k later, we need to know for each parent particle which scale it originally came from.\n",
    "            # This information isn't directly available in a simple resampling step.\n",
    "            # The algorithm implies that `r_k` is the count of *resampled* parents that were *originally generated*\n",
    "            # using scale nu_k. We need to preserve this info through resampling.\n",
    "            # Let's augment `parent_indices_resampled` to get the original scale choice.\n",
    "            parent_original_scale_choices = [self.scale_choices_history[-1][idx] for idx in parent_indices_resampled]\n",
    "            \n",
    "            # Step 1: Update\n",
    "            new_particles = [] # mu_{t+1}^{(i)}\n",
    "            new_parent_references = [] # Store mu_t^{(i')} for each new particle\n",
    "            scales_used_for_new_particles = [] # Store index of nu_k used for each new particle\n",
    "\n",
    "            # For zeta_k update later: count how many particles were generated from each nu_k\n",
    "            # and survived resampling. We already have `parent_original_scale_choices`.\n",
    "            \n",
    "            # Sample new particles (mu_{t+1}^{(i)}) based on current parents (mu_t^{(i')}) and chosen scales\n",
    "            for i in range(self.n_particles):\n",
    "                parent_mu_i_prime = parent_particles[i] # This is mu_t^{(i')}\n",
    "\n",
    "                # a. with probability zeta_k, take sigma_{t+1}^{(i)} = nu_k\n",
    "                # Choose scale_idx based on current zeta_k probabilities\n",
    "                scale_idx_chosen = custom_random_choice(list(range(len(self.K_scales))), size=1, p=self.zeta_k)[0]\n",
    "                selected_nu_k = self.K_scales[scale_idx_chosen]\n",
    "                \n",
    "                # b. generate mu_{t+1}^{(i)} ~ N_2(mu_t^{(i')}, sigma_{t+1}^{(i)} I_2)\n",
    "                sampled_mu = multivariate_normal_sampler_2D_spherical(parent_mu_i_prime, selected_nu_k)\n",
    "                \n",
    "                new_particles.append(sampled_mu)\n",
    "                new_parent_references.append(parent_mu_i_prime)\n",
    "                scales_used_for_new_particles.append(scale_idx_chosen) # Store index of nu_k used\n",
    "\n",
    "            # c. Compute weights\n",
    "            # This requires new_particles, their parent_mu_i_prime, and the proposal denominator.\n",
    "            current_weights, current_log_weights, current_raw_log_weights = \\\n",
    "                self.compute_importance_weights(new_particles, new_parent_references, scales_used_for_new_particles)\n",
    "            \n",
    "            # Store results for this iteration\n",
    "            self.particles_history.append(new_particles)\n",
    "            self.weights_history.append(current_weights)\n",
    "            self.log_weights_history.append(current_log_weights)\n",
    "            self.raw_log_weights_history.append(current_raw_log_weights)\n",
    "            self.scale_choices_history.append(scales_used_for_new_particles) # Store for next iter's zeta_k update\n",
    "\n",
    "            # Compute diagnostics\n",
    "            sum_sq_weights = custom_sum([w**2 for w in current_weights])\n",
    "            ess = 1.0 / sum_sq_weights if sum_sq_weights != 0 else 0.0\n",
    "            self.ess_history.append(ess)\n",
    "            \n",
    "            # Z estimate: Cumulative mean of raw importance ratios\n",
    "            all_raw_log_weights = []\n",
    "            for item in self.raw_log_weights_history:\n",
    "                all_raw_log_weights.extend(item)\n",
    "            \n",
    "            cumulative_raw_weights = [math.exp(lw) for lw in all_raw_log_weights]\n",
    "            self.normalizing_constant_estimates.append(custom_mean(cumulative_raw_weights))\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"  ESS: {self.ess_history[-1]:.1f}, Z_hat: {self.normalizing_constant_estimates[-1]:.4f}\")\n",
    "\n",
    "            # Update the zeta_k's for the next iteration (after resampling has happened for current iteration's weights)\n",
    "            # This is the \"resample ... Update the zeta_k's\" step.\n",
    "            # For this, we need the *resampled* particles from the current iteration, and which scale they came from.\n",
    "            \n",
    "            # First, resample particles based on `current_weights`\n",
    "            resampled_particles_current_iter, resampled_indices_current_iter = self.resample(new_particles, current_weights)\n",
    "            \n",
    "            # Determine which scales contributed to the resampled particles\n",
    "            # This is `r_k`: count of resampled particles that were generated using `nu_k`\n",
    "            # For this, we use `scales_used_for_new_particles` which stores the scale_idx for `new_particles`.\n",
    "            # We then get the scales used for the `resampled_particles_current_iter`.\n",
    "            \n",
    "            r_k_counts = [0] * len(self.K_scales)\n",
    "            for resampled_idx in resampled_indices_current_iter:\n",
    "                original_scale_idx = scales_used_for_new_particles[resampled_idx]\n",
    "                r_k_counts[original_scale_idx] += 1\n",
    "            \n",
    "            # Update zeta_k: zeta_k prop to r_k + epsilon\n",
    "            new_zeta_k_raw = [r_k + self.epsilon for r_k in r_k_counts]\n",
    "            sum_new_zeta_k_raw = custom_sum(new_zeta_k_raw)\n",
    "            self.zeta_k = [val / sum_new_zeta_k_raw for val in new_zeta_k_raw]\n",
    "            \n",
    "            # Prepare for next iteration: current_particles become the new_particles\n",
    "            current_particles = new_particles # The new generation of particles (before resampling for next loop)\n",
    "            initial_weights = current_weights # Their weights (will be used for next iteration's resampling)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"PMC completed!\")\n",
    "        \n",
    "        return self.particles_history, self.weights_history\n",
    "        \n",
    "    def get_final_sample(self):\n",
    "        \"\"\"\n",
    "        Get final weighted sample\n",
    "        \"\"\"\n",
    "        if not self.particles_history:\n",
    "            raise ValueError(\"No samples generated. Run PMC first.\")\n",
    "            \n",
    "        return self.particles_history[-1], self.weights_history[-1]\n",
    "        \n",
    "    def estimate_expectation(self, func):\n",
    "        \"\"\"\n",
    "        Estimate E[h(X)] using final sample.\n",
    "        func: A function that takes a 2D particle [mu1, mu2] and returns a scalar.\n",
    "        \"\"\"\n",
    "        particles, weights = self.get_final_sample()\n",
    "        return self.estimate_integral(func, particles, weights)\n",
    "\n",
    "\n",
    "# --- Demo Function ---\n",
    "def demo_mixture_pmc():\n",
    "    \"\"\"Demonstrate Mixture PMC Algorithm A.62\"\"\"\n",
    "    print(\"=== Mixture PMC Algorithm A.62 Demo (Core Python) ===\")\n",
    "    random.seed(42) # Set seed for reproducibility\n",
    "\n",
    "    # Define synthetic data (Example 5.19 normal mixture: 0.3*N(0,1) + 0.7*N(5,1))\n",
    "    # We need to simulate observations 'x' from this mixture.\n",
    "    true_mu1 = 0.0\n",
    "    true_mu2 = 5.0\n",
    "    true_p = 0.3 # Known p\n",
    "    noise_std = 1.0 # Standard deviation for components N(mu, 1)\n",
    "\n",
    "    n_data_points = 200\n",
    "    data_x = []\n",
    "    for _ in range(n_data_points):\n",
    "        if random.random() < true_p:\n",
    "            data_x.append(custom_normal_sampler(true_mu1, noise_std))\n",
    "        else:\n",
    "            data_x.append(custom_normal_sampler(true_mu2, noise_std))\n",
    "    \n",
    "    print(f\"Generated {n_data_points} data points from a mixture with true (mu1, mu2) = ({true_mu1}, {true_mu2})\")\n",
    "\n",
    "    # Define K scales (nu_k)\n",
    "    K_scales = [0.1, 0.5, 1.0, 5.0, 10.0] # Variances for proposals\n",
    "\n",
    "    # Run PMC\n",
    "    pmc = MixturePMC(\n",
    "        data_x=data_x,\n",
    "        p_mixture=true_p,\n",
    "        K_scales=K_scales,\n",
    "        n_particles=1000,\n",
    "        max_iterations=50\n",
    "    )\n",
    "    \n",
    "    pmc.run_pmc(verbose=True)\n",
    "    \n",
    "    # Estimate posterior means of mu1 and mu2\n",
    "    estimated_mu1 = pmc.estimate_expectation(lambda mu_vec: mu_vec[0])\n",
    "    estimated_mu2 = pmc.estimate_expectation(lambda mu_vec: mu_vec[1])\n",
    "\n",
    "    print(f\"\\nTrue (mu1, mu2): ({true_mu1}, {true_mu2})\")\n",
    "    print(f\"Estimated (mu1, mu2): ({estimated_mu1:.3f}, {estimated_mu2:.3f})\")\n",
    "    \n",
    "    # Print final ESS and Z_hat\n",
    "    print(f\"Final ESS: {pmc.ess_history[-1]:.1f}\")\n",
    "    print(f\"Final Normalizing Constant Estimate: {pmc.normalizing_constant_estimates[-1]:.4f}\")\n",
    "\n",
    "    # Print final zeta_k distribution\n",
    "    print(f\"Final zeta_k distribution for scales {K_scales}:\")\n",
    "    for k_idx, zeta_val in enumerate(pmc.zeta_k):\n",
    "        print(f\"  nu_{k_idx+1}={K_scales[k_idx]:.1f}: {zeta_val:.4f}\")\n",
    "\n",
    "    return pmc\n",
    "\n",
    "# --- Main execution block ---\n",
    "if __name__ == \"__main__\":\n",
    "    pmc_instance = demo_mixture_pmc()\n",
    "\n",
    "    # You could add more analysis here, e.g.,\n",
    "    # Plotting is not possible without matplotlib.\n",
    "    # print(\"\\nNormalizing constant evolution:\")\n",
    "    # for i, z_est in enumerate(pmc_instance.normalizing_constant_estimates):\n",
    "    #     print(f\"Iter {i+1}: {z_est:.4f}\")"
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "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"
    },
    "image-3.png": {
     "image/png": "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"
    },
    "image-4.png": {
     "image/png": "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"
    },
    "image-5.png": {
     "image/png": "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"
    },
    "image-6.png": {
     "image/png": "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"
    },
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAD8CAIAAADv+9RVAAAgAElEQVR4Aey9z0tkTbfvef8TBaeKKMjzoDhSsOoWDUKB4lyx0nLQrQ4T0aTG6rhKhXTQP9SZKZijcyfH5DYlfbltNmwOHDgm9uF0OjAP50fffiF3w/lcvme9EXuHO3dmWvq8WRQSGTt+rFixYsVaK1as+A/x4N8AAwMMDDDw5jHwH948hAMABxgYYGCAgfi/s6p2u22RYX92mo7juNMqtvyguibCoiVL+vVR9/o9WjwMen9HpNL9xA2kKk33IDHAwAADbxcDA1b1dudmANkAAwMMCAMDBfDP1NWBTiHKsBJ7WnqAro7QZdE4QF2nqBtIVcLYIDHAwAADbxcDA6lqIFX9O3XabT9LeiAaCHdZ0GXLDFDXKeoGUpUwNkgMMDDAwNvFwIBVvd25GUA2wMAAA8LAQAEcKIAihj9DhdVW0tIDLUa4S0NRWv4AdZ2ibiBVCWODxAADAwy8XQwMWNXbnZsBZAMMDDAgDAwUwD/TegZiuSgjTXOx+QN0dYSuAepyo6vdbr8Dqarx0NAIO0q0nlsdlX9HhXPj5B2NMTuof+CJzo6EP3zJvrCq3WKxdlsDdyRazy27umq3tamJyU8fPlZvqo2HRhRFcRzX7+ut51Zpb/+p2Ww8NPgfRdHRwWHjoVG/rz81m63nVv2+HsfxdaVS2tv/9OFjHMe12xrtUyyKoupN9ejgcGdrW802HhoUo/zUxKQgfHdzPDUxOTs9Ax7eHfA9B3h9de3Th4+WunrexTtq8PL8YmRo+B0BnB3UviiAX78UYASbhY3Pi4ubhY2FufmFufmvXwpAVrutfV5cPDo43C0WV5aWv34pHB0cTk1MriwtL8zNfyuVKH90cDgyNLxZ2Dgrlxfm5kkzE5WrK3J2i0W6oO7UxCTFNgsbK0vLx99/0MXK0jLF4jiOoujz4qJY1bsTy+9+3mkz+LXAvwUF8KnZnJqYfGo2LSqypN8C8FqoWQC2ZdKA3yxsWFZlq9h0WvWM+RmL2R5tOl/1vkhVm4UNGMH46Fgcx+OjY7PTM0cHh7CPlaXl0t7+wtz80cFh9aZavaleVyrrq2vjo2MrS8srS8u7xSLpna3t60rl6OBwZWmZ6uOjY9WbKlLV0cHh7PQMHGp9dW1labnx0Pj04ePUxOTRwSG1NgsbrecWzcZxvLK0DHEIQtHKO0pIYHxHMPcP1OpNdWdrWxtP/zp6+y03Hhqz0zMjQ8N/SIm7L6xqt1gcGRr+9OHj0cEhLKm0tz87PbNZ2GC+6/f1o4PDOI7R+HaLxfp9HYZydHB4Vi6vr66tr65dnl/UbmuX5xfVm6q+Mg3kl/b2T49PYGSlvf3GQ4NiKIClvf3aba20t395flHa24/jmL9xHB8dHL7f6WSM7xf+3q75o4PD9dW1gblKWNV+rJw/RqIvCqAV9kijA1auroQ1v8yLn9Kq2Px8sqW6HlQXKixW09IDdHWELovGAeo6RV1fpCoBoYRjVlf+IDHAwAADAwxkwcArsaosoAzKDDAwwMAAA2kYeCUFkO6tAJyWHgjGmqo0FKXlvz7qXr9HO/ZB7++IVLqfuIFUpekeJAYYGGDg7WJgwKre7twMIBtgYIABYWDAqoSKQWKAgQEG3i4Gesaq8GDC95K/OD3JGxMv0NLePo4wcobCh3NkaBhP0Z2tbfyGVpaW5RRKDu7sK0vL+Ll9+vBxdnqGMuura6W9/fHRsfHRMdrf2drGG/7o4LC0t0+zOE+Oj47hjDoyNEwxruD0cJZqtzVatgh5L2l5n/UQIeura+9l+A6cPXdTqt/X3yk21lfXfqE3339nVd0bvXDphLhta6Sfms3dYlH5Z+Wyvdry9UthZGiY/1EUPT4+PjWbZ+XyyNCwqlxXKiNDw9wWxMVUVXRfhyp3P++0xtrtdu22xpVDmoqiaGRo+Fup9NRsjgwNHx0c3v28k29qryy1tdva+73qwVQK8wGcBD451eVNbvOzV7cTqvTrVBd1Od05P+24wmkIMnd1DT/cC8XSyuTrXZDnqy7I81XPI1XVbmvVm+pTs2n77tT/G6mKFri4hDTEfctPHz5++vARYae0t1+9qX768HG3WORWKs7uK0vLp8cnCGuC5PL8gruBp8cncRzD1Li1Q5nWc2t9da12W6MRBLT11TW10GkCbDjXZWm/06byld/Z2maw+ar7teyu438N55wen3BJwBaLokisyua/i7TdxjoFuH5ft8ub6n5Op83+qvK/FvKOWRVX6tZX18Sqarc1Ltw5yzWO49PjE4pxRQYUnx6fcA/504eP8Iijg8PL8wtiHnCbjwbJGRkaRrlDJYR/nZXL3KVYWVq+rlS0Vkt7+zDBxkPj8vxis7CBHrq+ujY1MUmx0t4+t5q5c3NdqeRWAMGGvdlPKAi4oSWpp2bT5+at5xZxI2xJpdGp9TMxcVYu+6yBa5KUB7FxHBN2ApTCOI4ODpkdbimp/W5Y1eX5BeEuaK3x0EANFxjkM3Bfmzg9PvGpiCqQmYBMTFRvqv4Nm9ptTW1qCxE24CbcKqUYl1LVfjesCrODxg4NJN5YPCuXHWyAIoHhJGq3tTBgreeWJQNVt5kC7KxcpoDWkT7ZGXlnrIqLe3bADNLJqd/Xd7a2ubvH1Tyiu5T29gn2giQ1PjpWu62hiME4JOzQ7FOzWdrbbz23dra20fhgRiNDwyI7eCJ2KMrwqbS3zxxwwRChjGJcaV5ZWoayu1mccRxrXkUQzqSeHp9IJFSZ+n0dnCgHPgJb4aq2/ZSYBj/Op+pNVXRvIdEwSbSeWyJ3rknCuVTMaTbjT/EFW962iSHPKVa/r3MV1NYiHUWRz479YrpS6nx6aja1Arn+SQGBRMJi0kIoFDnNZvx5Xak4I7UzQpAin3lBGz7bhTYyYuPy/OK6UnHg1KgtKtAMoGRsLKfHJyKho4NDEOhA7rTc7589s1VZCf/4+4/NwsZ1pYLxCC3srFz++qUgWexbqQS7wXi0MDfPp5WlZdmkrE771Gx+K5WmJibR7ypXV1Q8K5dpamRoeGFunsAvCGUjQ8OEmuEG4sxvv7OtIVJJvmi323b+0tT7LPkCmEmlym6xeF2pONVrt7XdYlHlmWa49m6xyPJot9tCl1NdZIExThRJMYapKkcHh6QZZrvd3i0Wafnx8dEfu4rZXhLTDvzq0c8XhN9KJb9HsJFYHbLJ3nvttuZjG1QDlXoXWsCGzJoO8H21VV1XKpprjbFydWUBVj4QinUmossH3iGh60qFpeqMF7Q8NZufFxfpUfjhpy3v9JIFElsmX/WOFUAhzkkocN3RwSG4IOaZjN+IHmLVcLFPHz6Oj44tzM1rA6nf1yFrhUOwHdXv69Wb6unxCdFdOJLYLGzQzqcPH1eWlqcmJne2tuv3ddmh1lfXSLO/lfb2NwsbyHrSQG0v3ae1/1yeXzibauu5tVssasHYvhoPDWmpqCQjQ8O+yIYUKYzZiBFqzbavEz0B03hoSNAgiIrmxW62aq37BPBcnl+wadsGOXGzOaQRpR1p3S/m52i8+pSGDYCx2JAEobriGsrpMiHaIAiSbY0hSx1zPqWRjS3mpNm0nExhw+qYyjwrl1m/9fu6EytJkDsNvs7PXrIqZ00SlwoRhsBVyEGnxycKRIWrQRRFreeWFk8cxztb21iyaMTiAhs5ctP66trp8cnI0HD1popieHl+gfmGeKHXlQoxrdZX11j2RweHredWFEV0waxonmxH3aTTJhU4tdHFcfzUbOLWgP5iO0UlGRkatlxJ9juLLkxCtq6shNZiSMgdil2eX4gJtp5bPVQALRhKJ2K4elN1lD4gVGHO9S261GAg0XhoSPSgGDuck8bOSObl+YU6RcTDUhHHsdNUoN+Mn8K0Yefa2dU6xYOGBpELPI3UbkvWXqmxoxLiYCQtRO28cqKXrMoBHVUOozhc7KnZ5FyPOHn1+zpRiVlONiSYJgwvKpEsRqjqTRWhDO7DFNbv61p72NRB7vrq2s7WdmlvnxBa/D0rlwmnBcx28pxR5PvpkyMGFysjwF+uKxW4xuX5xfjomMhR5CVU2J3ACkFAiEVP0Frm1XhoSDQ4PT5Ry6xP2yzVe44NuyToovHQ4GBXAGOjJDbZztY2ACP5qoyT4HjEh5/uNExq2UFJ7Krd1sTxOcTwW3sFVgVztLTBisDAX72pOmNx8PDiT+fUSMI1nEi0ZElIJ122cZ+q7dd+p3tpq5Js3263rysVbDTWPoX/FHJW5epqZGgYikSPZT6iKJr57XfO0VaWljGmwJg+Ly5i3kLX5Rixdlu7+3l3Xak8NZubhY2nZvP4+w/OR8TORoaGryuVu593URSdlctTE5Mzv/0u4fbu551187NKdadpKeFMqqofHRxaPJDPARxhlLGwbBY2+ITPlw3vdffzTiY8NavuiMLs2GgUNjqOY9v758VFMUTQu7K0DPIFmG05kA58coAUp4A2mClbHcvIytLyZmGDINQifdtU5epK+tHRweHMb7+DOtsUadujmJcGCAas2Q7LINK6xXxfbVUAZl0OAf6sXL6uVIjlnThAf7yJ6GK8Z+Wy9fJjpQir6p1Fp3yiiu8Wi6zrP5StCvbMFqHNCgzubG1zcDs7PYOMs1ssIlhaUYIDkamJSSxNGJhg8Ni8oL/GQ+Op2aRM/b6uT58+fMQtiyqYtCA+bSycM0ZRdHl+wRkl+qZmuicJ7T/s1c6uuFnYAAmnxycLc/MoX63nFrYDziVthGxAwlfD3/YFsMaoHG2YUCH5qJwS1nSkK98FLXK1032CNqENCb80iz+dDohxl7M92oP8qYlJjAk6RD86OCTHVoEFOLgSNqzIiXnIwQaOEZTvn1TFUyYObaBw4OyC2Xdna9sZiDPSF39axZ/CrCDS9hjaKsIqeXl+wXIWVb/YYz8K9EwBxKUFqwfUz0xjI8d2OzI0DKvC40mLk4F9+vARJVl7PkoBOuP66ppOkWanZ7Cd48WzMDfP8fz46BhW+cvzC0gQHRDdivcgRoaGxUb1vEfPF6cmVcuDMUKXKH31+zqR4LVOxkfHEDkRGJEK8e3gtR4rovvU4DgEqUDttgarEjAyCUkQVmEWuf3ZkzQ4FwC0CTbgCxiYZqdnpJ1Rhq1IPrq8ZkTA/pWlZZGKD6S1GduvuFlZHzew4VjNVKV/rMphUhxMIUOxXjRqAZM7oX3IaYGFwyEVn3DUYAU5hUXVTv7r/OwZq3KGIS6wWdhACedsjnccsDJQRQsVeYcDQU6FODBSAWGEzRlvlJGhYWkEcRxXb6ojQ8MrS8uS48ZHx3a2tmkEGzymEM5f2OH7x6oEMwkd+iBVkakjhdPjE84BgPap2eRUAdaMqChsJL6vJU8xp9+zchmHMuub2nhocASBeCthp+fYSGN/xNFHqg10yqkLuw6EwR063PE0uc6QORgVuuzX0+MTZOrNwoZG/dRsIt6CjdPjE+rKzGdb6CbtrBQ1xdE2uMoiSWFo041Fx9SlZkn4Rw3kw6bPymWUHtXCsYv7szrTT4Nctfqa6KWtSrsE9oiVpeUoitrtNvsSD21NTUwiHLXbbezuu8UiVhXejECswHiEtrwwNx9F0crS8rdSSbhAo8aP9PHxUfkrS8uYunhzSa4S6Pb4ZHHN8OjgEAtXn/yqzsplqf3WsoBBClcv8nGnemo2OSGdmpiMogh7DUDyMhgPjq0sLWNJAS22iziOMduBDfuJNDix6LJlarc1fsI17Ke0tB1XOC1OZJuK4xjDmWNM8ZtCiz8rlwH+rFxeWVrmJmnAhBdFkWO/s70/NZszv/0uUd1+arfbURQhsvXbVmUnC7Z4/P2HpF0HKo6MWSnYZKn++Ph4Vi5vFjZYcVoOtjr3XhM/YYdamJv3MU95aMOyKttyp+m0XsL5OaUqX3m2w4jjGOcAOE4av+d1rNPjE7S5na1t1MOzcllVIErO7/z9DYcGWCEgWcDq9/WpiUleNl1fXcNBFBvQbrE4Oz0j/wAtJE1kRwnbqabWaZNNG7lP0h8HCzrikd2NY0rGpYNUWWewcQA8vhcWWqdf+wkbDVEl7PUXWyZNAnLKpP1sPDSsr7yKOVDp6C2KIkcrVBV5ZussRZ/Qj/iJ/4c+OQmnX/uVg1F8XALY6FIBRHO3/TorhWHqWoVPS6qLkxRGEi0QfYUeuLVmM5V2vPaVT4JjaMKcODq4SvqQ69MrJDpmVfgNyNVCYrlzOaB6U9WZKITVem5NTUzitIlojWemtGh8F6zEztJFRMdhShjBNgwR47ZnfR1UDORKtsJOz4UbtACCxgQIWk0lJnCTk2MUmx7ULxkTFOnSotrBYRWuxHuIaKasPd2KwNJpW6NBNFx8ytQmn5zC+opxsHZbw/w3Oz2zMDfPHUl7Syk3NtC5QCydol/Yq+mszDQIBep1pQJ+0OjDIKGtqK5N6PjMZpJuPbc4nAEbPPctbAjCblgVF1q18iFanbcChnVo8oEUqKW9fd3N4r3LtMKBy5LSav26sEgsM7gcMmvc3uXrO2NVGM7lU64xSzRQjhIYiWETl+cXBJ/iBFA7KkrQ+OiYbAfQNFymelPFPKGviEXaDFm3tdsapi7LtlrPLbqGrylNy+OjYzw7KGg7SmC71WGC6r44qRw+MmpxUuzEWA1YqOOjY3jMSiNAFtAVbniT0AgA4YWNNw0kiA3r04ePlr+8WF3D9BOscH/Pz94mKLXzG0UR4rZzWGx75wqhzVF6t1i0+5/ylUCguK5UeD4Sh7vqTZX12Q2r4jBBxzj0+CJtCDASWKPCQ3CqiP2JbCggq6hTXj9lvpQB8dOHj+yj4V1QLfQv0S9bFRBzgat2W+PhUpgF954ci8lTs7kwN88tYqv68kY8zlDygiF2lQ6Ajr//GBkaJvAe1ivegkf1FTuY+e132hkZGq5cXcmvStY0YLa9d5qWsg05BqpLqdEFRhS9x8dHDGriXyS+lUpYT+D7AH90cPj4+GhlFnpElAj0DtkdHRx+XlxESYeVUMWmwzjReMPFrDXQQuVXxyEuiqK7n3cLc/P4WD0+PkZRtFnYmJqYTKweRdHUxOS3UinR8GTvOSZWBxvfSiVUY9zQGJGTTqvuD0TVbRXSYlX+JweNtdva1y8F2I3iuLFSsPAGesHKKTIThFJiAr1z3LEwN485jO3nD+VXJZlZGBwfHRsZGubMVadvkoxUTAmCeeon+hRSKweIWFtQCnB9YDslHCjaJfnSjCTN4QGMGw5bqDrKvuerSjghckwsxnm5LnzBTIm9xYm1w6dmp2euKxVinGIEBLEYm7X/276ss4zNt2ni/3G+Y+eu59jIYv9CmKJr2DEj5ZiPA2Ud3jsWGTm1+55ljNfGCbAYsGk5MTg6YzdSlW1f6TBtUAxsSByDNribwTqCQtZX13wBVi3orqu6xp4lhdTm23TruSUt0uqMCphjC79aumNbVRpkiRPA/VsICB8iX1XxFwbmQ9m/mSGiDEP0kDJOCQjGNgfinp2egSc2HhrkAHnjoTE+OuZY6H0Y0oaZMd9iw2ElrLrS3j72vpWlZQqg4UoqdLiV/Smx6+jgMIoiEbSFjQAvWbQGZ9lnYSu2o4zpMIaxx+GfTQAvxPDGQ0MMCwxwTnJ6fIKtAOwBA3HHbEc2wG7YJU2j8LHx+qyKYxNrXyceJE4bxOkGG+xeadzKXqLSAPGyTqQZW4ZizvWaPzKrYvCNhwZG9yiK7ATEcfzpw0fLR/CLXZibV2xP1Lo4jmWMxIiD/QLxCrkdL+dPHz7iEQojg87wogT7tdsa0fjsxFj6tvm505ZVYW/SzU9YNnu4DGcE9uInEhNGNzzULZ/i6gmyKveuV5aWHawCNredrbiUcTg9x0aA/XFvHKM+g2KDCbNs7L6gRWPfLRYxuolBW8xg4JeGmBEVr3ldGeOsPZ7CGYrhcHUZa6yoguXDObLwYIe2WdhI5Eoo2olVbHUn3Xho5CAnp5HcP/trq4rjuHJ1haNQHMeElCKUFaqyFiE0BNOZ+e13+Jcu8WFjOv7+I47jqYnJzcLGzG+/T01MEinl8fERh2xFKGY9y2+Lku12+6xcJsaF1eErV1d9vQOIfvf4+KjBYhbRTyQIRX1RvmO3kjCFYW6zsMF6JoYXp914tEFPYPisXN4tFh3LoMjFGiysOUNpStpiNp2xWJqtyoYwI6iZvM+FhMQEHkAgxDG+OFH8HQixUcrYbMeSln41vyoF9hQk2GSZTSJJRVFkyUDIwQ7rTxY3bRmvmlUxRZWxn8JpsapwMXVBwpkF52fGpvqoAOq+AudxHPwRzFMnd1yR47kajtLRk3lLBlcAziA0ZhI4STmZSC6bhQ2UKf5yxcxe+0IW4yYQMo5lVX6bOXKsVEUUAQXAwUcMf3qRmqI+gAqbr7TioJLDPSTs6xyAAqe1spPD2NE3RWqBQb2CVIWdzgLD2RNQ1e/rWpDImEKCk9gtFiW0akRiXsqxCU7BhA2JYLaMTb+CAsipbqL4A51gY6rd1hx1GGxwviRndws8Ho6BMWKT2i0Ws5jzWF9O+6/2s1+sCucgcAQWEJSsOMMgcc7c2dpG8sf9ykZoiePYv0SCPYtz3IW5eX+aYXm4Gpb29pljpOvS3r72Vd6zeNHQ2Ol8iFWxJmFPXAE5OjhU/DwpgM4KfPEnkhp0hhVG/CUg1RNvm9sSrFVkTKeKmup01IHytk352fnlgcoqwgFUOHZPWsNpJu2Cke1RxmPZDTHuONjoN6vCTidx0kKIlgDxB1g2pw28TedUl1+on+/kEDcJ/PMXTDpsLs0u5rTWj5+9Z1UcyWnDRLDHvRObhTN4zAHwGqxa15WKU8ZeicLKw3Ee9/vkdgCCWMao8cQXxc8bqyTMC9F3ZWmZabYLqSdYFquq39cxAOOHoV2RlyMwqMniEFiWzidsqzipIaLKlaYj+HlLhtUiYaTn2JCtCuNLIrlzmsm4MiLk04ePPqkgShMdrCNUyDdV2IAV9o9V4RGqleJDy57KPucQgPMT4SsRsayUQC9+v+RAw5wzSBRQIq1W//J7b6tSSGZZmjhuOyuXbRggKai12xrRoxjk1MSkojs7Ou23Ugk2xON9WL50c43q15XK4+Mj5rDdYrFydUUVueRwDw5IuFpoLSlOjwIyY76KMc1Yx9gwsVVJr1mYmwcwDHMO5YV/zvz2u8w0FsKMNilbxaYFPKzKfkpLqwrITysmDDv3Im11tjQ8pEaGhrOjhYuc15XKzG+/491Cswq8mwaV7T2Q7p+t6vj7DwlTPpAsn+PvP0QzaVTBtVmM6zYulR2UQqGJlfg9vjiJOKBlKRYuYwHLnu69VCVcVG+qSK0I/LhlOioxngQ2IJF8aogEwFyiuXBChOcREQiQwmQdZPHTmhxDuHUhlxycFWwwBu35grz7hKQqNYXGytEVr4EBSfioK5E6FW0ZfyIZ/ojAG3BbEzDhRP+kKr9fBXVhFggCMzs9A+cKaD3CDAIFkb+c9p1Ao87XjD/7J1WFAVC0ImZZ4w0n0uaOA8RElTkMhvO1e+pyGsz+s2NWhbFcjEBic6ITR/2+flYusyZLe/vsD+OjYzCOxkMD0gT7AI2OQM746BhGJYIOKwT7zta2eA0OROJEHKPg2TA7PQMjcOKE4F+Hcs7kpU3wi3ikd+t+8tRsomP6Ijd82Vrr0AfxXw2ToP3KMp6dnmEg1tAGo/fp6anZTNMO/DHmxgbsRjFDMJQQRSutTYXKAwwilOn9NDvqtDQXRdNGlxjDK+2NPB8VXTorcHFPSlOANvyuMZkRCCht7MrH3UxBpnQVxmn28vzC51bchXRKpv1Mw3Na+R7md8yqeN6DWIXAAT/iEEosw4LIdeLqTRWPJ4UKKO3tYzK8rlRgRnyS24joG2aHQ4Oq4yfFQxLMK+/9cZqmgEQYPuyzeuura7xYg/nWRsi0YGdJs1nZi/5hcgR4vdAj5iWa6yjhkJ3PFLhHTcjH9dU1PCoJxuDUtYMV2m1mxvTp8YnFhg43bJv2kEQv0NE+E51FmBKiMC05xs1EaMEGUjnY4EVbXgxJrNIlq8JHV2IvClTipp7WO/4KPDauIScmPn34qDmt39fxJdTxkdO+QvVy7MPljTTnR1vX34Dt176m89uqHFcdxBnMUo4ajLeUjRxEqCAwjhVJ+vbC3Dy3jXaLRWvaWFlavvt5x5mI0ngAyNvTavWoYMQU19QCJF2AVqCyC8kBXtjPki/FG0dT3zYnr3rOQ4mhLjwIzuwJzQKoSDOsYC3CcP71S2G3WCRm9tcvBcmnAh5sdDResBSoIgy3220ibSVW0YRmx0AgXlViF2Rydsz1QLBx9/NOof7sQNJQKnQFekksI+OA7SUt7fjWhdHiTBwqhbiV7QLAdKuU27Xw5a9fCsS92ixsiLo0EPnQ2tY6Tau1jlDXsVRF6/5fTYD/CecOu7dQBo8YrOOoRQgdIJczda7y+W8CcqFEmgIFiHiFaxJKH+dudoKRvJzNQQspEfgcmVjNnOs7MscQhsVChWyYRZqQVkt1bpYo7YxLkEdRRNgAyJH9c2drO/GkrOfY6MgayMUji5y0NHI6AfUlUGjIgQRBtRgmJlEMGj6ZdSlVJcIQXimJVTISBgKjWlBYcOUkJoQHDDIoGYjevp2uH7SRCJWf+XqsihniNhMuGxgO11fXuD1DBHSehucmzfrqGmGeCI8H9NWbqnQ6dHIQigfp6fEJ+iO0i9ecdZ7E2E8waZkDrLnHx1GOnDRyhLcS12l2eoaB8N5q2oJ08uEvSG18go7lTBtYtJwwRFHEtXDuZkJ8aGqMtB/kmL1NBE/8eJ2x2/FqJ+M+YKLlITxx8qoBG5jYBKeWvb9cw82++DWNNgIV2fkSsaFMvUsWaCfxE7qzoqTBu7mJCTYaDw3p18JPYlN9zXwNVoWsxI1wOT3qUQZ5ireeW9b7bmdrO5H+bKhMAuOhAGKt5/AIlGF1rv+bZxNX6iBr9MdlkREAACAASURBVCCCTLWeW1TvLZbTyBF+yisGckwVTkR2LyYuzy8ITMhdSH7ieb++uibCShtU46GBOWO3WJShFG/YjiSgtPb9/BdJXNZGxp7lYBTnYQ52nCETV9YHIzEHbHBlUtgAP29EqiJ6VIAq2OwlOCcOM2MmfovWMVWvavaJNjIClt9W5SiodnE6n6YmJnnXjHcAcdf+vLiI1O1Eg5Yee12pWFcsHKYYleh4YW4e9xOmSp5KRHDnE64MURRVrq4whawsLVsIv5VKYpfqnY5ssSxpVQcbgSoovHI9I1ZXgBadTwRfZyB4ivHqIuGrEAQCvYs4bBkBD1uxn9LSqvIiusSqbFOqzsThhoZBIOBXJbPmbrHItVC/98+Li7LB2R5tWr371W2xX2urEiQOAdifetcS3U1VAgMMfApXT5zHcBUfvfl6769UxeWm8dExNDh8ixCv5AzFSPCBsHsj2xqXAdFxJIpXb6o8hMP5kb1AT3BLQlbprFD6Hbf/rIpESINE8Q3A8v21jNu2QAgBViZgACQ35i39paURwQgiCt20nltEFKAj60diu86eFjlmr/JiyXCb+MdJdmBSHAxI9iTyib765jnkbj//RSATC4jqEr/myEyjjXBTioKtkxmFq8TRXy4R4Xa6/NorrOYAo4+sigjQ8Bo9+I6bP+6gXF5bX13jesfI0LBVAGXKwQumfl/HHVT3DHDb4eUSOZIQi6p6U52dnuGQfnZ6RkITZizrdsSqSAvJlgOhVEkjR/8uMaxKg9IKDCcst8Xy1UNuG2Yr+XASaJOnZ2mWu8SQAfsWr4Sw2zGVvJ8o/GBVcaDyI9k7BbL/fAusivMituTZ6Rm5O+Dswrl2AMPZB/tiyT8Uq+LxPj3KAhtShFzn/iQSFrKGzATgS8d5DvqINa5D052tbWkEsEWithN44KxcRuumI4zuOt5Wyz2fZrEqjJ2SFlmEvL5HyEDOK7nNp+UnwcEeCOhr2uIhgkL3xNRzbMjGUb2p8uSc3ZMkUmk6nAT+q5j5sCidHp/wWBGr13rVOnW7/5mG7dwtizZ4mUm04TQoYxnGOH3lbO7y/AI691/hVsl+JF5HdkuEPCRVYfnXNaXE+srUBJAjcR2jNecp9hbFytLy7PQMis9mYQMZijN79UjUQbxDYXaaV1yoZqdn6EhgcKzDYkPP2tnaTsQvh+KolllEEi0Y9RVIONigpM7IZWvD7Z5HLpwDaSJ72JN7CjAWNFneBwu/LhUAMu1TFlaFJ7DlOGmtkW/bZBIV5kFCrl7NQcZEhiJWIj4Z9fs6jixcpqnd1mB86hpVSD97ksjCqvCCFnGG+02kDXmTsGEjXSI7415D9GECkODlwxvd2acgDFXGr4lLKWPdLouFzOpEZfP9GOnSsaXZCeDFx7NyeWFu3r4ziscdDmY8f6BFy/XdqYlJnurUqPAYxDfPbp4ywY4MDVvbKnH7R4aGiX4r6yyWPGLjk+au8nWlgkuk7TExXbm64nAgYBTUJ7DhoMg2iyS4Wdj4+qVwXanAVUeGhj8vLsqR9fj7DwmMPK6JeQL0sgeABy2nQI+298S0gIethJviNVDro6vqNO5UF6uy+U6VytUVE80NdgKcHR0cYtjmggTPIug9UULHqUeFRbe9pKWd3tOKZTGrX1cqdz/v5EaX1hT5WimBYk/Npn0tBYdV/HhxWD06OPxWKi3MzbOvB5oKz7VQl1jMb/bFwwq/it9FRsw7TYWkKoQayTgajC4okIMd174wrpKt55bGxq131JPqTZXwsshWuoeMUYlbL/X7Ou/iwaFQy61Rib0XUxc9rq+uocbrjT/8s1QLo7sMz7o7rYUkyP3EWbmsR0Pt183Chp53j+OYUxgbdtYWtmleVCTuID5lHH5J89WxADst9lQeMeRSEej99OFjxv3c9h5IZ8EG7zz6jbCopMujk5LpF07LwT6F5IjaS2xr3kaEhKQf0UX/hAttA2nQYn5NtI6xUoQNFOEstOH0BQIJGkP1Tx8+ogtTUpGRnIo9//nrpSp/SMjniZAlkoX2CpYrCjbeTK3n1vjomIIQwXQW5ubJwS6uAoRO1yqFl6GKMmE8oYEYwgOTaAcSTIhmqyupeoWBN+9gXlMTk9Kt4DU+Bpyc2m1NLM9+0sUFm2mxoXxfU0NxoABxEWTAkmWKJ/8waUnh5eoWfDkLZxEMWRJZGmQj8VtLpA3ZqvzyaTlTE5OEteRVxNLePvjXaW/9vo69BitkWr9p7WfPz8KqMGz7MPg52DFy2BPlJHh6fFLa28cCq6NtbsjvbG075y3Zh5mxZBbayNhUp8VSFUBeXsseAkmLE5ZBsHO0M27z1W5r30ql3WIRPyAu9LHO2+22NB2WKIrhbrHYbrd5+GxkaFjxqmq3NcI/8TYcwggtnJXLtIz3FjIkYcg/Ly5CdoRD4ol5BGk7AY7YKYRWrq6uKxUBrHxbXpIt2LCfrKZGfhRFjgLFEIBcGNDFI97FOyuXj7//YET2WiXwOD0mAplWRsCDjbRi5KNqOT5xgSrCsC2jHn3gFSzcdvHUbNpbaVSHUANN2R5tOmOVjAogkdH8gdgeSWul+J+yVNec3v28k8ajpgK+ZiqTvRdbhXTiPPrFwl1kxLzTbEgBFFKyJJgAxTNgP4FtjY+OcZ+GzQTHBb1ec3p8QoQpFBy8B3AgVr/IFESARssTa1tZWkaXJFa6qtAaxyWEV+eGsJzdrYikCVD1LhMiR6cdq6n5NmDeOpydnpGZv35fR2pAtkIS5Ply7ahOF93/7Dk2sktVkoUZhY+ixNE5D8FbWTWxfEeZWaSqjhpMo42OGgkUxtweKNDNp37QRkZ4esmqsBBxrsd8YG7goW0ZxTGXEqoFFsb4JY6hk2tVw7aIDIW3VOu5hSmayyVOIBFGjk+pOtUBIqoThid10fMJEDkiqOtZUOXjtCEANFv401vjFBZDXF4/ffgoDgsXU8UeJnqODbEqbn6gyIMKnfoBPzY7jSX7w3O8GEJFTF0+btVsR4mesyoNCi9osAE9gxPJSh3BaQvni15tW0hL94M20vpy8lMVQJVzxLC0fC3C2m0NXem6UkG04XWZkaFh4kugyHA25wSN4aIJxzqIYPbWy9cvhamJSR151G5rUxOTUxOTlasr7FPAJoB5R5vM60rl8+IiwaQUegXnLIXTdarnEFNVBWwIEq71XFcqHOvgAQvLBidciwFIxvLUbH4rlRggzW4WNvikZnkIXjOi3vMNROoV5KheAs0GPjnVReLkoz9eVyq8dqWHwsDJZmEDEoIGnKbSxssRLV+tnpixul8MSsuiAGbHg7VVqUdLHrzwDkIW5uYteVSuriwXU/XE3rnomlYmsUoWsnHmMUsVv0y+3nspVUFY46Nj8s/ExM5hDeE90f5YyafHJ7rUzqshmMlhcAo3iqWQx5fwWmbwzDqmZazRysdVB31KcUqxvo+PjnEHld7ZezUBaqHLhBi33w5KnGP+pDxCx8rSsn1BV078/itSSJp+FzlyEDZZCT3HhqSqjIDxNCYHtUcHh/g6Hh0cOkjzW0Pf9/Nz5JT29umu51IV7nXZQbLhCQl7wDJJPM9Rs5jh9bObhNWv+0EbGWHrJavimEYPnwiC0+MTAj9OTUxaatNdLeILE2lAcY1rt7XZ6RnNh/WQhCfqjg6ymDQjrpIRK0YuS7XbGm9wffrwEU1TZ/wZDSIaTpZEgFXphDStHfGyo4NDnuRhvI4xjuppD8GnNZ6Yj7+4NKZ+kGP3bbL2MDgmjsK5CJFW5sV8vIhFqD1nVZ0y7kSA2bm5CppYgNWhlZJW5sV8y6d6AvmLPaYV6KUCSJwDX7rTI7GOOMqbyVEUzfz2uwJyE6ITD4Y4jr+VSshoiFo4FnAyCBer3dZwlcRvSzoR7g7IzKwTzuDwNZ357XckiN1icea333VJ0AdeiHOAT8xXdVhVoAq9wzTFjqmOuQrtlXeh7SvElBEJor1KLwj0mAgwB6xajVQXutKqKF/jJSfQu1iVLaPqYMB+SkzzwjBHtwzZL8YRs5/vQ6je7aenZtN53KXnCqAWfBYg08oIeEwKacXSHn9SdTt2P83jTzY/cR7Tek/Lz9i7U72XUpWMwdi5OfhjnNgOcVycnZ5B0yFiNJs5V7r0fCuKHk6ehA/d2dpWSHKUvvXVNU7KkIqpi5+60mflMmW4Kli9qdb/LXyVuEP2izUMJONfSVXWVVJeNpwbcE1yamISTYcI30hJ+IVy0keP9qgBBieXNy5hZATMKWab1SeRo3K6T9CmRurca+OGEIE3FO070CkP/0gMtCW58WNzsqfp2mlWfDx7Oy+WZO7SrmrtFovIdBCMjWyX2DJHCg7YlOzGvn55fuH7tfaDNhIH5Wf2klVpq2cREvdut1gkf3Z6BrdPrvuxSLjMxRMsPq7lpQlD0cWFy/OLhbl59Eetf8bGkV9pb98qjHil8zjKztb2+OjYZmEDauC0SM4BPoLy5YhV2eowaLCBVYUHKUjzpO1uscgNZ1uRtLU+4AerMvlsNDgu+mjvBzn6bYINicx4wOKJglmTHciZX4Z8enyCJ6QwYBOnxyfaimx+OM2TZT42+sGqhA0tGfyTZWPFPsU9UB5Y4S0fHzwGpc3PH6P68j8Fcji19wvka81vJ0dOLxVA4d2R3LB/c7VtamISJa7dbmOiOjo4xKdR0D8+PvJIAeIDfp56CTWOY4xTvEnpPFm6MDd/9/POunrrZsbx9x8oejxCwY0fziXtBPjAA1iWfEm2LyqAPLS5srSM8oveweEpaMTNVTihd0xvco9Ud8gj+pkFYAQcOyhVBxv2U1paVV7sURi2Tak69k1OPNmQOPkSGqN/+6fydIfu76AIO0Ca1pbYO/SZViUt3wHGtvxiGtpLK0aPRIvEs5T7j1yh9ccLJByq+lDhaezkOz8dSDi7TyyTOI9O9TQIlZ/YMl8DTXUsVXEwV9rbl32EPnw5gkM9ZkUSweX5BUdvm4UN7kwgWcxOz2gXxbalqzac2cGhpGOyjXBHR9IWly2Q1Lh8wHNeaGHCsi7oI/2xaC0eO0rruo9qEQpZjFv5NiHZnjuDPK7pPFnmRB+k+vrqGkeZtjVCVqVtuU5JVmbAg1SI8iu+mIOwY1uAMMjBpci/sCbIMR2U9vavKxWiCEgVkg3BwiBdyWZiDArj35ZHvrM5Nt2NVOXTBiRq8WP7Is2S4SU0RTHi1IiKOFr7kqM9WbLNBubaFiNtH7VM/Opnvk5Ox6wKz0M7uyx1XcJkenAQJ0ILPIugd0cHh9zygyjXV9dgHBAWfFDC8PrqGiQrQYPXzQg4pdB9IibdH8RrFA2UZWyvjPLwhM0Jk054JmAcoga9oiyYhRASXGEljdKH6Q1blTYA4gI65y9wmURoQV0YVL7yLGOgZGL7gfL20+nxCQ80kIkio10aViW3WCFkfXUNpwSQw61y7gDaxhONMsK8LZmdd6dpOmpN1KWc7Anu8FsIwQ8YBi3odw6RwN/Zzy7PLzii3SxsiP+y9yt+DiClWaYy2u/kHhQYYDe0EWg2y6c8CiCipiOqWanKfnKc8fBjxM+NOzFc8kLLYymODA2zsUhQtJ6iHJDRLNdrdJzHRNK7bt4ovIyi2SC1gfSpicnj7z/sBFjgM6bR5kA3VcBGxuoEVOG1RAG5srTM8Q2Oo7aptGMdG4peqLNQoWaqC6eMfoIN22NaWlVsL4lpYdg2lVid+Ce4/vp+jBgH6ILqco6xLXOyGdaziBckH0CnurroRgF8ajat36a6CGBY7qBn5TIxgrCZOIYOjd05PHWOL22P3I3VuPSJpqCNp2bTyXfKJ85juAot2DKJ8+4Xs1Xa7XbHUpVAdxKWVTmfJAvgcCDDNgeCbKcrS8vYthsPDaxaxCGA+xCU9qnZZIfB3IjEgeCm4zC65h0a32KF/II9nh1pZGh4amLydczqPlqcHC4MoQwiWVDAUbejKHK2U7Vjw9EokwSRCRKt1CqJTCdyVH73iXxtMsVOXYXuAaqAyBCQmHiLzNeh/JF2I1X5rZHjjCitmPJ5MwZXWDuDviiddqSAt7CcxdQyietKhejhTr7/s1PI/RZy57wGq7JvHGDYJg4vbEjvyJf29jUNnARxioev5unxCdIQQ9WBPQn5FvP18vyClyxXlpZRP3VLWVyJ64coiT2fAIdxt55bWhWcu+Ghp/Ha+SNmjrU7cCJmywQARr2S9Qe/DQ4WbQtO+pW91aXIcO4GNoQiBzaYrB2RRQ66nlNFP8GGxTPsL43Xq6JiB/WbVdln6GU2TYyMho8rO5ngdJS+8AUGfycDPxIt1axN2NumAcKzVfqRzqMAAocjntnF2W63CcLJsZ29+7aytIyKrtCdiFroa1zxQ1KlJFIP77/f/bwTNT8+PlIFEQyHT25Ozfz2O1fqHDkTV8/abQ0PUg4ZUT/tBDjjEtKz5KtHRwGMoujrlwKqKHqHjbGzWdiQiQrNBZnfamrfSiWNHV9Wqlio1DuNf/1S4EqdEyvGVlEaGPgJNvRJzfrzHvjkVBeGyceNE8CODg4BmEuaFhL1iHqi7s7KZbCh1mysGBWjOjrjytLyZmHDPrrlFLMAE4+U6t0ogGldWAxj3Py8uCi/jbufd5uFDbx8vn4pWNoAJPylBbCj9BEoVagjIUhwGUW13Cxs0KmaUjFVdzDvzKOKOb2E8/1eslTvr1SFwMkB3MrS8sLcPEZEYoqvr65dnl9wjwHZB0dQItvjysAj8kcHhyh6kmBxxSL89nWlQqQUth2kWc4NFSlRSh9SGG5ZQpAmQDldJsS4dZ1Nx15EBCfWDQGziWPpP2azWyxKHHhqNq2Sa1+R7BJUpBIhVr7U3TdrWwDDPjZ06AFX1aO+MgioEZR3fjperwEdUNWzJxA0VL5/UhUvpEAq8CPOmuDjHLlwQOzTxvrqmliYHl4B5p7ctaIp30O45ytFeH4x0Xupyl4N3yxszPz2O+EBFubmj7//QLJAkpLHEyIS1uWVpWXCsSvy3MLcPC96ypyMZZ0g05gbibLAMiPoONbWmd9+h9S4voPesbK0LGM/rkx2AgI7jLCZVkbbhaQqBnVdqXwrlRD6sJcjN01NTLIHriwtJ743KT8MG/6B3u1Rw4uApQFMs1LHKAY2AlXUncZLTqAKbcpmjFsGezuTSyhB4u6vLC3f/bzTpKhZxGH6coC0bncZoUos5rub9U+quvt5h8KhJQO/JvDG1MTk0cHh3c+7RNqIokivFhCEQ5PSbrct2dh8pRPHzldhm2tMYojk+5OSpSmnjPNTPYbz+ytV4Zt/eX4h93ECEOO5vr66hgB1Vi6Pj46xYKwZQqe8PKxkb+rxBM766prkDhBtX7tEgLJOCYkSBOfEdha7T0uqSmtKh81TE5OEIZaJ1IYVtG7oPfFQd+BJdKIROTqFu/kZbhNsXFcqhJSYnZ6ROIwgRtc67MO2Za1Xp8cnWlS54fRdQ/rxEPyLcisqIaG7FubmZ6dnRBssBAbIEwRK21FntJHbKk7a2i7tp/A82pI9T/eeVfHWHuIrHkysW66wEE8dJYiwAQQ7Jx+vEy7uyXULNodLjsN3nKtk8CZ0JbE5i7KVpeVEe2rPJ0CsCm3C+lJxtOdwWHzENDoBb1UbvAc1nO51QCJhqEEleo4NLU5kFpR9eRI50fWYU85DAEmKMI91k+ljQ6KEBtJRgjNBv0r/FED5VQkVKLkySgKMpQ3xLF3Op8x1pSLiAYGJdO6PLjEn8S4kJftBG4kw+Jm9VwDjOD7+/oMtjhswmNhR91B8kPSU5kaFDZGOaxXaGSZzuV/JnqoAL7LQ49Fu/UeOv/+4rlSQpXlE66nZjKJIZXgWyU5ARnFUqLTlJcFKAfSLEU9ut1jEACFVlPVMawyNNLCRdhyFHK1HvdOpBUzV5Z7jmGZtFdujzffTL/aoKsKwhSqOY5Qg4vB8/VKwquhZuQwVWeVXRgDm2rZmP9n8tLR1Q7NRGJ1B9U8B9AHDYxGfMo59VEZzbY8UxJ0tiqji2wfUlCaFBOMlIgVpnfPYKqQT59EvltiFunMwnLF676UqCxCykvWfIigVOwA3MDG3w8h0x5jDWk7rFNs3iiJu28RxjOOC1D09tYQVDFkGuQy/eUriqaDbzurOqpYW/txpSVXhFsCA7OWcMFBFNKGEZBO1aT8p00/w5iVSg1y0HLEOnwZYYcZm/Y4COVnaxG9OOq+VILjVAHvSCYDTpiNZpAGjMP8I/jBHpylIjk/9k6rSICQfgVrYEG3YIwVrExAVUT2jDsgdHVCH7SWKImFYEAo/SujTqyXysCrUGW2AwJq4OAmN4CCRVcGYUdk47iHYCwZy2bZGhoYJ0P7pw8epiUl4H6hE01xfXdstFikDFXLO2HhojI+O6UozF/cJpDk+OsbbTcRaUQyZfEh33gEMYCOtfWsiUdwu6YAErqGug0k4XVqzsDYmi3CDaHyJTjTWW7IbckSXscoI4GVv01pJ5AfLFVG0HiFBCWFASFOOTWDLp82drW0KJwJmT766YVVgw4czsVMLqtIWEp826vd1odppM2wfQJXG3kLUSdlb1LUS1mnR6UVlXiGRRwGUCgZ83B4QHq10xyGCmJqV9BRnHXmKSzasos+Li7hTISJxdosXFWHR0eD0CjEPFC/MzXP//vPiIk40FOBQKY5jvbTMwRO+V0/NJpAI1xbILGnpkrTw+PiIDQJVixNAqV2U8ZvlJAjUQQ1opoQMlWOUr1da9cRinsOy60qFO89cykfPsgADiROYAQB8IH3gbY+kZWdRyyi8tKkTwDC2IRvKoPhYCLVasA/YpqxCZPOhq+tKhUtUTBDvNjtXuKiFhxdpi2GLE3/stkfSvrfXdaWi9yhRflkdtmUn/dRsSptj7KjGFNNk8ZydhcoemCqfe0tRFEEStMwSQLdwescWoepCvlPMH7uq8MmWD3yyxZx0HqmKgAQCjjMasSpYNYIS+xjRhTRIjm/0Bmdpb593KInPW72potxRQEHTGw8NjvNHhoY5MJJHOzsP+fX7+sLcvBXK9CyVJDicvzk/wt+qSwXQEZh5PxISRIwnRiA7OWED7OkVmJREAKJwtuKTUGeFfz45zspkIpioWTyY1T75+uvbUNWdynSU8LEhJ2zC7CoQc2lvHzd6HxvS5gSMn2g9t8SbgDBNlNjZ2kbhZaKx66cNqrS3L4bb/Qmg/Onojs2GseAAVdrbn52e2SxsAJWkJAue1EAqJgpT/tgTL9lw85ktECv+ztZ2oqCdGIFDs2DBe510TlblQywFUIn11TVeVybgwfjomCgATUQx5MQpkLBGhoZnp2ekRdu+mFd7OUbPCPK0LEyBWWeFwPJwm0Djk71GKLZdKDN7QmKjqggJcnpk7VVvqoSLwFCi8ijFLHLuOdpFYsGzaarbHLg5r+nhT5gYMcb26xs1bIO2ZMa0jw1Z2YSN6k2V/5uFDT9uDB3BW+XfKKiUsCgSbNbZBXb/1GyyjKs3VeLrq7CfcC4YJnbh1wrkSCqxZRiCXEDhKdAGT0bbMXKihxYp2lABJYRkdYTRQz/lGgrjIwqTb7JUeVnHlON3YT/1O51HAQQmRzzT4ryuVKxyhxPmyNAwfm6iY15UZlfUy7RHB4dn5fK3UkkT4BxtiPvwkhK3BNBoONrToRK+pjpMif8tTPvC3DzXOBzg1V0+0dROEi2DjXa7jQJIcHROPDcLG5z6MRYLCcqOYqRJ9bCPMPtSvd58JtSc9gN7tmh7sWlOSAU/n8CGLZaWzo4u2pQCSCCNzcKGYuf7Z3BUUfw8QWUXv3/vRIEo0BmlgkF4diA+8JL+bDHNglPe+WmrvJhmLCiARFDA7VOXinxIHNrQgaANPiEUaUI1v2i70AZ2kheBdO7rUJ4uuhk7sL3Yu99FTqlKuFBCrEryP4ZtohehhXFLBvEnjmNeLUXOxA1ESoowgpigXsZHxzjjh+kon0NGopGhE+lFZWgUA//s9Iy1ceqmqLqzDXaTFjYkR+A+xl0igEc3FO+2126BhzMB9GX5NyaCahvJDrbWA1V0pzqxi+zNJpakTWFD4Yl1V5RPdnaqN1XGhWFbKFWCg2B/7KLAREjSMjEj2K+0041Z3bZm02BDUlXruUV4j8vzC8gb2rADcZaGflpsKNP25ePHfk1LO0+ZSUPvB22kweDk955V4SgAhyJuAcd2nz585Br9yNAwFMkzEJiQeH1LiGAC+MQBBGd8aIiWoDWekaFhwsuclcvcJdTai+P404ePnAxSPooi5G0ea0qcY7WcIyEC0grEpI1iy1Emj1FL+bXStUgZy4XkLKyEaZaFjuC0rgBUlF6sWeiowXBh2gQbUAj3FnhC7dOHjyjyVn0TQmAW1hYjCGVuD/f+4lfMeVqQbA+vw6rQf8HG5fkFFzmgDUuWogHGriVg0cKN2hcH+2IBdHMVSzSb6uurJXqvANrTLm4n6YxPZ3NId9wN5NIfPp96KYiJoTppvEk5ByTuuAQNohHohbh2uz0yNCzvQVDJFTMyia3O2zb4l1p+kUM0tbNFdVgVESYIvEd+FEXcAeS6taMU69RPrp7QZRRFcnP1L3z5vZMTHogOlSjMqQhV6DRcXZ1mKSYtntNAqahRFEESYIPg90gBFhJddpPWI2u6Wvb1hRchtFXOymWrL79OZAVekAYb2Aq4A/itVMJgsrK0LPRq3qENe/optGBtUBU7QCft/LRVbAR38tkqSGuTsFU6TQd6DzTVe6kKZx88Smq3tadmc3x0jLgIRLYfHx1jv+KZWWzkbCC129qnDx9hKEKK1Yzk/SHGBEWi32lXRLPjySYK4AxBmruH9Mhhot2+ROLdJBypivCBKLnoPly+4/1UnRI4O6cduFVDbDofkPbJL6y2Fts2na99vxZtSsYk8j3FFKR4ZWmZuPuqTi0ZpwSYEpK8VCVHwnFPc6KDdY9tHyTgf2o2dMa8/AAAIABJREFUOSwu7e3zjBWOgaKN0+MTMWUZ+KkrUrFE0j02kC6trd0GtOi+fR8V2XN6z6o424IZcZwxOz3DwdzK0jIO4nrZQYNnAmAcQK+btLXb2vrqGtocaxuvZYvQ1nNLLwlSXYey2MIkMNf/7R3AlaVl8TXuuGRHWZaSYlVc1QYbChH31GzOTs/sbG0TxEaDUly0y/MLwNOatAvGprMA45TxjTIOp1anTsVuftIm9CCtdmdr+6nZbD23wAY7mbChRYi2LlKxCSedA0Lr2EF1BxtdYjsRJLABPYANbCNcusCUAU54LI5GkP2hDZGKg4Eu545DJ8GsQ0PldNm+2smR6L0CiHR3Vi6zISgYNkdXTDxPKMNxEF+FAkmzKAVfvxRwB+VgUZuMLyhqn7GfiGzNwQoS/nWlot7hYgSNEe5s9U7TkmylANKsnkfGnU9qC4cslj44b1J1ocWeQ+nAVN11BLz1b0RFleWV8dJplrE7AASqaCDtdps4qE/Nplw9+fqtVMLSr2M7QUJCrrBOa1ZnBBUBSIQrgBfyqYIEZ6tbzNv87GNXj6qucUGBOhRmddCj0tKXLW0QoJGWtWRgW+olAGHiJz8MkX+t0mLeH1disxSzUGUsZqv0Jbb60cEhdl/tV9xUYrPC44mDPIyXqD9cHyHQMJOEVIXdFG+XzcKGFceEqbQE7p0Y7PFf5xhO2yam5amJSceam9Zg9nxHqkIA3NnaxoeTZ5NRZnn9QSIeY7fV6ZSYc6QDsdVfhPDy/MJa5RVrhVtvvur9YoMZCyDVIlXBWcAGrAGfRk4DrcDruBFpndh4vtaunBEYFXOs8s5RA7PGjKhKTxIMhBiQYIOYn8w7DnHc99KL4rAhNGiqCBtKOIfFnYLqeNhZD1JpMLavTtvvsnweBRATLPhS91pdHCFzbIcVgJNXfPkgWdwgLcZrtzUs3LPTM/6lWUjZiYSprgMJPaVXvamyO8lxmXllDrqZgN1i0dHn2SqFH9gTxghFuaR3JEERqOwRvCRoZXvZaxhsPoDtUQ7t7BaL4pIizXyN0yA3E3yXa9smb0FK2ecThCHSAl0iKn2lF+V3gw2Mhho+M6Kf8AvNCB11+hfW7Mdj8bEhbVfYYIzMOy2QFm2Ih3LBA9h4qaBTOEWNqsia1U/t7hZyfX2dRB5WRYAhbc7wI548Y3NmQVKMi9rQ7lm5jDYO6vlLrGGds2peefJPWFC+cl5M6FaUStpGqjdV0WU3ExBFEXudemE/FKuSAzR3LERMFGBNSjQQVvmKkYuW7fpX4+o0S8KpZX/2ChuNh4a81QBJwZj4eV2pMAtgQxwBYACDS1SNhwb/Yf2Y/6UNaZ/X1ywYUBlnKdKI6MGG0BJHUN3sCT3mqCoONhQRhHmXl4Cwgas9P6E0jVe3FxsPDZGN3d7U6YsJiFDFuO2gn3bVdLNS1GC+RE5blVWP0TztRucomYIsMZ9TWFQPSj4+PooiE6sEdN3Ap0BTdgICxdIGYtc81cFGp03lA15Q9ao62MgCfGKPYMOprnVl8xOrMxxbLC39OtW7tFUlGhazY/jXjt3vPXEe/WLhScw3cXmkKi6s2RUCp7cr1vna0c/NwgYBYdJqcSfZ7qtpJTPmW1aVsYotZmUf8i3jtiXfRbpLbCSSgRUJ3wUSBGQ3UhXrwiePLjEs2F4/8Qshz8mqfBzV7+s2LK8E3XCCYANYlGyMY07x8YgjSAPp9dW1laVlxa5SAcqoNcUwwEe8tLe/s7XNlQV64a4mcf54CdIfUTc5emszgBNOGNLww9voOb6Gmw3DQ+ytfpCjJjdtRATYSPvKhAa+pn0ieEPaV403sQBT0CWrSqQiZgGCTOwaitUnsKefAdrgDSSVVEL4d5oStawsLe9sbbO++GsXF26JOL4ljugVMnMqgAERztcNNYxEYVhNaYUkypMZm1VrdCq3AD+fOG3Wt15VBHAiJIlNpVUJDMpXEm3LOphPhCqxWapLoEsEPoDG+N9udKcNJDHfApwl7fTuVLHvHjrAJw5K1cGGUwWArVe3ymssacodTQWapYXEHp1e0spYb4PEKoHeE1XsF8dr10KnPYYnLm2MafmJvb+I0p5JVZp+rSLlKOEcYymfRKCiEyHLqdhNs4naitN+Nz8Dg9LyS2w/DFjuZgMVcXNLBKZXmeHerW3Y6dGJ+uR8DTQrbzunCj/DEhPHjokVe5IZGG/YOm7t3A4kredWoNkAosI9his6MPTpZ+9Zla+ZC3SOM/TTSQQqcrDolNfPKIp0dqNMJcImrUBFtdBNItC7fSjJ7yIMWOBruNkAPIiZPiQ9zMnde2C8nAymAdl6btkTG6eYTm+cfH6GO02s0lFmALAXBxXoKNBsGP+Br4FPAUh6+6n3CmA+6c6OKk1uzJI/6F2YzIIuWyYH6nJU6bLHQfXc8/veUdd7qUqoHCQGGBhgYICBXmGgL6wqLFengR5WAAMiKFdee95sWoOd5oetTmm4Cj8XHMCG3CYT4QwjOQ2YxKbyZYYNi2lt2md70sok5uNNmvgJ21wAIQEkpzXYab5uDnVUMQBzuB3HrdoWdhx37Sd76crJf82fvVcAjw4OuXfKMKzYyRkEJjonP4oinpBJ1Ck4c3Wq0D5Pzugas1P97ufdZmEj7cSE6FG2Wae6/ZQl7Ve3r9doXtUUYWSVr+oYgxWnSfmUPP7+Q/ZgNcUnMAw27CfSURRtFjbSDtqiKBoZGhYwfnV1oTIOYC9W0eNGasFWSRtXGtnQOzHO0iA5Ojj079zSO+8eyWBsISE9NTGZ1qyPCr96uEwcx4+PjwrE6ldPo3mtFL8KpvG0Y029WpQIGHGT08brkE1asYz5GYs5A+yxVIVNd7Ow4e9IMlKKOEAZfzkOS/xEgcAnzbdtUOnT45M0/0O8V1SytwmgwsHKx4be3RPTsb2DjcRPFAtgo3pTDRxdEWzT9qU0nk2aJuX3JMH1Q16s8Q+whI20cbFu0yBJq8XBsd3GnBbSHn/HydlenHYqdvlTFOvEBaZZhT9KHNeLKyVANoG1QKTcxHE1HhorS8vyU08s8wqZvWRVrecWIXhsGACNoX5fR7/wKZXzjp2t7TSeontPak2JxkNjYW4+sU1eEAo068RUU5s9TBCvymdV6iLxaJkr/gHNMfCJ8O1q3yaI4ZVGc7xQ0idWBRhErUubrMRbEFQkgK8di00HGsRb0hZWmmc70+rCW/uKDWJUBaYyETYmMbBSEhkcK2hnazutO+ImCzk2wQXpREK1xfqd7r0CmE+6s+N0BD99ypI/6L0jdFmU5kBdjipd9jionnt+3zvqeilVCYmDxAADAwwMMNBbDAxYVW/xOWhtgIEBBvqCgYECGL93wdjShR1Lp+kc2lyOKhaqQXXNnUVLlvRfIOoGUpWoZZAYYGCAgbeLgQGrertzM4BsgIEBBoSBgQI4UABFDH+GioEaAl7S8PAXqIL9O6HEHZOKRWM+1A2kKov/QXqAgQEG3igG3oFUdV2pnJXLT82mfarbMmmbzsew7eTY1jpNv0LvPBbPs9VOd87PVwD+9Xu0g4rj+O7nHZcK9XQgU2mLpaV/OfBpgGXJTwT+rFw+K5dzV3/jqHsHUtXRwSEvlAVuSFhe88dOHx0cnpXLupnxxx7si6PTU3ppLtovtvBHKsBK4aWsP9K4GMv7YFW8uTQgR+6jXlcqznNefzy6zDgiboPrabKMtf6oxao3VcTtxBs5733U70ABFIr/qJKtBpgo1fP1bY793QFs0TgAXoRn0ZIl/UtQ9w6kKiF0kBhgYICBv1gMDFjVX+zUDwY+wMB7wsBAAfwzD5FfItlaeskifqeVeX3gX79HO/ZB76Ici5Ys6feIuoFUpekeJAYYGGDg7WJgwKre7twMIBtgYIABYWCgAA4UQBHDn6Hij6pH/Ptof8XtkEHvYCALdTllBlKVJZ5BeoCBAQbeKAYGrOqNTswArAEGBhiwGBgogH+m9bzHkxE7nY7MrE9Z8nOMPUcVC8mgekcT9BeOuoFUJWoZJAYYGGDg7WJgwKre7twMIBtgYIABYWCgAA4UQBHDn6HCqhtp6YEGJ9yloSgtf4C6TlE3kKqEsUFigIEBBt4uBt4Hq/pPf/VXtdtbu0G9XYz2H7Labe3ifzv/13/91/539T56ODk+/od/+If3AWufobw4P/9f/+f/5U9/+lOf+/kFzb8PVlXa2//04WPaG9a/AG2/tMuRoeH11bXT45NfCsUb6nxlafkNQfNLQZmdnpmamKzf138pFH3p/H3YqnaLxc3CRuXqSjiwEpZN/yWYAD4vLm4WNs7KZWewzk+LlizpHNVzVLGQ9KS6AqLalrOke9L7iwSZBkk/eo+iaGFu/vPi4nWlAmCv2Xu4RwtJvrG/D6mqelMdCBFaFU/N5unxSeu5pZy/5ETjofGHFCLyzenp8Ql7WL7qb7nW+2BVbxmDA9gGGBhg4BUw8D4UQBBhZci0dD7Z0iI6reUs+X9pvf+ljdfSwGDsWjUWLVnS+VA3kKqE8EFigIEBBt4uBgas6u3OzQCyAQYGGBAGBgrgn7lo5xNNhc2/tOp/aeO12s1g7CJ7i5Ys6XyoG0hVQvggMcDAAANvFwMDVvV252YA2QADAwwIA71UAK8rFf5Xrq5yp68rldevbv3gs0iwaWWsZJtjIOEqZ+XydaVyVi4ff//hoJdPfvW0fKe68xNspI3R5tvxhtO12xq92Mn1AXYg8av8kupaLfnG7lcHG3YsnaZ/Feqemk2GY1HRaTpMKj66KN9Lqero4LB2W3uP/3e2toWgniTq9/XT45P3iIraba20t98TJNhG3i82oGo7lu7T66tr75E2qjfVo4PD7oefr4WesarWc8vKJvmg+VW1up8Ax3ccQvxVw+my355jI47j6k21S6h+VfXrSqVLwnZoI47j7jH8q7DxCyHPowDuFosrS8vH33+Ar6dms3J1dVYua0Y7FQht+adm0/7sNJ1PtrQT0GmPnxcXF+bmd4tFsNFut68rFbZiv6koinwIyVR1USFNJearzN3PO6XVMlI6vavHp2ZT+WQK1QKAKmDDB96HRD3q026xCDZUHVVFtz2UryqC335KTF9XKjbf7z17U4HehRbKVK6uEgk7S+/cyLO0geqXHcN2vDYdx/Hj42NH43Wq25/Z01op2av4qM6COr9MHqnq8vzi04ePQhPylH9Nr/Xc8oXn1nOrtLffeGiouhKt59bp8cmLd/0uzy/8O1+125oya7c19vDGQ4MVUr+vX55fsLdDdlEUlfb2td1pAgRM9sRTs4k8ryq12xr6jnLiOH5qNne2tgUkn+r39d1i0cnUp6ODQ8C27Tjp60rFL2NvCF6eX4Dt1nNLJVHxdNG3fl/vFTZazy0fG75SCW04A39qNgO0kQUbibRxXamoI9FGHMdQmmjjqdmEDOr39c3ChmijG6mqfl9fWVoWp4vjGHHbobfGQ8MnAybFmW5+Nh4apb193UlOLIPsJtOSytj1JTqJooglc3p8wr51dHAIBpx17UCuZl8hkYdVxXGcyGssFmq3tZ2tbacYJCsisMNDDU78ZIuRLu3t+3NgLSxC6GZhQ1WchGWaKu/3lS/HUQCPDg53i0VndGl8mWUstvIiAKfHJw6etfyYKTWlYaqKZGH2CZHpi512WuBF2rg8v9DysI2DDS0q+ykxbXmuCiTShrChr0ILTBMG1w2rEgBOQl3DMY8ODh16vjy/sBiz1dPIxpYh3XpuWZ5LpmXW9fu6FHNAokocx6CdKpZpWsj9Hvuak0cBBCBfApSQ/61U0pBUbLdYlM5opbunZvPrl4Lq2k9paaoIL3Rhe5TIffz9B8vvrFxGV2LzFFR0obppPWbMVzFYVbvdfmo2NwsbURQ5PW4WNthsbT5S/crSMjDbT+G0xqtiRweHSu8Wi6QZJlBRpd1u7xaLdCfgVczBsD/vquJ/Uu+U0fxa2lD13WLRUe6o/tRsriwtWyXXNqvqtvfw/DJeyl9XKrR8Vi5rgoQWysRx3I0CmAihbFUAg3CkcUHbkpiUD22IbNJadvIfHx9F22rKzq/Gq2LfSiXoAc1deKC6iqk1p8cs+TmqtNvtnFKVBmATDOPy/EKkz9fWc2tna9uKwfX7OtsIn5zyts20tL/X2Y1XaUn1doep3lQ3CxvaT6QLpPWVI19SVf2+7ghTtdvaZmFDKgmCj3Q0X/jK0ruv+IiktDDiOLbS1unxCTCwf5b29gWSrZul9yxl0mgDvdjSRuOhISExUc56sbvT4xNHSBE9MNfMiJUgJFjV7+s7W9vXlYpmzeqPL3adsQDYODo41EipSO92OURRRJnabW23WHTKZ+nOjp3ydn6Vrt5UmQUkSkqelcuO1ULls3Td2zK9Z1UWPpaBQ3D1+/rRweFmYSMH3m3jjodB46EhTcempRGwKkSC1Zuq1mfPJ0CsygIMX7Yskq87W9tpNhpbPZx2sCHKw0KnXdoWK+3ti0dgyeJnz7Fh2aVGkUgbcRyDDbtcVSVjovXccuKCWnqwadlSHfsUlgpmyt8UM4IRKOZjmD3VUfowZXZJGxg6LDAyX8ZxbNOiDavxQRgyufiQ25b7mu6lAqhhIARGUbRZ2LDS++Pj48Lc/NHBIbKl1okVGrMLh/gH2vIAQGuSbCVYBdQxQW5by5FWFSmAmrzK1dVmYYPdHgifms2FufnK1dVusSjWZlHRUdpqMXT6eXFRvX/9UiAdRdG3Ukn5x99/oJ+SQ48WjTbfT2u8/icHeGGYfGhDahfHDp8XFzHq1W5rXUZ8xUvWQmUHBW0AvNKPj49ChQW+rwogEF5XKl+/FMSdIVRWyvH3H4m0kR3zcRzvFov2WPOp2Twrlxmj1ZdhyuQjxPmHjM48WgxnT3cEvJrtl1R1dHBohanWc4uNq/HQYNs8Ojj05QvAyv5XcjtVLs8vJFjJRMqWLu2GXWK3WESmQMjSBGTvOlyyfl8XI2bIMtawLI8ODtktd4vFna3t7rFh7aDAVrutCRsSH8CG8jGgnh6flPb2Vabn2HCkqkTaODo4jKLo9PgEbFh0hVGd9jUjbVRvqsIGtAEAtdsatNFXqQqRxwpTjYdGFEXohjtb27vFYve00Xho2C7iOLYCtUXUzta2dGcO0He2tu1xdj9oI20GnfzeS1XXlcrnxUW7RcDXNwsbx99/nJXLnHekbZsdcVxflFD1p2ZT5uQ4jjcLG/4WcV2psLHbCbA7aqdp9S6p6rpS4RTSNvX1S4H8s3KZTVsKmi3WadqOV5Aw39ac3G63EWydMvoJNrL0rirqReTlVKdNhzaoTuD860rlW6kE3hJN7H4X4d6hjcQy0IY+waMdgKGNvprVEWmtoA2hEhydlZLmWyfgfbQ4A6GAQxu2+nWlovOup2bz8+KiuBVNPTWb15UKy0crJbEX22wgHfgUaLaXUhWcW/ILOMJCiQsP0qbl4pTJ/dcXJWiq8dCgR4k2recWkpQDHuU1AbkhcSpKaHfyMQ1EUUQB9B3fZpfP9R8joNMjvjy4X1kx9vL8Ymdr+6xc9nvvOTZ0cOEgnxMYZoqplF2mdlubnZ7xx5I9J402cMs4Oji0wDARFj/qqH9SlYiTvpDjOHURNgRGl4nqTVXboW2qelPleEHYwKzum/yp1Q/asPAE0r1kVYnDOCuXYWHI1f7CcICDcI8ODtdX10p7+2flsgzhTkl+yuDnfMVRa7OwsbO17Uj4pb195GodjjjisdNUjp9WAbTVxU1Oj0/WV9fSsHF0cMhCBRsoAjyolVaFXtIOK7ATl/b2x0fH7ApB50L70xaSOI92FDnSiW1iE8CU7hSIokhWXrqDfaM4Hx0cophIeE8ESScqzlfMxjtb25uFDdEG5w+lvX2wobXavxNAByo5W2Klcr46Py021lfXsvjHriwt+0sJDRQvyPXVNTEsdEZ2d9u4M00OVH392XsF0JfusFyelcu+CsbYkPqODg5XlpadYnc/7xIfkpKgGEWRxFfbmtIrS8vsJ6oiCKMowtxoJ8AvpqZIqLqfr09SAP0qu8Xi4+Oj1pjtzlbnTsZZuWwVBKzR1i7uVH98fJSVx35SempiEnTBsJRvxwI27Ke0tAC21RPTwrBtKo5j7N8M035y0qINm88Rgbx87SfSURQFdMmnZnPmt98lazjVn5pN5ugVzOpCIyvlW6nkqGAWpWivK0vLlasrW6x2W8Mz3hkIdeM4vvt5p8GqR7X81GxOTUxa67stU7ut0WziPKb1mJZvW86ezilVJe7tGgbjJ7oA7jyJ5SnWem7hvmF3e+GXhH8zwxYI+yKxT64sLY8MDfu7Cu04kNvGX0xzKcEB3lcArysVZLfWc0sU5jcuHVn7m18GiSPHWPBO3i0Wx0fHZqdnfCDpqxtsNB4a1k9CwDttcveIrwHa0N7uoFfN4pW2s7WdAxtcZynt7a8sLduLYrbxOI67UQDr9/XE6g42Ls8v2GDq9/UANkQbgTKnxydO43Y4gU+NhwaqTBgbgRZsR/1I52FV66trCM8AhF69srRsh2G9V9LgpqKuHaUVI1/Kgl+Md/H8fHJ4J+7Th4+bhY1PHz5++vBRp11aABbytHbS8hfm5i19QE/+PTiJUWntcLEro5sfLlqJ6/NFzOMCXtrbX19d2yxsMJtHB4fSgrvBBnqZbeH0+GRlaXl9dU0Dx5Kon4kJ5tQeIicWIxNsJG4AXA9OrMueUb+vf/rwcWdre2piEtpQvBpqJfKaxAb9TFQziw3Ygc2p3dYCrIc2oY1Ew6LfKUYDP183EBM/tZ5bHIAuzM3vbG3PTs98+vARqrAXbC3kie30LzOPAoibhlx1JMJpGGmCn82/+3mXeIOEMxeRna0S0G7UtYABZap+dHB49/OOs56zcnnmt993i0UdIL5YPa1ZQeuoXQEFMLGp60rFcX5JLGYHZb1jRB+Ml+Fo7H5TLL/abe34+4+jg8OFufnabU1eTi9WV3d+y7Xbmg8YZ44WeLWQCKRzUJhYxmmNo6vEZn1CdYodHRzqKPasXEZH1gFiNwog6qdDG3LdSBuXk89hsaOa+Zi3g5K87DSlrgPVueUGv7v7eTc1MamzyCzV/R6dmfJ/ZqnSl4s1QllaQltEYoHabW1kaFg7vFNG10GcfN9zxCnAz52t7Z2t7ZWlZXt7wE5AYq0cmaKVF+uizflnTyho4eryhHKK2Qs0zif95A4HUpWDAcu4Vb7LRMY2oQ1Ju7bTxkMjUYpUGanYyiHB0YGT6fzU8cXK0nLjoSH7V5cKoNOLfmbEBn6YHNKpbsZE2pFConrutIl6vrK0DDYstDbt1Or3zzwKYBpMWYaBrtR6biUqREjC15WKo0DZHnVQZTM5Dg/YdyiMLQDHLssNs0DudBf+mYVVof8m6jgc1Uu0DPSVpjCmcTG/qdLevnWXddiWXz5fzosYljXA8qPL8wtN9/jomNUiE8FwBqIyaTucCqAcYa9xdMZuFEDbvk1nxwa1ZqdnrJKok2vbppMGn04mP9O4mC1MAAZJ3/pkV40yXyeRRwEEMl9s0wT4n+I4jqII3zYWw8xvv2uE7XabwzikzePvP0aGhkeGhnXuYHuMokjXAmw+jqYByVZQ7RaLjp+bIM9SPVBGn15UAP2bJXYsKGUCWM3aMqTt1Xmn2NcvBTG7QFPEa7ctg41AFQrbKi+mhWHbrACOomhladk/IN4sbExNTFKFeDWJ1dW749up/ETaUO9Osc3Chu2lGwUwsQttBrYXm/ZtI2Dv65cCdxtHhoYDJ5tqStFE7AB1WULF0oAkxoMETMr7ymxa9UB+4FMAqleSqri6oZWj4wbJQZg2Z6dnxkfHdBIBiv2/ab5U+MuoF79iWo4WUlqBTvPT/KpoB+Xfig+2feziI0PDGDjtHQhbTGl5ACmHBEpuojLllHR+9hwbWpxOR/wkAFMiNlrPLStNJFZ3MtOwkZs2XlOqwsspUdCO41hnc8xpFEWJSBNCbDQRZZKo3lTD5+ZOef389VKVQOkmkUjifpBMuoiiaHZ6Rppz9aY6PjqGMMVfixSHXh1rgoVZWpVTxZbx04mQ+8Wy56QpgPjaJSq/NH50cGiRMDI0XL2pVm+qgSqcf6XBRgAJ61CTVlL5PcdGGqvCFqPtSgCgjmFNY0K5Q4oCWL+vz07PpK1SwpDappTORxuvxqrq9/WAVzDSkEZdvamODA1LO+YYWiNVguuE+mkTHFVn0SVtrRw7n63eTbq/CuBZueyoWoK13W6flcsLc/MLc/PO4uQnc/P4+IihXUIji1Yx85RvW0YR2CxsOG5ytoxN28UZEEFtlcS0gElUAM/KZXz80rqI4zgRFaBI3MqvruMq/xNwVq6uVpaWNwsbAcVBwIONtKZsvqrQi/3kpIVh5Z+Vy2mKvMXDWbmMKWBqYhLkHB0cTk1MsmZoTa68gJGm+ACtaCOACgHZ1zuAtpdvpZKjavko/fqlAP3grjkyNKwqAV9WH/O2ZQwRXEq1+WnpP6ACiChrby0wePuXnSFxcY4MDR8dHH768HFqYpLIBKoI4XI7XJmJCXv5AF+q6k01cQ/XdCa2kyPTujjiBOsE80tss/HQSGPcI0PDAaMy2E5s02a2nlvcN9L1EQxAjgTac2w4UpUuc1jYnPRZuUxUwp2t7ZGhYUncMKzZ6ZmRoWFR18rSsuQL2vED9Trt+6iw3kO2cL+lKsg7i9j71Gx++vARjydWzfjo2MrS8s7W9sLcvDOJGkKWw/GnZhPpm7uQnMkkNugfVaujfif6Yqu6rlT8wOr+SOr39TQ+Rf7s9Mxusfjpw0fJvQQD42eWI3mnU+KiEISEv3Cuni9OhsamR0cOJIk/P334mIYQHBQD3MoGM0lsPDGTi9PENVeE755jw7KqsJ3OAkk4UDEpBzP2GMsPteo4o9hmE9PsasKDpY2+siodiCdC5Wdy6cJBxcrS8sLcvF9YOX55B2D/AAAgAElEQVSQWH1KTIANYNNiwQSs7SGxYl8ze68A8vyvgLZSrtJPzSYh9wJCBHblb6USb1U5USxoitWlZunU/syYtoszY5XEAVqFCPXTj/9nyzhpCFGajkOR/HSqWGiPDg79Q7TsOFHLYMO2nJZWlRd7oU0ccYW6cHWOg9MoZGpiMqzBicV0CXz/TgCh7RdRJ3Td/bxLJImRoWHnPJ0qNoyis3zCmFePPuok/fmfsg8kX+99kao01LQEAQZaz620PZMp4SvxAKyVXc0GblSoTJaEZVVZymcpk8MAiV6TRo7WjJoIgBPNI7FMlsx+YCNHm+urawFUrCwtz07PyH6XOK4XD08TazmZYnlOfjc/O8UGZwWBPSyR2DiiAU4nInNu4N+ZAli/v288PNhIxP/Y+sd//ud/rt3eZkTBv/zLv1yeX/x//+2/bf+P/1OAHPn04rxaBm8B+H/+4R/sz0A6O+R+I5WrqyiK/tNf/ZX99PT09Pz8bHOypP/3//yf07DxeXERd5s//elPWZryy/z93/+9n5mY0w02bv/6r/+vev1v//Zv1fI///M/x3F8cX6unHDiT3/6E89k/A//8T8GdjJcpf7P//pfw605G7gKW/FTmYmJ//vxMcdU0tTtX//13/3d3/2X/+O/OC3nwPDf/M3fpNHG+OjYP/3TPzld8NMuDZu2hf/ff/3Xf/zHf7Q5gfQ/ZF5TgUbyfcojVVVvqtxKd7p8kadQvnZbGx8du65UqjfVsBxBMaeX8M/abU1v25X29jmsLe3tX55f8Cpk4uX1jJAndv3UbGKjdb4mbnROGfszfMgwMjQ8Oz3jGI9t9cQ05jwgIepQ46GxsrRcvanyhpAeRLHVu8EG11/8sXfaJjddAsa7HNs7cQ6wtkASvFwLNq4rFftYjhDSjVTVeGg8NZvdYwNg0ljVyNCwDuYEdjghaxRXx7Gx4MxBiDcK+I34Y/HL9CknD6tKAyUjOcoPaHZ6ZmdrO40cx0fHOl2ZFjAcKaEzIrFxaKi0LZwRclslnM4SPMBpgaOuNHLEZJOoBTvtpP2UdX+zsAFiV5aWiezuVOk5NqxZ3ekr7eduscjBX6JgNTs9k3iSm9aany9sEKsPB0uuiDqFu2FVTlP6mQ/DiWY7nBNpGc9q9ZIxAe/GdZbAsIS+Ynd3GskHudNIvp+9N6s7IrcVO/00PlNp63NkaDgcZowx22Zt7xjvNwsbvOX1+PhI7DH7nCfl7QTY1jpN294DTkOJzV5XKmE8aENLrO6jwinG9k5INt5cWJibT7yXAzac6iIvm2/HG04Lw9mrPzWbaQjBvSjcYyLA6h1sfF5c5ERSt778sffPrC5gMg6EB58cnHDVhqa4n5SlWb9H1ghPSZ2Vyxxe+0EpEucxS4+2jN97eLIo/wukKoFFiFhQ72ye46NjOCsvzM13eT6Ke8jp8clusYhXkdCtpziUY2HrMt0R2AQ2Oj0+cQhRPyEdJ4YvXt05YpDjRMPZvNrUs7L9wEa+Nj99+Dg+OrYwNy/yQCh2nvnrcqbABiEuhI3T4xNm8JWlKmKrp40I/Z2Dps3CBgSjPYxAg2l1s+TzBAFx9yEPvAI1fUpkaa23ZX4xq7o8v8BcRdA7USQaCuYbOxPdD973wcmhnrwIBlHKXiymAvJ8Qfau39d9Dxp8ylSFhB+D3CkQ/pkY160f5NhRm58+fIQZQQBRFK2vrtnYjdbPLjzAjr4m2jFfmVWdHp+EnaScEXV6M8apnvYzzVbV0TymNZ4v/xezKvaBqYlJAg/y0sHUxCRGGV6XhS4vzy9y3EPOiJR+TECONondDMxsmKW9fYIxdmo3zTjwxGI5IE9sx2Z21CZXC6hOfLEc95Zt792kX5lVZQRVCkHG8r0qluM0o1dd/2JbFcP4+qXAra6RoeHdYhFXN2KEouJy6cmqu2npfGqwXUhpLWfJt737FjHNWVpTWO7wsjs6OOR5ZDCTVsXm295zpFUFbNiW09KqwtDSinUaBdQ2e3RwaJ/5sF3YYjnSGau8HVuVHTsOxi9SlK1i0xnHbquQlorjf3qRBgRtvt5/vVQlgwsujkS8Riu0B15dnvhYNPlpy6r8r/lyaDNR30xrEFbFxsXJOsjpk76TBkZHVra0Rpx8YaN/orHTY69+9k+qSvQUyQh24gW9jHW7KfbrpapuoFddyFGma9lfVCCc+PTho3h2otUgXL2br/1jVVwW5Wg8HIsS4uOF127G0n3dfpAjGOZt8SzYeDscrX+s6qnZtLcORfz+DNq96sVnPvzqPczpx0rJCF4fpSpwKrp0AOLdFEzaRN0lkDPUPDI03FcxygEm4wR0JCJZkZDueHiKRwfIEXW2nlu8KMlbqjjIPDWbPLfjQNvvn4Iq0BFer9n3dh/DwoYQpVsyrecWpmV5PxGJOIe3WmAIGT9lYVUYGbvBBs4T9t0ggYcfImdzFAg8E6dafUr489injvxmQ7YqfFjTLAW+sqph+J/ouN1ubxY29LAi3j24cpA5NTG5srQ889vvCsQTaEqDsWXyqcGCPFC9cnWVJeCUgMniV3VWLisIESwMRyeuYX/9UiAoh96SERp7OHY1pbFjLNNAlG9751aAE9s3UEUYtmWclo+//9DztF+/FHhwFFsVL/psFjbsFV+num05Szpj9Sy2qtptjcddLIoCabARBpKVUrm6YjvnKV94N28CEb8Y8TPclA9JxrH7zb7R68poYQKOAXNkbkUDRABtgCr2YoKwOHosJI7j8dGx6k01yz72YuMdFdBCCtTCsuBLHGflMi8pqC4O0BIWlB9OCIEktIumBRQNt9bN1yy2KsQ9X/JFo7EqJMORv1JGwCxt8Lq9xU/GRnpSLAs1Nh4ahNNxegQblhKk8Tklwz+pBc8inPH66hoXyHyCDDfV5Vc7li6b6rR6SAG074XYdtOwk2XB23bQp0p7+3gMs+Avzy8UF42Atn3yHLGQZIGc64T+4uQOoG0tjmOuUzmZ4Z/E5JWfKhcYd7a2dbuIJ6bJDzfV5VfLaNKaIlS5taFQsle0QeDw0t4+W9fO1jauVVzk5LShtLe/Wyym9ZgGeaf5WVhV/b5+Vi77eEuDLQu9WTjZGKCN0+OTna1tHmTW0mAFcTkmkSBta92kO4W8m76cuiFWhWewLAhOTf9nT4ZxeX7hTDBvw/l04AOQOycL5KjDDmyBHrO0GajOJ/8CLWaRtJcCXmwwS4EsUhX7/Gtig2iFfo9A4jPNLCPNUiYLqwKGLHijx57QRiJzJJpzIARjliEHyvQE8kD7gU8hWxXVfH01LV/DyF7FbypNiz4rl7+VShpJWhdp1cP5gjxcrKPec/hVZe9d4f0tHrJXTxyIquNualtOS6uKP49OFWHY5mevjhg1MjScWB1s2E9Z0hl7z2KrytiUoAIb+tlp9TC2K1dXL96RzNEj0CbOY6cDydd7SKoSQWdMMAxsK/zNfibid7Gzte0oxjyj6JfsPkcT0H1TaoE2eWULbPjKowrnSOSI15yxlzeLjYDYQrDGjAPsqFgWqaqjBnlet9MqHZXPF706Sxf9oI0s/cZx3HtWpcUpBysUyZ2tbVlYSch0muhEw1dnGL566BTI97MfE0CbnK/DqjTq3WKR+8lcZ1d+p/y9T7crXhkbpb19YUNEcnRwyMNr2Xc75+mNfJTg1+oHqwLDMjCV9vaJ/wElyF7ezd6W9tC0P8AsOdKv+0EbWQDoC6vK2DEiPeQFL+Pm14vTY+P/Z+8rsaScVPsxAZ22CZ+CfLGms1wTIVdm2kPwKpAxYUM/dwp5li46bRNsYANiGWNiD/fVw/VZ2tuHFPvBqhx1wQ7K7m16iIGr2gS9y74/6UDGtp8jzREKFTudxxzdpVV5W7YqnlHUe/GJOm3gIXgGmVFzxkmCLuwEZKwuhNryFuCe2KrOyuWVpeXAeweJAac6wgOFNwsbT80mYwk/Vpg2Xjt2Py0M56sOkDwrqab8XqAfP//FyXKqfP1SkP3+rdmq8GhbWVq2QFqsKl27reGW5dODM15V8fOfmk2cHCkj5AeqJGLblvd7ebFKu93uvQKoXp2EZEgnP/EnfhJpVdIegk9sKjGTg3990gQop/tEuM3seg2ObDqk9wFLe/rcL5mWIwmCAmHI0xoJ54fb7AgbzF2a9N0TbIhPxXHcD6kqjI0wJvWVeznhV+zyvfZuu9jZ2rbLsCeQq/2OEr1nVQjtACESVJBiHI4wgqZRG3WtSuIMKTGyu1Mm8PP0+MSJqdKPCaBNyW5O2DOe/OaNGT3vGr444jAUDTCHD5fq8l6epon8fmOD7mynegAd7R5TQFrIJIDsBzaYCAtYn1gVCmCi1ygkYVFUu61ZZqG5UwILl37axFOzGVA2bUk/nfjITT9ow+86Maf3rMp2g2WdgxsGSfhqtGgocmdrO811SzfjbJukc+91iSTejwnw24RBO9ggOBfs5ujg8LpSCdCWs8UJLZfnF84C06dAIpEW+xFoMLFNsAGW9Hd8dAy3RkJcVm+qYWwkHshcnl+kUVQAG0/NZiJ6c1NaoC/Ga1kVNkpoA4WLIIvXlQoaht4xSWzW7ohOgXxi5uX5ReJ5q0/VTnf9+/l6tioMLpuFDYJSEcOIYz6rUTt6rLXFWHW33W4nOo841Z0qOlX084Vi51NH+bb3sK1Ki3NkaBjSZG9UaKcoiuzzZUCFLSYRwuwGJqpHUeTc4BPwwJbYi8p0hBYNKq06PR5//zE1MQk2uP8Ij2u323r3xUL11Gz6wb8BjFBfpG0Vm7bAEFtdjM8W64etKuy5xqC4D0vaoY3EcaXRtvYJOyg7dj8txmerkBar8j8lQkWm04XzM2NTeaQqHakKDh3GE4k58dBd2z6iFiEEuEwDiRDRWcXUeNq2wGG2ioUTyNXWBmHLawJsZsb0brFoo1bqZJM2mXWuTIIW/sr5/rpS4YSFWPJHB4foxUSY8Pd57nj7sHV0+GXPdPymusHG6fGJgw2cV5CjhQ2OsYQQYaN2WwM2DFIKm0MA6J2tbXETwEbo8IdQu60lCgV+SSg2cFjWjVRFRH97Zo2Ojzc59x949EyoUGz1xkNjfXVNl2mYdwYFchxU8CBT4gA7og3ku8R2xPXSvvY1Pw+rWl9dq95UJdRgU4ABiVVhsYKp4YuA70xpbx/fGZxHqjdVkSlX5/wXcbEgJGIhQGG2PNTvT63KdLM4xXPVGq6qtk17Al27rYlG5VADcqo3VUdzUQAQNY5SrJ82kREbiZFGbDsWcpufJc35uoWERWivK0MwWpzW/w488FeuJOo38flo27JKsqjCJh4KX55fBHTMLm1VYMPuNwzWwuzQhhaOVsr46NjRwf/f3vm8Rpk0cfxPUfC6y6IguyieEojiRVhQvCs6MSf1OAQNno1ndRcmR/WWCZh/IHNZb+YwV8OcJgfzD+R54f28fPlS/XTnmWd+vMYdkdDTT3dVdXV1d3V1dfU2PFGL9F6DNzk3QRdGkFdnssst55ScRjYCrkl/tpmqcvbO5s0AApvwrRcvQ/CG9A5qTrFq8vCZ5tACa5pTXgASPk0Kk/Be6GiuWupEQvBzqgS2JxVLE4hsWRbntHJOyo3j8ZiHZNLr2T7y0WFrFaiUb4EhjHZfKUMBfk6jVdUCbMHhnGx8+vAx0O+ToGPnmQLPCemjb0flw0TKT9qPAcs0PxdnqypsUAlUpGakdqiCL9Wb19sFU9errS0d9hW2xN4BhWJOYW3a21i2VRWq48niMaoI6eVVpNI6tVVV9Xd31Rb/dHp6inFKzlNA8zIiHgj+KZdWlRRaqFJLVZPqGKS0mGG3CtBydjr2m4ESSIUb/hx8bTFYqsndyzQhPlemOYcdI23f6KyjevPJnZ7QAX04eHWXjUBYk2uDgAqcP7PfKRDQhZ9OZCHdRqsS+pBQM0L+yfcTdGwie4Sv/MRSI/02VWV9TxEg1O5oWJMlZKEKP3nRvsUqVwstZAZu6Mj56NsRAZgKtrZU/SFGqFAUIiukOxpGrAKGCEhIaPsZKA/F2v0MMD2eKos5wV5ywPUqHwXc+lPe67GfklzhMoLAeGaKFxPblBvAFCw5gRuSUlQb3sdUZgCCbMjRJ2wsCvYBHPSCGOx/3n/+9JlWgoBLP7VHDpSrwAISc5yqtl68ZHMHc4++Ha2trD568JCD+dRydPL9xINXBFW2fJ9AJ99Yx1KDV8pKP46dRwcEmJoveHOcv/fv3uNQj0nT930UkEQOh0OJCwZB/xla58EOsdqGAunPBXOD/qIJLEL3797b6KyzW9//vH88HqvtUOteJkSsVysOvx4WuIFvkcymYawKiCfcQ3gBG0BaHbhx/+49uFQrG48ePNQICh7RWIG9OZ5m9HH00WSYYMBSXwSpdsjzTs9+qnIzocYeF7ju373HbSZ8OImX5i10ZWr/874YhMV9hm/qhgE8jw4Aps8aOva6f/ceqxlHPEzlKTeqqvL5OhDpn5yHLdI+T81Vx6zlxvOnz+DG2soq2iKnDc+fPnMBWCQ3nNXzm6qIXaPzdJ0/7PX7CANkYF/3VRzdkK2f9ET1O269+jllwleIOclGQwpnb6saDof93V0OuTY6608edzY662srq1cvX+G9PzbbTx53dCzqG1R39gnmniePO1pJvIqnm2yDg3nLvX6aVC+U8U+B+NFotNfv8x/bnB55Hw6HXPQLVU5PT3d6PRkmdno9mk97ib8+adudQtKoe4iLIKfFJE/tMGrwU/14PIYVRKzH2w6GwI33b98xdJ2SnV5PvmZwQ8S8eb3dxPCk8t5eT6fmrXn4VcENEaMhw6h58rgDK9ZWVkejUa1sVFX1amtL58XBv6zWlCl03t5yOr1mGPqxXN0xetr7tHl69loV1Kd/0Tw/ffh4++atG9eur62sYk6ipA4y3NVYfKGM61wp/IY5QYOgVkDUEFS52JkwCV3/5vW2lE0pStrOwDQQhVeVZhKvync6as6ZlKtk88SZMA+/Hg6Hw08fPsINPwnVwMNZIceNM1GcSW2tu9n8tKoCPcjG1ouXBdnQ3eyqqnZ6PddAUz+PAq7cp9rt4fRMzqE7M3/2UxXrEoYqGQhw7XNquMcgY7m81Nwu+Pf7v7RuUFflHVTzdO08NSe1lk5ly0MUcLihkEwytEO/3530sFzeZE8XXP5yDAnPqTtGrzIPcXRu4GcHN+RAOzgYSGXGBUFbHoU8rarKg94Ebigkv7elebp21p6rWZ12+UiZlWz4CtecA14y7Pv0aR6yIeDlxOynqhQf1isGRojtqenfmavr4HhsO0DNaJ5Zm2aR2eis67Qo2Ke81jw6oAwTz7LwkAHxPSBM1f1+n7QtyqRTuTfK05haMaYy++dm7blO3E6Sp+EGU5hOvlwkxA00L+oGbjRXuo++HQFc8Spys/ZcpyrngKe5RcQUpqV6UtkI87jDD2lGCrMkn3Lz1JxkI9CT+zl7W9WZm8/g0rLZ7bKPlTi6dSBswnGwKqCoqmo0GmHv2Ox2eU4O1yqZOVSd7l+Mrcr36iGNhYIekgFCdiuew6PKXr/v/lbD4dDjzatdgMINh0nq1dYWAep0b44x4JQMDgZAoyP8Uy6dYpSchSrqXM+vrQ43KIap7vT01O1WArXX74c+1VbRsSh9PB73d3d5K5fjHXnwOVeh6ng8BppLo0CJw7n2lvObc/j923dqr8sGRCIbpFUMItm3OsGeFucJiAYWcVvzo6q8eb0NqwOWdnwQ9omqt9GqdDNG/UFCzQj56U+/IfHpw0fcOqRh+eQt4ROQ8nLx/OkzLuWjz3NoWEuYGyZqCwhjOYEuEFZ4b0K5Ol+l4+j4xv2MRB4vEjvA3K4HpyGuWBKwYf/zPu/C6uTI4cyKG1zknJ4bNJmz0fBYmXND/r20JeduBjc4gWXjiVEs100eZWEaWxUvxaVUqQneBbl0rWxI9xQozebAcZ20FvL9u/e4rINbDJYpgfUqIiDHLi88v3SbqQrREU0wBQnQg6aIhZv6VF4J3ZBg8MhT1DmSCopviASqqipMGzhYyl6GOSAlQzMCENTfDrB5mg2FyvNkKTAHB4NHDx4iE9x9z3ke6vKQiNGcohznDOh8QyQCED5MP1svXsITzv6DSYgqmhH46egcZsN0eBBM9+CwQPFoMNJSSwxY9HKUiEkTVVWJRdQKJw8iWKGf9/p9DnP+fv+XfLhUjATrqLoplcBQ/syfAqXRgazu9futZaOWG2GFyC3qt2/eqqpKDn3MpwwZJ5V2BZ814T2z1TMv0HKqqqVYmdzXvX3z1t/v/+IIo3b3K8HS+YUgKJEOzjCu4MjJ9xO9GrC2sioPplp+pXGaHF1tlXJmWNAo7DA5K2CQ/PbLr9iSg1hoGRQ0jUMH5WkQ6dxQRPL66U6vd/L95Ma160iwfNxUjER6IzpFEaqUf9ZeEQ0w8aXaevHy0oWLBJIP3NChAbe7XQzEn3SqCr5X0MmUDQFXL19hSai9NsgaHOI3TD9VhbZ7W8D46MFDNgG//fIrW5bAjVQ2BFOJABY/Yf8KLgYdz0GD18/cQ8+mRw0BYCg/158tp6pammgGNxJYsn775VemKsZJbcvpFVYAqcoujunioCig4UgrdHCOyFTJmkcHOExG741r1y9duIibjEaFEykzOU2WnVjDlWU51dIpf/L9RFYGB1tI10byc8oLdSf6FGAODgZwAwsa3OC+kcDKG4NdvH76mAxO/NSVwKQdLeC1ido3b6afqlJczg1WWRyp2KE3kQ2Jio8UDR9h9MNTP2DNrVuqyKTvVfjklHvhBaT/N1XJfgZK/9k8TTMIPr/X7x+Px1cvX3n/9t1wOCRk2unpqToesDBahm39LNgLyxSWLXbqObAfj8c7vZ6wlyE34YNjxy6+1+9vdNY3Ouv93V2G5XA4lK9jsIsPh8P3b99pKIqw4/FY5vPBwYAyKbWOvUl6OBz6qYWw0I+TtreMEZh7/T4uwTu9HtwYjUZrK6uXLlzEsC3TJNip9WprS5qR54MxVEnZkmtISrDUWMcyP7M6nsAbnfW9fv/PO3eISOWygXDSoiAbeuJBMqxAaaG9ut/n+WnbwaJ8TmNURejoERVrzm2BaldlLs9AoFURYu32zVtrK6ufPny8ce367Zu3FH1VfNGwhAVuNhZTCtd6HU6TdNgruR9Dk+oTlRH9iuG19eIlm2LuQj568PD502fhHjKjRXVlfdAoqt31TESYCqfc0IygMrNK0CLUXpxX4AYnUJhsNjrrXBEVUmppeRM3xB/Jj6q0TgSdTlH9hL015LSi03/49ZDob8jG7Zu34AOhvb2uy4a2hM6BcDXS606UxhlQVdzk4pSrwGISs98A4qKy9eIl5oDhcMiAfP702dXLV3if0ndqNP7Th49kihdS493cPg1TwmGZ4m16Z08DP9SlITLwYzniZV3iqd++eUunUaqLOKYhH/z+o09bqjhpImwWFsMN7t/iMcQ2dq/fx5rGSvb86TO3IsFDnmbxbpJseOakHPDy3FJSju+L5zdV4ZahkYJs4EWBbIRnB4JsSAxmzg0HyE5QA1bDU7xaWGL2G0Aph8Sxxx0Dbf/LP1+uXr7C1T8phGyUtOUOblYUg0GqIhSwyfNzn8K9vxCy3TvAoU2aduxyjILIL/98QdWvqur923drK6vaIF+9fEVGAe45aiOs3Y3v1NhTN2+7U0WaCVT5uqJBe6fntiCLSGAej8fyhGIPiE0Ably6cPHN6224IUoIsEX1IBtgwdcsxQjqQr4+wQ31tVzPgDC/DaAwDg4Gevtys9v9884dZGOz273++x+1slFVleLHu6R5Wg1UL4gnhU/h3p9mavVICk0NKYD1Mg2LeZW5bAB5WoNzFtRUHKY4+bpx7frzp88uXbgorjGFa+unWUOJ6VfOVKFNNSzRM6sE9CtiOgZvxV26f/fe86fPbly7TixaWcqRDEKJe8MlMZgkdGWyHbXp1k/LpiNtB7y2FtxQZAUisShsKdxYW1klooC4oQWMrZ9EQvlsrmfODc0Oc/VWHxwMOO/DyI1snHw/uXr5CrLx6cPHq5eviBtBNqRViS3T993+5313VQs+PdPDr5WNhpmz3AAiTxJ6xXhjrwFDGSS63uWNp8A87BFy4IIpQdt3GhpyrUkxmnP49ZBzKLR95m52NEffjojG6wYaTUlU124IhyDh5at+TpTY6Kz70VhqCpwGeI4SuhX9RfdadOMKX7mdXu/Th4/ODU1JgRt4wwjXNAT7zrc2pp16ROimT0CwLsZiM0E2+ItsHH49XFtZ1YASJVRXq12e095sTm0a4jms6HMaKQ0pnP0GkNe6OXfY6fW4yrDT6+30emy71lZWPdKLrkfAep160DEogeFCSUGBTD/ppB9QIfYxT36p19Pq4mNQR2vzvTqqOHsr2sv5IwdtHNzoZXM5GejUj+oaq8oHhQh2qhx7Lp0eIGqPyc5U4uiQc+laLLQlVBHBo9GIjTA3V2gX3PjyzxdCVvk1F/hAdZ1DBSL5GjDWdpCX4Q6WCOMT3CCNDM9vA8hwQDn68s8XZhyGCeNlo7OuyzTe79AswpwtOiik+d5eT9d2HASomIfc0VNvgV1lLAIV0IWfuWIhv41Wxa1XES2Z8BypVNw9xgWU2UeGkv3P+zgcIRMFJV/OosLVMMENCS/sROqUxzO9cJP0ZrcbjMHUAia6Pf7inA/IGRo/VfFEXvhUlBoi/d+J9HQTIimTLptykcemC652wNVq3VtwwoA5OBhoI4yfFI5ROrrCoZ9iaJRUFDd09O5EetqRltP45UpnwWdNDkfy0pYuU4ZW+/XN6+2NzrrHyaAYBMMKFCj4r7M2+TCDneZrguanCNNiDHBtDGtJymVy4qGv4SxLgUbbsVpgp0m0maq4prC2sirELP40g4sUOLYRrlvX1jkP1k9qidFUFy/YHQiF8pXTJBFOoKWkEDsxSEATgGkZPFD8hM65gYX3p2wAAAemSURBVCAefTti28+ci5CxL+Zyv1ghcaS9ivCNiUrYNa8pp0nCJyYAauRrshABTQCmZdjwui2MJuhQSfEUMVex/9LqpZ8iw6Xi8OuhCNYMHqaYlKRcTnhRMbyZLoI1I+TgFPKRfw9n6twYDocs4Twng2yovUwWCIYi4uqrvKjwF3VutJuqvMs0b9I031RCQKHJ8/vUcgMYHj5R2E8IHY1GGCbR5I/HY35y+sPNL+7984n4jSwyAbKUQN8UFBRI/yStFaoEijIynfreyqs3T0tZoArxLf0sxhtFWtg9dmVzjBIIb9SZ1RnnXkVp6OEn4qhPBbC5T95ZbE+0zXSwaXWxxYvl0mn1WrbkqrP3z1URJdpnBXThZw4LoVwlgSzMvs1klqE6w0GgJDYhX9Bqif/yzxeGUoHC8KlcJZWNUF0EN8xvWCyAbaNVacUTp0hMeRAToC3y55RrhStrIntKmIKz+MT0lPsiD/3nVzam0apoe8rPNGfxvdwOozYi7apPU6vlVJXKop5m1V7mHCWC9jsNQ1X3+dNn54gDTur03HADEAyREcoRnYs0lKtbZ5JQxJUfigOYXHIkKeDfTDjQAkjLDWCtCodye//uPfaDivNPgnc3uaxL2vP3+n1eVK/9xE26AlgOlWox6lNtdVEr3gW1c6J8Zwsbn0J700Z527k2GFikBtaCVXWaXNveAlhuokmJaMIHb285zaXOjc76+7fv1CgRTM6fd+7s9Hpqo4rpqYhQXj8L7VWjUrB7/f6rrS2CeQmUF4PJHGEjBs6TcnvLYsNIKbR3r98X9r1+H7aoQze7Xc7WnUVKX//9D6VVhfKb3e5mt+tt5KiRJ0vXVlaJRrnRWd/sdvWGC3F7/rxzZ6OzLq8rZ8Wk6Xasa6lVqSfSRFm5rVXHAMJ0ngIkpwy28LXwKbeTzdHQIr819tYVy40qg5VFqUVLm1QpY5fJvBZUoW7hU/nKpOblSTHWlp80s0x24WthEBF+PkdJ6yGms68c5AXkz36qktdiLfXufBgKFD5xyhPK+88C0sKncKzmAGeVLmMvfC0bdwoVy7wqgy2Pgel5Uia7jL0gHmWw5TFfAFumZ3pulOEXGtW6E+WQXEt8AaOfRNfWXUDmLDeAIndShdDLt1MOhXpZXaxwrjZJt2BdiypOybL6IjvrvHN+9lqVuL9MLDmw5MCSA7PiwHKqmhUnl3CWHFhyYI4cmP0GkDtuBSc0Prk6Snqz22X3nn6qqsq9CsPGgfMLMSlUL4PVlcNc9YnyA2HerkAVYHnuSSi8+ma3q8ifnl97c00QiKmCv3ItxgLYqqpCABAHW5sOhNViDGWePO648cirhMg8jnGn13O3Sf+EbAQsAkvc0VpprP77lrpOElRFoPDsTfMDdn7miuXywVIWzpzMUysHWWF21BBRyHmffoaGbHa7cjoNZY7HY489m0IOoEL1UD78zDUk5M9eq+JFbxdHNQOLb+0nwp7UfsL4XXD2SUO2N8EIMQWwDqR1mhcZcu0K0WkcC9fHPEfp9GKjPnFhqNCo/c/7uYsXg4PBRme9bOt1RC3SRH/XnZUAodCu2nuFVD/6duS3mgJMwvDnbOeEYQlV9FORzpUz28TxeBxu3jl83T/zTI8oG/L5yfMztZ+om2M+opjr/YI05nDNPH+WWhWOQkQm070ETY1vXm8TH45xq3ymWO7Wpyunivk9lTArP3nc8XNuVdHzpTmwG531tZVVLx8g+6cmaa8+OBigQWx01tPFCl5VVdXf3fVOFZY3r7cVO83Bktbcp/IA4ZJQTm9FAbn++x/C6NVxQZrIcSYlrBYyl6gIr0jswFAMbvgNJyeM/LQThb1WokChtzb56WCrqiLeYfqJR1LXVlaD0h2q+8+J0rzaS7h9v7YCJcRcx+kkBYuHmqIMpsR7FMZQfaOzXqtgUkwv+AJT7K2qam1l1cXGP7VIt6gy49B6tJBA0bnpueAfUHYLLgAsLLn0d25RLRCj3poyUV6seI6tFoXfEU0LKABA+om3gtJ8criyn/t6PB6njua5wi3yFWoxVzfXLgKQ52oVZANu5MDqtcFayOFBw9oy02QSFKhAfO6TIoLUYvdlOxR483o755Fw9O3Ir1WHioQYTDMXmTP7DeAiqV/iWnJgyYF/CQdmuQEUy4LaOVF+O+VQKJbVxYpJe6EF61pUcaqW1RfZWeed80utStKyTCw5sOTAj8uB5VT14/bNkrIlB5YcEAeWG8DqvCvG6svF76cWj3HZWepuZ8Wk6fPYcUutSl2/TCw5sOTAj8uB5VT14/bNkrIlB5YcEAfOzQYw9aJUG1z7PY+arRrShPjj8Xg0Gsnj5v/b9iYEF8oUPnm7cmmqD4dDuJErlsufCXb1XQ5LLn9O2H/iYXIOtCqeM9GjJhKOf2eCIGc8GvTv5EBoNQ7AOSfPUPjn/jk4GHz68HGv3/8puXE+pqpHDx5yQ+3nFrUmrYMPZZf0JnB+mjL3797b/7xfjjb30zS23JDBwYCR8lNy4xxsAIf//ceNLXXVgvXqhup6w2LTEM8GsJYPC8AeUISfuXbl8mdSnUttg4NBDksufybYazsih9Hz54Fdj6fV2gfmjR1WOJZcul3b/wNO+1aq2vjqfAAAAABJRU5ErkJggg=="
    }
   },
   "cell_type": "markdown",
   "id": "98b0439f",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)\n",
    "![image-2.png](attachment:image-2.png)\n",
    "![image-3.png](attachment:image-3.png)\n",
    "\n",
    "The performance of this algorithm is illustrated on a simulated dataset of 500 observations from $0.3N(0, 1) + 0.7N(2, 1)$. As described by Fig.7 through the sequence of simulated samples, the result of the experiment is that, after 8 iterations of the PMC algorithm, the simulated $\\mu$'s are concentrated around the mode of interest and the scales $\\nu_k$ (equal to .01, .05, .1 and .5) have been selected according to their relevance, that is, with large weights for the smallest values (as also described in Figure 14.8). While the second spurious mode is visited during the first iteration of the algorithm, the relatively small value of the posterior at this mode implies that the corresponding points are not resampled at the next iteration.\n",
    "\n",
    "**Fig. 14.7.** Representation of the log-posterior distribution via contours and of a sequence of PMC samples over the first 8 iterations. The sample of 500 observations was generated from $0.3N(0, 1) + 0.7N(2, 1)$ and the prior on $\\mu$ was a $N(1, 10)$ distribution on both means.\n",
    "\n",
    "###  Adaptativity in Sequential Algorithms\n",
    "\n",
    "A central feature of the PMC method is that the generality in the choice of the proposal distributions $q_t$ is due to the abandonment of the MCMC framework. Indeed, were it not for the importance resampling correction, a pointwise Metropolis-Hastings algorithm would produce a parallel MCMC sampler which simply converges to the target $\\pi^{\\otimes n}$ in distribution. Similarly, a samplewise Metropolis-Hastings algorithm, that is, a Metropolis-Hastings\n",
    "\n",
    "**Fig. 14.8.** Evolution of the cumulative weights of the four scales $\\nu_k - .5, .1, .05, .01$ for the mixture PMC algorithm over the first 8 iterations corresponding to Figure 14.7.\n",
    "\n",
    "algorithm aimed at the target distribution $\\pi^{\\otimes n}$, also produces an asymptotic approximation to this distribution, but its acceptance probability approximately decreases as a power of $n$. This difference is not simply a theoretical advantage since, in one example of Cappe et al. (2004), it actually occurs that a Metropolis-Hastings scheme based on the same proposal does not work well while a PMC algorithm produces correct answers.\n",
    "\n",
    "![image-4.png](attachment:image-4.png)\n",
    "![image-5.png](attachment:image-5.png)\n",
    "![image-6.png](attachment:image-6.png)\n",
    "\n",
    "**Example .7. (Continuation of Example.3)** For the stochastic volatility model (14.4), Celeux et al. (2003) consider a noninformative prior $\\pi(\\beta^2, \\varphi, \\sigma^2) = 1/(\\sigma\\beta)$ under the stationarity constraint $|\\varphi| < 1$. Posteriors on $\\beta^2$ and $\\sigma^2$ are both conjugate, conditional on the $z_t$'s, while the posterior distribution of $\\varphi$ is less conventional, but a standard proposal (Chib et al. 2002) is a truncated normal distribution on $]-1, 1[$ with mean and variance\n",
    "$$\\frac{(1+\\varphi^2)\\mu_t/\\sigma^2 + 0.5 \\exp(-\\mu_t)y_t^2(1+\\mu_t)/\\beta^2 - 0.5}{(1+\\varphi^2)/\\sigma^2 + 0.5 \\exp(-\\mu_t)y_t^2/\\beta^2}$$\n",
    "and variance\n",
    "$$1/\\left\\{ (1+\\varphi^2)/\\sigma^2 + 0.5 \\exp(-\\mu_t)y_t^2/\\beta^2 \\right\\}.$$\n",
    "There have been many proposals in the literature for simulating the $z_t$'s (see Celeux et al. 2003). For instance, one based on a Taylor expansion of the exponential is a normal distribution with mean\n",
    "$$\\sum_{t=2}^n \\frac{z_t z_{t-1}}{\\sigma^2} / \\sum_{t=2}^n \\frac{z_t^2}{\\sigma^2} \\quad \\text{and} \\quad \\sigma^2 / \\sum_{t=2}^n \\frac{z_t^2}{\\sigma^2}.$$\n",
    "where $\\mu_t = \\varphi (z_{t-1} + z_{t+1})/(1+\\varphi^2)$ is the conditional expectation of $z_t$ given $z_{t-1}, z_{t+1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0412b647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Mixture PMC Algorithm A.62 Demo (Core Python) ===\n",
      "Generated 200 data points from a mixture with true (mu1, mu2) = (0.0, 5.0)\n",
      "Starting Mixture PMC Algorithm A.62 (Core Python)...\n",
      "Iteration 1/50 (Initialization complete)\n",
      "  ESS: 1.4, Z_hat: 0.0000\n",
      "  ESS: 39.1, Z_hat: 0.0000\n",
      "  ESS: 139.4, Z_hat: 0.0000\n",
      "  ESS: 180.5, Z_hat: 0.0000\n",
      "  ESS: 186.9, Z_hat: 0.0000\n",
      "Iteration 6/50\n",
      "  ESS: 197.3, Z_hat: 0.0000\n",
      "  ESS: 190.7, Z_hat: 0.0000\n",
      "  ESS: 192.1, Z_hat: 0.0000\n",
      "  ESS: 176.6, Z_hat: 0.0000\n",
      "  ESS: 201.4, Z_hat: 0.0000\n",
      "Iteration 11/50\n",
      "  ESS: 188.1, Z_hat: 0.0000\n",
      "  ESS: 171.8, Z_hat: 0.0000\n",
      "  ESS: 187.0, Z_hat: 0.0000\n",
      "  ESS: 189.6, Z_hat: 0.0000\n",
      "  ESS: 193.1, Z_hat: 0.0000\n",
      "Iteration 16/50\n",
      "  ESS: 189.1, Z_hat: 0.0000\n",
      "  ESS: 194.1, Z_hat: 0.0000\n",
      "  ESS: 182.3, Z_hat: 0.0000\n",
      "  ESS: 186.0, Z_hat: 0.0000\n",
      "  ESS: 191.7, Z_hat: 0.0000\n",
      "Iteration 21/50\n",
      "  ESS: 188.0, Z_hat: 0.0000\n",
      "  ESS: 186.7, Z_hat: 0.0000\n",
      "  ESS: 183.3, Z_hat: 0.0000\n",
      "  ESS: 188.5, Z_hat: 0.0000\n",
      "  ESS: 183.4, Z_hat: 0.0000\n",
      "Iteration 26/50\n",
      "  ESS: 190.4, Z_hat: 0.0000\n",
      "  ESS: 196.9, Z_hat: 0.0000\n",
      "  ESS: 171.1, Z_hat: 0.0000\n",
      "  ESS: 199.1, Z_hat: 0.0000\n",
      "  ESS: 188.9, Z_hat: 0.0000\n",
      "Iteration 31/50\n",
      "  ESS: 192.8, Z_hat: 0.0000\n",
      "  ESS: 188.4, Z_hat: 0.0000\n",
      "  ESS: 168.5, Z_hat: 0.0000\n",
      "  ESS: 167.6, Z_hat: 0.0000\n",
      "  ESS: 210.9, Z_hat: 0.0000\n",
      "Iteration 36/50\n",
      "  ESS: 181.3, Z_hat: 0.0000\n",
      "  ESS: 200.5, Z_hat: 0.0000\n",
      "  ESS: 194.7, Z_hat: 0.0000\n",
      "  ESS: 193.1, Z_hat: 0.0000\n",
      "  ESS: 193.0, Z_hat: 0.0000\n",
      "Iteration 41/50\n",
      "  ESS: 170.0, Z_hat: 0.0000\n",
      "  ESS: 190.3, Z_hat: 0.0000\n",
      "  ESS: 173.5, Z_hat: 0.0000\n",
      "  ESS: 186.8, Z_hat: 0.0000\n",
      "  ESS: 183.3, Z_hat: 0.0000\n",
      "Iteration 46/50\n",
      "  ESS: 168.2, Z_hat: 0.0000\n",
      "  ESS: 183.2, Z_hat: 0.0000\n",
      "  ESS: 170.6, Z_hat: 0.0000\n",
      "  ESS: 178.3, Z_hat: 0.0000\n",
      "  ESS: 175.4, Z_hat: 0.0000\n",
      "PMC completed!\n",
      "\n",
      "True (mu1, mu2): (0.0, 5.0)\n",
      "Estimated (mu1, mu2): (-0.000, 0.005)\n",
      "Final ESS: 175.4\n",
      "Final Normalizing Constant Estimate: 0.0000\n",
      "Final zeta_k distribution for scales [0.1, 0.5, 1.0, 5.0, 10.0]:\n",
      "  nu_1=0.1: 1.0000\n",
      "  nu_2=0.5: 0.0000\n",
      "  nu_3=1.0: 0.0000\n",
      "  nu_4=5.0: 0.0000\n",
      "  nu_5=10.0: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "# --- Basic Vector Operations for 2D (Core Python) ---\n",
    "def vector_add(v1, v2):\n",
    "    return [v1[i] + v2[i] for i in range(len(v1))]\n",
    "\n",
    "def vector_sub(v1, v2):\n",
    "    return [v1[i] - v2[i] for i in range(len(v1))]\n",
    "\n",
    "def scalar_mul_vector(scalar, v):\n",
    "    return [scalar * v_i for v_i in v]\n",
    "\n",
    "def vector_dot_product(v1, v2):\n",
    "    return sum(v1[i] * v2[i] for i in range(len(v1)))\n",
    "\n",
    "def squared_euclidean_distance(v1, v2):\n",
    "    diff = vector_sub(v1, v2)\n",
    "    return vector_dot_product(diff, diff)\n",
    "\n",
    "# --- Replacements for common NumPy/SciPy functions (from previous implementation) ---\n",
    "\n",
    "def custom_logsumexp(log_x_list):\n",
    "    if not log_x_list:\n",
    "        return -float('inf')\n",
    "    max_log_x = log_x_list[0]\n",
    "    for x_val in log_x_list:\n",
    "        if x_val > max_log_x:\n",
    "            max_log_x = x_val\n",
    "    if max_log_x == -float('inf'):\n",
    "        return -float('inf')\n",
    "    sum_exp = 0.0\n",
    "    for x_val in log_x_list:\n",
    "        sum_exp += math.exp(x_val - max_log_x)\n",
    "    return max_log_x + math.log(sum_exp)\n",
    "\n",
    "def custom_normal_sampler(mean, std, size=1):\n",
    "    if std < 0:\n",
    "        raise ValueError(\"Standard deviation cannot be negative.\")\n",
    "    samples = []\n",
    "    i = 0\n",
    "    while i < size:\n",
    "        u1 = random.random()\n",
    "        u2 = random.random()\n",
    "        z0 = math.sqrt(-2 * math.log(u1)) * math.cos(2 * math.pi * u2)\n",
    "        samples.append(z0 * std + mean)\n",
    "        i += 1\n",
    "    if size == 1:\n",
    "        return samples[0]\n",
    "    return samples\n",
    "\n",
    "def custom_mean(data):\n",
    "    if not data:\n",
    "        return 0.0\n",
    "    return sum(data) / len(data)\n",
    "\n",
    "def custom_sum(data):\n",
    "    return sum(data)\n",
    "\n",
    "def custom_variance(data, weights=None):\n",
    "    if not data:\n",
    "        return 0.0\n",
    "    if weights:\n",
    "        weighted_sum = sum(data[i] * weights[i] for i in range(len(data)))\n",
    "        total_weights = sum(weights)\n",
    "        if total_weights == 0: return 0.0\n",
    "        mean = weighted_sum / total_weights\n",
    "        sum_sq_diff_weighted = sum(weights[i] * (data[i] - mean)**2 for i in range(len(data)))\n",
    "        return sum_sq_diff_weighted / total_weights\n",
    "    else:\n",
    "        mean = custom_mean(data)\n",
    "        sum_sq_diff = sum((x - mean)**2 for x in data)\n",
    "        return sum_sq_diff / len(data)\n",
    "\n",
    "def custom_std(data, weights=None):\n",
    "    return math.sqrt(custom_variance(data, weights))\n",
    "\n",
    "def custom_average(data, weights):\n",
    "    if not data or not weights or len(data) != len(weights):\n",
    "        raise ValueError(\"Data and weights must be non-empty and of same length.\")\n",
    "    weighted_sum = sum(data[i] * weights[i] for i in range(len(data)))\n",
    "    total_weights = sum(weights)\n",
    "    if total_weights == 0: return 0.0\n",
    "    return weighted_sum / total_weights\n",
    "\n",
    "def custom_random_choice(items, size, p=None):\n",
    "    if p is None:\n",
    "        return random.choices(items, k=size)\n",
    "    else:\n",
    "        chosen = []\n",
    "        cumulative_probs = [0.0] * len(p)\n",
    "        current_sum = 0.0\n",
    "        for i, prob in enumerate(p):\n",
    "            current_sum += prob\n",
    "            cumulative_probs[i] = current_sum\n",
    "        for _ in range(size):\n",
    "            r = random.random()\n",
    "            for i, cum_prob in enumerate(cumulative_probs):\n",
    "                if r <= cum_prob:\n",
    "                    chosen.append(items[i])\n",
    "                    break\n",
    "        return chosen\n",
    "\n",
    "# --- New 2D Multivariate Normal PDF and Sampler (Spherical Covariance) ---\n",
    "\n",
    "def multivariate_normal_log_pdf_2D_spherical(x_vec, mean_vec, variance):\n",
    "    \"\"\"\n",
    "    Calculates the log PDF of a 2D spherical multivariate normal distribution.\n",
    "    phi(mu; xi, nu) where x_vec=mu, mean_vec=xi, variance=nu.\n",
    "    Assumes covariance matrix is diag(variance, variance).\n",
    "    \"\"\"\n",
    "    if variance <= 0:\n",
    "        return -float('inf')\n",
    "    \n",
    "    D = 2 # Dimension is fixed at 2\n",
    "    \n",
    "    # log( (1 / ( (2*pi)^D * det(Sigma) )^0.5 ) )\n",
    "    # det(Sigma) = (variance)^D\n",
    "    log_normalization = -0.5 * D * math.log(2 * math.pi) - 0.5 * D * math.log(variance)\n",
    "    \n",
    "    # -0.5 * (x - mu).T @ Sigma_inv @ (x - mu)\n",
    "    # Sigma_inv = (1/variance) * I_2\n",
    "    sq_dist = squared_euclidean_distance(x_vec, mean_vec)\n",
    "    exponent = -0.5 * (1.0 / variance) * sq_dist\n",
    "    \n",
    "    return log_normalization + exponent\n",
    "\n",
    "def multivariate_normal_sampler_2D_spherical(mean_vec, variance, size=1):\n",
    "    \"\"\"\n",
    "    Generates samples from a 2D spherical multivariate normal distribution.\n",
    "    Assumes covariance matrix is diag(variance, variance).\n",
    "    \"\"\"\n",
    "    if variance < 0:\n",
    "        raise ValueError(\"Variance cannot be negative.\")\n",
    "    \n",
    "    std = math.sqrt(variance)\n",
    "    samples = []\n",
    "    for _ in range(size):\n",
    "        # Sample two independent univariate normals\n",
    "        z1 = custom_normal_sampler(0, 1)\n",
    "        z2 = custom_normal_sampler(0, 1)\n",
    "        \n",
    "        sample_x = mean_vec[0] + z1 * std\n",
    "        sample_y = mean_vec[1] + z2 * std\n",
    "        samples.append([sample_x, sample_y])\n",
    "        \n",
    "    if size == 1:\n",
    "        return samples[0]\n",
    "    return samples\n",
    "\n",
    "# --- Algorithm A.62 Mixture PMC Implementation ---\n",
    "\n",
    "class MixturePMC:\n",
    "    \"\"\"\n",
    "    Implementation of Algorithm A.62 (Mixture PMC Algorithm) in core Python.\n",
    "    Designed for a 2D parameter space (mu1, mu2) and 1D data x.\n",
    "    Assumes spherical covariance for proposals.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_x, p_mixture, K_scales, epsilon=1e-6, n_particles=1000, max_iterations=50):\n",
    "        self.data_x = list(data_x) # Observed data (1D list)\n",
    "        self.p_mixture = p_mixture # Known mixture weight (p)\n",
    "        \n",
    "        self.K_scales = list(K_scales) # List of K possible variances (nu_k)\n",
    "        self.epsilon = epsilon # Small constant for zeta_k update\n",
    "        self.n_particles = n_particles\n",
    "        self.max_iterations = max_iterations\n",
    "        \n",
    "        # Step 0: Initialization\n",
    "        self.zeta_k = [1.0 / len(self.K_scales)] * len(self.K_scales) # Initialize zeta_k to 1/K\n",
    "        \n",
    "        # History storage\n",
    "        self.particles_history = [] # Stores lists of 2-element lists [mu1, mu2]\n",
    "        self.weights_history = [] # Normalized weights\n",
    "        self.log_weights_history = [] # Log of normalized weights\n",
    "        self.raw_log_weights_history = [] # Log of UNNORMALIZED weights (for Z estimate)\n",
    "        self.scale_choices_history = [] # To track which nu_k was used for each particle\n",
    "        self.normalizing_constant_estimates = []\n",
    "        self.ess_history = []\n",
    "        \n",
    "        # Parameters for the target posterior (Example 5.19 normal mixture model)\n",
    "        # pi(mu1, mu2 | x) proportional to prior * likelihood\n",
    "        # Assuming prior is N(theta, sigma_prior_sq / lambda) for each mu\n",
    "        # For Example 5.19, the standard deviation of components is 1.0 (sigma_noise_sq = 1.0)\n",
    "        self.prior_theta = 0.0 # Placeholder for prior mean\n",
    "        self.prior_lambda = 1.0 # Placeholder for prior precision/strength\n",
    "        self.prior_sigma_sq = 100.0 # Placeholder for prior variance (large for diffuse prior)\n",
    "        self.noise_sigma_sq = 1.0 # From Example 5.19: N(mu, 1) means variance is 1\n",
    "\n",
    "    def target_log_pdf(self, mu_vec):\n",
    "        \"\"\"\n",
    "        Calculates the log-posterior density pi(mu1, mu2 | x) for the mixture model.\n",
    "        Assumes mu_vec = [mu1, mu2]\n",
    "        \"\"\"\n",
    "        mu1, mu2 = mu_vec[0], mu_vec[1]\n",
    "\n",
    "        # Prior term: exp(-lambda(theta - mu1)^2 / 2*sigma_prior_sq) * exp(-lambda(theta - mu2)^2 / 2*sigma_prior_sq)\n",
    "        # Log prior for N(prior_theta, prior_sigma_sq / prior_lambda)\n",
    "        log_prior_mu1 = multivariate_normal_log_pdf_2D_spherical([mu1], [self.prior_theta], self.prior_sigma_sq / self.prior_lambda)\n",
    "        log_prior_mu2 = multivariate_normal_log_pdf_2D_spherical([mu2], [self.prior_theta], self.prior_sigma_sq / self.prior_lambda)\n",
    "        log_prior = log_prior_mu1 + log_prior_mu2\n",
    "        \n",
    "        # Likelihood term: Product_i { p * N(xi | mu1, noise_sigma_sq) + (1-p) * N(xi | mu2, noise_sigma_sq) }\n",
    "        log_likelihood_sum_terms = []\n",
    "        for x_i in self.data_x:\n",
    "            # log( p * N(x_i | mu1, 1) + (1-p) * N(x_i | mu2, 1) )\n",
    "            \n",
    "            # log(p) + log(N(x_i | mu1, 1))\n",
    "            log_comp1 = math.log(self.p_mixture) + multivariate_normal_log_pdf_2D_spherical([x_i], [mu1], self.noise_sigma_sq)\n",
    "            \n",
    "            # log(1-p) + log(N(x_i | mu2, 1))\n",
    "            log_comp2 = math.log(1.0 - self.p_mixture) + multivariate_normal_log_pdf_2D_spherical([x_i], [mu2], self.noise_sigma_sq)\n",
    "            \n",
    "            log_likelihood_sum_terms.append(custom_logsumexp([log_comp1, log_comp2]))\n",
    "            \n",
    "        log_likelihood = custom_sum(log_likelihood_sum_terms) # Sum of log-terms for product\n",
    "        \n",
    "        return log_prior + log_likelihood\n",
    "\n",
    "    def initial_proposal(self, size):\n",
    "        \"\"\"\n",
    "        Generates initial particles from an arbitrary distribution.\n",
    "        Here, a broad 2D spherical normal.\n",
    "        \"\"\"\n",
    "        return multivariate_normal_sampler_2D_spherical([0.0, 0.0], 10.0, size) # Mean 0, Variance 10\n",
    "\n",
    "    def initial_proposal_log_pdf(self, mu_vec):\n",
    "        \"\"\"\n",
    "        Log PDF of the initial proposal.\n",
    "        \"\"\"\n",
    "        return multivariate_normal_log_pdf_2D_spherical(mu_vec, [0.0, 0.0], 10.0)\n",
    "\n",
    "    def compute_weighted_proposal_log_pdf(self, mu_vec, parent_mu_vec):\n",
    "        \"\"\"\n",
    "        Computes the denominator in the weight calculation (Step 1.c):\n",
    "        sum_k { zeta_k * phi(mu_vec; parent_mu_vec, nu_k) }\n",
    "        This is log(sum_k { zeta_k * phi(...) })\n",
    "        \"\"\"\n",
    "        log_terms = []\n",
    "        for k in range(len(self.K_scales)):\n",
    "            zeta = self.zeta_k[k]\n",
    "            nu_k = self.K_scales[k]\n",
    "            \n",
    "            if zeta <= 0: # Avoid log(0)\n",
    "                log_terms.append(-float('inf'))\n",
    "                continue\n",
    "\n",
    "            # log(zeta_k) + log(phi(mu_vec; parent_mu_vec, nu_k))\n",
    "            log_phi = multivariate_normal_log_pdf_2D_spherical(mu_vec, parent_mu_vec, nu_k)\n",
    "            log_terms.append(math.log(zeta) + log_phi)\n",
    "            \n",
    "        return custom_logsumexp(log_terms)\n",
    "\n",
    "    def compute_importance_weights(self, particles, parent_particles_for_each_new_particle, scales_used_for_each_new_particle):\n",
    "        \"\"\"\n",
    "        Compute importance weights: ω_i = π(z_i) / q_t(z_i)\n",
    "        Here, q_t(z_i) = sum_k { zeta_k * phi(z_i; z_i_parent, nu_k) }\n",
    "        z_i_parent is the parent particle from which z_i was drawn.\n",
    "        \"\"\"\n",
    "        n = len(particles)\n",
    "        log_weights = [0.0] * n\n",
    "        raw_log_weights = [0.0] * n # Store unnormalized for Z estimate\n",
    "\n",
    "        for i in range(n):\n",
    "            current_particle = particles[i]\n",
    "            parent_particle = parent_particles_for_each_new_particle[i]\n",
    "            \n",
    "            log_target = self.target_log_pdf(current_particle)\n",
    "            log_proposal_denominator = self.compute_weighted_proposal_log_pdf(current_particle, parent_particle)\n",
    "            \n",
    "            raw_log_weights[i] = log_target - log_proposal_denominator\n",
    "        \n",
    "        # Normalize log_weights\n",
    "        log_sum_raw_weights = custom_logsumexp(raw_log_weights)\n",
    "        normalized_log_weights = [lw - log_sum_raw_weights for lw in raw_log_weights]\n",
    "        \n",
    "        weights = [math.exp(lw) for lw in normalized_log_weights]\n",
    "        \n",
    "        return weights, normalized_log_weights, raw_log_weights\n",
    "\n",
    "    def resample(self, particles, weights):\n",
    "        \"\"\"\n",
    "        Resample particles according to weights, and keep track of parent indices.\n",
    "        Returns resampled particles and their original indices.\n",
    "        \"\"\"\n",
    "        n = len(particles)\n",
    "        # Items to choose from are the indices of the particles\n",
    "        original_indices = list(range(n))\n",
    "        \n",
    "        # Use custom_random_choice for weighted sampling of indices\n",
    "        resampled_indices = custom_random_choice(original_indices, size=n, p=weights)\n",
    "        \n",
    "        resampled_particles = []\n",
    "        for idx in resampled_indices:\n",
    "            resampled_particles.append(particles[idx])\n",
    "            \n",
    "        return resampled_particles, resampled_indices\n",
    "        \n",
    "    def estimate_integral(self, func, particles, weights):\n",
    "        \"\"\"\n",
    "        Estimate E[h(X)] using importance sampling.\n",
    "        h(X) is a function of the 2D particle vector.\n",
    "        \"\"\"\n",
    "        weighted_values = []\n",
    "        for i in range(len(particles)):\n",
    "            weighted_values.append(weights[i] * func(particles[i]))\n",
    "            \n",
    "        return custom_mean(weighted_values)\n",
    "        \n",
    "    def run_pmc(self, verbose=True):\n",
    "        \"\"\"\n",
    "        Run Population Monte Carlo Algorithm A.62\n",
    "        \"\"\"\n",
    "        if verbose:\n",
    "            print(\"Starting Mixture PMC Algorithm A.62 (Core Python)...\")\n",
    "        \n",
    "        # Step 0: Initialization is done in __init__ for zeta_k\n",
    "        \n",
    "        # Initialize particles for t=0 from initial proposal (arbitrary distribution)\n",
    "        current_particles = self.initial_proposal(self.n_particles)\n",
    "        # For t=0, parent particles are just themselves, and scales are not yet chosen\n",
    "        # For initial weights, use initial proposal's log_pdf directly\n",
    "        initial_log_target = [self.target_log_pdf(p) for p in current_particles]\n",
    "        initial_log_proposal = [self.initial_proposal_log_pdf(p) for p in current_particles]\n",
    "        \n",
    "        initial_raw_log_weights = [initial_log_target[i] - initial_log_proposal[i] for i in range(self.n_particles)]\n",
    "        log_sum_initial_raw = custom_logsumexp(initial_raw_log_weights)\n",
    "        initial_normalized_log_weights = [lw - log_sum_initial_raw for lw in initial_raw_log_weights]\n",
    "        initial_weights = [math.exp(lw) for lw in initial_normalized_log_weights]\n",
    "\n",
    "        self.particles_history.append(current_particles)\n",
    "        self.weights_history.append(initial_weights)\n",
    "        self.log_weights_history.append(initial_normalized_log_weights)\n",
    "        self.raw_log_weights_history.append(initial_raw_log_weights) # Store raw weights\n",
    "        \n",
    "        # For t=0, ESS and Z estimate\n",
    "        sum_sq_weights_t0 = custom_sum([w**2 for w in initial_weights])\n",
    "        ess_t0 = 1.0 / sum_sq_weights_t0 if sum_sq_weights_t0 != 0 else 0.0\n",
    "        self.ess_history.append(ess_t0)\n",
    "        \n",
    "        # Z estimate for t=0 is mean of raw (unnormalized) importance ratios\n",
    "        self.normalizing_constant_estimates.append(custom_mean([math.exp(lw) for lw in initial_raw_log_weights]))\n",
    "\n",
    "        # Track which nu_k was used for each particle in current_particles to update zeta_k later\n",
    "        # For t=0, there's no \"parent\" choice based on zeta_k, so we'll just assign a dummy or average\n",
    "        self.scale_choices_history.append([0] * self.n_particles) # Store index of nu_k used\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Iteration 1/{self.max_iterations} (Initialization complete)\")\n",
    "            print(f\"  ESS: {self.ess_history[-1]:.1f}, Z_hat: {self.normalizing_constant_estimates[-1]:.4f}\")\n",
    "        \n",
    "        # Loop for subsequent iterations (t=1 to max_iterations-1)\n",
    "        for t in range(1, self.max_iterations):\n",
    "            if verbose and t % 5 == 0:\n",
    "                print(f\"Iteration {t+1}/{self.max_iterations}\")\n",
    "            \n",
    "            # Resample from previous iteration's particles and weights\n",
    "            # This implements the \"Resample the mu_t^(i)'s using the weights\" part at the end of previous iteration.\n",
    "            # So, current_particles are mu_t from previous step, resampled according to their weights.\n",
    "            # This makes them \"parents\" for the new generation.\n",
    "            parent_particles, parent_indices_resampled = self.resample(current_particles, initial_weights)\n",
    "            \n",
    "            # To update zeta_k later, we need to know for each parent particle which scale it originally came from.\n",
    "            # This information isn't directly available in a simple resampling step.\n",
    "            # The algorithm implies that `r_k` is the count of *resampled* parents that were *originally generated*\n",
    "            # using scale nu_k. We need to preserve this info through resampling.\n",
    "            # Let's augment `parent_indices_resampled` to get the original scale choice.\n",
    "            parent_original_scale_choices = [self.scale_choices_history[-1][idx] for idx in parent_indices_resampled]\n",
    "            \n",
    "            # Step 1: Update\n",
    "            new_particles = [] # mu_{t+1}^{(i)}\n",
    "            new_parent_references = [] # Store mu_t^{(i')} for each new particle\n",
    "            scales_used_for_new_particles = [] # Store index of nu_k used for each new particle\n",
    "\n",
    "            # For zeta_k update later: count how many particles were generated from each nu_k\n",
    "            # and survived resampling. We already have `parent_original_scale_choices`.\n",
    "            \n",
    "            # Sample new particles (mu_{t+1}^{(i)}) based on current parents (mu_t^{(i')}) and chosen scales\n",
    "            for i in range(self.n_particles):\n",
    "                parent_mu_i_prime = parent_particles[i] # This is mu_t^{(i')}\n",
    "\n",
    "                # a. with probability zeta_k, take sigma_{t+1}^{(i)} = nu_k\n",
    "                # Choose scale_idx based on current zeta_k probabilities\n",
    "                scale_idx_chosen = custom_random_choice(list(range(len(self.K_scales))), size=1, p=self.zeta_k)[0]\n",
    "                selected_nu_k = self.K_scales[scale_idx_chosen]\n",
    "                \n",
    "                # b. generate mu_{t+1}^{(i)} ~ N_2(mu_t^{(i')}, sigma_{t+1}^{(i)} I_2)\n",
    "                sampled_mu = multivariate_normal_sampler_2D_spherical(parent_mu_i_prime, selected_nu_k)\n",
    "                \n",
    "                new_particles.append(sampled_mu)\n",
    "                new_parent_references.append(parent_mu_i_prime)\n",
    "                scales_used_for_new_particles.append(scale_idx_chosen) # Store index of nu_k used\n",
    "\n",
    "            # c. Compute weights\n",
    "            # This requires new_particles, their parent_mu_i_prime, and the proposal denominator.\n",
    "            current_weights, current_log_weights, current_raw_log_weights = \\\n",
    "                self.compute_importance_weights(new_particles, new_parent_references, scales_used_for_new_particles)\n",
    "            \n",
    "            # Store results for this iteration\n",
    "            self.particles_history.append(new_particles)\n",
    "            self.weights_history.append(current_weights)\n",
    "            self.log_weights_history.append(current_log_weights)\n",
    "            self.raw_log_weights_history.append(current_raw_log_weights)\n",
    "            self.scale_choices_history.append(scales_used_for_new_particles) # Store for next iter's zeta_k update\n",
    "\n",
    "            # Compute diagnostics\n",
    "            sum_sq_weights = custom_sum([w**2 for w in current_weights])\n",
    "            ess = 1.0 / sum_sq_weights if sum_sq_weights != 0 else 0.0\n",
    "            self.ess_history.append(ess)\n",
    "            \n",
    "            # Z estimate: Cumulative mean of raw importance ratios\n",
    "            all_raw_log_weights = []\n",
    "            for item in self.raw_log_weights_history:\n",
    "                all_raw_log_weights.extend(item)\n",
    "            \n",
    "            cumulative_raw_weights = [math.exp(lw) for lw in all_raw_log_weights]\n",
    "            self.normalizing_constant_estimates.append(custom_mean(cumulative_raw_weights))\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"  ESS: {self.ess_history[-1]:.1f}, Z_hat: {self.normalizing_constant_estimates[-1]:.4f}\")\n",
    "\n",
    "            # Update the zeta_k's for the next iteration (after resampling has happened for current iteration's weights)\n",
    "            # This is the \"resample ... Update the zeta_k's\" step.\n",
    "            # For this, we need the *resampled* particles from the current iteration, and which scale they came from.\n",
    "            \n",
    "            # First, resample particles based on `current_weights`\n",
    "            resampled_particles_current_iter, resampled_indices_current_iter = self.resample(new_particles, current_weights)\n",
    "            \n",
    "            # Determine which scales contributed to the resampled particles\n",
    "            # This is `r_k`: count of resampled particles that were generated using `nu_k`\n",
    "            # For this, we use `scales_used_for_new_particles` which stores the scale_idx for `new_particles`.\n",
    "            # We then get the scales used for the `resampled_particles_current_iter`.\n",
    "            \n",
    "            r_k_counts = [0] * len(self.K_scales)\n",
    "            for resampled_idx in resampled_indices_current_iter:\n",
    "                original_scale_idx = scales_used_for_new_particles[resampled_idx]\n",
    "                r_k_counts[original_scale_idx] += 1\n",
    "            \n",
    "            # Update zeta_k: zeta_k prop to r_k + epsilon\n",
    "            new_zeta_k_raw = [r_k + self.epsilon for r_k in r_k_counts]\n",
    "            sum_new_zeta_k_raw = custom_sum(new_zeta_k_raw)\n",
    "            self.zeta_k = [val / sum_new_zeta_k_raw for val in new_zeta_k_raw]\n",
    "            \n",
    "            # Prepare for next iteration: current_particles become the new_particles\n",
    "            current_particles = new_particles # The new generation of particles (before resampling for next loop)\n",
    "            initial_weights = current_weights # Their weights (will be used for next iteration's resampling)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"PMC completed!\")\n",
    "        \n",
    "        return self.particles_history, self.weights_history\n",
    "        \n",
    "    def get_final_sample(self):\n",
    "        \"\"\"\n",
    "        Get final weighted sample\n",
    "        \"\"\"\n",
    "        if not self.particles_history:\n",
    "            raise ValueError(\"No samples generated. Run PMC first.\")\n",
    "            \n",
    "        return self.particles_history[-1], self.weights_history[-1]\n",
    "        \n",
    "    def estimate_expectation(self, func):\n",
    "        \"\"\"\n",
    "        Estimate E[h(X)] using final sample.\n",
    "        func: A function that takes a 2D particle [mu1, mu2] and returns a scalar.\n",
    "        \"\"\"\n",
    "        particles, weights = self.get_final_sample()\n",
    "        return self.estimate_integral(func, particles, weights)\n",
    "\n",
    "\n",
    "# --- Demo Function ---\n",
    "def demo_mixture_pmc():\n",
    "    \"\"\"Demonstrate Mixture PMC Algorithm A.62\"\"\"\n",
    "    print(\"=== Mixture PMC Algorithm A.62 Demo (Core Python) ===\")\n",
    "    random.seed(42) # Set seed for reproducibility\n",
    "\n",
    "    # Define synthetic data (Example 5.19 normal mixture: 0.3*N(0,1) + 0.7*N(5,1))\n",
    "    # We need to simulate observations 'x' from this mixture.\n",
    "    true_mu1 = 0.0\n",
    "    true_mu2 = 5.0\n",
    "    true_p = 0.3 # Known p\n",
    "    noise_std = 1.0 # Standard deviation for components N(mu, 1)\n",
    "\n",
    "    n_data_points = 200\n",
    "    data_x = []\n",
    "    for _ in range(n_data_points):\n",
    "        if random.random() < true_p:\n",
    "            data_x.append(custom_normal_sampler(true_mu1, noise_std))\n",
    "        else:\n",
    "            data_x.append(custom_normal_sampler(true_mu2, noise_std))\n",
    "    \n",
    "    print(f\"Generated {n_data_points} data points from a mixture with true (mu1, mu2) = ({true_mu1}, {true_mu2})\")\n",
    "\n",
    "    # Define K scales (nu_k)\n",
    "    K_scales = [0.1, 0.5, 1.0, 5.0, 10.0] # Variances for proposals\n",
    "\n",
    "    # Run PMC\n",
    "    pmc = MixturePMC(\n",
    "        data_x=data_x,\n",
    "        p_mixture=true_p,\n",
    "        K_scales=K_scales,\n",
    "        n_particles=1000,\n",
    "        max_iterations=50\n",
    "    )\n",
    "    \n",
    "    pmc.run_pmc(verbose=True)\n",
    "    \n",
    "    # Estimate posterior means of mu1 and mu2\n",
    "    estimated_mu1 = pmc.estimate_expectation(lambda mu_vec: mu_vec[0])\n",
    "    estimated_mu2 = pmc.estimate_expectation(lambda mu_vec: mu_vec[1])\n",
    "\n",
    "    print(f\"\\nTrue (mu1, mu2): ({true_mu1}, {true_mu2})\")\n",
    "    print(f\"Estimated (mu1, mu2): ({estimated_mu1:.3f}, {estimated_mu2:.3f})\")\n",
    "    \n",
    "    # Print final ESS and Z_hat\n",
    "    print(f\"Final ESS: {pmc.ess_history[-1]:.1f}\")\n",
    "    print(f\"Final Normalizing Constant Estimate: {pmc.normalizing_constant_estimates[-1]:.4f}\")\n",
    "\n",
    "    # Print final zeta_k distribution\n",
    "    print(f\"Final zeta_k distribution for scales {K_scales}:\")\n",
    "    for k_idx, zeta_val in enumerate(pmc.zeta_k):\n",
    "        print(f\"  nu_{k_idx+1}={K_scales[k_idx]:.1f}: {zeta_val:.4f}\")\n",
    "\n",
    "    return pmc\n",
    "\n",
    "# --- Main execution block ---\n",
    "if __name__ == \"__main__\":\n",
    "    pmc_instance = demo_mixture_pmc()\n",
    "\n",
    "    # You could add more analysis here, e.g.,\n",
    "    # Plotting is not possible without matplotlib.\n",
    "    # print(\"\\nNormalizing constant evolution:\")\n",
    "    # for i, z_est in enumerate(pmc_instance.normalizing_constant_estimates):\n",
    "    #     print(f\"Iter {i+1}: {z_est:.4f}\")"
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "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"
    },
    "image-3.png": {
     "image/png": "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"
    },
    "image-4.png": {
     "image/png": "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"
    },
    "image-5.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVYAAAAQCAIAAADCu8ARAAAKd0lEQVR4Ae2ZMW8aSxeG809Aor1XV7ZkJYqVypacKI2lSCB6WzaYyna5QjZKDdQJtrSUQMcgef8A28QdFNuCqJaC/QM7X/FI750sdq7j5LtfPoUoxTA758w57zlz5j3jF3bzb4PABoHfGIEXv7HvG9c3CGwQsC/SNHVhcH9+79ha+70i7vqNuALhwvLYeAPXd8HlwriBzoVuwwKExmawQeB3RGBTAn7HqG98fgYC89n8GVL/E5HpZBpF0RO3/qoRWMaxGQ4lmabpMo7Dcfht4jQyplap8v/stFKrVJdx/G2Rru+3m63MmszPNE3Zen3etVDjJy5zCaE7dsWjKFosFtLsLnts7IprvIzjKIoeE3HnJcKm7qfMOByH30A4iqJCLn//5f4fjbfWEiwC97HRQKRWqZ6dVoggVnV9v1aphuMQS+qeVy6WapVq59Pnru//o8EPWvJ0f13xru+7hrmf/nFshkOl0zN2PzuthOMQ39fFw3FYyOUFkbV2GceCNLM+8zMTX2SBd90pN6OWcdxutjLBQqTdbO2+fLUuzkxmx79ZQOPq+q8//qxVqqybz+Z1z/vrjz85q1L34KBcLAnf286Nxg8uttYGd0G5WHrwa7JKVG5Pjo6nk+mDy/6rk7edm7rnWWvns/kzDAjuAsybTqYnR8c/19RysRTcBRmrtKO1tlwsPf0GKOTymKfkJpsHvb7MfvN6VzlweX6hT+1m67EgSvbnDtrNlnLjiZqFTNf3NX6irJa1my1SOhyHjatrzWsALNPJtO55Sv5apfq91kphu9lSedVkOA5Pjo7dWEwn02UcK8dIWmttOA4P9vYl+O3B3yWA7FEJQKxcLGnLbyhSCRgZY63NJCiC89lc6ITjkOxRUU9WCctUQSAgzLvjKIrCcZisEmnLGMYnac58HRnTbrYetFArw3HIKbo8v7jt3DBOVslt56bdbMlUrZ9OpjJmOpmCRrJKppOpNnLdl6AGfNVizXMn4C+T66cuWSXv374LxyEJVy6WgEv5F47Dx1xWCRgZ89cff5I97Wbr/dt3bNduthpX1+RAOA41z9f18wD4cgSrZBtfM1C4ePIpWSWgPTIGkUGvr7hTl/XTBT+ze7vZujy/mE6m2peyzgHjsiFwLsIu+Ky/PL+Qv6oj4TjEzXAcvnm9G45DqqcWjIxRVkina+2g1x/0+iSkggUCjatrjpIEGbSbLZ1HxaJcLE0n08vzi4O9fUWKq+K2c+PCm9HGz68agXKxdHZa0bo0TVUCMuTBXUPtgBxKvO55jOH8Zjisex4tAwyfVP5weNhutqIo2tnaDsfhYrHY2do+2NsfGbNYLA729kH27LSC7DKO77/c72xtg8WHw0NZAr9axnGtUh0ZI+bWbrbSNMUM5q21tUo1iiIxYeqFfBQZLhdLdc+DV1PgF4sFrLhcLH1sNOqe1/X9uudByay1I2N2trbNcLiM467vl4sl/MX9D4eHyzg+2NtHnBs7iqK654E27siScBy6vn9sNPDdXQZ6nU+fKVUEkV2stYvFAqhrlarb3QBXIZcfGQMsyh4zHB7s7aPtY6OhtDs7reieeYzN7mxt33+5ByJrLQaPjCkXS2BysLcPaLsvX1GqCrn82WmFBKh7nhkO6XRGxhRyecBx84Fm52OjMTKGVOl8+ozx7u7LOD47rVCOl3FMppEewEIO7GxtS9WDTtU9T90c5XUZx7svX2GYtRa4qLMfDg917DufPmtMQDOpsozjQi6/WCxo7lBVLpaAq/Pps3Jb+UAs6NAJK2kTjsORMToOFCMysOv7EnfTRuOfyQLmszkkIlklg14fKsL9o9umcXVN+cQBSiBFBLxEujT55vUu5gZ3wW3nhnnqutQKrMvzC/RAkAa9PiWc25s6BYMF98vzi+AuyFTKdrOFI64xhVyeAGAP2Tno9aeTaXAXBHeBjME1blTGcqHr+9AcWQU+79++6/q+MkbuSND1XV810I6AwwXCZK1SpY6TWxJhUMjlg7tArAebR8bcdm5uOzfBXRBFkUpArVIV58zo0c9Br89h4EySzRDDQi6frBIRxrrnQSIKufwyjuez+bqz7Wbr5OhYsEhWUCOiXdZ3xwyKfrvZgsdhbblYwh4uAOmUL1qmGba7PL8AUrJxZIwbTS1WHdTMY6kiUryztQ2JEOaSZaB5ieiYqI4QRNwhFhklmZ8vXGbLCXFXiAVYa+Fm7leNFRtmaBe5wzlFwhdWKQceKwGcSdRKNrgLwJrkptTJBgayZBnHBOz923c8nLjHA3cEaEZJpgRwH8oMbFO+3nZuLs8v5rM5Kc4uEEi5Kdmu71OkSE0MSFZJcBdQmDLFSIIZ3zMGA4jbCMiMWqWqY7DeHEm/FHKfJKtETwBCKYoiec16aeYnLcnIGNxJVokOZ7JKCrn8fDZXgIDCWitCK2Pk7DKO3799J2otWa3EcXZ5cHc9H4CDWwLevN6lBGC8dAoKBqp6PATQ6LlI1j2PWnBydBxFkSj9ztZ2RtVjqeLmiS5Cl3BJj2JhrVUsysUS7QP3Fr0G4yeVAC43GOzB3v7uy1fcIfx1AMrKU2e72co8e4o46YZJ0xSaZ63tfPq8s7XN+dl9+QrfDvb2YT4EzwyHpBHRTdO03WxBTcVwapUqf6eAS6dpCr9YLwEi/OwOiHXPg7ZRHSFL7WYLB90kFl8Sq6dp5GkXw3CQA8Z6LMcYtO1sbWMJoU3TVBfCh8NDWkTaEyLKqcN34JIlGd/F6skJLSsXS/df7nlAOtjbp3PZ2dpexrFE2s1WphFYLBbKe6kaGQPa9FNYhV84oh7VDIcaIy5/8avdbJnhkEB3fZ/GELhg5koJxEEJhEfGsMZae7C3v4xj5YO1tpDLu2SYXR7cvVapAsvZaYWgo43OFOXsDhTCgdzWEUrTdGSM+j4QRiEtJymxWCzAamTM+l8EMqlCI0PgsIq2y1pb97x1cWttu9miZ4TXCBZrLf0RbTVHNYoiOKDrlM6sUuhvFiCaBC+Yz+aaocg9xgJE/BR4FUIubd604Ja8oMDPk1WyjOPG1TXVkV142BAFHfT6ySqBP3MbsB1PKS5RV6Uc9Pq3nRs9qKo9YQHMdj6bJ6sELpq5eAGa2yNZJe4Wg16/6/s8I6nqTSfTQa8f3AVd34f+6A4c9PqEBOj00tm4ur48v4ii6PL8AgbBJz22y5eM7xlirGXTyZSGgqh1fZ8ZzhiTCoqkiFdmUz158oq2jGNmJM7P286Nzr8UWmtxBATms/nImDevd4kIy8rFEhF3bUMVKPF0P5/NT46OKeLApbgzGBkDvEq/+Wye2R17grsABDic7MLuoESI3UDLIxbwE0GeKnlaAhOxP3KAdDo5OnaZAhoyqcLVHUUR9zaCt50b4BJ/kTHy1IXLXYYq2i4eON3XR+nJDL56DlyvEFrtFpLHxhvx74LLhfEZ0D1D5Ad3fIa4WICs5SbUTxBzNT9l/G+KU4Zcq7Q77beewDXPNeOKuGMt+0V8/+o5UBm8GWwQ+HEE4FDuYxOXqnr7H9/iX9AAOX1wI9zJ3PaQhQfX/5qTmxLwa8ZlY9X/KwLrfeUv7sl/AEL3tlnUzRrdAAAAAElFTkSuQmCC"
    },
    "image-6.png": {
     "image/png": "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"
    },
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "82793cfc",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)\n",
    "![image-3.png](attachment:image-3.png)\n",
    "![image-4.png](attachment:image-4.png)\n",
    "\n",
    "![image-2.png](attachment:image-2.png)\n",
    "![image-5.png](attachment:image-5.png)\n",
    "![image-6.png](attachment:image-6.png)\n",
    "\n",
    "Note the formal similarity with Warnes’s (2001) use of the previous sample to build a nonparametric kernel approximation to $\\pi$. The main difference is that the proposal does not aim at a good approximation of $\\pi$ using standard nonparametric results like bandwidth selection, but may remain multiscaled over the iterations, as illustrated in Section 14.4.4 The main feature of the PMC algorithm is indeed that several scenarios can be tested in parallel and tuned along iterations, a feature that can hardly be achieved within the domain of MCMC algorithms (Section 7.6.3).\n",
    "\n",
    "There also are similarities between the PMC algorithm and earlier proposals in the particle system literature, in particular with Algorithm [A.60], since the latter also considers iterated samples with (SIR) resampling steps based on importance weights. A major difference, though (besides the dynamic setting of moving target distributions), is that [A.60] remains an MCMC algorithm and thus needs to use Markov transition kernels with a given stationary distribution. There is also a connection with Chopin (2002), who considers iterated importance sampling with changing proposals. His setting is a special case of the PMC algorithm in a Bayesian framework, where the proposals $q_t$ are the posterior distributions associated with a portion $k_t$ of the observed dataset (and are thus independent of $x$ and of the previous samples). As detailed in the following sections, the range of possible choices for the $q_t$’s is actually much wider.\n",
    "\n",
    "### 14.4.4 An Illustration for the Mixture Model\n",
    "\n",
    "Consider the normal mixture model of Example 5.19, that is, $pN(\\mu_1, 1) + (1 - p)N(\\mu_2, 1)$, where $p \\ne 1/2$ is known, and the corresponding simulation from $\\pi(\\mu_1, \\mu_2|\\mathbf{x})$, the posterior distribution for an i.i.d sample $\\mathbf{x} = (x_1, \\dots, x_n)$ and an arbitrary proper prior on $(\\mu_1, \\mu_2)$. While we presented in Chapter 9 a Gibbs sampler based on a data augmentation step via the indicator variables, Celeux et al. (2003) show that a PMC sampler can be efficiently implemented without this augmentation step.\n",
    "\n",
    "Given the posterior distribution\n",
    "$$\\pi(\\mu_1, \\mu_2|\\mathbf{x}) \\propto \\exp(-\\lambda(\\theta - \\mu_1)^2 / 2\\sigma^2) \\exp(-\\lambda(\\theta - \\mu_2)^2 / 2\\sigma^2)$$\n",
    "$$\\prod_{i=1}^n \\left\\{ p \\exp(-(x_i - \\mu_1)^2 / 2\\sigma^2) + (1 - p) \\exp(-(x_i - \\mu_2)^2 / 2\\sigma^2) \\right\\},$$\n",
    "a natural possibility is to choose a random walk for the proposal distribution (see Section 7.5). That is, starting from a sample of values of $\\mu = (\\mu_1, \\mu_2)$, generate random isotropic perturbations of the points of this sample.\n",
    "\n",
    "The difficult issue of selecting the scale of the random walk (see Section 7.6), found in MCMC settings, can be bypassed by virtue of the adaptivity of the PMC algorithm. Indeed, if we take as proposals $q_t$ normal distributions centered at the points of the current sample, $N_2(\\mu_t^{(i)}, \\sigma^2 \\mathbf{I}_2)$, the variance factors $\\sigma_k$ can be chosen at random from a set of $K$ scales $\\nu_k$ ($1 \\le k \\le K$) ranging from, e.g., $10^0$ down to $10^{-3}$ if this range is compatible with the range of the observations. At each iteration $t$ of the PMC algorithm, the probability of choosing a particular scale $\\nu_k$ can be calibrated accordingly to the performance of the different scales over the previous iterations. For instance, possible criterion is to select a scale proportional to its non-degeneracy rate on the previous iterations, that is, the percentage of points associated with $\\nu_k$ that survived past the resampling step 3. The reasoning behind this scheme is that, if most $\\mu_t^{(i)}$s associated with a given scale $\\nu_k$ are not resampled, the scale is not appropriate and thus should not be much used in the next iterations. However, when the survival rate is null, in order to avoid a definitive removal of the corresponding scale, the next probability $\\zeta_k$ is set to a positive value $\\epsilon$.\n",
    "\n",
    "In order to smooth the selection of the scales, Rao-Blackwellization should also be used in the computation of the importance weights, using as the denominator\n",
    "$$\\sum_k \\zeta_k \\varphi \\left( \\mu_t^{(i)}; \\mu_t^{(i')}, \\nu_k \\right),$$\n",
    "where $\\varphi(\\mu; \\xi, \\nu)$ here denotes the density of the two-dimensional normal distribution with mean $\\xi$ and variance $\\nu \\mathbf{I}_2$ at the vector $\\mu$.\n",
    "\n",
    "The corresponding PMC algorithm thus looks as follows.\n",
    "\n",
    "**Algorithm A.62 —Mixture PMC algorithm—**\n",
    "\n",
    "**Step 0: Initialization**\n",
    "For $i = 1, \\dots, n$, generate $\\mu_1^{(i)}$ from an arbitrary distribution.\n",
    "For $k = 1, \\dots, K$, set $\\nu_k$ and $\\zeta_k = 1/K$.\n",
    "\n",
    "**Step 1: Update**\n",
    "For $i = 1, \\dots, n$,\n",
    "a. with probability $\\zeta_k$, take $\\sigma_{t+1}^{(i)} = \\nu_k$\n",
    "b. generate\n",
    "$$\\mu_{t+1}^{(i)} \\sim N_2 \\left( \\mu_t^{(i')}, \\sigma_{t+1}^{(i)} \\mathbf{I}_2 \\right)$$c. compute the weights$$\\frac{\\pi \\left( \\mu_{t+1}^{(i)} | \\mathbf{x} \\right)}{\\sum_k \\zeta_k \\varphi \\left( \\mu_{t+1}^{(i)}; \\mu_t^{(i')}, \\nu_k \\right)}$$\n",
    "\n",
    "Resample the $\\mu_{t+1}^{(i)}$'s using the weights.\n",
    "Update the $\\zeta_k$'s as $\\zeta_k \\propto r_k + \\epsilon$ where $r_k$ is the number of $\\mu_t$'s generated with variance $\\nu_k$ that have been resampled in the previous step.\n",
    "\n",
    "---\n",
    "\n",
    "Celeux et al. (2003) use a simulated dataset of size $n=1000$ with $\\beta^2=1$, $\\varphi=0.99$ and $\\sigma^2=0.01$, in order to compare the performance of the PMC algorithm with an MCMC algorithm based on exactly the same proposals.\n",
    "\n",
    "First, the results of the MCMC algorithm, based on 10,000 iterations, are presented in Fig.9 and 10. The estimate of $\\beta^2$ (over the last 5000 simulated values) is 0.98, while the estimate of $\\varphi$ is equal to 0.89 and the estimate of $\\sigma^2$ is equal to 0.099. While the reconstituted volatilities are on average close to the true values, the parameter estimates are rather poor, even though the cumulative averages of Figure 14.9. do not exhibit any difficulty with convergence. Note, however, the slow mixing on $\\beta$ in Figure 14.9 (upper left) and, to a lesser degree, on $\\sigma^2$ (middle left).\n",
    "\n",
    "**Fig. 14.9.** Evolution of the MCMC samples for the three parameters (left) and convergence of the MCMC estimators (right). (Source: Celeux et al. 2003.)\n",
    "\n",
    "Then, with the same proposal distributions, Celeux et al. (2003) have iterated a PMC algorithm ten times with $M=1000$. The results are presented in Figures 14.11 and 14.12. The estimate of $\\varphi$ (over the 10 iterations) is equal to 0.87, while the estimate of $\\sigma^2$ is equal to 0.012 and the estimate of $\\beta^2$ is equal to 1.04. These estimations are clearly closer to the true values than the ones obtained with the MCMC algorithm. (Note that the scales on Figure 14.11 (left) are much smaller than those of Figure 14.9 (right).) Moreover, Figure 14.12 provides an excellent reconstitution of the volatilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f3dcae",
   "metadata": {},
   "source": [
    "#### Code already given in above"
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "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"
    },
    "image-3.png": {
     "image/png": "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"
    },
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "ecd3ed82",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)\n",
    "![image-2.png](attachment:image-2.png)\n",
    "![image-3.png](attachment:image-3.png)\n",
    "\n",
    "It seems you're asking for the text and mathematical formulas from the provided images to be formatted in Markdown, suitable for a Jupyter Notebook, with LaTeX for the equations. I will process each image and extract the relevant content.\n",
    "\n",
    "Here's the combined content from the images you provided, formatted as requested:\n",
    "\n",
    "---\n",
    "\n",
    "Note the formal similarity with Warnes’s (2001) use of the previous sample to build a nonparametric kernel approximation to $\\pi$. The main difference is that the proposal does not aim at a good approximation of $\\pi$ using standard nonparametric results like bandwidth selection, but may remain multiscaled over the iterations, as illustrated in Section 14.4.4 The main feature of the PMC algorithm is indeed that several scenarios can be tested in parallel and tuned along iterations, a feature that can hardly be achieved within the domain of MCMC algorithms (Section 7.6.3).\n",
    "\n",
    "There also are similarities between the PMC algorithm and earlier proposals in the particle system literature, in particular with Algorithm [A.60], since the latter also considers iterated samples with (SIR) resampling steps based on importance weights. A major difference, though (besides the dynamic setting of moving target distributions), is that [A.60] remains an MCMC algorithm and thus needs to use Markov transition kernels with a given stationary distribution. There is also a connection with Chopin (2002), who considers iterated importance sampling with changing proposals. His setting is a special case of the PMC algorithm in a Bayesian framework, where the proposals $q_t$ are the posterior distributions associated with a portion $k_t$ of the observed dataset (and are thus independent of $x$ and of the previous samples). As detailed in the following sections, the range of possible choices for the $q_t$’s is actually much wider.\n",
    "\n",
    "### 14.4.4 An Illustration for the Mixture Model\n",
    "\n",
    "Consider the normal mixture model of Example 5.19, that is, $pN(\\mu_1, 1) + (1 - p)N(\\mu_2, 1)$, where $p \\ne 1/2$ is known, and the corresponding simulation from $\\pi(\\mu_1, \\mu_2|\\mathbf{x})$, the posterior distribution for an i.i.d sample $\\mathbf{x} = (x_1, \\dots, x_n)$ and an arbitrary proper prior on $(\\mu_1, \\mu_2)$. While we presented in Chapter 9 a Gibbs sampler based on a data augmentation step via the indicator variables, Celeux et al. (2003) show that a PMC sampler can be efficiently implemented without this augmentation step.\n",
    "\n",
    "Given the posterior distribution\n",
    "$$\\pi(\\mu_1, \\mu_2|\\mathbf{x}) \\propto \\exp(-\\lambda(\\theta - \\mu_1)^2 / 2\\sigma^2) \\exp(-\\lambda(\\theta - \\mu_2)^2 / 2\\sigma^2)$$\n",
    "$$\\prod_{i=1}^n \\left\\{ p \\exp(-(x_i - \\mu_1)^2 / 2\\sigma^2) + (1 - p) \\exp(-(x_i - \\mu_2)^2 / 2\\sigma^2) \\right\\},$$\n",
    "a natural possibility is to choose a random walk for the proposal distribution (see Section 7.5). That is, starting from a sample of values of $\\mu = (\\mu_1, \\mu_2)$, generate random isotropic perturbations of the points of this sample.\n",
    "\n",
    "The difficult issue of selecting the scale of the random walk (see Section 7.6), found in MCMC settings, can be bypassed by virtue of the adaptivity of the PMC algorithm. Indeed, if we take as proposals $q_t$ normal distributions centered at the points of the current sample, $N_2(\\mu_t^{(i)}, \\sigma^2 \\mathbf{I}_2)$, the variance factors $\\sigma_k$ can be chosen at random from a set of $K$ scales $\\nu_k$ ($1 \\le k \\le K$) ranging from, e.g., $10^0$ down to $10^{-3}$ if this range is compatible with the range of the observations. At each iteration $t$ of the PMC algorithm, the probability of choosing a particular scale $\\nu_k$ can be calibrated accordingly to the performance of the different scales over the previous iterations. For instance, possible criterion is to select a scale proportional to its non-degeneracy rate on the previous iterations, that is, the percentage of points associated with $\\nu_k$ that survived past the resampling step 3. The reasoning behind this scheme is that, if most $\\mu_t^{(i)}$s associated with a given scale $\\nu_k$ are not resampled, the scale is not appropriate and thus should not be much used in the next iterations. However, when the survival rate is null, in order to avoid a definitive removal of the corresponding scale, the next probability $\\zeta_k$ is set to a positive value $\\epsilon$.\n",
    "\n",
    "In order to smooth the selection of the scales, Rao-Blackwellization should also be used in the computation of the importance weights, using as the denominator\n",
    "$$\\sum_k \\zeta_k \\varphi \\left( \\mu_t^{(i)}; \\mu_t^{(i')}, \\nu_k \\right),$$\n",
    "where $\\varphi(\\mu; \\xi, \\nu)$ here denotes the density of the two-dimensional normal distribution with mean $\\xi$ and variance $\\nu \\mathbf{I}_2$ at the vector $\\mu$.\n",
    "\n",
    "The corresponding PMC algorithm thus looks as follows.\n",
    "\n",
    "**Algorithm A.62 —Mixture PMC algorithm—**\n",
    "\n",
    "**Step 0: Initialization**\n",
    "For $i = 1, \\dots, n$, generate $\\mu_1^{(i)}$ from an arbitrary distribution.\n",
    "For $k = 1, \\dots, K$, set $\\nu_k$ and $\\zeta_k = 1/K$.\n",
    "\n",
    "**Step 1: Update**\n",
    "For $i = 1, \\dots, n$,\n",
    "a. with probability $\\zeta_k$, take $\\sigma_{t+1}^{(i)} = \\nu_k$\n",
    "b. generate\n",
    "$$\\mu_{t+1}^{(i)} \\sim N_2 \\left( \\mu_t^{(i')}, \\sigma_{t+1}^{(i)} \\mathbf{I}_2 \\right)$$c. compute the weights$$\\frac{\\pi \\left( \\mu_{t+1}^{(i)} | \\mathbf{x} \\right)}{\\sum_k \\zeta_k \\varphi \\left( \\mu_{t+1}^{(i)}; \\mu_t^{(i')}, \\nu_k \\right)}$$\n",
    "\n",
    "Resample the $\\mu_{t+1}^{(i)}$'s using the weights.\n",
    "Update the $\\zeta_k$'s as $\\zeta_k \\propto r_k + \\epsilon$ where $r_k$ is the number of $\\mu_t$'s generated with variance $\\nu_k$ that have been resampled in the previous step.\n",
    "\n",
    "---\n",
    "\n",
    "**Fig. 14.12.** Comparison of the true volatility (black) with the PMC estimation based on the 10th iteration weighted PMC sample (grey). (Source: Celeux et al. 2003.)\n",
    "\n",
    "As shown in Cappé et al. (2004) (see also West 1992 and Guilllin et al. 2004), the PMC framework allows, in addition, for a construction of *adaptive* schemes, i.e., of proposals that correct themselves against past performances, that is much easier than in MCMC setups, as described in Section 7.6.3. Indeed, from a theoretical point of view, ergodicity is not an issue for PMC methods since the validity is obtained via importance sampling justifications and, from a practical point of view, the total freedom allowed by unrestricted parallel simulations is a major asset.\n",
    "\n",
    "An extension of the PMC method can be found in Del Moral and Doucet (2003): their generalization is to consider two Markov kernels, $K_+$ and $K_-$, such that, given a particle at time $t-1$, $\\tilde{x}_i^{(t-1)}$, a new particle $\\tilde{x}_i^{(t)}$ is generated from $K_+(\\tilde{x}_i^{(t-1)}, \\tilde{x})$ and associated with a weight\n",
    "$$\\omega_i(t) \\propto \\frac{\\pi(\\tilde{x}_i^{(t)}) K_-(\\tilde{x}_i^{(t)}, \\tilde{x}_i^{(t-1)})}{\\pi(\\tilde{x}_i^{(t-1)}) K_+(\\tilde{x}_i^{(t-1)}, \\tilde{x}_i^{(t)})}$$As in Algorithm [A.61], the sample $(x_1^{(t)}, \\dots, x_n^{(t)})$ is then obtained by multinomial sampling from the $\\tilde{x}_i^{(t)}$'s, using the weights $\\omega_i^{(t)}$. The most intriguing feature of this extension is that the kernel $K_-$ is irrelevant for the unbiasedness of the new sample. Indeed,$$E \\left[ h(\\tilde{X}_i^{(t)}) \\frac{\\pi(\\tilde{x}_i^{(t)}) K_-(\\tilde{x}_i^{(t)}, \\tilde{x}_i^{(t-1)})}{\\pi(\\tilde{x}_i^{(t-1)}) K_+(\\tilde{x}_i^{(t-1)}, \\tilde{x}_i^{(t)})} \\right] = \\int h(\\tilde{x}) \\pi(\\tilde{x}) K_-(\\tilde{x}, x) \\,dx \\,d\\tilde{x}$$\n",
    "$$= E^R[h(X)] \\,.$$\n",
    "whatever $K_-$ is chosen; the only requirement is that $K_-(\\tilde{x}, \\tilde{x})$ integrates to 1 as a function of $x$ (which is reminiscent of Monte Carlo marginalization; see Problem 3.21).\n",
    "\n",
    "While this scheme does provide a valid PMC algorithm, what remains to be assessed is whether wealth is a mixed blessing, that is, if the added\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384eca2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
