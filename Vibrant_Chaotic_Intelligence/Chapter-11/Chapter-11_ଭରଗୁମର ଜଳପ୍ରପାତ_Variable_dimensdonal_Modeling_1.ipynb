{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcf6163",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " * Copyright (c) 2008 Radhamadhab Dalai\n",
    " *\n",
    " * Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    " * of this software and associated documentation files (the \"Software\"), to deal\n",
    " * in the Software without restriction, including without limitation the rights\n",
    " * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    " * copies of the Software, and to permit persons to whom the Software is\n",
    " * furnished to do so, subject to the following conditions:\n",
    " *\n",
    " * The above copyright notice and this permission notice shall be included in\n",
    " * all copies or substantial portions of the Software.\n",
    " *\n",
    " * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    " * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    " * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    " * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    " * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    " * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
    " * THE SOFTWARE.\n",
    "'''"
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAATAAAAAWCAIAAADIG1c7AAAJyElEQVR4Ae1Zv27izBb/3iSRaHe1SqToXiVKlUhJlGalT7LlHkQgVEBpIeABgPpeQDIl0MVI+AU8zabDxbRYrkyBX8Dzae9vdfbssEkIm7ubRE4RzXjOnHPmd/7O8JfK/jIEMgReDQJ/vRpNMkUyBDIEVBaQmRNkCLwiBL4GZJqmXCM+5eOdKR9hki1lCHAE+Fjzt92WXoTJbqJ32/VDhUzWCY/Mh8bhMhS+EL4AAaZSSk4vfBEuQ/5lcxwuw1Ucb35/8guYC19sqTAYSilJ5ydFbEOwimNiGCyCJ7ck6+RJTJ5k8jsJYNlnSSRAnrXrTxFLKbcx3O9U71tAtput68urXqe7jexwGVqG2W62QJysk+vLK26JZJ1Yhvkkt2F/0LBtMNkel+l4MnNdCN3ev6HSswL4SSiklJ8+fAQZofHQrmARFPOF0+OThwi078P+ILe3r3386XR7nkqpbYjJFuEypAP+VDT/2G62GrYtfDHsD4r5wsx1+epLjeF78K5ep1uv1n7Fpr1O1zJMpZRlmFpF4QrPXPf68ur0+AQSG7a9jdDc3v72/knivresFEK81PIxr/4z162UyliVUs5cV6O8vSlRQGpLfIrxKo5BvLlEimJJStmwbYyPDg6x+uQupdTIcdy7O+LGz6KNtSlnri1FUQRzKqVmrsv5b+7qdbojx9E4PDIVvtACkvPkY+ELPuVjjX+apjxvcko+JoSVUkcHh3xpkyEg7XW6fFfDtjkaD+3a3nycQ6/T7XW60Kph2zQm426jMIjduztYUEoZRRFx4OIwptBVSv39+fM2vn3/5Z43gFwrPtZkfW9ZKSC5Wo+MP334CHnD/gAJYzqeTMcT5NdKqQylvbkHBPE9WSe9TnfYH4TLcNgfVEplpVQxX7AMczqeSCl7ne50PAGZN/c0BerVGrJOsAjq1Rr+SymH/QFy88hxMOA5LFknVMGm40mv06VVb+4N+wNIgf50FiIb9gfBIhj2B0RJypNhhC+0mhAsAn5wyzCL+QIVH5I4c91hf1Cv1pRS0/Fk5DjT8UQpRQGZrBOIBtrAUynlzT1v7uGwxG06niDktGsFCCALzNFo9DpdLYsP+wOUAnxH39RutojtyHHI4mCLwsv50I1G+KLX6eLUwSKAwjgIXxK+APikT7AIYCnOFuKAKsaWYcJJgBI8B16EQp2sk5nrTscT8qXpeAJvQRq1DDNchr1OF1qBEiag0ymleEBahglPCJchRwOQwpo4HXxp2B9A52Sd4KQz16WTcilKsVfW5wZkvVpDwwmnJJiQcpC60KcppdAxKqWuL69WcYzv5HPQnuDGaRGrmrrFfAFfhv0BjOHNvYZtt5stLOX29gE3hYpSqt1swa7BImg3WzC2UqpercGtZ65br9bIRZAdknVSzBeEL7y5d3p8giOgWyZZVHB6na4WkGgO6eC9TpeSAh0BSlqGmawTwgqJhsAZ9gcIM3QE4TI8PT5ZxTHIlFIopHBfdF+clQYgiJN1gnwqfEGQEiWVfTBfxTGdAuYDMkRPOvAvSBk4cr1aQ1ScHp/AOt7c40vQB8EDfZC8pJSb6vU6XdgFRofTX19ecQyBNrwfjgS703mvL6+QmHBYyzBnrgv3QGbUztLrdE+PT7y5ZxkmeSZHA1EH/KFSbm8f6RL+LHyBBvsR5L8FJAooBSSvp3ys1VZ4DOXC3N5+w7ZHjlMplVdxjJYVUcr5W4ZJPMnnKCDTNF3F8cXZudYBQjQnq5TKF2fn1AQiHlZxDIcbOQ7CAwyRONI0lVLm9vYvzs6VUlEUQeeGbUdRhI+8NEkpoS3yGbBO03TkOAgk3lKCCVmReiHscu/uKGHR8WeuizaPAmDmurc3pYuzc+ELqAqG2EviCHms5vb20zS1DBP4396UhC+ODg4rpbKUksQBQ2KCowlfQDon4zYCc5wCbPv/+e/IcQhS6HB0cMhlreI4iqJKqYyEJXxx8q9/C1/QLm0J/JVShNsqjhu2fXtTInBIQzT/mPY63UqpfP/lnsgsw7z/ck9oW4Z5e1OCwujtcdtCdiNxlmG6d3fwvaODw81bQMO2IWLmurm9fbznHR0cEhqb1kRAWoYJENI0Bfga8lpY/dCyUgpHuSf3emhwcXaOTANAUeiRHtCyenMPzRi6GuELokdPBRURaVRtivnCZl5E20A04IMzQ3qyTry5Rz0wPfPy3mA6noTLEPl15rpkRT6mRppqTrvZ8uZeuAzxdtXrdFE2CWt03RylVRzT88np8QmaKF60Efn1ao06Om/u4dS9Ttebe9PxBOC0my2kWHokwGMYGYvIqNFCrZiOJ5tvFSCmAKCA5MoDFkBN9kIZp0PByrQLFw2aQmE0ICiV8HJCQFsifcgQ15dXaHQtw9T6fAo2lDKckfQkG0FWu9kiock6GTkOQAZbEocKGS7DcBkGi4C40YmoZU3WCbwuWSccDRRAsia6BuGLdrMFu0gpQU/wYqD91vAtIHHDsQwT8bNlQFLpUEqt4hiHx9WrUiqDFT6SWpiiDUPbicjhb7z8XkeIICDpRgF3JNuQK8ONivkCCBAJxKSYL0zHE8oRiEwEWDFfQB8VLIKLs3OQwe2K+QJcHFUIWabdbF2cnVM3ggEJgq+0my06uGWY8Gmi8eZebm//6OAQHTK6KbzjXV9etZstGB4B2W62jg4OcS4YEg/dqJZopIEt3gAhq16t8cdDZHc0NZ8+fIT5To9PCFXoBluADJ4Kf6B7nRZ+uJIguaBLxIUtWATIWfhPlzqllLYkfPHpw0fhi0qpDH2K+QIeiq4vrzi2eGWF4ZBxEK71ag037Xq1topjvEok6yRZJ7g9tZstaokRXRABVqfHJyja5AZkJqUUeiUC6ujgEO8gSNlAY9Oaub19xAKQqZTKwSLASTny/LeGH1pW0oB6A62YPj7luzTK7ZeiKJJSjhxnFcebuxA5GnNtqu36+/Pnn56LdsFftV18yse0CzxpCWWZphqZNiUyxBWm6OUeotTEaWTaFAzxyMTbSI1Mm5JWO8gihKMomrmuBindHYiMZD2ytIMa8n9/2rm0KYnegT/pj2PiEYgYblqTlp4l63vLSvL+4AAdFM+IXBk80/Evj483H1oep99tFc9CO+xFfkW7Tt3mDnyyLa8BgZey5usKyCeRpTvkk5S4pG1D9os09J7+i3yy7RkCr65l5VWej/8fjQfnz8d/UNYfFP1KEHhxNd4cpG+sQmZJNEPgfSOQBeT7tm92ujeGwNeA3K1P0DbuxiTblSHAEeDjF3GwF2Hy4lo9wjCrkG8sg2bqvm8EsoB83/bNTvfGEMha1q8Ge6SF+J1Lmia/U/R7lfXmIP0HGdW5cHdG3oIAAAAASUVORK5CYII="
    },
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "dc1d3310",
   "metadata": {},
   "source": [
    "## Variable Dimension Models and Reversible Jump Algorithms\n",
    "\n",
    "While the previous chapters have presented a general class of MCMC algorithms, there exist settings where they are not general enough. A particular case of such settings is that of variable dimension models. There, the parameter (and simulation) space is not well defined, being a finite or denumerable collection of unrelated subspaces. To have an MCMC algorithm moving within this collection of spaces requires more advanced tools, if only because of the associated measure theoretic subtleties. Section 11.1 motivates the use of variable dimension models in the setup of Bayesian model choice and model comparison, while Section 11.2 presents the general theory of reversible jump algorithms, which were tailored for these models. Section 11.3 examines further algorithms and methods related to this issue.\n",
    "\n",
    "## 1 Variable Dimension Models\n",
    "\n",
    "In general, a variable dimension model is, to quote Peter Green, “a model where one of the things you do not know is the number of things you do not know.” This means that the statistical model under consideration is not defined precisely enough for the dimension of the parameter space to be fixed. As detailed below in Section 11.1.1, this setting is closely associated with model selection, a collection of statistical procedures that are used at the early stage of a statistical analysis, namely, when the model to be used is not yet fully determined.\n",
    "\n",
    "In addition to model construction, there are other situations where several models are simultaneously considered. For instance, this occurs in model checking, model comparison, model improvement, and model pruning, with many areas of application: variable selection in generalized linear models, change point determination in signal processing, object recognition in image analysis, coding identification in DNA analysis, dependence reconstruction in expert systems, and so on.\n",
    "\n",
    "### Example 11.1: Mixture Modeling\n",
    "\n",
    "Consider the dataset represented by the histogram of Figure 11.1, and also provided in Table 11.1 (see Problem 11.7). It consists of the velocities of 82 galaxies previously analyzed by Roeder (1992) and is often used as a benchmark example in mixture analysis (see, e.g., Chib 1995, Phillips and Smith 1996, Rafttery 1996, Richardson and Green 1997, or Robert and Mengersen 1999). The probabilistic model considered for the representation of this dataset is a Gaussian mixture model:\n",
    "\n",
    "$$\n",
    "M_k : x_i \\sim \\sum_{j=1}^k p_j \\mathcal{N}(\\mu_j, \\sigma_j^2) \\quad (i = 1, \\dots, 82),\n",
    "$$\n",
    "\n",
    "but the index $k$, that is the number of components in the mixture (or of clusters of galaxies in, say, the sample), is under debate. It cannot therefore be arbitrarily fixed to, say, $k = 7$ for the statistical analysis of this dataset.\n",
    "\n",
    "#### 11.1.1 Bayesian Model Choice\n",
    "\n",
    "While the concept of a variable dimension model is loosely defined, we can give a more formal definition which mostly pertains to the important case of model selection.\n",
    "\n",
    "**Definition 11.2 (Bayesian variable dimension model)** A variable dimension model is defined as a collection of models $(k = 1, \\dots, K)$,\n",
    "\n",
    "$$\n",
    "M_k = \\{f(x \\mid \\theta_k), \\theta_k \\in \\Theta_k\\},\n",
    "$$\n",
    "\n",
    "associated with a collection of priors on the parameters of these models, $\\pi_k(\\theta_k)$, and a prior distribution on the models $(k = 1, \\dots, K)$,\n",
    "\n",
    "$$\n",
    "\\pi(k), \\quad k = 1, \\dots, K.\n",
    "$$\n",
    "\n",
    "Note that we will also use the more concise notation $\\pi_k(M_k) = \\pi(k \\mid M_k)$.\n",
    "\n",
    "This is done in $N$ dimensions, where $n_k(\\theta_k)$ is a density with respect to the counting measure on $\\theta_k$. The function $\\pi(k)$ is then a density with respect to Lebesgue measure on the union of spaces, $\\theta \\in \\bigcup_k \\Theta_k$.\n",
    "\n",
    "From a Bayesian perspective, this representation of the problem implies that inference is formally completed. Indeed, once the prior and the model are defined, the model selected from the dataset $x$ is determined from the posterior probabilities\n",
    "\n",
    "$$\n",
    "p(M_k \\mid x) = \\frac{\\pi(k) \\int f(x \\mid \\theta_k, M_k) \\pi_k(\\theta_k) d\\theta_k}{\\sum_{j} \\pi(j) \\int f(x \\mid \\theta_j, M_j) \\pi_j(\\theta_j) d\\theta_j},\n",
    "$$\n",
    "\n",
    "either taking the model with largest $p(M_k \\mid x)$ or using model averaging through\n",
    "\n",
    "$$\n",
    "\\sum p(M_k \\mid x) \\int f(x \\mid \\theta_k, M_k) \\pi_k(\\theta_k) d\\theta_k,\n",
    "$$\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "![image-2.png](attachment:image-2.png)\n",
    "\n",
    "where $x$ denotes the observed dataset, as a predictive distribution, even though sophisticated decision theoretic perspectives could be adopted (see Robert, 2001, Chapter 7)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6656384e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Current k = 2\n",
      "Iteration 100, Current k = 3\n",
      "Iteration 200, Current k = 2\n",
      "Iteration 300, Current k = 2\n",
      "Iteration 400, Current k = 3\n",
      "Iteration 500, Current k = 3\n",
      "Iteration 600, Current k = 2\n",
      "Iteration 700, Current k = 1\n",
      "Iteration 800, Current k = 1\n",
      "Iteration 900, Current k = 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "def propose_move(current_state: Dict, data: np.ndarray) -> Tuple[Dict, float]:\n",
    "    \"\"\"\n",
    "    Propose a move in the reversible jump MCMC (birth, death, or update).\n",
    "    Returns the proposed state and the Jacobian determinant for dimension changes.\n",
    "    \"\"\"\n",
    "    k = current_state['k']\n",
    "    weights = current_state['weights']\n",
    "    means = current_state['means']\n",
    "    stds = current_state['stds']\n",
    "    \n",
    "    move_type = np.random.choice(['birth', 'death', 'update'], p=[0.3, 0.3, 0.4])\n",
    "    \n",
    "    if move_type == 'birth' and k < 10:  # Max k for practicality\n",
    "        new_k = k + 1\n",
    "        new_weights = np.zeros(new_k)\n",
    "        new_weights[:k] = weights * (1 - 0.5)  # Split weight for new component\n",
    "        new_weights[k] = 0.5  # New component weight\n",
    "        new_weights /= new_weights.sum()  # Normalize\n",
    "        \n",
    "        new_means = np.zeros(new_k)\n",
    "        new_means[:k] = means\n",
    "        new_means[k] = np.random.normal(np.mean(data), 1.0)  # Random mean\n",
    "        \n",
    "        new_stds = np.zeros(new_k)\n",
    "        new_stds[:k] = stds\n",
    "        new_stds[k] = np.random.uniform(0.1, 0.5)  # Random std\n",
    "        \n",
    "        jacobian = 1.0  # Simplified Jacobian (could be more complex)\n",
    "        return {'k': new_k, 'weights': new_weights, 'means': new_means, 'stds': new_stds}, jacobian\n",
    "    \n",
    "    elif move_type == 'death' and k > 1:\n",
    "        component_to_remove = np.random.randint(k)\n",
    "        new_k = k - 1\n",
    "        new_weights = np.delete(weights, component_to_remove)\n",
    "        new_weights /= new_weights.sum()  # Normalize\n",
    "        new_means = np.delete(means, component_to_remove)\n",
    "        new_stds = np.delete(stds, component_to_remove)\n",
    "        \n",
    "        jacobian = 1.0  # Simplified Jacobian\n",
    "        return {'k': new_k, 'weights': new_weights, 'means': new_means, 'stds': new_stds}, jacobian\n",
    "    \n",
    "    else:  # Update parameters\n",
    "        if k > 0:\n",
    "            component = np.random.randint(k)\n",
    "            if np.random.random() < 0.5:\n",
    "                means[component] += np.random.normal(0, 0.1)\n",
    "            else:\n",
    "                stds[component] = abs(stds[component] + np.random.normal(0, 0.05))\n",
    "            weights = np.random.dirichlet(np.ones(k))  # Update weights\n",
    "        \n",
    "        jacobian = 1.0\n",
    "        return {'k': k, 'weights': weights, 'means': means, 'stds': stds}, jacobian\n",
    "\n",
    "def log_likelihood(data: np.ndarray, weights: np.ndarray, means: np.ndarray, stds: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Compute the log-likelihood of the data under the mixture model.\n",
    "    \"\"\"\n",
    "    ll = 0\n",
    "    for x in data:\n",
    "        comp_ll = np.log(np.sum(weights * stats.norm.pdf(x, means, stds)))\n",
    "        ll += comp_ll\n",
    "    return ll\n",
    "\n",
    "def log_prior(k: int, weights: np.ndarray, means: np.ndarray, stds: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Compute the log-prior for the model parameters.\n",
    "    \"\"\"\n",
    "    # Uniform prior on k (e.g., k in [1, 10])\n",
    "    log_k_prior = -np.log(10) if 1 <= k <= 10 else -np.inf\n",
    "    \n",
    "    # Dirichlet prior for weights (uniform)\n",
    "    log_weights_prior = stats.dirichlet.logpdf(weights, np.ones(len(weights)))\n",
    "    \n",
    "    # Normal prior for means (centered at 0, variance 10)\n",
    "    log_means_prior = np.sum(stats.norm.logpdf(means, 0, 10))\n",
    "    \n",
    "    # Inverse-gamma prior for stds (shape=2, scale=1)\n",
    "    log_stds_prior = np.sum(stats.invgamma.logpdf(stds, 2, scale=1))\n",
    "    \n",
    "    return log_k_prior + log_weights_prior + log_means_prior + log_stds_prior\n",
    "\n",
    "def reversible_jump_mcmc(data: np.ndarray, n_iter: int) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Run reversible jump MCMC to sample from the posterior.\n",
    "    \"\"\"\n",
    "    # Initialize with k=2 components (arbitrary starting point)\n",
    "    k = 2\n",
    "    weights = np.random.dirichlet(np.ones(k))\n",
    "    means = np.random.normal(np.mean(data), 1.0, k)\n",
    "    stds = np.random.uniform(0.1, 0.5, k)\n",
    "    \n",
    "    current_state = {'k': k, 'weights': weights, 'means': means, 'stds': stds}\n",
    "    chain = [current_state.copy()]\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        proposed_state, jacobian = propose_move(current_state, data)\n",
    "        \n",
    "        # Log posterior for current and proposed states\n",
    "        current_log_posterior = log_likelihood(data, current_state['weights'], current_state['means'], current_state['stds']) + \\\n",
    "                               log_prior(current_state['k'], current_state['weights'], current_state['means'], current_state['stds'])\n",
    "        \n",
    "        proposed_log_posterior = log_likelihood(data, proposed_state['weights'], proposed_state['means'], proposed_state['stds']) + \\\n",
    "                                log_prior(proposed_state['k'], proposed_state['weights'], proposed_state['means'], proposed_state['stds'])\n",
    "        \n",
    "        # Acceptance probability (including Jacobian for dimension changes)\n",
    "        log_acceptance = proposed_log_posterior - current_log_posterior + np.log(jacobian)\n",
    "        \n",
    "        if np.log(np.random.random()) < log_acceptance:\n",
    "            current_state = proposed_state.copy()\n",
    "        \n",
    "        chain.append(current_state.copy())\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Iteration {i}, Current k = {current_state['k']}\")\n",
    "    \n",
    "    return chain\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# True parameters for the mixture model (k=3 components)\n",
    "n_components = 3\n",
    "n_samples = 82  # Number of galaxies, as in the example\n",
    "mix_weights = np.array([0.4, 0.3, 0.3])  # Mixing proportions\n",
    "means = np.array([1.5, 2.5, 3.5])  # Means of Gaussian components\n",
    "stds = np.array([0.3, 0.2, 0.25])  # Standard deviations\n",
    "\n",
    "# Generate data\n",
    "component = np.random.choice(n_components, size=n_samples, p=mix_weights)\n",
    "data = np.array([np.random.normal(means[i], stds[i]) for i in component])\n",
    "\n",
    "# Visualize the data\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(data, bins=20, density=True, alpha=0.7, color='skyblue')\n",
    "plt.title(\"Histogram of Simulated Galaxy Velocities\")\n",
    "plt.xlabel(\"Velocity (km/second)\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()\n",
    "\n",
    "# Run the MCMC\n",
    "n_iterations = 1000\n",
    "chain = reversible_jump_mcmc(data, n_iterations)\n",
    "\n",
    "# Analyze results\n",
    "k_values = [state['k'] for state in chain]\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(k_values, bins=range(max(k_values)+2), density=True, alpha=0.7, color='skyblue')\n",
    "plt.title(\"Posterior Distribution of Number of Components (k)\")\n",
    "plt.xlabel(\"Number of Components (k)\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cebb246",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "# Basic statistical functions without libraries\n",
    "def normal_pdf(x: float, mean: float, std: float) -> float:\n",
    "    \"\"\"\n",
    "    Compute the probability density function of a normal distribution.\n",
    "    \"\"\"\n",
    "    variance = std * std\n",
    "    exponent = -((x - mean) ** 2) / (2 * variance)\n",
    "    return (1 / (std * math.sqrt(2 * math.pi))) * math.exp(exponent)\n",
    "\n",
    "def dirichlet_pdf(weights: List[float], alpha: List[float]) -> float:\n",
    "    \"\"\"\n",
    "    Compute the probability density function of a Dirichlet distribution (simplified, uniform case).\n",
    "    Here, we use a uniform Dirichlet with alpha = [1, ..., 1].\n",
    "    \"\"\"\n",
    "    if len(weights) != len(alpha):\n",
    "        return 0.0\n",
    "    product = 1.0\n",
    "    for w in weights:\n",
    "        if w <= 0 or w >= 1:\n",
    "            return 0.0\n",
    "        product *= w ** (alpha[0] - 1)\n",
    "    return product / math.gamma(len(weights))  # Simplified for alpha=1\n",
    "\n",
    "def invgamma_pdf(x: float, shape: float, scale: float) -> float:\n",
    "    \"\"\"\n",
    "    Compute the probability density function of an inverse-gamma distribution.\n",
    "    \"\"\"\n",
    "    if x <= 0:\n",
    "        return 0.0\n",
    "    return (scale ** shape) / (math.gamma(shape) * (x ** (shape + 1))) * math.exp(-scale / x)\n",
    "\n",
    "def propose_move(current_state: Dict, data: List[float]) -> Tuple[Dict, float]:\n",
    "    \"\"\"\n",
    "    Propose a move in the reversible jump MCMC (birth, death, or update).\n",
    "    Returns the proposed state and the Jacobian determinant for dimension changes.\n",
    "    \"\"\"\n",
    "    k = current_state['k']\n",
    "    weights = current_state['weights']\n",
    "    means = current_state['means']\n",
    "    stds = current_state['stds']\n",
    "    \n",
    "    move_type = random.choices(['birth', 'death', 'update'], weights=[0.3, 0.3, 0.4])[0]\n",
    "    \n",
    "    if move_type == 'birth' and k < 10:  # Max k for practicality\n",
    "        new_k = k + 1\n",
    "        new_weights = [0.0] * new_k\n",
    "        for i in range(k):\n",
    "            new_weights[i] = weights[i] * 0.5  # Split weight for new component\n",
    "        new_weights[k] = 0.5  # New component weight\n",
    "        total = sum(new_weights)\n",
    "        for i in range(new_k):\n",
    "            new_weights[i] /= total  # Normalize\n",
    "        \n",
    "        new_means = [0.0] * new_k\n",
    "        for i in range(k):\n",
    "            new_means[i] = means[i]\n",
    "        new_means[k] = random.gauss(sum(data) / len(data), 1.0)  # Random mean\n",
    "        \n",
    "        new_stds = [0.0] * new_k\n",
    "        for i in range(k):\n",
    "            new_stds[i] = stds[i]\n",
    "        new_stds[k] = random.uniform(0.1, 0.5)  # Random std\n",
    "        \n",
    "        jacobian = 1.0  # Simplified Jacobian (could be more complex)\n",
    "        return {'k': new_k, 'weights': new_weights, 'means': new_means, 'stds': new_stds}, jacobian\n",
    "    \n",
    "    elif move_type == 'death' and k > 1:\n",
    "        component_to_remove = random.randint(0, k - 1)\n",
    "        new_k = k - 1\n",
    "        new_weights = [w for i, w in enumerate(weights) if i != component_to_remove]\n",
    "        total = sum(new_weights)\n",
    "        for i in range(len(new_weights)):\n",
    "            new_weights[i] /= total  # Normalize\n",
    "        new_means = [m for i, m in enumerate(means) if i != component_to_remove]\n",
    "        new_stds = [s for i, s in enumerate(stds) if i != component_to_remove]\n",
    "        \n",
    "        jacobian = 1.0  # Simplified Jacobian\n",
    "        return {'k': new_k, 'weights': new_weights, 'means': new_means, 'stds': new_stds}, jacobian\n",
    "    \n",
    "    else:  # Update parameters\n",
    "        if k > 0:\n",
    "            component = random.randint(0, k - 1)\n",
    "            if random.random() < 0.5:\n",
    "                means[component] += random.gauss(0, 0.1)\n",
    "            else:\n",
    "                stds[component] = abs(stds[component] + random.gauss(0, 0.05))\n",
    "            # Update weights using Dirichlet (uniform prior)\n",
    "            alpha = [1.0] * k\n",
    "            weights = []\n",
    "            for _ in range(k):\n",
    "                w = random.random()\n",
    "                weights.append(w)\n",
    "            total = sum(weights)\n",
    "            for i in range(len(weights)):\n",
    "                weights[i] /= total  # Normalize to ensure sum to 1\n",
    "        \n",
    "        jacobian = 1.0\n",
    "        return {'k': k, 'weights': weights, 'means': means, 'stds': stds}, jacobian\n",
    "\n",
    "def log_likelihood(data: List[float], weights: List[float], means: List[float], stds: List[float]) -> float:\n",
    "    \"\"\"\n",
    "    Compute the log-likelihood of the data under the mixture model.\n",
    "    \"\"\"\n",
    "    ll = 0.0\n",
    "    for x in data:\n",
    "        comp_ll = 0.0\n",
    "        for w, mu, sigma in zip(weights, means, stds):\n",
    "            comp_ll += w * normal_pdf(x, mu, sigma)\n",
    "        ll += math.log(comp_ll) if comp_ll > 0 else float('-inf')\n",
    "    return ll\n",
    "\n",
    "def log_prior(k: int, weights: List[float], means: List[float], stds: List[float]) -> float:\n",
    "    \"\"\"\n",
    "    Compute the log-prior for the model parameters.\n",
    "    \"\"\"\n",
    "    # Uniform prior on k (e.g., k in [1, 10])\n",
    "    log_k_prior = -math.log(10) if 1 <= k <= 10 else float('-inf')\n",
    "    \n",
    "    # Dirichlet prior for weights (uniform, alpha=1 for each)\n",
    "    alpha = [1.0] * len(weights)\n",
    "    log_weights_prior = math.log(dirichlet_pdf(weights, alpha))\n",
    "    \n",
    "    # Normal prior for means (centered at 0, variance 10)\n",
    "    log_means_prior = 0.0\n",
    "    for mu in means:\n",
    "        exponent = -((mu - 0) ** 2) / (2 * 10)\n",
    "        log_means_prior += math.log((1 / (math.sqrt(2 * math.pi * 10))) * math.exp(exponent))\n",
    "    \n",
    "    # Inverse-gamma prior for stds (shape=2, scale=1)\n",
    "    log_stds_prior = 0.0\n",
    "    for sigma in stds:\n",
    "        log_stds_prior += math.log(invgamma_pdf(sigma, 2.0, 1.0))\n",
    "    \n",
    "    return log_k_prior + log_weights_prior + log_means_prior + log_stds_prior\n",
    "\n",
    "def reversible_jump_mcmc(data: List[float], n_iter: int) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Run reversible jump MCMC to sample from the posterior.\n",
    "    \"\"\"\n",
    "    # Initialize with k=2 components (arbitrary starting point)\n",
    "    k = 2\n",
    "    weights = []\n",
    "    for _ in range(k):\n",
    "        w = random.random()\n",
    "        weights.append(w)\n",
    "    total = sum(weights)\n",
    "    for i in range(len(weights)):\n",
    "        weights[i] /= total  # Normalize to ensure sum to 1\n",
    "    means = [random.gauss(sum(data) / len(data), 1.0) for _ in range(k)]\n",
    "    stds = [random.uniform(0.1, 0.5) for _ in range(k)]\n",
    "    \n",
    "    current_state = {'k': k, 'weights': weights, 'means': means, 'stds': stds}\n",
    "    chain = [current_state.copy()]\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        proposed_state, jacobian = propose_move(current_state, data)\n",
    "        \n",
    "        # Log posterior for current and proposed states\n",
    "        current_log_posterior = log_likelihood(data, current_state['weights'], current_state['means'], current_state['stds']) + \\\n",
    "                               log_prior(current_state['k'], current_state['weights'], current_state['means'], current_state['stds'])\n",
    "        \n",
    "        proposed_log_posterior = log_likelihood(data, proposed_state['weights'], proposed_state['means'], proposed_state['stds']) + \\\n",
    "                                log_prior(proposed_state['k'], proposed_state['weights'], proposed_state['means'], proposed_state['stds'])\n",
    "        \n",
    "        # Acceptance probability (including Jacobian for dimension changes)\n",
    "        log_acceptance = proposed_log_posterior - current_log_posterior + math.log(jacobian)\n",
    "        \n",
    "        if math.log(random.random()) < log_acceptance:\n",
    "            current_state = proposed_state.copy()\n",
    "        \n",
    "        chain.append(current_state.copy())\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Iteration {i}, Current k = {current_state['k']}\")\n",
    "    \n",
    "    return chain\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# True parameters for the mixture model (k=3 components)\n",
    "n_components = 3\n",
    "n_samples = 82  # Number of galaxies, as in the example\n",
    "mix_weights = [0.4, 0.3, 0.3]  # Mixing proportions\n",
    "means = [1.5, 2.5, 3.5]  # Means of Gaussian components\n",
    "stds = [0.3, 0.2, 0.25]  # Standard deviations\n",
    "\n",
    "# Generate data\n",
    "data = []\n",
    "for _ in range(n_samples):\n",
    "    component = random.choices(range(n_components), weights=mix_weights)[0]\n",
    "    x = random.gauss(means[component], stds[component])\n",
    "    data.append(x)\n",
    "\n",
    "# Simple text-based histogram for visualization (no matplotlib)\n",
    "def print_histogram(data: List[float], bins: int = 20):\n",
    "    \"\"\"\n",
    "    Print a text-based histogram of the data.\n",
    "    \"\"\"\n",
    "    min_val, max_val = min(data), max(data)\n",
    "    bin_size = (max_val - min_val) / bins\n",
    "    counts = [0] * bins\n",
    "    \n",
    "    for x in data:\n",
    "        bin_idx = min(int((x - min_val) / bin_size), bins - 1)\n",
    "        counts[bin_idx] += 1\n",
    "    \n",
    "    total = sum(counts)\n",
    "    for i, count in enumerate(counts):\n",
    "        lower = min_val + i * bin_size\n",
    "        upper = min_val + (i + 1) * bin_size\n",
    "        density = count / (total * bin_size) if total > 0 else 0\n",
    "        stars = int(density * 50)  # Scale for text visualization\n",
    "        print(f\"{lower:.2f}-{upper:.2f}: {'*' * stars} ({density:.3f})\")\n",
    "\n",
    "print(\"Histogram of Simulated Galaxy Velocities:\")\n",
    "print_histogram(data)\n",
    "\n",
    "# Run the MCMC\n",
    "n_iterations = 1000\n",
    "chain = reversible_jump_mcmc(data, n_iterations)\n",
    "\n",
    "# Analyze results (text-based histogram for k values)\n",
    "k_values = [state['k'] for state in chain]\n",
    "k_counts = {}\n",
    "for k in k_values:\n",
    "    k_counts[k] = k_counts.get(k, 0) + 1\n",
    "total = sum(k_counts.values())\n",
    "\n",
    "print(\"\\nPosterior Distribution of Number of Components (k):\")\n",
    "for k in sorted(k_counts.keys()):\n",
    "    density = k_counts[k] / total\n",
    "    stars = int(density * 50)  # Scale for text visualization\n",
    "    print(f\"k={k}: {'*' * stars} (Probability: {density:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3f091b",
   "metadata": {},
   "source": [
    "## Difficulties in Model Choice\n",
    "\n",
    "There are several kinds of difficulties with a formal resolution of the model choice issue. While the definition of a prior distribution on the parameter space\n",
    "\n",
    "$$\n",
    "\\theta = \\bigcup_{k} \\{k\\} \\times \\Theta_k\n",
    "$$\n",
    "\n",
    "does not create any problem, thanks to the decomposition of $\\pi(k)$ into $\\pi(k \\mid \\theta_k)$, a first difficulty is that at the inferential level model choice is a complex notion. The setting does not clearly belong either to the estimation or the testing domain.\n",
    "\n",
    "As an example, when considering model choice as an estimation problem, there is a tendency to overfit the data by selecting a model $M_k$ with a large number of parameters, and overfitting can only be countered with priors distributions $\\pi(\\theta_k)$ that depend on the sample size (see Robert, 2001, Chapter 7). Similarly, when adopting the perspective that model choice is a special case of testing between models, the subsequent inference on the model’s “likelihood” model fails to account for the selection process and its inherent error. This vagueness, central to the model choice formulation, will translate into a requirement for a many-faceted prior distribution.\n",
    "\n",
    "We trust stress here that our understanding of the Bayesian model choice issue is that we must choose a completely new set of parameters $\\Theta_k$, and set the parameter space as the union of the model parameter spaces $\\Theta_k$, even though some parameter spaces may have a similar meaning in two different models.\n",
    "\n",
    "### Example 3: Order of an AR(p) model\n",
    "\n",
    "Recall that an AR(p) model is given as the autoregressive representation of a time series,\n",
    "\n",
    "$$\n",
    "M_p : x_t = \\sum_{i=1}^p \\theta_i x_{t-i} + \\sigma_p \\epsilon_t,\n",
    "$$\n",
    "\n",
    "where the autoregressive coefficients $\\theta_i$ (for $i=1,\\dots,p$) would be the same as the $\\theta_{p+1,i}$’s, that is, that an AR(p) model is simply an AR(p+1) model with an extra zero coefficient.\n",
    "\n",
    "When comparing an AR(p) and an AR(p+1) model, it could be assumed that the autoregressive coefficients $\\theta_i$ (for $i=1,\\dots,p$) would be the same as the $\\theta_{p+1,i}$’s, that is, that an AR(p) model is simply an AR(p+1) model with an extra zero coefficient.\n",
    "\n",
    "We note that it is important to consider the coefficients for each of the models as an entire set of coefficients, and not individually. This is not only because the models are different, but, more importantly, because the best fitting AR(p+1) model is not necessarily a modification of the best fitting AR(p) model obtained by adding an extra term, that is, a non-zero $\\theta_{p+1}$. Moreover, from a Bayesian point of view, the parameters $\\theta_k$’s are not independent a posteriori. Similarly, even though the variance $\\sigma_p^2$ has the same formal meaning for all values of $p$, we insist on using a different variance parameter for each value of $p$, hence the notation $\\sigma_p^2$.\n",
    "\n",
    "However, many statisticians prefer to use some parameters that are common to all models, in order to reduce model and computational complexity (Problems 11.1 and 11.2), and also to enforce Occam’s parsimony requirement (see Note 11.5.1). As we will see below, the reversible jump technique of Section 11.2 is based upon this assumption of partially exchangeable parameters between models, since it uses proposal distributions that modify only a part of the parameter vector to move between models. (The centering technique of Brooks et al. 2003b relates to the same assumption.)\n",
    "\n",
    "Section 11.2 is the cornerstone of this book, there are also computational difficulties related to variable dimension models. For instance, the number of models in competition may well be infinite. Even when the number of models is finite, there is additional complexity in representing, or simulating from, the posterior distribution (11.2) in that a sampler must move both within and between models $\\Theta_k$. While the former (move) pertains to previous developments in Chapters 7–10, the latter (move) requires a deeper measure-theoretic basis to ensure the overall validity of the correct MCMC moves, that is, to preserve $\\pi(x)$ as the stationary distribution of the simulated Markov chain on $\\Theta$.\n",
    "\n",
    "Lastly, we mention that there is an enormous, and growing, literature on the topic of model selection, from both a frequentist and a Bayesian point of view. Starting with the seminal paper of Akaike (1974), which defined one of the first model selection criteria (now known as AIC), a major focus of that methodology is to examine the properties of the model selection procedure, and its inference, in some sense, that the correct model will be selected if the number of observations is infinite. (This is known as consistency in model selection.) However, many of our concerns are different from those in the model selection literature, and we will not go into details of the many model selection criteria that are available. A good introduction to the many facets of model selection is edited by Lahiri (2001)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ab9d96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Histogram of Simulated AR(2) Time Series:\n",
      "-3.03--2.73: *** (0.067)\n",
      "-2.73--2.44: * (0.034)\n",
      "-2.44--2.14: * (0.034)\n",
      "-2.14--1.84: ****** (0.134)\n",
      "-1.84--1.54:  (0.000)\n",
      "-1.54--1.24: ****** (0.134)\n",
      "-1.24--0.95: ***** (0.101)\n",
      "-0.95--0.65: ********** (0.201)\n",
      "-0.65--0.35: ******** (0.168)\n",
      "-0.35--0.05: ************************* (0.503)\n",
      "-0.05-0.25: ************************** (0.537)\n",
      "0.25-0.54: ************* (0.268)\n",
      "0.54-0.84: ************* (0.268)\n",
      "0.84-1.14: **************** (0.335)\n",
      "1.14-1.44: *********** (0.235)\n",
      "1.44-1.74: ***** (0.101)\n",
      "1.74-2.03: * (0.034)\n",
      "2.03-2.33: ****** (0.134)\n",
      "2.33-2.63:  (0.000)\n",
      "2.63-2.93: *** (0.067)\n",
      "Iteration 0, Current p = 2\n",
      "Iteration 100, Current p = 1\n",
      "Iteration 200, Current p = 1\n",
      "Iteration 300, Current p = 1\n",
      "Iteration 400, Current p = 1\n",
      "Iteration 500, Current p = 1\n",
      "Iteration 600, Current p = 1\n",
      "Iteration 700, Current p = 1\n",
      "Iteration 800, Current p = 1\n",
      "Iteration 900, Current p = 1\n",
      "\n",
      "Posterior Distribution of Model Order (p):\n",
      "p=1: ************************************************* (Probability: 0.982)\n",
      "p=2:  (Probability: 0.018)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import math\n",
    "from typing import List, Dict\n",
    "\n",
    "# Basic statistical functions without libraries\n",
    "def normal_pdf(x: float, mean: float, std: float) -> float:\n",
    "    \"\"\"\n",
    "    Compute the probability density function of a normal distribution.\n",
    "    \"\"\"\n",
    "    variance = std * std\n",
    "    exponent = -((x - mean) ** 2) / (2 * variance)\n",
    "    return (1 / (std * math.sqrt(2 * math.pi))) * math.exp(exponent)\n",
    "\n",
    "def ar_likelihood(data: List[float], p: int, theta: List[float], sigma: float) -> float:\n",
    "    \"\"\"\n",
    "    Compute the log-likelihood of the data under an AR(p) model.\n",
    "    \"\"\"\n",
    "    n = len(data)\n",
    "    ll = 0.0\n",
    "    for t in range(p, n):\n",
    "        pred = sum(theta[i] * data[t - i - 1] for i in range(p))\n",
    "        error = data[t] - pred\n",
    "        ll += -0.5 * math.log(2 * math.pi * sigma * sigma) - (error * error) / (2 * sigma * sigma)\n",
    "    return ll\n",
    "\n",
    "def log_prior_model(p: int) -> float:\n",
    "    \"\"\"\n",
    "    Uniform prior over model orders (e.g., p=1 or p=2).\n",
    "    \"\"\"\n",
    "    return -math.log(2)  # Uniform prior over {1, 2}\n",
    "\n",
    "def log_prior_params(theta: List[float], sigma: float) -> float:\n",
    "    \"\"\"\n",
    "    Normal prior for theta (mean=0, variance=10) and inverse-gamma for sigma (shape=2, scale=1).\n",
    "    \"\"\"\n",
    "    log_theta_prior = 0.0\n",
    "    for t in theta:\n",
    "        exponent = -((t - 0) ** 2) / (2 * 10)\n",
    "        log_theta_prior += math.log((1 / (math.sqrt(2 * math.pi * 10))) * math.exp(exponent))\n",
    "    \n",
    "    log_sigma_prior = math.log((1 ** 2) / (math.gamma(2) * (sigma ** (2 + 1))) * math.exp(-1 / sigma))\n",
    "    return log_theta_prior + log_sigma_prior\n",
    "\n",
    "def mcmc_model_choice(data: List[float], n_iter: int) -> List[int]:\n",
    "    \"\"\"\n",
    "    Run MCMC to sample model orders (p=1 or p=2).\n",
    "    \"\"\"\n",
    "    # Initialize with p=1\n",
    "    current_p = 1\n",
    "    if current_p == 1:\n",
    "        theta = [random.gauss(0, math.sqrt(10))]  # AR(1) coefficient\n",
    "        sigma = random.uniform(0.1, 2.0)  # Noise std\n",
    "    else:  # p=2\n",
    "        theta = [random.gauss(0, math.sqrt(10)), random.gauss(0, math.sqrt(10))]  # AR(2) coefficients\n",
    "        sigma = random.uniform(0.1, 2.0)  # Noise std\n",
    "    \n",
    "    chain = [current_p]\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        # Propose a new model order (toggle between p=1 and p=2)\n",
    "        proposed_p = 2 if current_p == 1 else 1\n",
    "        \n",
    "        # Propose new parameters for the proposed model\n",
    "        if proposed_p == 1:\n",
    "            new_theta = [random.gauss(0, math.sqrt(10))]\n",
    "            new_sigma = random.uniform(0.1, 2.0)\n",
    "        else:  # proposed_p == 2\n",
    "            new_theta = [random.gauss(0, math.sqrt(10)), random.gauss(0, math.sqrt(10))]\n",
    "            new_sigma = random.uniform(0.1, 2.0)\n",
    "        \n",
    "        # Compute log posterior for current and proposed models\n",
    "        current_log_posterior = ar_likelihood(data, current_p, theta, sigma) + \\\n",
    "                               log_prior_model(current_p) + log_prior_params(theta, sigma)\n",
    "        \n",
    "        proposed_log_posterior = ar_likelihood(data, proposed_p, new_theta, new_sigma) + \\\n",
    "                                log_prior_model(proposed_p) + log_prior_params(new_theta, new_sigma)\n",
    "        \n",
    "        # Acceptance probability\n",
    "        log_acceptance = proposed_log_posterior - current_log_posterior\n",
    "        \n",
    "        if math.log(random.random()) < log_acceptance:\n",
    "            current_p = proposed_p\n",
    "            theta = new_theta\n",
    "            sigma = new_sigma\n",
    "        \n",
    "        chain.append(current_p)\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Iteration {i}, Current p = {current_p}\")\n",
    "    \n",
    "    return chain\n",
    "\n",
    "def print_histogram(data: List[float], bins: int = 20):\n",
    "    \"\"\"\n",
    "    Print a text-based histogram of the data.\n",
    "    \"\"\"\n",
    "    min_val, max_val = min(data), max(data)\n",
    "    bin_size = (max_val - min_val) / bins\n",
    "    counts = [0] * bins\n",
    "    \n",
    "    for x in data:\n",
    "        bin_idx = min(int((x - min_val) / bin_size), bins - 1)\n",
    "        counts[bin_idx] += 1\n",
    "    \n",
    "    total = sum(counts)\n",
    "    for i, count in enumerate(counts):\n",
    "        lower = min_val + i * bin_size\n",
    "        upper = min_val + (i + 1) * bin_size\n",
    "        density = count / (total * bin_size) if total > 0 else 0\n",
    "        stars = int(density * 50)  # Scale for text visualization\n",
    "        print(f\"{lower:.2f}-{upper:.2f}: {'*' * stars} ({density:.3f})\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Parameters for AR(2) model\n",
    "p = 2\n",
    "theta = [0.5, 0.3]  # AR coefficients\n",
    "sigma = 1.0  # Standard deviation of noise\n",
    "n_samples = 100  # Number of time points\n",
    "\n",
    "# Generate AR(2) data\n",
    "data = [0.0] * n_samples\n",
    "for t in range(p, n_samples):\n",
    "    noise = random.gauss(0, sigma)\n",
    "    data[t] = sum(theta[i] * data[t - i - 1] for i in range(p)) + noise\n",
    "\n",
    "# Print text-based histogram of the data\n",
    "print(\"Histogram of Simulated AR(2) Time Series:\")\n",
    "print_histogram(data)\n",
    "\n",
    "# Run the MCMC\n",
    "n_iterations = 1000\n",
    "chain = mcmc_model_choice(data, n_iterations)\n",
    "\n",
    "# Analyze results (text-based histogram for p values)\n",
    "p_values = chain\n",
    "p_counts = {1: 0, 2: 0}\n",
    "for p in p_values:\n",
    "    p_counts[p] += 1\n",
    "total = sum(p_counts.values())\n",
    "\n",
    "print(\"\\nPosterior Distribution of Model Order (p):\")\n",
    "for p in sorted(p_counts.keys()):\n",
    "    density = p_counts[p] / total\n",
    "    stars = int(density * 50)  # Scale for text visualization\n",
    "    print(f\"p={p}: {'*' * stars} (Probability: {density:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb19926b",
   "metadata": {},
   "source": [
    "# Reversible Jump Algorithms\n",
    "\n",
    "There have been several earlier approaches in the literature to deal with variable dimension models using, for instance, birth-and-death processes (Ripley 1977, Geyer and Møller 1994) or pseudo-priors (Carlin and Chib 1995, see Problem 11.9), but the general formalization of this problem by Green (1995) is a landmark. Note that, at this stage, regular Gibbs sampling is impossible when considering distributions on the form (11.2) if one conditions on $k$, then $\\theta_k \\in \\Theta_k$, and if one conditions on $\\theta_k$, then $k$ cannot move. Therefore, a standard Gibbs sampler cannot provide moves between models $\\Theta_k$ without further modification of the setting.\n",
    "\n",
    "## 11.2.1 Green’s Algorithm\n",
    "\n",
    "If we let $x = (k, \\theta_k)$, the solution proposed by Green (1995) is based on a reversible transition kernel $K$, that is, a kernel satisfying\n",
    "\n",
    "$$\n",
    "\\int_{A \\times B} K(x, dy) \\pi(x) dx = \\int_{A \\times B} K(y, dx) \\pi(y) dy\n",
    "$$\n",
    "\n",
    "for all $A, B \\subset \\Theta$ and for some invariant density $\\pi$ (see Section 6.5.3). To see more clearly how this condition can be satisfied and how a proper reversible kernel $K$ can be constructed, we decompose $K$ according to the model in which $x$ and $y$ can be found, i.e., according to the model $M_{k_x}$ and $M_{k_y}$ denoting a transition measure (or jump). The decomposition of the kernel is thus\n",
    "\n",
    "$$\n",
    "K(x, B) = \\sum_{y \\in B} \\int_{M_{k_x} \\times M_{k_y}} q(x, dy) + w(x) I_B(x),\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "w(x) = 1 - \\sum_{m \\neq k_x} q_m(x, \\Theta_m)\n",
    "$$\n",
    "\n",
    "represents the probability of no move.\n",
    "\n",
    "Typically, and mostly for practicality’s sake, the jumps are limited to moves from $M_{k_x}$ to models with dimensionalities close to the dimension of $\\Theta_{k_x}$, possibly including $y = M_{k_x}$, constructing generally sensible proposal $q_m$. A move from $x = (m, \\theta_m)$ to $y = (n, \\theta_n)$ is generally too difficult when $M_n$ and $M_{k_x}$ differ by many dimensions. The definition of $q_m$ (and the verification of the reversibility assumptions) relies on the following assumption: The joint measure $\\pi(x) dx, dy$ must be absolutely continuous with respect to a symmetric measure $\\xi_n(x, dx, dy)$ on $\\Theta \\times \\Theta$. If $\\pi(x, y)$ denotes the density of $\\pi(x)$ with respect to $\\xi_n(x, dx, dy)$, and if $\\pi_m$ is written in the usual Metropolis-Hastings form\n",
    "\n",
    "$$\n",
    "\\rho_m(x, y) = \\min \\left\\{ \\frac{q_m(y, x)}{q_m(x, y)} \\right\\},\n",
    "$$\n",
    "\n",
    "then reversibility is ensured by the symmetry of the measure $\\xi_n$:\n",
    "\n",
    "$$\n",
    "\\int_{A \\times B} \\rho_m(x, y) q_m(x, dy) \\pi(x) dx = \\int_{A \\times B} \\rho_m(y, x) q_m(y, dx) \\pi(y) dy\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\int_{A \\times B} \\rho_m(x, y) q_m(x, dy) \\pi(x) dx = \\int_{A \\times B} \\rho_m(y, x) q_m(y, dx) \\pi(y) dy,\n",
    "$$\n",
    "\n",
    "as $\\rho_m(x, y) = \\rho_m(y, x)$ by construction.\n",
    "\n",
    "The main difficulty of this approach lies in the determination of the measure $\\xi_n$ given the symmetry constraint. If the jumps are decomposed into moves between pairs of models, $M_{k_x}$ and $M_{k_y}$, the (clever) idea of Green (1995) is slightly involved. For an alternate description of this technique, which might be easier to understand, we refer the reader to Section 11.2.2. There the reversible jump algorithm is justified using ordinary Metropolis-Hastings arguments.\n",
    "\n",
    "Green (1995) imposes a dimension-matching condition which is that the opposite move from $\\Theta_{k_y}$ to $\\Theta_{k_x}$ is concentrated on the curve\n",
    "\n",
    "$$\n",
    "\\{(\\theta_{k_y}^{k_x}, \\theta_{k_y}) = T(\\theta_{k_x}^{k_y})\\},\n",
    "$$\n",
    "\n",
    "into $[\\theta_{k_x}, u_1]$ and $[\\theta_{k_y}, v_2]$ by $u_1 = q(u_2)$ into $[\\theta_{k_y}, v_2]$, so that the mapping between $[\\theta_{k_x}, u_1]$ and $[\\theta_{k_y}, v_2]$ is a bijection,\n",
    "\n",
    "$$\n",
    "(\\theta_{k_x}, u_1) \\text{ and } (\\theta_{k_y}, v_2) = T(\\theta_{k_x}^{k_y}, u_1),\n",
    "$$\n",
    "\n",
    "the probability of acceptance for the move from $M_{k_x}$ to $M_{k_y}$ is then\n",
    "\n",
    "$$\n",
    "\\min \\left\\{ \\frac{\\pi(\\theta_{k_y}, \\theta_{k_y}^{k_x}) q_{k_y}(\\theta_{k_y}, \\theta_{k_y}^{k_x})}{ \\pi(\\theta_{k_x}, \\theta_{k_x}^{k_y}) q_{k_x}(\\theta_{k_x}, \\theta_{k_x}^{k_y})}, 1 \\right\\},\n",
    "$$\n",
    "\n",
    "involving the Jacobian of the transformation (11.3), the probability $\\pi_{k_y}$ of choosing a jump to $M_{k_y}$, while in $M_{k_y}$, and $q_{k_y}$, the density of this proposal saturates (Green, 1995) from the balance condition $M_{k_y}$ to $M_{k_x}$, and also satisfies (11.3) with $u_2 = q(u_1)$.\n",
    "\n",
    "The pseudo-code representation of Green’s (1995) algorithm is thus as follows:\n",
    "\n",
    "**Algorithm A.48 — Green’s Algorithm**\n",
    "\n",
    "At iteration $t$, if $x^{(t)} = (m, \\theta_m^{(t)})$,\n",
    "1. Select model $M_n$, with probability $\\pi_{nm}$.\n",
    "2. Generate $u_{nm}$ with probability $q_{nm}(x^{(t)}, u_{nm})$.\n",
    "3. Set $(\\theta_n^{(t)}, v_{nm}) = T_{nm}(\\theta_m^{(t)}, u_{nm})$.\n",
    "4. Take $\\theta_n^{(t+1)} = \\theta_n^{(t)}$ with probability\n",
    "\n",
    "$$\n",
    "\\min \\left\\{ \\frac{\\pi(\\theta_n^{(t)}, v_{nm}) q_{mn}(v_{nm}, u_{nm})}{ \\pi(\\theta_m^{(t)}, u_{nm}) q_{nm}(\\theta_m^{(t)}, u_{nm})}, 1 \\right\\},\n",
    "$$\n",
    "\n",
    "and take $\\theta_m^{(t+1)} = \\theta_m^{(t)}$ otherwise.\n",
    "\n",
    "As pointed out by Green (1995), the density $\\pi$ does not need to be normalized, but the different component densities $\\pi_k(\\theta_k)$ must be known up to the same constant.\n",
    "\n",
    "# Example 11.4: A Linear Jacobian\n",
    "\n",
    "To illustrate the procedure, Green (1995) considers the toy example of switching between the parameters $(1, \\theta_2)$ and $(2, \\theta_2)$, using the following moves:\n",
    "1. To go from $(1, \\theta_2)$ to $(2, \\theta_2)$, set $\\theta = (\\theta_2 + \\theta_3)/2$, generate a random variable $u \\sim q(u)$ and set $\\theta_2 = \\theta - u$, $\\theta_3 = \\theta + u$.\n",
    "2. To go from $(2, \\theta_2)$ to $(1, \\theta_2)$, generate a random variable $u \\sim q(u)$ and set $\\theta_1 = \\theta - u$, $\\theta_2 = \\theta + u$.\n",
    "\n",
    "These moves represent one-to-one transformations of variables in $\\mathbb{R}^2$, that is,\n",
    "\n",
    "$$\n",
    "(\\theta_1, \\theta_2, \\theta_3) = T_{21}(\\theta_2, \\theta_3), \\quad (\\theta - u, \\theta + u) = T_{12}(\\theta, u),\n",
    "$$\n",
    "\n",
    "with corresponding Jacobians\n",
    "\n",
    "$$\n",
    "\\frac{\\partial T_{21}(\\theta_2, \\theta_3)}{\\partial (\\theta_2, \\theta_3)} = 2, \\quad \\frac{\\partial T_{12}(\\theta, u)}{\\partial (\\theta, u)} = 2.\n",
    "$$\n",
    "\n",
    "The acceptance probability for a move from $(1, \\theta_2)$ to $(2, \\theta_2)$ is thus\n",
    "\n",
    "$$\n",
    "\\min \\left( \\frac{\\pi(2, \\theta_2, u)}{ \\pi(1, \\theta_2) q(u)}, 1 \\right),\n",
    "$$\n",
    "\n",
    "where $u = (\\theta_2 - \\theta_3)/2$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e448ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Current k = 2\n",
      "Iteration 100, Current k = 2\n",
      "Iteration 200, Current k = 2\n",
      "Iteration 300, Current k = 2\n",
      "Iteration 400, Current k = 2\n",
      "Iteration 500, Current k = 2\n",
      "Iteration 600, Current k = 2\n",
      "Iteration 700, Current k = 2\n",
      "Iteration 800, Current k = 2\n",
      "Iteration 900, Current k = 2\n",
      "\n",
      "Posterior Distribution of Model Order (k):\n",
      "1-2:  (Probability: 0.005)\n",
      "2-2: ************************************************* (Probability: 0.995)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import math\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "# Basic statistical functions without libraries\n",
    "def normal_pdf(x: float, mean: float, std: float) -> float:\n",
    "    \"\"\"\n",
    "    Compute the probability density function of a normal distribution.\n",
    "    \"\"\"\n",
    "    variance = std * std\n",
    "    exponent = -((x - mean) ** 2) / (2 * variance)\n",
    "    return (1 / (std * math.sqrt(2 * math.pi))) * math.exp(exponent)\n",
    "\n",
    "def log_prior_model(k: int, theta: List[float]) -> float:\n",
    "    \"\"\"\n",
    "    Uniform prior over models (k=1 or k=2) and normal prior for theta (mean=0, variance=10).\n",
    "    \"\"\"\n",
    "    log_k_prior = -math.log(2)  # Uniform prior over {1, 2}\n",
    "    log_theta_prior = 0.0\n",
    "    for t in theta:\n",
    "        exponent = -((t - 0) ** 2) / (2 * 10)\n",
    "        log_theta_prior += math.log((1 / (math.sqrt(2 * math.pi * 10))) * math.exp(exponent))\n",
    "    return log_k_prior + log_theta_prior\n",
    "\n",
    "def log_likelihood(k: int, theta: List[float], data: List[float]) -> float:\n",
    "    \"\"\"\n",
    "    Compute the log-likelihood for models (k=1 or k=2) with simulated data (assumed normal).\n",
    "    For simplicity, assume data points are drawn from N(theta[0], 1) for k=1, and N(theta[0], 1) + N(theta[1], 1) for k=2.\n",
    "    \"\"\"\n",
    "    ll = 0.0\n",
    "    n = len(data)\n",
    "    if k == 1:\n",
    "        for x in data:\n",
    "            ll += math.log(normal_pdf(x, theta[0], 1.0))\n",
    "    else:  # k == 2\n",
    "        for x in data:\n",
    "            ll += math.log(0.5 * normal_pdf(x, theta[0], 1.0) + 0.5 * normal_pdf(x, theta[1], 1.0))\n",
    "    return ll\n",
    "\n",
    "def propose_move(current_state: Dict) -> Tuple[Dict, float]:\n",
    "    \"\"\"\n",
    "    Propose a move in Green’s reversible jump MCMC between (1, θ_2) and (2, θ_2).\n",
    "    Returns the proposed state and the Jacobian determinant for dimension changes.\n",
    "    \"\"\"\n",
    "    k = current_state['k']\n",
    "    theta = current_state['theta']\n",
    "    \n",
    "    if k == 1:  # Move from (1, θ_2) to (2, θ_2)\n",
    "        theta_2 = theta[0]\n",
    "        u = random.gauss(0, 1.0)  # Random variable u ~ N(0, 1)\n",
    "        theta_new = [theta_2 - u, theta_2 + u]  # θ_2 = θ - u, θ_3 = θ + u\n",
    "        new_k = 2\n",
    "        jacobian = 2.0  # Jacobian from Example 11.4\n",
    "        return {'k': new_k, 'theta': theta_new}, jacobian\n",
    "    \n",
    "    else:  # Move from (2, θ_2) to (1, θ_2)\n",
    "        theta_2 = (theta[0] + theta[1]) / 2  # θ = (θ_2 + θ_3)/2\n",
    "        u = (theta[0] - theta[1]) / 2  # u = (θ_2 - θ_3)/2 for reference\n",
    "        new_k = 1\n",
    "        jacobian = 2.0  # Jacobian from Example 11.4\n",
    "        return {'k': new_k, 'theta': [theta_2]}, jacobian\n",
    "\n",
    "def reversible_jump_mcmc(data: List[float], n_iter: int) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Run Green’s reversible jump MCMC to sample from the posterior of models (k=1 or k=2).\n",
    "    \"\"\"\n",
    "    # Initialize with k=1, θ_2 = 0\n",
    "    k = 1\n",
    "    theta = [random.gauss(0, math.sqrt(10))]  # θ_2 ~ N(0, 10)\n",
    "    \n",
    "    current_state = {'k': k, 'theta': theta}\n",
    "    chain = [current_state.copy()]\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        proposed_state, jacobian = propose_move(current_state)\n",
    "        \n",
    "        # Log posterior for current and proposed states\n",
    "        current_log_posterior = log_likelihood(current_state['k'], current_state['theta'], data) + \\\n",
    "                               log_prior_model(current_state['k'], current_state['theta'])\n",
    "        \n",
    "        proposed_log_posterior = log_likelihood(proposed_state['k'], proposed_state['theta'], data) + \\\n",
    "                                log_prior_model(proposed_state['k'], proposed_state['theta'])\n",
    "        \n",
    "        # Acceptance probability (including Jacobian for dimension changes)\n",
    "        log_acceptance = proposed_log_posterior - current_log_posterior + math.log(jacobian)\n",
    "        \n",
    "        if math.log(random.random()) < log_acceptance:\n",
    "            current_state = proposed_state.copy()\n",
    "        \n",
    "        chain.append(current_state.copy())\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Iteration {i}, Current k = {current_state['k']}\")\n",
    "    \n",
    "    return chain\n",
    "\n",
    "def print_histogram(data: List[int], bins: int = 2):\n",
    "    \"\"\"\n",
    "    Print a text-based histogram of the data (for k values: 1 or 2).\n",
    "    \"\"\"\n",
    "    min_val, max_val = min(data), max(data)\n",
    "    bin_size = (max_val - min_val) / bins\n",
    "    counts = [0] * bins\n",
    "    \n",
    "    for x in data:\n",
    "        bin_idx = min(int((x - min_val) / bin_size), bins - 1)\n",
    "        counts[bin_idx] += 1\n",
    "    \n",
    "    total = sum(counts)\n",
    "    for i, count in enumerate(counts):\n",
    "        lower = min_val + i * bin_size\n",
    "        upper = min_val + (i + 1) * bin_size\n",
    "        density = count / total if total > 0 else 0\n",
    "        stars = int(density * 50)  # Scale for text visualization\n",
    "        print(f\"{lower:.0f}-{upper:.0f}: {'*' * stars} (Probability: {density:.3f})\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Generate synthetic data (assume 50 points from N(0, 1) for simplicity)\n",
    "n_samples = 50\n",
    "data = [random.gauss(0, 1.0) for _ in range(n_samples)]\n",
    "\n",
    "# Run the MCMC\n",
    "n_iterations = 1000\n",
    "chain = reversible_jump_mcmc(data, n_iterations)\n",
    "\n",
    "# Analyze results (text-based histogram for k values)\n",
    "k_values = [state['k'] for state in chain]\n",
    "print(\"\\nPosterior Distribution of Model Order (k):\")\n",
    "print_histogram(k_values)"
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "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"
    },
    "image-3.png": {
     "image/png": "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"
    },
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "c5232a9b",
   "metadata": {},
   "source": [
    "## A Fixed Dimension Reassessment\n",
    "\n",
    "While the above development is completely valid from a mathematical point of view, we now redefine Green’s algorithm via a saturation scheme that provides better intuition for the determination of the acceptance probability. When considering a specific move from $M_m$ to $M_n$, that is, from $\\theta_m \\in \\Theta_m$ to $\\theta_n \\in \\Theta_n$, we indeed have $d_m = \\dim \\Theta_m < d_n = \\dim \\Theta_n$, we can indeed describe an auxiliary variable $u \\in \\mathbb{R}^{d_n - d_m}$, so that $\\theta_n = T_m(\\theta_m, u)$, and $\\theta_m$ are in bijection (one-to-one).\n",
    "\n",
    "As described above, the central feature of Green’s algorithm is to add an auxiliary variable $u \\in \\mathbb{R}^{d_n - d_m}$ so that $\\theta_n = T_{mn}(\\theta_m, u)$, and we consider that the special case, where $\\theta_m$ are not completed (using a regular Metropolis-Hastings scheme, to propose a move from the pair $(\\theta_m, u_m)$ to $\\theta_n$ is like proposing to do so when the corresponding stationary distributions are $\\pi(m, \\theta_m) q_{mn}(\\theta_m, u_{mn})$ and $\\pi(n, \\theta_n)$, respectively, and when the proposal distribution is deterministic, since $\\theta_n = T_{mn}(\\theta_m, u_{mn})$).\n",
    "\n",
    "This unusual setting for Metropolis-Hastings moves, because of its deterministic nature, but it can be solved by the following approximation: Consider the move from $(\\theta_m, u_{mn})$ to $\\theta_n$ proceeds by generating\n",
    "\n",
    "$$\n",
    "\\theta_n = N_{d_n}(T_{mn}(\\theta_m, u_{mn}), \\epsilon I),\n",
    "$$\n",
    "\n",
    "and that the reciprocal proposal then has the density\n",
    "\n",
    "$$\n",
    "\\exp \\left\\{ -\\frac{1}{2} (2\\pi)^{d_n/2} \\left[ \\frac{\\|T_{mn}(\\theta_m, u_{mn}) - \\theta_n\\|^2}{\\epsilon^2} \\right] \\right\\} \\times \\left| \\frac{\\partial T_{mn}(\\theta_m, u_{mn})}{\\partial (\\theta_m, u_{mn})} \\right|.\n",
    "$$\n",
    "\n",
    "by the Jacobian rule. Therefore, the Metropolis-Hastings acceptance ratio for this Jacobian move is:\n",
    "\n",
    "$$\n",
    "1 \\wedge \\left( \\frac{\\pi(n, \\theta_n) q_{mn}(\\theta_m, u_{mn})}{ \\pi(m, \\theta_m) q_{nm}(\\theta_n, u_{nm})} \\right)\n",
    "\\times\n",
    "\\exp \\left\\{ -\\frac{1}{2} (2\\pi)^{d_n/2} \\left[ \\frac{\\|T_{mn}(\\theta_m, u_{mn}) - \\theta_n\\|^2}{\\epsilon^2} \\right] \\right\\}\n",
    "\\times\n",
    "\\exp \\left\\{ -\\frac{1}{2} (2\\pi)^{d_n/2} \\left[ \\frac{\\|T_{nm}(\\theta_n, u_{nm}) - \\theta_m\\|^2}{\\epsilon^2} \\right] \\right\\},\n",
    "$$\n",
    "\n",
    "and the normal densities cancel in a regular random walk proposal. If we take into account the probabilities of the moves between $M_m$ and $M_n$, we end up with\n",
    "\n",
    "$$\n",
    "1 \\wedge \\left( \\frac{\\pi(n, \\theta_n) q_{mn}(\\theta_m, u_{mn})}{ \\pi(m, \\theta_m) q_{nm}(\\theta_n, u_{nm})} \\right).\n",
    "$$\n",
    "\n",
    "Since this probability does not depend on $\\epsilon$, we can let $\\epsilon \\to 0$ and obtain the equivalent of the ratio (11.4). The reversible jump algorithm can thus be the reinterpretation of local fixed dimensional moves between the models $M_k$ (Problem 11.5).\n",
    "\n",
    "## The Practice of Reversible Jump MCMC\n",
    "\n",
    "The dimension matching transform, $T_{mn}$, while incredibly flexible, can be quite difficult to create and much more difficult to optimize; one could almost say this difficulty, in the choice of $T_{mn}$, is a drawback with the method. In fact, the total freedom left by the reversible jump principle about the choice of the jumps, which are often referred to as split and merge moves in embedded models, creates a potential opening for inefficiency and requires tuning steps which can be quite demanding. As also mentioned in a later chapter, this is a setting where wealth is a mixed blessing, if only because the total lack of calibration of the algorithm.\n",
    "\n",
    "### Example 5: Linear versus Quadratic Regression\n",
    "\n",
    "Consider a particular regression. Instead of choosing a model averaging, we can use the reversible jump algorithm to do model averaging.\n",
    "\n",
    "Suppose that the two candidate models are the linear and quadratic regression models:\n",
    "\n",
    "$$\n",
    "y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i, \\quad \\text{and} \\quad y_i = \\beta_0 + \\beta_1 x_i + \\beta_2 x_i^2 + \\epsilon_i,\n",
    "$$\n",
    "\n",
    "If we represent either regression by $y = X \\beta + \\epsilon$, where $\\epsilon \\sim \\mathcal{N}(0, \\sigma^2 I)$, the least squares estimate $\\hat{\\beta} = (X^T X)^{-1} X^T y$ has distribution\n",
    "\n",
    "$$\n",
    "\\hat{\\beta} \\sim \\mathcal{N}(\\beta, \\sigma^2 (X^T X)^{-1}).\n",
    "$$\n",
    "\n",
    "Using normal prior distributions will result in normal posterior distributions, and the reversible jump algorithm will then be jumping between a two-dimensional and three-dimensional normal distribution.\n",
    "\n",
    "To jump between these models, it seems sensible to first transform orthogonal coordinates, as a jump that is made by simply adding or deleting a coefficient will not affect the fit of the other coefficients. We thus find an orthogonal matrix $P$ and diagonal matrix $D_A$ satisfying\n",
    "\n",
    "$$\n",
    "P^T X^T X P = D_A.\n",
    "$$\n",
    "\n",
    "The elements of $D_A, \\lambda_i$, are the eigenvalues of $X^T X$ and the columns of $P$ are its eigenvectors. We then write $X' = X P$ and $a = P^T \\beta$, and we work with the model $y = X' a + \\epsilon$.\n",
    "\n",
    "If each $a_i$ has a normal prior distribution, $a_i \\sim \\mathcal{N}(0, \\tau^2)$, its posterior density, denoted $f_i(s \\mid a_i, b_i, \\sigma^2)$, where $a_i = \\lambda_i^{-1/2} \\tau^2$, its possible moves are:\n",
    "1. (linear — linear): $(\\alpha_0, \\alpha_1) \\to (\\alpha_0', \\alpha_1')$, where $(\\alpha_0', \\alpha_1') \\sim f_{01}$.\n",
    "2. (linear — quadratic): $(\\alpha_0, \\alpha_1) \\to (\\alpha_0', \\alpha_1', \\alpha_2')$, where $(\\alpha_0', \\alpha_1', \\alpha_2') \\sim f_{012}$.\n",
    "3. (quadratic — quadratic): $(\\alpha_0, \\alpha_1, \\alpha_2) \\to (\\alpha_0', \\alpha_1', \\alpha_2')$, where $(\\alpha_0', \\alpha_1', \\alpha_2') \\sim f_{012}$.\n",
    "4. (quadratic — linear): $(\\alpha_0, \\alpha_1, \\alpha_2) \\to (\\alpha_0', \\alpha_1')$, where $(\\alpha_0', \\alpha_1') \\sim f_{01}$.\n",
    "\n",
    "The algorithm was implemented on simulated data with move probabilities $\\pi_{ij}$ all taken to be 1/4 and a prior probability of 1/2 on each regression model. The resulting fits are given in Figure 11.2. It is interesting to note that when the model is quadratic, the reversible jump fit is close to that of quadratic least squares, but it deviates from quadratic least squares when the underlying model is linear. (See Problem 11.3 for more details.)\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "![image-2.png](attachment:image-2.png)\n",
    "![image-3.png](attachment:image-3.png)\n",
    "\n",
    "### Example 6: Piecewise Constant Densities\n",
    "\n",
    "Consider a density $f(x)$ on $[0, 1]$ of the form\n",
    "\n",
    "$$\n",
    "f(x) = \\sum_{i=1}^k w_i f_{a_i, b_i}(x),\n",
    "$$\n",
    "\n",
    "where the $w_i$ are weights summing to 1, and $f_{a_i, b_i}(x)$ are piecewise constant functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75fca8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of Simulated Data (x, y):\n",
      "x[0] = 0.56, y[0] = 1.72\n",
      "x[1] = -1.90, y[1] = -4.36\n",
      "x[2] = -0.90, y[2] = -1.33\n",
      "x[3] = -1.11, y[3] = -0.66\n",
      "x[4] = 0.95, y[4] = 2.03\n",
      "Iteration 0, Current k = 2\n",
      "Iteration 100, Current k = 2\n",
      "Iteration 200, Current k = 2\n",
      "Iteration 300, Current k = 2\n",
      "Iteration 400, Current k = 2\n",
      "Iteration 500, Current k = 2\n",
      "Iteration 600, Current k = 2\n",
      "Iteration 700, Current k = 2\n",
      "Iteration 800, Current k = 2\n",
      "Iteration 900, Current k = 2\n",
      "\n",
      "Posterior Distribution of Model Order (k) for Regression:\n",
      "1-2:  (Probability: 0.001)\n",
      "2-2: ************************************************* (Probability: 0.999)\n",
      "Iteration 0, Current k = 2\n",
      "Iteration 100, Current k = 1\n",
      "Iteration 200, Current k = 2\n",
      "Iteration 300, Current k = 1\n",
      "Iteration 400, Current k = 1\n",
      "Iteration 500, Current k = 2\n",
      "Iteration 600, Current k = 1\n",
      "Iteration 700, Current k = 1\n",
      "Iteration 800, Current k = 2\n",
      "Iteration 900, Current k = 2\n",
      "\n",
      "Posterior Distribution of Piecewise Intervals (k):\n",
      "1-2: ************************************** (Probability: 0.769)\n",
      "2-2: *********** (Probability: 0.231)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import math\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "# Basic statistical functions without libraries\n",
    "def normal_pdf(x: float, mean: float, std: float) -> float:\n",
    "    \"\"\"\n",
    "    Compute the probability density function of a normal distribution.\n",
    "    \"\"\"\n",
    "    variance = std * std\n",
    "    exponent = -((x - mean) ** 2) / (2 * variance)\n",
    "    return (1 / (std * math.sqrt(2 * math.pi))) * math.exp(exponent)\n",
    "\n",
    "def log_likelihood(k: int, beta: List[float], x: List[float], y: List[float], sigma: float) -> float:\n",
    "    \"\"\"\n",
    "    Compute the log-likelihood for linear (k=1) or quadratic (k=2) regression.\n",
    "    \"\"\"\n",
    "    ll = 0.0\n",
    "    for x_i, y_i in zip(x, y):\n",
    "        if k == 1:  # Linear: y = β_0 + β_1 x\n",
    "            pred = beta[0] + beta[1] * x_i\n",
    "        else:  # k == 2, Quadratic: y = β_0 + β_1 x + β_2 x^2\n",
    "            pred = beta[0] + beta[1] * x_i + beta[2] * x_i * x_i\n",
    "        error = y_i - pred\n",
    "        ll += -0.5 * math.log(2 * math.pi * sigma * sigma) - (error * error) / (2 * sigma * sigma)\n",
    "    return ll\n",
    "\n",
    "def log_prior_model(k: int, beta: List[float]) -> float:\n",
    "    \"\"\"\n",
    "    Uniform prior over models (k=1 or k=2) and normal prior for beta (mean=0, variance=10).\n",
    "    \"\"\"\n",
    "    log_k_prior = -math.log(2)  # Uniform prior over {1, 2}\n",
    "    log_beta_prior = 0.0\n",
    "    for b in beta:\n",
    "        exponent = -((b - 0) ** 2) / (2 * 10)\n",
    "        log_beta_prior += math.log((1 / (math.sqrt(2 * math.pi * 10))) * math.exp(exponent))\n",
    "    return log_k_prior + log_beta_prior\n",
    "\n",
    "def log_prior_sigma(sigma: float) -> float:\n",
    "    \"\"\"\n",
    "    Inverse-gamma prior for sigma (shape=2, scale=1).\n",
    "    \"\"\"\n",
    "    return math.log((1 ** 2) / (math.gamma(2) * (sigma ** (2 + 1))) * math.exp(-1 / sigma))\n",
    "\n",
    "def propose_move(current_state: Dict, x: List[float]) -> Tuple[Dict, float]:\n",
    "    \"\"\"\n",
    "    Propose a move in Green’s reversible jump MCMC between linear (k=1) and quadratic (k=2) models.\n",
    "    Returns the proposed state and the Jacobian determinant for dimension changes.\n",
    "    \"\"\"\n",
    "    k = current_state['k']\n",
    "    beta = current_state['beta']\n",
    "    sigma = current_state['sigma']\n",
    "    \n",
    "    if k == 1:  # Move from linear to quadratic (k=1 to k=2)\n",
    "        beta_0, beta_1 = beta\n",
    "        u = random.gauss(0, 0.1)  # Auxiliary variable for dimension matching\n",
    "        beta_new = [beta_0, beta_1, u]  # Add β_2 = u\n",
    "        new_k = 2\n",
    "        jacobian = 1.0  # Simplified Jacobian (could be adjusted for specific transform)\n",
    "        return {'k': new_k, 'beta': beta_new, 'sigma': sigma}, jacobian\n",
    "    \n",
    "    else:  # Move from quadratic to linear (k=2 to k=1)\n",
    "        beta_0, beta_1, beta_2 = beta\n",
    "        beta_new = [beta_0, beta_1]  # Drop β_2\n",
    "        new_k = 1\n",
    "        jacobian = 1.0  # Simplified Jacobian\n",
    "        return {'k': new_k, 'beta': beta_new, 'sigma': sigma}, jacobian\n",
    "\n",
    "def reversible_jump_mcmc(x: List[float], y: List[float], n_iter: int) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Run Green’s reversible jump MCMC to sample from the posterior of linear vs. quadratic models.\n",
    "    \"\"\"\n",
    "    # Initialize with linear model (k=1), random beta, and sigma\n",
    "    k = 1\n",
    "    beta = [random.gauss(0, math.sqrt(10)), random.gauss(0, math.sqrt(10))]  # [β_0, β_1]\n",
    "    sigma = random.uniform(0.1, 1.0)  # Noise std\n",
    "    \n",
    "    current_state = {'k': k, 'beta': beta, 'sigma': sigma}\n",
    "    chain = [current_state.copy()]\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        proposed_state, jacobian = propose_move(current_state, x)\n",
    "        \n",
    "        # Log posterior for current and proposed states\n",
    "        current_log_posterior = log_likelihood(current_state['k'], current_state['beta'], x, y, current_state['sigma']) + \\\n",
    "                               log_prior_model(current_state['k'], current_state['beta']) + \\\n",
    "                               log_prior_sigma(current_state['sigma'])\n",
    "        \n",
    "        proposed_log_posterior = log_likelihood(proposed_state['k'], proposed_state['beta'], x, y, proposed_state['sigma']) + \\\n",
    "                                log_prior_model(proposed_state['k'], proposed_state['beta']) + \\\n",
    "                                log_prior_sigma(proposed_state['sigma'])\n",
    "        \n",
    "        # Acceptance probability (including Jacobian for dimension changes)\n",
    "        log_acceptance = proposed_log_posterior - current_log_posterior + math.log(jacobian)\n",
    "        \n",
    "        if math.log(random.random()) < log_acceptance:\n",
    "            current_state = proposed_state.copy()\n",
    "        \n",
    "        chain.append(current_state.copy())\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Iteration {i}, Current k = {current_state['k']}\")\n",
    "    \n",
    "    return chain\n",
    "\n",
    "def piecewise_likelihood(k: int, weights: List[float], intervals: List[Tuple[float, float]], data: List[float]) -> float:\n",
    "    \"\"\"\n",
    "    Compute the log-likelihood for piecewise constant densities with k intervals.\n",
    "    Assume data points are uniform in [0, 1], and each interval has a constant density.\n",
    "    \"\"\"\n",
    "    ll = 0.0\n",
    "    total_weight = sum(weights)\n",
    "    for x in data:\n",
    "        for i in range(k):\n",
    "            start, end = intervals[i]\n",
    "            if start <= x < end:\n",
    "                ll += math.log(weights[i] / (end - start) / total_weight)\n",
    "                break\n",
    "        else:\n",
    "            ll += float('-inf')  # Point outside intervals (should not happen)\n",
    "    return ll\n",
    "\n",
    "def propose_piecewise_move(current_state: Dict) -> Tuple[Dict, float]:\n",
    "    \"\"\"\n",
    "    Propose a move in reversible jump MCMC between k=1 and k=2 piecewise intervals.\n",
    "    \"\"\"\n",
    "    k = current_state['k']\n",
    "    weights = current_state['weights']\n",
    "    intervals = current_state['intervals']\n",
    "    \n",
    "    if k == 1:  # Move from 1 interval to 2 intervals\n",
    "        w = weights[0]\n",
    "        start, end = intervals[0]\n",
    "        mid = random.uniform(start, end)\n",
    "        weights_new = [w * 0.5, w * 0.5]  # Split weight\n",
    "        intervals_new = [(start, mid), (mid, end)]\n",
    "        new_k = 2\n",
    "        jacobian = 1.0  # Simplified Jacobian\n",
    "        return {'k': new_k, 'weights': weights_new, 'intervals': intervals_new}, jacobian\n",
    "    \n",
    "    else:  # Move from 2 intervals to 1 interval\n",
    "        w1, w2 = weights\n",
    "        start1, end1 = intervals[0]\n",
    "        start2, end2 = intervals[1]\n",
    "        weights_new = [w1 + w2]  # Merge weights\n",
    "        intervals_new = [(min(start1, start2), max(end1, end2))]\n",
    "        new_k = 1\n",
    "        jacobian = 1.0  # Simplified Jacobian\n",
    "        return {'k': new_k, 'weights': weights_new, 'intervals': intervals_new}, jacobian\n",
    "\n",
    "def reversible_jump_piecewise(data: List[float], n_iter: int) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Run reversible jump MCMC for piecewise constant densities.\n",
    "    \"\"\"\n",
    "    # Initialize with k=1 interval, uniform weight, and [0, 1]\n",
    "    k = 1\n",
    "    weights = [1.0]\n",
    "    intervals = [(0.0, 1.0)]\n",
    "    \n",
    "    current_state = {'k': k, 'weights': weights, 'intervals': intervals}\n",
    "    chain = [current_state.copy()]\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        proposed_state, jacobian = propose_piecewise_move(current_state)\n",
    "        \n",
    "        # Log posterior for current and proposed states (simplified uniform prior)\n",
    "        current_log_posterior = piecewise_likelihood(current_state['k'], current_state['weights'], current_state['intervals'], data) + \\\n",
    "                               -math.log(2)  # Uniform prior over k=1,2\n",
    "        \n",
    "        proposed_log_posterior = piecewise_likelihood(proposed_state['k'], proposed_state['weights'], proposed_state['intervals'], data) + \\\n",
    "                                -math.log(2)  # Uniform prior over k=1,2\n",
    "        \n",
    "        # Acceptance probability (including Jacobian for dimension changes)\n",
    "        log_acceptance = proposed_log_posterior - current_log_posterior + math.log(jacobian)\n",
    "        \n",
    "        if math.log(random.random()) < log_acceptance:\n",
    "            current_state = proposed_state.copy()\n",
    "        \n",
    "        chain.append(current_state.copy())\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Iteration {i}, Current k = {current_state['k']}\")\n",
    "    \n",
    "    return chain\n",
    "\n",
    "def print_histogram(data: List[int], bins: int = 2):\n",
    "    \"\"\"\n",
    "    Print a text-based histogram of the data (for k values: 1 or 2).\n",
    "    \"\"\"\n",
    "    min_val, max_val = min(data), max(data)\n",
    "    bin_size = (max_val - min_val) / bins\n",
    "    counts = [0] * bins\n",
    "    \n",
    "    for x in data:\n",
    "        bin_idx = min(int((x - min_val) / bin_size), bins - 1)\n",
    "        counts[bin_idx] += 1\n",
    "    \n",
    "    total = sum(counts)\n",
    "    for i, count in enumerate(counts):\n",
    "        lower = min_val + i * bin_size\n",
    "        upper = min_val + (i + 1) * bin_size\n",
    "        density = count / total if total > 0 else 0\n",
    "        stars = int(density * 50)  # Scale for text visualization\n",
    "        print(f\"{lower:.0f}-{upper:.0f}: {'*' * stars} (Probability: {density:.3f})\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Parameters for quadratic regression\n",
    "beta = [1.0, 2.0, -0.5]  # [β_0, β_1, β_2]\n",
    "sigma = 0.5  # Noise standard deviation\n",
    "n_samples = 50  # Number of data points\n",
    "x = [random.uniform(-2, 2) for _ in range(n_samples)]  # x values\n",
    "\n",
    "# Generate quadratic data\n",
    "data = []\n",
    "for x_i in x:\n",
    "    noise = random.gauss(0, sigma)\n",
    "    y_i = beta[0] + beta[1] * x_i + beta[2] * x_i * x_i + noise\n",
    "    data.append(y_i)\n",
    "\n",
    "# Print text-based summary of data\n",
    "print(\"Sample of Simulated Data (x, y):\")\n",
    "for i in range(min(5, n_samples)):  # Show first 5 points or all if fewer\n",
    "    print(f\"x[{i}] = {x[i]:.2f}, y[{i}] = {data[i]:.2f}\")\n",
    "\n",
    "# Run the MCMC for regression models\n",
    "n_iterations = 1000\n",
    "chain = reversible_jump_mcmc(x, data, n_iterations)\n",
    "\n",
    "# Analyze results for regression models\n",
    "k_values = [state['k'] for state in chain]\n",
    "print(\"\\nPosterior Distribution of Model Order (k) for Regression:\")\n",
    "print_histogram(k_values)\n",
    "\n",
    "# Generate synthetic data for piecewise constant densities (uniform in [0, 1])\n",
    "piecewise_data = [random.uniform(0, 1) for _ in range(50)]\n",
    "\n",
    "# Run the MCMC for piecewise densities\n",
    "n_iterations_piecewise = 1000\n",
    "piecewise_chain = reversible_jump_piecewise(piecewise_data, n_iterations_piecewise)\n",
    "\n",
    "# Analyze results for piecewise densities\n",
    "k_piecewise_values = [state['k'] for state in piecewise_chain]\n",
    "print(\"\\nPosterior Distribution of Piecewise Intervals (k):\")\n",
    "print_histogram(k_piecewise_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7778765b",
   "metadata": {},
   "source": [
    "# Reversible Jump MCMC for Mixture Models\n",
    "\n",
    "This model corresponds, for instance, to a special kind of nonparametric density estimation, where the estimator is a step function.\n",
    "\n",
    "Assuming all parameters unknown (including $k$), defining $p_k = (w_k(a_{k-1}, a_k), a_k)$, so these are probabilities. Let $n_k^{(k)}$ be the prior distribution on $p_k$.\n",
    "\n",
    "$$\n",
    "\\pi(k, p^{(k)}, a^{(k)}) = \\frac{\\lambda^k e^{-\\lambda} \\Gamma(k) (p_2)^{n_2} \\cdots p_k^{n_k}}{ \\Gamma(1) \\Gamma(n_2 + \\cdots + n_k) (k - 1)! I_{(a_0, \\dots, a_k)}},\n",
    "$$\n",
    "\n",
    "where $p^{(k)} = (p_1, \\dots, p_k)$ and $a^{(k)} = (a_2, \\dots, a_k)$, which implies a Poisson distribution on $k$, a uniform distribution on $(a_2, \\dots, a_k)$, and a Dirichlet distribution $D_k(1/2, \\dots, 1/2)$ on the weights $p_k$ of the components $\\mu_k(a_{k-1}, a_k)$ of $f$. (Note that the density integrates to 1 over $\\Theta$.)\n",
    "\n",
    "For a sample $x_1, \\dots, x_n$, the posterior\n",
    "\n",
    "$$\n",
    "\\pi(k, p^{(k)}, a^{(k)} \\mid x_1, \\dots, x_n) \\propto \\frac{\\lambda^k e^{-\\lambda} \\Gamma(k) (p_2)^{n_2 - 1/2} \\cdots p_k^{n_k - 1/2}}{ \\Gamma(1) (n_2 + \\cdots + n_k - k)! I_{(a_0, \\dots, a_k)}},\n",
    "$$\n",
    "\n",
    "where $n_j$ is the number of observations between $a_j$ and $a_{j+1}$. We can, for instance, restrict the moves to jumps only between neighboring models; that is, models with one more or one less component in the partition of [0, 1]. We then represent the jump from model $\\Theta_k$ to model $\\Theta_{k-1}$ as a random choice of $(i \\leq k - 1)$, and the aggregation of the $i$-th and $(i+1)$-st components as\n",
    "\n",
    "$$\n",
    "a^{(k-1)} = (a_1^{(k)}, \\dots, a_{i-1}^{(k)}, a_{i+1}^{(k)}, \\dots, a_k^{(k)})\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "p^{(k-1)} = (p_1^{(k)}, \\dots, p_{i-1}^{(k)}, p_i^{(k)} + p_{i+1}^{(k)}, p_{i+2}^{(k)}, \\dots, p_k^{(k)}).\n",
    "$$\n",
    "\n",
    "For reasons of symmetry, the opposite (upward) jump from $\\Theta_{k-1}$ to $\\Theta_k$ implies choosing a component $i$ at random and breaking it by the procedure:\n",
    "\n",
    "1. Generate $u_{k-1} \\sim U(0, 1); v_{k-1}^{(i)} = u_{k-1} a_i^{(k-1)} + (1 - u_{k-1}) a_{i+1}^{(k-1)}$ and $a^{(k)} = a^{(k-1)}$.\n",
    "2. Take $p_i^{(k)} = u_{k-1} p_i^{(k-1)}$ and $p_{i+1}^{(k)} = (1 - u_{k-1}) p_i^{(k-1)}$.\n",
    "\n",
    "The other quantities remain identical up to a possible index shift. The weight corresponding to the jump from model $\\Theta_k$ to model $\\Theta_{k-1}$ is\n",
    "\n",
    "$$\n",
    "\\alpha_m = \\min \\left[ 1, \\frac{\\pi(k-1, p^{(k-1)}, a^{(k-1)})}{\\pi(k, p^{(k)}, a^{(k)})} \\right].\n",
    "$$\n",
    "\n",
    "As an illustration, take $k = 3$ and consider the jump from model $\\Theta_3$ to model $\\Theta_2$. The transformation is given by\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "p_1^{(3)} \\\\\n",
    "p_2^{(3)} \\\\\n",
    "p_3^{(3)} \\\\\n",
    "a_2^{(3)} \\\\\n",
    "a_3^{(3)} \\\\\n",
    "u_1\n",
    "\\end{pmatrix}\n",
    "\\to\n",
    "\\begin{pmatrix}\n",
    "u_2 \\\\\n",
    "(1 - u_2) p_2 \\\\\n",
    "p_3^{(3)} \\\\\n",
    "a_2^{(3)} \\\\\n",
    "(1 - u_1) a_3^{(3)}\n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "p_1^{(2)} \\\\\n",
    "p_2^{(2)} \\\\\n",
    "p_3^{(2)} \\\\\n",
    "a_2^{(2)} \\\\\n",
    "a_3^{(2)}\n",
    "\\end{pmatrix},\n",
    "$$\n",
    "\n",
    "with Jacobian\n",
    "\n",
    "$$\n",
    "\\frac{\\partial (p^{(2)}, a^{(2)}, u_2)}{\\partial (p^{(3)}, a^{(3)}, u_1, u_2)} =\n",
    "\\begin{pmatrix}\n",
    "1 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & u_2 & 1 - u_2 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 1 & 0 \\\\\n",
    "0 & 0 & 0 & 1 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 1 - u_1 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & -a_3^{(3)} & 0\n",
    "\\end{pmatrix}\n",
    "= \\left[ p_2^{(3)} - p_3^{(3)} \\right].\n",
    "$$\n",
    "\n",
    "(See Problem 11.6 for extensions.)\n",
    "\n",
    "## Example .7: Continuation of Example .1\n",
    "\n",
    "If we consider a model $M_k$ to be the $k$-component normal mixture distribution in (11.1), moves between models involve changing the number of components in the mixture and thus adding new components or removing older components is the mixture to the moves toward models with one more or one less component, that is, from $M_k$ to $M_{k+1}$ or $M_{k-1}$, and create a reversible birth-and-death process using the prior on the components (assumed to be independent) as a proposal for the birth step.\n",
    "\n",
    "The birth step associated with the move from $M_k$ to $M_{k+1}$ consists in adding a new normal component in the mixture. The new $(k+1)$-component normal mixture distribution is then made of the previous $k$-component normal mixture distribution and a new component, with weight $p_{k+1}^{(k+1)}$ and parameters $\\mu_{k+1}^{(k+1)}$ and $\\sigma_{k+1}^{(k+1)}$. These parameters vary in a natural solution that is similar to $p_{k+1}^{(k+1)}$ from the marginal distribution of $p^{(k+1)} = (p_1^{(k+1)}, \\dots, p_{k+1}^{(k+1)})$ (which typically is a Dirichlet corresponding prior distribution). Obviously, constraining the weights to sum to one implies that the weights of the $k$ component mixture, $p^{(k)} = (p_1^{(k)}, \\dots, p_k^{(k)})$, have to be multiplied by $(1 - p_{k+1}^{(k+1)})$ to obtain the weights of the $(k+1)$ component mixture $p^{(k+1)}$.\n",
    "\n",
    "The death step for the above probability assumes that the numbers of ways of choosing $k$ and $(k+1)$ in the above probability appear as the numbers of ways of choosing $k$ and $(k+1)$ components, respectively, from the sample. (See Problem 11.11 for details.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58d77f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Current k = 3\n",
      "Iteration 100, Current k = 8\n",
      "Iteration 200, Current k = 10\n",
      "Iteration 300, Current k = 9\n",
      "Iteration 400, Current k = 9\n",
      "Iteration 500, Current k = 9\n",
      "Iteration 600, Current k = 5\n",
      "Iteration 700, Current k = 9\n",
      "Iteration 800, Current k = 7\n",
      "Iteration 900, Current k = 6\n",
      "\n",
      "Posterior Distribution of Number of Components (k):\n",
      "2-3:  (Probability: 0.001)\n",
      "3-4:  (Probability: 0.002)\n",
      "4-4:  (Probability: 0.004)\n",
      "4-5: *** (Probability: 0.076)\n",
      "5-6:  (Probability: 0.000)\n",
      "6-7: ************ (Probability: 0.245)\n",
      "7-8: **** (Probability: 0.085)\n",
      "8-8: ******** (Probability: 0.165)\n",
      "8-9: *************** (Probability: 0.305)\n",
      "9-10: ***** (Probability: 0.118)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import math\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "# Basic statistical functions without libraries\n",
    "def normal_pdf(x: float, mean: float, std: float) -> float:\n",
    "    \"\"\"\n",
    "    Compute the probability density function of a normal distribution.\n",
    "    \"\"\"\n",
    "    variance = std * std\n",
    "    exponent = -((x - mean) ** 2) / (2 * variance)\n",
    "    return (1 / (std * math.sqrt(2 * math.pi))) * math.exp(exponent)\n",
    "\n",
    "def dirichlet_pdf(weights: List[float], alpha: List[float]) -> float:\n",
    "    \"\"\"\n",
    "    Compute the probability density function of a Dirichlet distribution (simplified, uniform case).\n",
    "    Here, we use a uniform Dirichlet with alpha = [1/2, ..., 1/2].\n",
    "    \"\"\"\n",
    "    if len(weights) != len(alpha):\n",
    "        return 0.0\n",
    "    product = 1.0\n",
    "    for w in weights:\n",
    "        if w <= 0 or w >= 1:\n",
    "            return 0.0\n",
    "        product *= w ** (alpha[0] - 1)\n",
    "    return product / math.gamma(sum(alpha))  # Simplified for alpha=1/2\n",
    "\n",
    "def poisson_pdf(k: int, lambda_param: float) -> float:\n",
    "    \"\"\"\n",
    "    Compute the probability density function of a Poisson distribution.\n",
    "    \"\"\"\n",
    "    return (lambda_param ** k * math.exp(-lambda_param)) / math.factorial(k)\n",
    "\n",
    "def log_likelihood(k: int, weights: List[float], means: List[float], stds: List[float], data: List[float]) -> float:\n",
    "    \"\"\"\n",
    "    Compute the log-likelihood of the data under a k-component normal mixture model.\n",
    "    \"\"\"\n",
    "    ll = 0.0\n",
    "    for x in data:\n",
    "        comp_ll = 0.0\n",
    "        for w, mu, sigma in zip(weights, means, stds):\n",
    "            comp_ll += w * normal_pdf(x, mu, sigma)\n",
    "        ll += math.log(comp_ll) if comp_ll > 0 else float('-inf')\n",
    "    return ll\n",
    "\n",
    "def log_prior(k: int, weights: List[float], means: List[float], stds: List[float]) -> float:\n",
    "    \"\"\"\n",
    "    Compute the log-prior for the mixture model parameters.\n",
    "    Poisson prior for k (λ=3), uniform on means, Dirichlet on weights, and inverse-gamma on stds.\n",
    "    \"\"\"\n",
    "    log_k_prior = math.log(poisson_pdf(k, 3.0))  # Poisson prior with λ=3\n",
    "    log_weights_prior = math.log(dirichlet_pdf(weights, [0.5] * len(weights)))  # Dirichlet(1/2, ..., 1/2)\n",
    "    log_means_prior = 0.0\n",
    "    for mu in means:\n",
    "        log_means_prior += -0.5 * math.log(2 * math.pi * 10) - ((mu - 0) ** 2) / (2 * 10)  # N(0, 10)\n",
    "    log_stds_prior = 0.0\n",
    "    for sigma in stds:\n",
    "        log_stds_prior += math.log((1 ** 2) / (math.gamma(2) * (sigma ** (2 + 1))) * math.exp(-1 / sigma))  # InvGamma(2, 1)\n",
    "    return log_k_prior + log_weights_prior + log_means_prior + log_stds_prior\n",
    "\n",
    "def propose_move(current_state: Dict, data: List[float]) -> Tuple[Dict, float]:\n",
    "    \"\"\"\n",
    "    Propose a move in reversible jump MCMC for a mixture model (birth or death, restricted to neighboring k).\n",
    "    Returns the proposed state and the Jacobian determinant for dimension changes.\n",
    "    \"\"\"\n",
    "    k = current_state['k']\n",
    "    weights = current_state['weights']\n",
    "    means = current_state['means']\n",
    "    stds = current_state['stds']\n",
    "    \n",
    "    move_type = random.choices(['birth', 'death'], weights=[0.5, 0.5])[0]\n",
    "    \n",
    "    if move_type == 'birth' and k < 10:  # Max k for practicality, birth to k+1\n",
    "        new_k = k + 1\n",
    "        new_weights = weights + [0.0]  # Add new weight\n",
    "        total = sum(new_weights)\n",
    "        for i in range(len(new_weights)):\n",
    "            new_weights[i] /= total  # Normalize\n",
    "        new_weights[-1] = 1.0 / new_k  # Set new weight to uniform split\n",
    "        \n",
    "        new_means = means + [random.gauss(sum(data) / len(data), 1.0)]  # New mean near data mean\n",
    "        new_stds = stds + [random.uniform(0.1, 0.5)]  # New std\n",
    "        \n",
    "        # Jacobian for birth (simplified, assuming deterministic split)\n",
    "        jacobian = 1.0\n",
    "        return {'k': new_k, 'weights': new_weights, 'means': new_means, 'stds': new_stds}, jacobian\n",
    "    \n",
    "    elif move_type == 'death' and k > 1:  # Death to k-1, remove random component\n",
    "        component_to_remove = random.randint(0, k - 1)\n",
    "        new_k = k - 1\n",
    "        new_weights = [w for i, w in enumerate(weights) if i != component_to_remove]\n",
    "        total = sum(new_weights)\n",
    "        for i in range(len(new_weights)):\n",
    "            new_weights[i] /= total  # Normalize\n",
    "        \n",
    "        new_means = [m for i, m in enumerate(means) if i != component_to_remove]\n",
    "        new_stds = [s for i, s in enumerate(stds) if i != component_to_remove]\n",
    "        \n",
    "        # Jacobian for death (simplified)\n",
    "        jacobian = 1.0\n",
    "        return {'k': new_k, 'weights': new_weights, 'means': new_means, 'stds': new_stds}, jacobian\n",
    "    \n",
    "    return current_state, 1.0  # No move, Jacobian = 1\n",
    "\n",
    "def reversible_jump_mcmc(data: List[float], n_iter: int) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Run reversible jump MCMC to sample from the posterior of a mixture model.\n",
    "    \"\"\"\n",
    "    # Initialize with k=2 components\n",
    "    k = 2\n",
    "    weights = []\n",
    "    for _ in range(k):\n",
    "        w = random.random()\n",
    "        weights.append(w)\n",
    "    total = sum(weights)\n",
    "    for i in range(len(weights)):\n",
    "        weights[i] /= total  # Normalize to ensure sum to 1\n",
    "    means = [random.gauss(sum(data) / len(data), 1.0) for _ in range(k)]\n",
    "    stds = [random.uniform(0.1, 0.5) for _ in range(k)]\n",
    "    \n",
    "    current_state = {'k': k, 'weights': weights, 'means': means, 'stds': stds}\n",
    "    chain = [current_state.copy()]\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        proposed_state, jacobian = propose_move(current_state, data)\n",
    "        \n",
    "        # Log posterior for current and proposed states\n",
    "        current_log_posterior = log_likelihood(current_state['k'], current_state['weights'], current_state['means'], current_state['stds'], data) + \\\n",
    "                               log_prior(current_state['k'], current_state['weights'], current_state['means'], current_state['stds'])\n",
    "        \n",
    "        proposed_log_posterior = log_likelihood(proposed_state['k'], proposed_state['weights'], proposed_state['means'], proposed_state['stds'], data) + \\\n",
    "                                log_prior(proposed_state['k'], proposed_state['weights'], proposed_state['means'], proposed_state['stds'])\n",
    "        \n",
    "        # Acceptance probability (including Jacobian for dimension changes)\n",
    "        log_acceptance = proposed_log_posterior - current_log_posterior + math.log(jacobian)\n",
    "        \n",
    "        if math.log(random.random()) < log_acceptance:\n",
    "            current_state = proposed_state.copy()\n",
    "        \n",
    "        chain.append(current_state.copy())\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Iteration {i}, Current k = {current_state['k']}\")\n",
    "    \n",
    "    return chain\n",
    "\n",
    "def print_histogram(data: List[int], bins: int = 10):\n",
    "    \"\"\"\n",
    "    Print a text-based histogram of the data (for k values).\n",
    "    \"\"\"\n",
    "    min_val, max_val = min(data), max(data)\n",
    "    bin_size = (max_val - min_val) / bins\n",
    "    counts = [0] * bins\n",
    "    \n",
    "    for x in data:\n",
    "        bin_idx = min(int((x - min_val) / bin_size), bins - 1)\n",
    "        counts[bin_idx] += 1\n",
    "    \n",
    "    total = sum(counts)\n",
    "    for i, count in enumerate(counts):\n",
    "        lower = min_val + i * bin_size\n",
    "        upper = min_val + (i + 1) * bin_size\n",
    "        density = count / total if total > 0 else 0\n",
    "        stars = int(density * 50)  # Scale for text visualization\n",
    "        print(f\"{lower:.0f}-{upper:.0f}: {'*' * stars} (Probability: {density:.3f})\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Generate synthetic data (assume 50 points from N(0, 1) for simplicity, mixture context)\n",
    "n_samples = 50\n",
    "data = [random.gauss(0, 1.0) for _ in range(n_samples)]\n",
    "\n",
    "# Run the MCMC\n",
    "n_iterations = 1000\n",
    "chain = reversible_jump_mcmc(data, n_iterations)\n",
    "\n",
    "# Analyze results (text-based histogram for k values)\n",
    "k_values = [state['k'] for state in chain]\n",
    "print(\"\\nPosterior Distribution of Number of Components (k):\")\n",
    "print_histogram(k_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0206366",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
