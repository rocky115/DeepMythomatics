{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ac1439",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " * Copyright (c) 2008 Radhamadhab Dalai\n",
    " *\n",
    " * Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    " * of this software and associated documentation files (the \"Software\"), to deal\n",
    " * in the Software without restriction, including without limitation the rights\n",
    " * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    " * copies of the Software, and to permit persons to whom the Software is\n",
    " * furnished to do so, subject to the following conditions:\n",
    " *\n",
    " * The above copyright notice and this permission notice shall be included in\n",
    " * all copies or substantial portions of the Software.\n",
    " *\n",
    " * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    " * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    " * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    " * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    " * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    " * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
    " * THE SOFTWARE.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f28c8a",
   "metadata": {},
   "source": [
    "##  Monotone Covariance and Rao-Blackwellization\n",
    "\n",
    "In the spirit of the Duality Principle, Rao-Blackwellization exhibits an interesting difference between statistical perspectives and simulation practice, in the sense that the approximations used in the estimator do not (directly) involve the chain of interest. As shown in Section 4.2 and Section 7.6.2, conditioning on a subset of the simulated variables may produce considerable improvement upon the standard empirical estimator in terms of variance, by a simple \"recycling\" of the rejected variables (see also Section 3.3.3). Two-stage Gibbs sampling and its generalization of Chapter 10 do not permit this kind of recycling since every simulated value is accepted (Theorem 10.13). Nonetheless, Gelfand and Smith (1990) propose a type of conditioning christened Rao-Blackwellization in connection with the Rao-Blackwell Theorem (see Lehmann and Casella 1998, Section 1.7) and defined as parametric Rao-Blackwellization by Casella and Robert (1996) to differentiate from the form studied in Sections 4.2 and 7.6.2.\n",
    "\n",
    "For $\\mathbf{Y} = (Y_1, Y_2) \\sim g(y_1, y_2)$, Rao-Blackwellization is based on the marginalization identity\n",
    "\n",
    "$$\n",
    "g^{(1)}(y_1) = \\int g_1(y_1|y_2) g^{(2)}(y_2) dy_2.\n",
    "$$\n",
    "\n",
    "It thus replaces\n",
    "$$\n",
    "\\delta_0 = \\frac{1}{T} \\sum_{t=1}^T h(y_1^{(t)})\n",
    "$$\n",
    "with\n",
    "$$\n",
    "\\delta_{rb} = \\frac{1}{T} \\sum_{t=1}^T \\mathbb{E}[h(Y_1)|y_2^{(t)}].\n",
    "$$\n",
    "\n",
    "Both estimators converge to $\\mathbb{E}[h(Y_1)]$ and, under the stationary distribution, they are both unbiased. An application of the identity $\\text{var}(U) = \\text{var}(\\mathbb{E}[U|V]) + \\mathbb{E}[\\text{var}(U|V)]$ implies that\n",
    "$$\n",
    "\\text{var}(\\mathbb{E}[h(Y_1)|Y_2]) \\le \\text{var}(h(Y_1)). \\quad (9.9)\n",
    "$$\n",
    "\n",
    "This led Gelfand and Smith (1990) to suggest the use of $\\delta_{rb}$ instead of $\\delta_0$. However, inequality (9.9) is insufficient to conclude on the domination of $\\delta_{rb}$ when compared with $\\delta_0$, as it fails to take into account the correlation between the $Y^{(t)}$'s. The domination of $\\delta_0$ by $\\delta_{rb}$ can therefore be established in only a few cases; Liu et al. (1994) show in particular that it holds for the two-stage Gibbs sampler. (See also Geyer 1995 for necessary conditions.)\n",
    "\n",
    "We establish the domination result in Theorem 9.19, but we first need some preliminary results, beginning with a representation lemma yielding the interesting result that covariances are positive in an interleaved chain.\n",
    "\n",
    "**Lemma 9.17.** If $h \\in \\mathcal{L}_2(g_2)$ and if $(X^{(t)})$ is interleaved with $(Y^{(t)})$, then\n",
    "$$\n",
    "\\text{cov}(h(Y^{(1)}), h(Y^{(2)})) = \\text{var}(\\mathbb{E}[h(Y)|X]).\n",
    "$$\n",
    "\n",
    "**Proof.** Assuming, without loss of generality, that $\\mathbb{E}_{g_2}[h(Y)] = 0$,\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{cov}(h(Y^{(1)}), h(Y^{(2)})) &= \\mathbb{E}[h(Y^{(1)}) h(Y^{(2)})] \\\\\n",
    "&= \\mathbb{E} \\left[ \\mathbb{E}[h(Y^{(1)})|X^{(2)}] \\mathbb{E}[h(Y^{(2)})|X^{(2)}] \\right] \\\\\n",
    "&= \\mathbb{E} \\left[ \\mathbb{E}[h(Y^{(1)})|X^{(2)}]^2 \\right] = \\text{var}(\\mathbb{E}[h(Y)|X]),\n",
    "\\end{aligned}\n",
    "$$\n",
    "where the second equality follows from iterating the expectation and using the conditional independence of the interleaving property. The last equality uses reversibility (that is, condition (iii)) of the interleaved chains. $\\Box$\n",
    "\n",
    "**Proposition 9.18.** If $(Y^{(t)})$ is a Markov chain with the interleaving property, the covariances\n",
    "$$\n",
    "\\text{cov}(h(Y^{(1)}), h(Y^{(t)}))\n",
    "$$\n",
    "are positive and decreasing in $t$ for every $h \\in \\mathcal{L}_2(g_2)$.$$\n",
    "g^{(1)}(y_1) = \\int g_1(y_1|y_2) g^{(2)}(y_2) dy_2.\n",
    "$$\n",
    "\n",
    "It thus replaces\n",
    "$$\n",
    "\\delta_0 = \\frac{1}{T} \\sum_{t=1}^T h(y_1^{(t)})\n",
    "$$\n",
    "with\n",
    "$$\n",
    "\\delta_{rb} = \\frac{1}{T} \\sum_{t=1}^T \\mathbb{E}[h(Y_1)|y_2^{(t)}].\n",
    "$$\n",
    "\n",
    "Both estimators converge to $\\mathbb{E}[h(Y_1)]$ and, under the stationary distribution, they are both unbiased. An application of the identity $\\text{var}(U) = \\text{var}(\\mathbb{E}[U|V]) + \\mathbb{E}[\\text{var}(U|V)]$ implies that\n",
    "$$\n",
    "\\text{var}(\\mathbb{E}[h(Y_1)|Y_2]) \\le \\text{var}(h(Y_1)). \\quad (9.9)\n",
    "$$\n",
    "\n",
    "This led Gelfand and Smith (1990) to suggest the use of $\\delta_{rb}$ instead of $\\delta_0$. However, inequality (9.9) is insufficient to conclude on the domination of $\\delta_{rb}$ when compared with $\\delta_0$, as it fails to take into account the correlation between the $Y^{(t)}$'s. The domination of $\\delta_0$ by $\\delta_{rb}$ can therefore be established in only a few cases; Liu et al. (1994) show in particular that it holds for the two-stage Gibbs sampler. (See also Geyer 1995 for necessary conditions.)\n",
    "\n",
    "We establish the domination result in Theorem 9.19, but we first need some preliminary results, beginning with a representation lemma yielding the interesting result that covariances are positive in an interleaved chain.\n",
    "\n",
    "\n",
    "\n",
    "**Lemma 9.17.** If $h \\in \\mathcal{L}_2(g_2)$ and if $(X^{(t)})$ is interleaved with $(Y^{(t)})$, then\n",
    "$$\n",
    "\\text{cov}(h(Y^{(1)}), h(Y^{(2)})) = \\text{var}(\\mathbb{E}[h(Y)|X]).\n",
    "$$\n",
    "\n",
    "**Proof.** Assuming, without loss of generality, that $\\mathbb{E}_{g_2}[h(Y)] = 0$,\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text{cov}(h(Y^{(1)}), h(Y^{(2)})) &= \\mathbb{E}[h(Y^{(1)}) h(Y^{(2)})] \\\\\n",
    "&= \\mathbb{E} \\left[ \\mathbb{E}[h(Y^{(1)})|X^{(2)}] \\mathbb{E}[h(Y^{(2)})|X^{(2)}] \\right] \\\\\n",
    "&= \\mathbb{E} \\left[ \\mathbb{E}[h(Y^{(1)})|X^{(2)}]^2 \\right] = \\text{var}(\\mathbb{E}[h(Y)|X]),\n",
    "\\end{aligned}\n",
    "$$\n",
    "where the second equality follows from iterating the expectation and using the conditional independence of the interleaving property. The last equality uses reversibility (that is, condition (iii)) of the interleaved chains. $\\Box$\n",
    "\n",
    "**Proposition 9.18.** If $(Y^{(t)})$ is a Markov chain with the interleaving property, the covariances\n",
    "$$\n",
    "\\text{cov}(h(Y^{(1)}), h(Y^{(t)}))\n",
    "$$\n",
    "are positive and decreasing in $t$ for every $h \\in \\mathcal{L}_2(g_2)$.\n",
    "\n",
    "**Proof.** Lemma 9.17 implies, by induction, that\n",
    "$$\n",
    "\\text{cov}(h(Y^{(1)}), h(Y^{(t)})) = \\mathbb{E} \\left[ \\mathbb{E}[h(Y)|X^{(2)}] \\mathbb{E}[h(Y)|X^{(t)}] \\right]\n",
    "$$\n",
    "$$\n",
    "\\text{(9.10)} \\quad = \\text{var} \\left( \\mathbb{E} \\left[ \\mathbb{E} \\left[ ... \\mathbb{E}[h(Y)|X] | Y \\right] ... \\right] \\right),\n",
    "$$\n",
    "where the last term involves $(t-1)$ conditional expectations, alternatively in $Y$ and in $X$. The decrease in $t$ directly follows from the inequality on conditional expectations, by virtue of the representation (9.10) and the inequality (9.9). $\\Box$\n",
    "\n",
    "The result on the improvement brought by Rao-Blackwellization then easily follows from Proposition 9.18.\n",
    "\n",
    "**Theorem 9.19.** If $(X^{(t)})$ and $(Y^{(t)})$ are two interleaved Markov chains, with stationary distributions $f_X$ and $f_Y$ respectively, the estimator $\\delta_{rb}$ dominates the estimator $\\delta_0$ for every function $h$ with finite variance under both $f_X$ and $f_Y$.\n",
    "\n",
    "**Proof.** Again assuming $\\mathbb{E}[h(X)] = 0$, and introducing the estimators\n",
    "$$\n",
    "\\text{(9.11)} \\quad \\delta_0 = \\frac{1}{T} \\sum_{t=1}^T h(X^{(t)}), \\quad \\delta_{rb} = \\frac{1}{T} \\sum_{t=1}^T \\mathbb{E}[h(X)|Y^{(t)}],\n",
    "$$\n",
    "it follows that\n",
    "$$\n",
    "\\text{var}(\\delta_0) = \\frac{1}{T^2} \\sum_{t, t'} \\text{cov}(h(X^{(t)}), h(X^{(t')}))\n",
    "$$\n",
    "$$\n",
    "\\text{(9.12)} \\quad = \\frac{1}{T^2} \\sum_{t, t'} \\text{var} \\left( \\mathbb{E} \\left[ ... \\mathbb{E}[h(X)|Y] ... \\right] \\right)\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\text{var}(\\delta_{rb}) = \\frac{1}{T^2} \\sum_{t, t'} \\text{cov}(\\mathbb{E}[h(X)|Y^{(t)}], \\mathbb{E}[h(X)|Y^{(t')}])\n",
    "$$\n",
    "$$\n",
    "\\text{(9.13)} \\quad = \\frac{1}{T^2} \\sum_{t, t'} \\text{var} \\left( \\mathbb{E} \\left[ ... \\mathbb{E}[\\mathbb{E}[h(X)|Y]|X] ... \\right] \\right),\n",
    "$$\n",
    "according to the proof of Proposition 9.18, with $|t - t'|$ conditional expectations in the general term of (9.12) and $|t - t'| + 1$ in the general term of (9.13). It is then sufficient to compare $\\text{var}(\\delta_0)$ term by term to conclude that $\\text{var}(\\delta_0) \\ge \\text{var}(\\delta_{rb})$. $\\Box$\n",
    "\n",
    "One might question whether Rao-Blackwellization will always result in an appreciable variance reduction, even as the sample size (or the number of Monte Carlo iterations) increases. This point was addressed by Levine (1996),\n",
    "who formulated this problem in terms of the *asymptotic relative efficiency* (ARE) of $\\delta_0$ with respect to its Rao-Blackwellized version $\\delta_{rb}$, given in (9.11), where the pairs $(X^{(t)}, Y^{(t)})$ are generated from a bivariate Gibbs sampler. The ARE is a ratio of the variances of the limiting distributions for the two estimators, which are given by\n",
    "$$\n",
    "\\text{(9.14)} \\quad \\sigma_0^2 = \\text{var}(h(X^{(0)})) + 2 \\sum_{k=1}^{\\infty} \\text{cov}(h(X^{(0)}), h(X^{(k)}))\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\sigma_{rb}^2 = \\text{var}(\\mathbb{E}[h(X)|Y])\n",
    "$$\n",
    "$$\n",
    "\\text{(9.15)} \\quad + 2 \\sum_{k=1}^{\\infty} \\text{cov}(\\mathbb{E}[h(X)|Y^{(0)}], \\mathbb{E}[h(X)|Y^{(k)}]).\n",
    "$$\n",
    "\n",
    "Levine (1996) established that the ratio $\\sigma_0^2 / \\sigma_{rb}^2 \\ge 1$, with equality if and only if $\\text{var}(h(X)) = \\text{cov}(\\mathbb{E}[h(X)|Y]) = 0$.\n",
    "\n",
    "**Example 9.20.** (Continuation of Example 9.1) For the Gibbs sampler (9.4), it can be shown (Problem 9.5) that $\\text{cov}(X^{(0)}, X^{(k)}) = \\rho^{2k}$, for all $k$, and\n",
    "$$\n",
    "\\sigma_0^2 / \\sigma_{rb}^2 = \\frac{1}{1 - \\rho^2} > 1.\n",
    "$$\n",
    "\n",
    "So, if $\\rho$ is small, the amount of improvement, which is independent of the number of iterations, can be substantial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24575be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Define conditional distributions (replace with your actual distributions)\n",
    "def pi_x_given_y(x, y):\n",
    "    \"\"\"Conditional distribution of X given Y (example).\"\"\"\n",
    "    if y == 0:\n",
    "        return [0.1 * (2.71828**(-((xi)**2) / 2)) for xi in x]  # Example: Normal-like distribution\n",
    "    else:\n",
    "        return [0.1 * (2.71828**(-((xi - 3)**2) / 2)) for xi in x] # Example: Shifted normal-like\n",
    "\n",
    "def f_y_given_x_y(y_new, x, y_old, rho):  # Add rho parameter\n",
    "    \"\"\"Conditional distribution of Y, controlled by rho.\"\"\"\n",
    "    if y_old == 0:\n",
    "        return rho if y_new == 0 else (1 - rho)\n",
    "    else:\n",
    "        return (1 - rho) if y_new == 0 else rho\n",
    "\n",
    "# 2. Dual chain sampler with convergence tracking\n",
    "def dual_chain_sampler(num_samples, y_initial, rho):\n",
    "    x_samples = []\n",
    "    y = y_initial\n",
    "    x_range = [-5 + i * 0.1 for i in range(101)]\n",
    "    # x_means = []  # Track mean of x samples  (Not needed for ARE calculation)\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        # Sample x given y\n",
    "        probabilities = pi_x_given_y(x_range, y)\n",
    "        total_prob = sum(probabilities)\n",
    "        normalized_probs = [p / total_prob for p in probabilities]\n",
    "        x = random.choices(x_range, weights=normalized_probs)[0]  # Sample using weights\n",
    "\n",
    "        # Sample y given x and old y (using rho)\n",
    "        y_new = random.choices([0, 1], weights=[f_y_given_x_y(0, x, y, rho), 1-f_y_given_x_y(0, x, y, rho)])[0]\n",
    "        y = y_new\n",
    "        x_samples.append(x)\n",
    "        # x_means.append(sum(x_samples) / len(x_samples)) # Calculate mean at each step\n",
    "    return x_samples\n",
    "\n",
    "def calculate_variances(samples_original, samples_rb):\n",
    "    \"\"\"Calculates variances of the original and RB estimators.\"\"\"\n",
    "    var_original = sum([(x - sum(samples_original) / len(samples_original))**2 for x in samples_original]) / len(samples_original)\n",
    "    var_rb = sum([(x - sum(samples_rb) / len(samples_rb))**2 for x in samples_rb]) / len(samples_rb)\n",
    "    return var_original, var_rb\n",
    "\n",
    "# 3. Experiment with different rho values and calculate variances\n",
    "num_samples = 1000\n",
    "y_initial = 0\n",
    "x_range = [-5 + i * 0.1 for i in range(101)]\n",
    "\n",
    "rho_values = [0.1, 0.3, 0.5, 0.7, 0.9]  # Different correlation levels\n",
    "\n",
    "results = []\n",
    "for rho in rho_values:\n",
    "    samples_original = dual_chain_sampler(num_samples, y_initial, rho)  # Get original samples\n",
    "    samples_rb = [sum(pi_x_given_y(x_range, y)) / sum(pi_x_given_y(x_range, y)) for y in [random.choices([0, 1], weights=[f_y_given_x_y(0, x, y, rho), 1-f_y_given_x_y(0, x, y, rho)])[0] for x in samples_original]]\n",
    "    var_original, var_rb = calculate_variances(samples_original, samples_rb)\n",
    "    results.append((rho, var_original, var_rb))\n",
    "\n",
    "# 4. Analyze and visualize ARE\n",
    "for rho, var_original, var_rb in results:\n",
    "    are = var_original / var_rb if var_rb > 0 else float('inf')  # Calculate ARE\n",
    "    print(f\"Rho: {rho:.1f}, Var(original): {var_original:.4f}, Var(RB): {var_rb:.4f}, ARE: {are:.2f}\")\n",
    "\n",
    "# (Optional) Plot ARE vs. Rho\n",
    "rhos, are_values = zip(*[(rho, var_original / var_rb if var_rb > 0 else float('inf')) for rho, var_original, var_rb in results])\n",
    "plt.plot(rhos, are_values, marker='o')\n",
    "plt.xlabel(\"Rho\")\n",
    "plt.ylabel(\"Asymptotic Relative Efficiency (ARE)\")\n",
    "plt.title(\"ARE vs. Correlation (Rho)\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "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"
    },
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "b4c3eeec",
   "metadata": {},
   "source": [
    "## The EM-Gibbs Connection\n",
    "\n",
    "As mentioned earlier, the EM algorithm can be seen as a precursor of the two-stage Gibbs sampler in missing data models (Section 5.3.1), in that it similarly exploits the conditional distribution of the missing variables. The connection goes further, as seen below.\n",
    "\n",
    "Recall from Section 5.3.2 that, if $X \\sim g(x|\\theta)$ is the observed data, and we augment the data with $z$, where $Z \\sim f(x, z|\\theta)$, then we have the complete-data and incomplete-data likelihoods\n",
    "$$\n",
    "L^c(\\theta|x, z) = f(x, z|\\theta) \\quad \\text{and} \\quad L(\\theta|x) = g(x|\\theta),\n",
    "$$\n",
    "with the missing data density\n",
    "$$\n",
    "k(z|x, \\theta) = \\frac{L^c(\\theta|x, z)}{L(\\theta|x)}.\n",
    "$$\n",
    "\n",
    "If we can normalize the complete-data likelihood in $\\theta$ (this is the only condition for the equivalence mentioned above), that is, if $\\int L^c(\\theta|x, z) d\\theta < \\infty$, then define\n",
    "$$\n",
    "L^*(\\theta|x, z) = \\frac{L^c(\\theta|x, z)}{\\int L^c(\\theta|x, z) d\\theta}\n",
    "$$\n",
    "and create the two-stage Gibbs sampler:\n",
    "\n",
    "(9.16)\n",
    "$$\n",
    "\\begin{aligned}\n",
    "1. \\quad z|\\theta &\\sim k(z|x, \\theta) \\\\\n",
    "2. \\quad \\theta|z &\\sim L^*(\\theta|x, z).\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Note the direct connection to an EM algorithm based on $L^c$ and $k$. The \"E\" step in the EM algorithm calculates the expected value of the log-likelihood over $z$, often by calculating $\\mathbb{E}(Z|x, \\theta)$ and substituting in the log-likelihood. In the Gibbs sampler this step is replaced with generating a random variable from the density $k$. The \"M\" step of the EM algorithm then takes as the current value of $\\theta$ the maximum of the expected complete-data log-likelihood. In the Gibbs sampler this step is replaced by generating a value of $\\theta$ from $L^*$, the normalized complete-data likelihood.\n",
    "\n",
    "**Example .21.** Censored data Gibbs. For the censored data example considered in Example 5.14, the distribution of the missing data is\n",
    "$$\n",
    "Z_i \\sim \\frac{\\phi(z - \\theta)}{1 - \\Phi(a - \\theta)}\n",
    "$$\n",
    "and the distribution of $\\theta|x, z$ is\n",
    "$$\n",
    "L(\\theta|x, z) \\propto \\prod_{i=1}^m \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{(x_i - \\theta)^2}{2}} \\prod_{i=m+1}^n \\frac{1}{\\sqrt{2\\pi}} e^{-\\frac{(z_i - \\theta)^2}{2}}\n",
    "$$\n",
    "which corresponds to a\n",
    "$$\n",
    "\\mathcal{N} \\left( \\frac{m\\bar{x} + (n-m)\\bar{z}}{n}, \\frac{1}{n} \\right)\n",
    "$$\n",
    "distribution, and so we immediately have that $L^*$ exists and that we can run a Gibbs sampler (Problem .14).\n",
    "\n",
    "The validity of the \"EM/Gibbs\" sampler follows in a straightforward manner from its construction. The transition kernel of the Markov chain is\n",
    "$$\n",
    "\\mathcal{K}(\\theta, \\theta'|x) = \\int_{\\mathcal{Z}} k(z|x, \\theta) L^*(\\theta'|x, z) dz\n",
    "$$\n",
    "and it can be shown (Problem 9.15) that the invariant distribution of the chain is the incomplete data likelihood, that is,\n",
    "$$\n",
    "\\pi(\\theta|x) = L(\\theta|x).\n",
    "$$\n",
    "\n",
    "## The EM-Gibbs Connection (Continued)\n",
    "\n",
    "Since $L(\\theta'|x, z)$ is integrable in $\\theta$, so is $L(\\theta'|x)$, and hence the invariant distribution is a proper density. So the Markov chain is positive, and convergence follows from Theorem 9.6.\n",
    "\n",
    "**Example .22.** Cellular phone Gibbs. As an illustration of the EM-Gibbs connection, we revisit Example.18, but now we use the Gibbs sampler to get our solution. From the complete data likelihood (5.18) and the missing data distribution (5.19) we have (Problem .16)\n",
    "\n",
    "$$\n",
    "p|W_1, W_2, ..., W_5, \\Sigma X_i \\sim D(W_1 + 1, W_2 + 1, ..., W_5 + \\Sigma X_i + 1)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Sigma X_i \\sim Neg \\left( \\sum_{i=1}^m n_i + m, 1 - p_s \\right)\n",
    "$$\n",
    "\n",
    "(9.17)\n",
    "\n",
    "The results of the Gibbs iterations are shown in Figure 9.3. The point estimates agree with those of the EM algorithm (Example 5.18), $\\hat{p} = (0.258, 0.313, 0.140, 0.118, 0.170)$, with the exception of $\\hat{p}_5$, which is larger than the MLE. This may reflect the fact that the Gibbs estimate is a mean (and gets pulled a bit into the tail), while the MLE is a mode. Measures of error can be obtained from either the iterations or the histograms.\n",
    "\n",
    "Based on the same functions $L(\\theta|y, z)$ and $k(z|\\theta, y)$ the EM algorithm will get the ML estimator from $L(\\theta|y)$, whereas the Gibbs sampler will get us\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "![image-2.png](attachment:image-2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cf8599",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np  # For some calculations (optional)\n",
    "\n",
    "# --- Define the distributions (replace with your actual distributions) ---\n",
    "\n",
    "def d_distribution(W, X_sum):  # Placeholder for Dirichlet distribution\n",
    "    \"\"\"Dirichlet distribution (simplified placeholder).\"\"\"\n",
    "    # Replace with your actual Dirichlet implementation.\n",
    "    # This example returns a list of random probabilities.\n",
    "    alpha = [w + 1 for w in W] + [X_sum + 1] # alpha parameters for Dirichlet\n",
    "    return np.random.dirichlet(alpha)\n",
    "\n",
    "def neg_binomial(n, p):  # Placeholder for Negative Binomial\n",
    "    \"\"\"Negative Binomial distribution (simplified placeholder).\"\"\"\n",
    "    # Replace with your actual Negative Binomial implementation.\n",
    "    # This example returns a random integer.\n",
    "    return np.random.negative_binomial(n, p)\n",
    "\n",
    "# --- EM-Gibbs Sampler ---\n",
    "\n",
    "def em_gibbs_sampler(num_samples, initial_W, initial_X_sum, n_list, m):\n",
    "    W_samples = []\n",
    "    X_sum_samples = []\n",
    "    W = initial_W\n",
    "    X_sum = initial_X_sum\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        # 1. Sample from the conditional distributions\n",
    "        p = d_distribution(W, X_sum)\n",
    "        X_sum = neg_binomial(sum(n_list) + m, 1 - p[-1]) # Use p[-1] for p_s\n",
    "\n",
    "        # 2. Update W (assuming you want the probabilities p)\n",
    "        W = p[:-1] # Remove the last element which corresponds to p_s\n",
    "\n",
    "        W_samples.append(W)\n",
    "        X_sum_samples.append(X_sum)\n",
    "\n",
    "    return W_samples, X_sum_samples\n",
    "\n",
    "# --- Example Usage (replace with your actual data) ---\n",
    "\n",
    "num_samples = 5000\n",
    "initial_W = [1, 1, 1, 1, 1]  # Initial values for W (replace with your data)\n",
    "initial_X_sum = 5  # Initial value for X_sum (replace with your data)\n",
    "n_list = [10, 12, 8, 15, 9]  # Replace with your n_i values\n",
    "m = 5  # Replace with your m value\n",
    "\n",
    "W_samples, X_sum_samples = em_gibbs_sampler(num_samples, initial_W, initial_X_sum, n_list, m)\n",
    "\n",
    "# --- Analyze and visualize the results ---\n",
    "\n",
    "# Example: Plot the distribution of one of the W components\n",
    "component_index = 0  # Choose which component of W to plot\n",
    "w_values = [W[component_index] for W in W_samples]\n",
    "plt.hist(w_values, bins=30)\n",
    "plt.title(f\"Distribution of W[{component_index}]\")\n",
    "plt.xlabel(f\"W[{component_index}] Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "# Example: Print point estimates (means)\n",
    "W_means = [np.mean([W[i] for W in W_samples]) for i in range(len(initial_W))]\n",
    "X_sum_mean = np.mean(X_sum_samples)\n",
    "\n",
    "print(\"Point Estimates:\")\n",
    "print(\"W:\", W_means)\n",
    "print(\"X_sum:\", X_sum_mean)\n",
    "\n",
    "# ... (Add more analysis and visualization as needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1bcd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Define the distributions (replace with your actual distributions) ---\n",
    "\n",
    "def dirichlet_distribution(W, X_sum):  # Placeholder for Dirichlet distribution\n",
    "    \"\"\"Dirichlet distribution (simplified placeholder, NO NUMPY).\"\"\"\n",
    "    # Replace with your actual Dirichlet implementation without numpy.\n",
    "    # This example returns a list of random probabilities.\n",
    "\n",
    "    alpha = [w + 1 for w in W] + [X_sum + 1]  # alpha parameters for Dirichlet\n",
    "    gamma_samples = [random.gammavariate(a, 1) for a in alpha]\n",
    "    total_gamma = sum(gamma_samples)\n",
    "    probabilities = [g / total_gamma for g in gamma_samples]\n",
    "    return probabilities\n",
    "\n",
    "def neg_binomial(n, p):  # Placeholder for Negative Binomial (NO NUMPY)\n",
    "    \"\"\"Negative Binomial distribution (simplified placeholder, NO NUMPY).\"\"\"\n",
    "    # Replace with your actual Negative Binomial implementation without numpy.\n",
    "    # This example returns a random integer.\n",
    "    k = 0\n",
    "    count = 0\n",
    "    while count < n:\n",
    "        if random.random() < p:\n",
    "            count += 1\n",
    "        k += 1\n",
    "    return k\n",
    "\n",
    "# --- EM-Gibbs Sampler ---\n",
    "\n",
    "def em_gibbs_sampler(num_samples, initial_W, initial_X_sum, n_list, m):\n",
    "    W_samples = []\n",
    "    X_sum_samples = []\n",
    "    W = initial_W\n",
    "    X_sum = initial_X_sum\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        # 1. Sample from the conditional distributions\n",
    "        p = dirichlet_distribution(W, X_sum)\n",
    "        X_sum = neg_binomial(sum(n_list) + m, 1 - p[-1])  # Use p[-1] for p_s\n",
    "\n",
    "        # 2. Update W (assuming you want the probabilities p)\n",
    "        W = p[:-1]  # Remove the last element which corresponds to p_s\n",
    "\n",
    "        W_samples.append(W)\n",
    "        X_sum_samples.append(X_sum)\n",
    "\n",
    "    return W_samples, X_sum_samples\n",
    "\n",
    "# --- Example Usage (replace with your actual data) ---\n",
    "\n",
    "num_samples = 5000\n",
    "initial_W = [1, 1, 1, 1, 1]  # Initial values for W (replace with your data)\n",
    "initial_X_sum = 5  # Initial value for X_sum (replace with your data)\n",
    "n_list = [10, 12, 8, 15, 9]  # Replace with your n_i values\n",
    "m = 5  # Replace with your m value\n",
    "\n",
    "W_samples, X_sum_samples = em_gibbs_sampler(num_samples, initial_W, initial_X_sum, n_list, m)\n",
    "\n",
    "# --- Analyze and visualize the results ---\n",
    "\n",
    "# Example: Plot the distribution of one of the W components\n",
    "component_index = 0  # Choose which component of W to plot\n",
    "w_values = [W[component_index] for W in W_samples]\n",
    "plt.hist(w_values, bins=30)\n",
    "plt.title(f\"Distribution of W[{component_index}]\")\n",
    "plt.xlabel(f\"W[{component_index}] Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "# Example: Print point estimates (means)\n",
    "W_means = [sum(W[i] for W in W_samples) / len(W_samples) for i in range(len(initial_W))]\n",
    "X_sum_mean = sum(X_sum_samples) / len(X_sum_samples)\n",
    "\n",
    "print(\"Point Estimates:\")\n",
    "print(\"W:\", W_means)\n",
    "print(\"X_sum:\", X_sum_mean)\n",
    "\n",
    "# ... (Add more analysis and visualization as needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef737f0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
