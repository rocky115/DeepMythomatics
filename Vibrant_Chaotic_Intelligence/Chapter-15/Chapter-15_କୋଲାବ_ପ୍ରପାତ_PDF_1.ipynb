{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df480ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " * Copyright (c) 2008 Radhamadhab Dalai\n",
    " *\n",
    " * Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    " * of this software and associated documentation files (the \"Software\"), to deal\n",
    " * in the Software without restriction, including without limitation the rights\n",
    " * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    " * copies of the Software, and to permit persons to whom the Software is\n",
    " * furnished to do so, subject to the following conditions:\n",
    " *\n",
    " * The above copyright notice and this permission notice shall be included in\n",
    " * all copies or substantial portions of the Software.\n",
    " *\n",
    " * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    " * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    " * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    " * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    " * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    " * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
    " * THE SOFTWARE.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba895675",
   "metadata": {},
   "source": [
    "## Probability Distributions\n",
    "\n",
    "In this notebook, we describe some widely used probability distributions.\n",
    "\n",
    "---\n",
    "\n",
    "### A.1. Normal Distribution, $N_p(\\theta, \\Sigma)$\n",
    "\n",
    "$$\n",
    "\\theta \\in \\mathbb{R}^p \\quad \\text{and} \\quad \\Sigma \\text{ is a } (p \\times p) \\text{ symmetric positive definite matrix.}\n",
    "$$\n",
    "\n",
    "$$\n",
    "f(x \\mid \\theta, \\Sigma) = (\\det \\Sigma)^{-1/2}\\,(2\\pi)^{-p/2}\\, \\exp\\left(-\\frac{(x-\\theta)^T\\Sigma^{-1}(x-\\theta)}{2}\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "E_{\\theta, \\Sigma}[X] = \\theta \\quad \\text{and} \\quad E_{\\theta, \\Sigma}\\left[(X-\\theta)(X-\\theta)^T\\right] = \\Sigma.\n",
    "$$\n",
    "\n",
    "> **Note:** When $\\Sigma$ is not positive definite, the $N_p(\\theta,\\Sigma)$ distribution does not have a density with respect to the Lebesgue measure on $\\mathbb{R}^p$. For $p=1$, the log-normal distribution is defined as the distribution of $e^X$ when $X \\sim N(\\theta, \\sigma^2)$.\n",
    "\n",
    "---\n",
    "\n",
    "## A.2. Gamma Distribution, $G_{\\alpha}(\\alpha, \\beta)$\n",
    "\n",
    "$$\n",
    "f(x \\mid \\alpha, \\beta) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)}\\, x^{\\alpha-1}\\,e^{-\\beta x}\\, I_{[0,\\infty)}(x)\n",
    "$$\n",
    "\n",
    "$$\n",
    "E_{\\alpha,\\beta}[X] = \\frac{\\alpha}{\\beta} \\quad \\text{and} \\quad \\operatorname{Var}_{\\alpha,\\beta}(X) = \\frac{\\alpha}{\\beta^2}.\n",
    "$$\n",
    "\n",
    "> **Note:** Particular cases of the Gamma distribution include:\n",
    ">\n",
    "> - **Erlang Distribution:** $G_{\\alpha}(\\alpha, 1)$\n",
    "> - **Exponential Distribution:** $G_1(\\beta)$ (denoted as $\\text{Exp}(\\beta)$)\n",
    "> - **Chi-squared Distribution:** $G_{\\nu/2}(1/2)$ (denoted as $\\chi^2_{\\nu}$)\n",
    ">\n",
    "> *Also, note that sometimes the parameterization may vary (for instance, one might encounter $G_{\\alpha}(1/\\beta)$).*\n",
    "\n",
    "---\n",
    "\n",
    "## A.3. Beta Distribution, $B_{\\alpha}(\\alpha, \\beta)$\n",
    "\n",
    "$$\n",
    "f(x \\mid \\alpha, \\beta) = \\frac{x^{\\alpha-1}(1-x)^{\\beta-1}}{B(\\alpha,\\beta)}\\, I_{(0,1)}(x)\n",
    "$$\n",
    "\n",
    "Here, $B(\\alpha,\\beta)$ is the Beta function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6c17066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal PDF at x = 0.5 with theta = 0 and sigma = 1 is: 0.3520653267642995\n",
      "Gamma PDF at x = 0.5 with alpha = 2 and beta = 1 is: 0.3032653298563167\n",
      "Beta PDF at x = 0.5 with alpha = 2 and beta = 2 is: 1.5\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def normal_pdf(x, theta, sigma):\n",
    "    \"\"\"\n",
    "    Compute the probability density function (PDF) of a univariate normal distribution.\n",
    "    \n",
    "    Parameters:\n",
    "      x     : Point at which PDF is evaluated.\n",
    "      theta : Mean of the distribution.\n",
    "      sigma : Standard deviation of the distribution.\n",
    "      \n",
    "    Returns:\n",
    "      PDF value at x.\n",
    "    \"\"\"\n",
    "    denominator = math.sqrt(2 * math.pi) * sigma\n",
    "    exponent = -0.5 * ((x - theta) / sigma) ** 2\n",
    "    return (1 / denominator) * math.exp(exponent)\n",
    "\n",
    "def gamma_pdf(x, alpha, beta):\n",
    "    \"\"\"\n",
    "    Compute the probability density function (PDF) of the Gamma distribution.\n",
    "    \n",
    "    Parameters:\n",
    "      x     : Point at which PDF is evaluated. x must be non-negative.\n",
    "      alpha : Shape parameter.\n",
    "      beta  : Rate parameter.\n",
    "      \n",
    "    Returns:\n",
    "      PDF value at x. Returns 0 if x is negative.\n",
    "    \"\"\"\n",
    "    if x < 0:\n",
    "        return 0\n",
    "    numerator = beta ** alpha * x ** (alpha - 1) * math.exp(-beta * x)\n",
    "    denominator = math.gamma(alpha)  # gamma(alpha) computes the Gamma function at alpha.\n",
    "    return numerator / denominator\n",
    "\n",
    "def beta_pdf(x, alpha, beta):\n",
    "    \"\"\"\n",
    "    Compute the probability density function (PDF) of the Beta distribution.\n",
    "    \n",
    "    Parameters:\n",
    "      x     : Point at which PDF is evaluated. x must be between 0 and 1.\n",
    "      alpha : First shape parameter.\n",
    "      beta  : Second shape parameter.\n",
    "      \n",
    "    Returns:\n",
    "      PDF value at x. Returns 0 if x is not in (0, 1).\n",
    "    \"\"\"\n",
    "    # The Beta function B(alpha, beta) can be computed via Gamma functions:\n",
    "    # B(alpha, beta) = gamma(alpha) * gamma(beta) / gamma(alpha + beta)\n",
    "    if x <= 0 or x >= 1:\n",
    "        return 0\n",
    "    B = math.gamma(alpha) * math.gamma(beta) / math.gamma(alpha + beta)\n",
    "    return (x ** (alpha - 1) * (1 - x) ** (beta - 1)) / B\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Test values\n",
    "    x_normal = 0.5\n",
    "    theta = 0\n",
    "    sigma = 1\n",
    "    print(\"Normal PDF at x =\", x_normal, \"with theta =\", theta, \"and sigma =\", sigma, \"is:\", \n",
    "          normal_pdf(x_normal, theta, sigma))\n",
    "    \n",
    "    x_gamma = 0.5\n",
    "    alpha_gamma = 2\n",
    "    beta_gamma = 1\n",
    "    print(\"Gamma PDF at x =\", x_gamma, \"with alpha =\", alpha_gamma, \"and beta =\", beta_gamma, \"is:\",\n",
    "          gamma_pdf(x_gamma, alpha_gamma, beta_gamma))\n",
    "    \n",
    "    x_beta = 0.5\n",
    "    alpha_beta = 2\n",
    "    beta_beta = 2\n",
    "    print(\"Beta PDF at x =\", x_beta, \"with alpha =\", alpha_beta, \"and beta =\", beta_beta, \"is:\",\n",
    "          beta_pdf(x_beta, alpha_beta, beta_beta))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333c8451",
   "metadata": {},
   "source": [
    "## Probability Distributions\n",
    "\n",
    "We recall here the density and the two first moments of most of the distributions used in this book. An exhaustive review of probability distributions is provided by Johnson and Kotz (1972) or the more recent Johnson and Hoeting (2003), Johnson et al. (1994, 1995). The densities are given with respect to Lebesgue or counting measure depending on the context.\n",
    "\n",
    "### A.1. Normal Distribution, $N_p(\\theta, \\Sigma)$\n",
    "\n",
    "($\\theta \\in \\mathbb{R}^p$ and $\\Sigma$ is a $p \\times p$ symmetric positive definite matrix.)\n",
    "\n",
    "$$\n",
    "f(x|\\theta, \\Sigma) = (\\det \\Sigma)^{-1/2}(2\\pi)^{-p/2} e^{-(x-\\theta)^T\\Sigma^{-1}(x-\\theta)/2}.\n",
    "$$\n",
    "\n",
    "$$\n",
    "E_{\\theta, \\Sigma}[X] = \\theta \\quad \\text{and} \\quad E_{\\theta, \\Sigma}[(X-\\theta)(X-\\theta)^T] = \\Sigma.\n",
    "$$\n",
    "\n",
    "When $\\Sigma$ is not positive definite, the $N_p(\\theta, \\Sigma)$ distribution has no density with respect to Lebesgue measure on $\\mathbb{R}^p$. For $p=1$, the log-normal distribution is defined as the distribution of $e^X$ when $X \\sim N(\\theta, \\sigma^2)$.\n",
    "\n",
    "### A.2. Gamma Distribution, $G_{\\alpha}(\\alpha, \\beta)$\n",
    "\n",
    "($\\alpha, \\beta > 0$)\n",
    "\n",
    "$$\n",
    "f(x|\\alpha, \\beta) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)} x^{\\alpha-1} e^{-\\beta x} I_{[0,\\infty)}(x).\n",
    "$$\n",
    "\n",
    "$$\n",
    "E_{\\alpha, \\beta}[X] = \\frac{\\alpha}{\\beta} \\quad \\text{and} \\quad \\operatorname{var}_{\\alpha, \\beta}(X) = \\frac{\\alpha}{\\beta^2}.\n",
    "$$\n",
    "\n",
    "Particular cases of the Gamma distribution are the Erlang distribution, $G_{\\alpha}(n,1)$, the exponential distribution, $G_{\\alpha}(1, \\beta)$ (denoted by $\\operatorname{Exp}(\\beta)$), and the chi-squared distribution, $G_{\\alpha}(1/2,1/2)$ (denoted by $\\chi^2$). (Note also that the opposite convention is sometimes adopted for the parameter, namely that $G_{\\alpha}(\\beta)$ may also be noted as $G_{\\alpha}(1/\\beta)$. See, e.g., Berger 1985.)\n",
    "\n",
    "### A.3. Beta Distribution, $B_{\\alpha}(\\alpha, \\beta)$\n",
    "\n",
    "($\\alpha, \\beta > 0$)\n",
    "\n",
    "$$\n",
    "f(x|\\alpha, \\beta) = \\frac{x^{\\alpha-1}(1-x)^{\\beta-1}}{B(\\alpha,\\beta)} I_{(0,1)}(x),\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "B(\\alpha,\\beta) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha+\\beta)}.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ff4792",
   "metadata": {},
   "source": [
    "## Statistical Distributions and Properties\n",
    "\n",
    "### A.8. Dirichlet Distribution, $D_k(\\alpha_1, \\ldots, \\alpha_k)$\n",
    "($\\alpha_1, \\ldots, \\alpha_k > 0$ and $\\alpha_0 = \\alpha_1 + \\cdots + \\alpha_k$)\n",
    "\n",
    "$$\n",
    "f(x_1, \\ldots, x_k) = \\frac{\\Gamma(\\alpha_0)}{\\Gamma(\\alpha_1) \\cdots \\Gamma(\\alpha_k)} x_1^{\\alpha_1 - 1} \\cdots x_k^{\\alpha_k - 1} I_{\\{0,1\\}}(x_1, \\ldots, x_k)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathrm{E}_{\\alpha}[X_i] = \\alpha_i (\\alpha_0 + \\text{var}(X_i)) = (\\alpha_0 - \\alpha_i) \\alpha_i / [\\alpha_0 (\\alpha_0 + 1)] \\quad \\text{and} \\quad \\text{cov}(X_i, X_j) = -\\alpha_i \\alpha_j / [\\alpha_0^2 (\\alpha_0 + 1)] \\quad (i \\neq j).\n",
    "$$\n",
    "\n",
    "As a particular case, note that $(X_1, \\ldots, X_k) \\sim D_k(\\alpha_1, \\alpha_0)$ is equivalent to $X \\sim \\text{Be}(\\alpha_1, \\alpha_0)$.\n",
    "\n",
    "### A.9. Pareto Distribution, $Pa(\\alpha, \\omega)$\n",
    "($\\alpha > 0$ and $\\omega > 0$)\n",
    "\n",
    "$$\n",
    "f(x \\mid \\alpha, \\omega) = \\omega \\alpha^\\omega [1 \\omega + \\omega (x)]^{-(\\alpha + 1)} I_{(\\omega, \\infty)}(x)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathrm{E}_{\\omega, \\alpha}[X] = \\alpha \\omega / (\\alpha - 1) \\quad (\\alpha > 1) \\quad \\text{and} \\quad \\text{var}_{\\omega, \\alpha}(X) = \\alpha \\omega^2 / [(\\alpha - 1)^2 (\\alpha - 2)] \\quad (\\alpha > 2).\n",
    "$$\n",
    "\n",
    "### A.10. Binomial Distribution, $B(n, p)$\n",
    "($0 \\leq p \\leq 1$)\n",
    "\n",
    "$$\n",
    "f(x \\mid p) = \\binom{n}{x} p^x (1 - p)^{n - x} I_{\\{0, \\ldots, n\\}}(x).\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathrm{E}_p[X] = np \\quad \\text{and} \\quad \\text{var}(X) = np(1 - p).\n",
    "$$\n",
    "\n",
    "### A.11. Multinomial Distribution, $M_k(n; p_1, \\ldots, p_k)$\n",
    "($n \\geq 1$ ($1 \\leq i \\leq k$) and $\\sum_{i=1}^k p_i = 1$)\n",
    "\n",
    "$$\n",
    "f(x_1, \\ldots, x_k \\mid p_1, \\ldots, p_k) = \\binom{n}{x_1 \\cdots x_k} \\prod_{i=1}^k p_i^{x_i} I_{\\{x_1 + \\cdots + x_k = n\\}}.\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathrm{E}_p[X_i] = np_i, \\quad \\text{var}(X_i) = np_i(1 - p_i), \\quad \\text{and} \\quad \\text{cov}(X_i, X_j) = -np_i p_j \\quad (i \\neq j).\n",
    "$$\n",
    "\n",
    "Note that, if $X \\sim M_k(n; p_1, \\ldots, p_k)$, $X_i \\sim B(n, p_i)$, and that the binomial distribution $X \\sim B(n, p)$ corresponds to $X \\sim M_2(n, p, 1 - p)$.\n",
    "\n",
    "### A.12. Poisson Distribution, $\\mathcal{P}(\\lambda)$\n",
    "($\\lambda > 0$)\n",
    "\n",
    "$$\n",
    "f(x \\mid \\lambda) = e^{-\\lambda} \\frac{\\lambda^x}{x!} I_{\\mathbb{N}}(x).\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathrm{E}_\\lambda[X] = \\lambda \\quad \\text{and} \\quad \\text{var}_\\lambda(X) = \\lambda.\n",
    "$$\n",
    "\n",
    "### A.13. Negative Binomial Distribution, $\\mathcal{Ne}(r, p)$\n",
    "($0 \\leq p \\leq 1$)\n",
    "\n",
    "$$\n",
    "f(x \\mid p) = \\binom{x + r - 1}{x} p^r (1 - p)^x I_{\\mathbb{N}}(x).\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathrm{E}_p[X] = r(1 - p)/p \\quad \\text{and} \\quad \\text{var}_p(X) = r(1 - p)/p^2.\n",
    "$$\n",
    "\n",
    "## Statistical Distributions and Properties (Continued)\n",
    "\n",
    "### A.14. Hypergeometric Distribution, $\\mathcal{H}yp(N; n, p)$\n",
    "($0 \\leq p \\leq 1$, $n < N$, and $pN \\in \\mathbb{N}$)\n",
    "\n",
    "$$\n",
    "f(x \\mid p) = \\frac{\\binom{pN}{x} \\binom{(1-p)N}{n-x}}{\\binom{N}{n}} I_{\\{0,1,\\ldots,n\\}}(x).\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathrm{E}_{N,n,p}[X] = np \\quad \\text{and} \\quad \\text{var}_{N,n,p}(X) = (N-n)np(1-p)/(N-1).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58e2418a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dirichlet PDF: 5.8060800000000015\n",
      "Dirichlet E[X_0]: 0.2222222222222222\n",
      "Pareto PDF at x=2: 0.037037037037037035\n",
      "Pareto E[X]: 1.5\n",
      "Binomial PMF at x=5: 0.24609375\n",
      "Binomial E[X]: 5.0\n",
      "Multinomial PMF: 0.07838207999999999\n",
      "Multinomial E[X_0]: 3.0\n",
      "Poisson PMF at x=3: 0.19536681481316456\n",
      "Poisson E[X]: 4\n",
      "Negative Binomial PMF at x=2: 0.1875\n",
      "Negative Binomial E[X]: 3.0\n",
      "Hypergeometric PMF at x=2: 0.3973168214654283\n",
      "Hypergeometric E[X]: 2.0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "from functools import reduce\n",
    "import operator\n",
    "\n",
    "# Helper function to compute binomial coefficient (n choose k)\n",
    "def comb(n, k):\n",
    "    if k < 0 or k > n:\n",
    "        return 0\n",
    "    # Use symmetry to minimize computation: (n choose k) = (n choose n-k)\n",
    "    k = min(k, n - k)\n",
    "    return math.factorial(n) // (math.factorial(k) * math.factorial(n - k))\n",
    "\n",
    "# A.8 Dirichlet Distribution\n",
    "class Dirichlet:\n",
    "    def __init__(self, alphas):\n",
    "        self.alphas = alphas  # List of alpha parameters\n",
    "        self.alpha_0 = sum(alphas)  # Sum of alphas\n",
    "\n",
    "    def pdf(self, x):\n",
    "        # x is a list of values (x_1, ..., x_k), sum(x) = 1, 0 <= x_i <= 1\n",
    "        if len(x) != len(self.alphas) or abs(sum(x) - 1.0) > 1e-9 or any(xi < 0 or xi > 1 for xi in x):\n",
    "            return 0.0\n",
    "        # Compute PDF: Γ(α_0)/(Γ(α_1)...Γ(α_k)) * x_1^(α_1-1) * ... * x_k^(α_k-1)\n",
    "        numerator = math.gamma(self.alpha_0)\n",
    "        denominator = reduce(operator.mul, (math.gamma(alpha) for alpha in self.alphas), 1)\n",
    "        prod = reduce(operator.mul, (xi ** (alpha - 1) for xi, alpha in zip(x, self.alphas)), 1)\n",
    "        return (numerator / denominator) * prod\n",
    "\n",
    "    def expected_value(self, i):\n",
    "        # E[X_i] = α_i / α_0\n",
    "        return self.alphas[i] / self.alpha_0\n",
    "\n",
    "    def variance(self, i):\n",
    "        # var(X_i) = (α_0 - α_i)α_i / [α_0^2 (α_0 + 1)]\n",
    "        alpha_i = self.alphas[i]\n",
    "        return (self.alpha_0 - alpha_i) * alpha_i / (self.alpha_0 ** 2 * (self.alpha_0 + 1))\n",
    "\n",
    "# A.9 Pareto Distribution\n",
    "class Pareto:\n",
    "    def __init__(self, alpha, omega):\n",
    "        self.alpha = alpha  # Shape parameter\n",
    "        self.omega = omega  # Scale parameter\n",
    "\n",
    "    def pdf(self, x):\n",
    "        # f(x) = ωα^ω / (ω + x)^(α+1) for x > ω\n",
    "        if x <= self.omega:\n",
    "            return 0.0\n",
    "        return self.omega * (self.alpha ** self.omega) / ((self.omega + x) ** (self.alpha + 1))\n",
    "\n",
    "    def expected_value(self):\n",
    "        # E[X] = αω / (α-1) for α > 1\n",
    "        if self.alpha <= 1:\n",
    "            raise ValueError(\"Expected value undefined for α <= 1\")\n",
    "        return (self.alpha * self.omega) / (self.alpha - 1)\n",
    "\n",
    "    def variance(self):\n",
    "        # var(X) = αω^2 / [(α-1)^2 (α-2)] for α > 2\n",
    "        if self.alpha <= 2:\n",
    "            raise ValueError(\"Variance undefined for α <= 2\")\n",
    "        return (self.alpha * self.omega ** 2) / ((self.alpha - 1) ** 2 * (self.alpha - 2))\n",
    "\n",
    "    def sample(self):\n",
    "        # Inverse CDF method: X = ω * (U^(-1/α) - 1), U ~ Uniform(0,1)\n",
    "        u = random.random()\n",
    "        return self.omega * (u ** (-1 / self.alpha) - 1)\n",
    "\n",
    "# A.10 Binomial Distribution\n",
    "class Binomial:\n",
    "    def __init__(self, n, p):\n",
    "        self.n = n  # Number of trials\n",
    "        self.p = p  # Probability of success\n",
    "\n",
    "    def pmf(self, x):\n",
    "        # f(x) = (n choose x) * p^x * (1-p)^(n-x)\n",
    "        if not isinstance(x, int) or x < 0 or x > self.n:\n",
    "            return 0.0\n",
    "        coef = comb(self.n, x)  # Use custom comb function\n",
    "        return coef * (self.p ** x) * ((1 - self.p) ** (self.n - x))\n",
    "\n",
    "    def expected_value(self):\n",
    "        # E[X] = np\n",
    "        return self.n * self.p\n",
    "\n",
    "    def variance(self):\n",
    "        # var(X) = np(1-p)\n",
    "        return self.n * self.p * (1 - self.p)\n",
    "\n",
    "    def sample(self):\n",
    "        # Generate via sum of Bernoulli trials\n",
    "        return sum(random.random() < self.p for _ in range(self.n))\n",
    "\n",
    "# A.11 Multinomial Distribution\n",
    "class Multinomial:\n",
    "    def __init__(self, n, ps):\n",
    "        self.n = n  # Number of trials\n",
    "        self.ps = ps  # List of probabilities [p_1, ..., p_k], sum(ps) = 1\n",
    "\n",
    "    def pmf(self, xs):\n",
    "        # f(x_1, ..., x_k) = (n choose x_1,...,x_k) * p_1^x_1 * ... * p_k^x_k\n",
    "        if len(xs) != len(self.ps) or sum(xs) != self.n or any(x < 0 for x in xs):\n",
    "            return 0.0\n",
    "        coef = math.factorial(self.n) // reduce(operator.mul, (math.factorial(x) for x in xs), 1)\n",
    "        prod = reduce(operator.mul, (p ** x for p, x in zip(self.ps, xs)), 1)\n",
    "        return coef * prod\n",
    "\n",
    "    def expected_value(self, i):\n",
    "        # E[X_i] = np_i\n",
    "        return self.n * self.ps[i]\n",
    "\n",
    "    def variance(self, i):\n",
    "        # var(X_i) = np_i(1-p_i)\n",
    "        return self.n * self.ps[i] * (1 - self.ps[i])\n",
    "\n",
    "    def sample(self):\n",
    "        # Generate by sampling from categorical distribution n times\n",
    "        result = [0] * len(self.ps)\n",
    "        for _ in range(self.n):\n",
    "            r = random.random()\n",
    "            cumsum = 0\n",
    "            for i, p in enumerate(self.ps):\n",
    "                cumsum += p\n",
    "                if r < cumsum:\n",
    "                    result[i] += 1\n",
    "                    break\n",
    "        return result\n",
    "\n",
    "# A.12 Poisson Distribution\n",
    "class Poisson:\n",
    "    def __init__(self, lambda_):\n",
    "        self.lambda_ = lambda_  # Rate parameter\n",
    "\n",
    "    def pmf(self, x):\n",
    "        # f(x) = e^(-λ) * λ^x / x!\n",
    "        if not isinstance(x, int) or x < 0:\n",
    "            return 0.0\n",
    "        return (math.exp(-self.lambda_) * (self.lambda_ ** x)) / math.factorial(x)\n",
    "\n",
    "    def expected_value(self):\n",
    "        # E[X] = λ\n",
    "        return self.lambda_\n",
    "\n",
    "    def variance(self):\n",
    "        # var(X) = λ\n",
    "        return self.lambda_\n",
    "\n",
    "    def sample(self):\n",
    "        # Knuth's algorithm for Poisson sampling\n",
    "        L = math.exp(-self.lambda_)\n",
    "        k = 0\n",
    "        p = 1.0\n",
    "        while p > L:\n",
    "            k += 1\n",
    "            p *= random.random()\n",
    "        return k - 1\n",
    "\n",
    "# A.13 Negative Binomial Distribution\n",
    "class NegativeBinomial:\n",
    "    def __init__(self, r, p):\n",
    "        self.r = r  # Number of successes\n",
    "        self.p = p  # Probability of success\n",
    "\n",
    "    def pmf(self, x):\n",
    "        # f(x) = (x+r-1 choose x) * p^r * (1-p)^x\n",
    "        if not isinstance(x, int) or x < 0:\n",
    "            return 0.0\n",
    "        coef = comb(x + self.r - 1, x)  # Use custom comb function\n",
    "        return coef * (self.p ** self.r) * ((1 - self.p) ** x)\n",
    "\n",
    "    def expected_value(self):\n",
    "        # E[X] = r(1-p)/p\n",
    "        return self.r * (1 - self.p) / self.p\n",
    "\n",
    "    def variance(self):\n",
    "        # var(X) = r(1-p)/p^2\n",
    "        return self.r * (1 - self.p) / (self.p ** 2)\n",
    "\n",
    "    def sample(self):\n",
    "        # Generate as sum of r Geometric distributions\n",
    "        return sum(self._geometric_sample() for _ in range(self.r))\n",
    "\n",
    "    def _geometric_sample(self):\n",
    "        # Sample from Geometric(p) (number of failures until first success)\n",
    "        u = random.random()\n",
    "        return int(math.log(u) / math.log(1 - self.p))\n",
    "\n",
    "# A.14 Hypergeometric Distribution\n",
    "class Hypergeometric:\n",
    "    def __init__(self, N, n, p):\n",
    "        self.N = N  # Population size\n",
    "        self.n = n  # Number of draws\n",
    "        self.p = p  # Proportion of successes\n",
    "        self.K = int(self.N * self.p)  # Number of successes in population\n",
    "\n",
    "    def pmf(self, x):\n",
    "        # f(x) = (K choose x) * and ((N-K) choose (n-x)) / (N choose n)\n",
    "        if not isinstance(x, int) or x < 0 or x > min(self.n, self.K):\n",
    "            return 0.0\n",
    "        numerator = comb(self.K, x) * comb(self.N - self.K, self.n - x)  # Use custom comb function\n",
    "        denominator = comb(self.N, self.n)  # Use custom comb function\n",
    "        return numerator / denominator\n",
    "\n",
    "    def expected_value(self):\n",
    "        # E[X] = np\n",
    "        return self.n * self.p\n",
    "\n",
    "    def variance(self):\n",
    "        # var(X) = (N-n)np(1-p)/(N-1)\n",
    "        return (self.N - self.n) * self.n * self.p * (1 - self.p) / (self.N - 1)\n",
    "\n",
    "    def sample(self):\n",
    "        # Simulate drawing without replacement\n",
    "        population = [1] * self.K + [0] * (self.N - self.K)\n",
    "        random.shuffle(population)\n",
    "        return sum(population[:self.n])\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Dirichlet\n",
    "    dirichlet = Dirichlet([2, 3, 4])\n",
    "    print(\"Dirichlet PDF:\", dirichlet.pdf([0.3, 0.3, 0.4]))\n",
    "    print(\"Dirichlet E[X_0]:\", dirichlet.expected_value(0))\n",
    "\n",
    "    # Pareto\n",
    "    pareto = Pareto(3, 1)\n",
    "    print(\"Pareto PDF at x=2:\", pareto.pdf(2))\n",
    "    print(\"Pareto E[X]:\", pareto.expected_value())\n",
    "\n",
    "    # Binomial\n",
    "    binomial = Binomial(10, 0.5)\n",
    "    print(\"Binomial PMF at x=5:\", binomial.pmf(5))\n",
    "    print(\"Binomial E[X]:\", binomial.expected_value())\n",
    "\n",
    "    # Multinomial\n",
    "    multinomial = Multinomial(10, [0.3, 0.3, 0.4])\n",
    "    print(\"Multinomial PMF:\", multinomial.pmf([3, 3, 4]))\n",
    "    print(\"Multinomial E[X_0]:\", multinomial.expected_value(0))\n",
    "\n",
    "    # Poisson\n",
    "    poisson = Poisson(4)\n",
    "    print(\"Poisson PMF at x=3:\", poisson.pmf(3))\n",
    "    print(\"Poisson E[X]:\", poisson.expected_value())\n",
    "\n",
    "    # Negative Binomial\n",
    "    neg_binomial = NegativeBinomial(3, 0.5)\n",
    "    print(\"Negative Binomial PMF at x=2:\", neg_binomial.pmf(2))\n",
    "    print(\"Negative Binomial E[X]:\", neg_binomial.expected_value())\n",
    "\n",
    "    # Hypergeometric\n",
    "    hypergeom = Hypergeometric(20, 5, 0.4)\n",
    "    print(\"Hypergeometric PMF at x=2:\", hypergeom.pmf(2))\n",
    "    print(\"Hypergeometric E[X]:\", hypergeom.expected_value())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06867a32",
   "metadata": {},
   "source": [
    "### Bas aaj ke liye itnaa hee.\n",
    "\n",
    "This was one of a good kind of bumpy road......\n",
    "\n",
    "This was a great journey...... And wish for more\n",
    "\n",
    "## Om Namoh Sachidananda\n",
    "## Vande\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b0769d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
