{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2b8349",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " * Copyright (c) 2008 Radhamadhab Dalai\n",
    " *\n",
    " * Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    " * of this software and associated documentation files (the \"Software\"), to deal\n",
    " * in the Software without restriction, including without limitation the rights\n",
    " * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    " * copies of the Software, and to permit persons to whom the Software is\n",
    " * furnished to do so, subject to the following conditions:\n",
    " *\n",
    " * The above copyright notice and this permission notice shall be included in\n",
    " * all copies or substantial portions of the Software.\n",
    " *\n",
    " * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    " * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    " * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    " * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    " * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    " * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
    " * THE SOFTWARE.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97b61dc",
   "metadata": {},
   "source": [
    "### M-step Equations\n",
    "\n",
    "For the **M-step** of the factor analysis algorithm, the update equations for the factor loadings matrix $ W $ and the diagonal noise variance matrix $ \\Sigma $ are given by:\n",
    "\n",
    "$$\n",
    "W = \\left( (X - \\mu)^T (X - \\mu) + \\Sigma \\right)^{-1} (X - \\mu)^T Z\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\Sigma = \\text{diag} \\left( (X - \\mu)^T (X - \\mu) - W (Z^T (X - \\mu)) \\right)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $ X $ is the data matrix with dimensions $ N \\times D $ (with $ N $ data points and $ D $ features),\n",
    "- $ \\mu $ is the mean of the data,\n",
    "- $ Z $ is the latent variable matrix with dimensions $ N \\times M $ (with $ M $ latent dimensions),\n",
    "- $ W $ is the factor loading matrix with dimensions $ D \\times M $,\n",
    "- $ \\Sigma $ is the diagonal matrix of noise variances (diagonal noise covariance matrix).\n",
    "\n",
    "### Bayesian Treatment of Factor Analysis\n",
    "\n",
    "The Bayesian treatment of the factor analysis model involves incorporating priors and posterior distributions. Specifically, the parameters \\( W \\) and \\( \\Sigma \\) are treated as random variables, and a posterior distribution over these parameters is computed given the observed data. This can be done using techniques like **Gibbs sampling**, **variational inference**, or other methods in Bayesian statistics.\n",
    "\n",
    "### Transformation Behavior\n",
    "\n",
    "- **PCA and probabilistic PCA**: When the coordinate system in data space is rotated, the fit to the data remains the same, but the factor loading matrix $ W $ is transformed by the corresponding rotation matrix. This shows that the model is invariant to **orthogonal rotations**.\n",
    "\n",
    "- **Factor analysis**: When the data vectors are rescaled component-wise, the elements of $ W $ absorb the rescaling factor, and the model fit remains unchanged. This shows that factor analysis is invariant to **scaling** (but not rotation).\n",
    "\n",
    "This can be written as:\n",
    "\n",
    "$$\n",
    "\\text{If } X' = X \\cdot A \\text{ (component-wise scaling of the data), then: } W' = A^{-1} W\n",
    "$$\n",
    "\n",
    "Where $ A $ is the diagonal matrix containing the scaling factors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f089a6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Simulating some data for Factor Analysis\n",
    "np.random.seed(42)\n",
    "\n",
    "# Parameters\n",
    "D = 10  # Number of observed dimensions\n",
    "M = 3   # Number of latent dimensions\n",
    "N = 300 # Number of data points\n",
    "\n",
    "# Generating synthetic data: 300 data points in D=10 dimensions\n",
    "X = np.random.randn(N, M) @ np.random.randn(M, D) + np.random.randn(N, D)\n",
    "\n",
    "# Factor Analysis Model (EM algorithm)\n",
    "\n",
    "def factor_analysis_em(X, M, max_iter=100, tol=1e-6):\n",
    "    N, D = X.shape\n",
    "    W = np.random.randn(D, M)  # Initial factor loadings\n",
    "    Sigma = np.eye(D)  # Diagonal noise variance (initial)\n",
    "    mu = np.mean(X, axis=0)  # Mean of the data\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        # E-step: Calculate the posterior of the latent variables (Z)\n",
    "        X_centered = X - mu  # Center the data\n",
    "        inv_term = np.linalg.inv(np.dot(W.T, W) + np.eye(M))  # Inverse term for posterior of Z\n",
    "        Z = np.dot(X_centered, W) @ inv_term.T  # Compute the expected latent variables (Z)\n",
    "        \n",
    "        # M-step: Maximize the log-likelihood\n",
    "        # Update W using the formula\n",
    "        W_new = np.linalg.solve(np.dot(Z.T, Z) + np.eye(M), np.dot(Z.T, X_centered))\n",
    "        \n",
    "        # Update Sigma (noise variance) - we take the diagonal of the residual variance\n",
    "        residuals = X_centered - np.dot(Z, W_new.T)  # Corrected: Z * W_new^T\n",
    "        Sigma_new = np.diag(np.var(residuals, axis=0))  # Diagonal variance matrix for each dimension\n",
    "\n",
    "        # Convergence check\n",
    "        if np.linalg.norm(W_new - W) < tol and np.linalg.norm(Sigma_new - Sigma) < tol:\n",
    "            break\n",
    "        W, Sigma = W_new, Sigma_new\n",
    "    \n",
    "    return W, Sigma, mu\n",
    "\n",
    "# Run the EM algorithm for factor analysis\n",
    "W, Sigma, mu = factor_analysis_em(X, M)\n",
    "\n",
    "# Print the learned parameters\n",
    "print(\"Learned factor loadings W:\\n\", W)\n",
    "print(\"Learned noise variance Sigma (diagonal matrix):\\n\", Sigma)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4260098",
   "metadata": {},
   "source": [
    "### Kernel PCA\n",
    "\n",
    "In Chapter 6, we saw how the technique of **kernel substitution** allows us to take an algorithm expressed in terms of scalar products of the form $ x x^T $ and generalize that algorithm by replacing the scalar products with a nonlinear kernel. Here we apply this technique of kernel substitution to **principal component analysis** (PCA), thereby obtaining a nonlinear generalization called **kernel PCA** (SchÃ¶lkopf et al., 1998).\n",
    "\n",
    "Consider a data set $ \\{ x_n \\} $ of observations, where $ n = 1, \\dots, N $, in a space of dimensionality $ D $. In order to keep the notation uncluttered, we shall assume that we have already subtracted the sample mean from each of the vectors $ x_n $, so that $ \\mathbb{E}[X] = 0 $.\n",
    "\n",
    "The first step is to express conventional **PCA** in such a form that the data vectors $ \\{ x_n \\} $ appear only in the form of the scalar products $ x_n x_m^T $. Recall that the **principal components** are defined by the eigenvectors $ \\mathbf{u}_i $ of the covariance matrix:\n",
    "\n",
    "$$\n",
    "S = \\frac{1}{N} \\sum_{n=1}^{N} x_n x_n^T\n",
    "$$\n",
    "\n",
    "where $ i = 1, \\dots, D $. Here the $ D \\times D $ sample covariance matrix $ S $ is defined by:\n",
    "\n",
    "$$\n",
    "S = \\frac{1}{N} \\sum_{n=1}^{N} x_n x_n^T\n",
    "$$\n",
    "\n",
    "and the eigenvectors are normalized such that:\n",
    "\n",
    "$$\n",
    "\\mathbf{u}_i^T \\mathbf{u}_j = \\delta_{ij}\n",
    "$$\n",
    "\n",
    "Now consider a **nonlinear transformation** $ \\phi(x) $ into an $ M $-dimensional feature space, so that each data point $ x_n $ is thereby projected onto a point $ \\phi(x_n) $. \n",
    "\n",
    "This results in a **kernel function** $ k(x_n, x_m) = \\langle \\phi(x_n), \\phi(x_m) \\rangle $, which allows us to express the principal components in terms of these kernel functions instead of directly in terms of the data vectors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39842bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projected data (Kernel PCA):\n",
      " [[ 0.11153846 -0.3692271   0.02684072]\n",
      " [-0.0164959   0.00418892 -0.00254115]\n",
      " [-0.00509869  0.01608903 -0.00403986]\n",
      " [-0.01672815  0.00407126 -0.00264009]\n",
      " [-0.01794355  0.00592729 -0.00564462]]\n",
      "\n",
      "Eigenvalues:\n",
      " [1.32398282 1.27177548 1.23705748]\n",
      "\n",
      "Eigenvectors:\n",
      " [[ 8.42446391e-02 -2.90324120e-01  2.16972310e-02]\n",
      " [-1.24593014e-02  3.29375528e-03 -2.05419211e-03]\n",
      " [-3.85102426e-03  1.26508419e-02 -3.26570093e-03]\n",
      " [-1.26347174e-02  3.20124379e-03 -2.13417097e-03]\n",
      " [-1.35527060e-02  4.66064550e-03 -4.56294451e-03]\n",
      " [ 3.12251911e-02  6.90870857e-03 -1.43084478e-02]\n",
      " [-1.95388850e-04  1.19778888e-02 -1.06527760e-03]\n",
      " [-1.23113567e-02  3.16986723e-03 -1.98599898e-03]\n",
      " [-1.25662519e-02 -1.64483600e-03 -3.62030619e-03]\n",
      " [-4.48145098e-02  4.64453514e-03 -3.80546728e-02]\n",
      " [-1.32474455e-02  3.83223488e-03 -3.88681065e-03]\n",
      " [-1.21260320e-02  2.73675636e-03 -2.09975659e-03]\n",
      " [-4.64587117e-02  3.60421713e-02  6.89914232e-01]\n",
      " [-1.37815955e-03  8.37535400e-03 -1.68063436e-03]\n",
      " [-1.18432551e-02  4.63652312e-03 -4.03447627e-03]\n",
      " [-1.71244709e-02 -1.73319787e-02 -8.87205771e-03]\n",
      " [-1.26696834e-02  3.11112191e-03 -2.10670536e-03]\n",
      " [-1.22885973e-02  3.30931982e-03 -2.29663408e-03]\n",
      " [ 4.18648728e-02  2.39965967e-02 -2.38453673e-03]\n",
      " [-2.54908362e-02  1.16913256e-02  1.48340926e-02]\n",
      " [-1.23838970e-02  3.13053840e-03 -1.98617542e-03]\n",
      " [ 5.34146618e-04 -1.32506294e-02 -7.02606322e-02]\n",
      " [-1.23113497e-02  3.25285687e-03 -1.46602258e-03]\n",
      " [-1.25531932e-02  3.23941824e-03 -1.64138972e-03]\n",
      " [-5.43252648e-03  9.46099835e-03 -4.02104633e-03]\n",
      " [-1.23055025e-02  2.84264723e-03 -1.98781954e-03]\n",
      " [-1.23072359e-02  3.12108046e-03 -1.96707029e-03]\n",
      " [-2.52997562e-03  1.10594065e-02 -2.64425077e-03]\n",
      " [-1.27593037e-02  3.23210337e-03 -2.14098507e-03]\n",
      " [ 9.05058419e-03 -6.91810159e-02 -4.97833308e-03]\n",
      " [ 4.98363330e-03 -4.91034691e-02 -3.14566371e-03]\n",
      " [-1.27839758e-02 -3.36735637e-02 -1.98235252e-02]\n",
      " [-7.18743178e-03 -1.29328844e-02 -9.11750748e-04]\n",
      " [-2.32600663e-02  7.94066251e-04 -2.01977218e-02]\n",
      " [-1.01235857e-02  5.38283855e-03 -3.86681544e-03]\n",
      " [-3.56901339e-02 -2.44007799e-03 -3.58315040e-02]\n",
      " [-3.31473524e-02 -1.14970743e-02 -3.93152880e-02]\n",
      " [-1.25964689e-02  2.88754631e-03 -2.28219570e-03]\n",
      " [-1.21665063e-02  3.41670811e-03 -2.13207243e-03]\n",
      " [-1.28904911e-02  2.80644159e-03 -2.41152776e-03]\n",
      " [ 6.03239852e-02  3.41968813e-02  4.59038787e-04]\n",
      " [-1.11709451e-02 -7.83529480e-03 -3.02752859e-03]\n",
      " [-1.24729735e-02  3.16233635e-03 -2.03761556e-03]\n",
      " [-1.22942600e-02  2.97310639e-03 -1.96940300e-03]\n",
      " [ 7.47930803e-04  1.04774554e-02 -2.30558014e-03]\n",
      " [-2.78081542e-02  7.16842828e-03 -2.08666892e-02]\n",
      " [ 1.73871826e-03  1.04815741e-02 -7.81209934e-03]\n",
      " [-1.23034788e-02  3.11539981e-03 -1.96525636e-03]\n",
      " [-1.28620589e-02  3.79372725e-03 -2.52508125e-03]\n",
      " [-1.71400527e-02  5.06935358e-03 -6.73907144e-04]\n",
      " [-2.42888575e-02  6.96024361e-03 -1.56755047e-02]\n",
      " [ 3.62046066e-02  3.11293767e-02 -2.49140834e-04]\n",
      " [-1.29155242e-02  3.73518603e-03 -2.72061445e-03]\n",
      " [-1.21733991e-02  7.95715769e-03 -4.53223168e-03]\n",
      " [-1.16742092e-02  3.66895317e-03 -2.03479086e-03]\n",
      " [-2.92167329e-02 -2.10382187e-02 -5.59359375e-02]\n",
      " [-1.24895572e-02  3.16085874e-03 -2.03764696e-03]\n",
      " [-1.34334966e-02  3.32561729e-03 -2.51513462e-03]\n",
      " [-9.80609274e-03 -3.10674402e-03 -3.52311864e-03]\n",
      " [-1.84546582e-02 -3.92431866e-02 -4.10050245e-02]\n",
      " [-1.25140389e-02  3.06953008e-03 -2.27556151e-03]\n",
      " [-1.51301174e-02  3.86033864e-03 -2.54686853e-03]\n",
      " [-1.31045690e-02 -1.17921514e-04 -4.20003518e-03]\n",
      " [-1.25908586e-02  3.17682678e-03 -2.25278005e-03]\n",
      " [-1.24085312e-02  3.17703721e-03 -1.95534478e-03]\n",
      " [-1.42185911e-02  3.67209463e-03 -2.51055563e-03]\n",
      " [-1.24124678e-02  3.19512789e-03 -2.03795194e-03]\n",
      " [-1.19703386e-02  3.97102386e-03 -2.20612659e-03]\n",
      " [ 2.93148010e-01  1.93018850e-01  4.83765269e-03]\n",
      " [-2.04909894e-02  3.54707220e-03 -1.11090298e-02]\n",
      " [-1.23599917e-02  3.13739819e-03 -1.97786474e-03]\n",
      " [ 4.80338487e-01  1.03624486e-01  1.08602149e-02]\n",
      " [ 2.09234257e-03  9.06544451e-03 -2.97998831e-03]\n",
      " [-1.30456174e-02  3.33835536e-03 -2.42734222e-03]\n",
      " [-1.27202946e-02  3.24836303e-03 -2.17196272e-03]\n",
      " [-1.37154190e-03  8.06458876e-03 -1.62933413e-03]\n",
      " [-1.28736982e-02  3.13350571e-03 -2.21598654e-03]\n",
      " [-1.93160580e-02 -9.56726081e-03 -1.85782721e-02]\n",
      " [-6.17423225e-03  3.00393617e-03 -1.88955910e-03]\n",
      " [ 2.19566955e-02  2.52220848e-02  4.46913758e-03]\n",
      " [-2.03885713e-02  7.31035564e-03 -2.08314722e-02]\n",
      " [-1.36115402e-02  5.51713447e-04 -4.27259089e-03]\n",
      " [-1.24905823e-02  3.06750804e-03 -2.09184641e-03]\n",
      " [-1.71498905e-02  5.71311240e-03 -5.49250751e-03]\n",
      " [-1.16499183e-02  3.35961991e-03 -3.08945733e-03]\n",
      " [-1.23262617e-02 -5.59258601e-03 -6.51427673e-03]\n",
      " [-1.16743875e-02  1.50729023e-03 -1.86575752e-03]\n",
      " [ 1.88563377e-02  1.72139789e-02  1.81155990e-04]\n",
      " [-1.22040478e-02  3.21572984e-03 -2.02562129e-03]\n",
      " [-1.49041465e-02 -6.66941746e-04 -7.24047288e-03]\n",
      " [-1.06048052e-02  1.56046206e-03 -4.23974567e-03]\n",
      " [ 2.43267307e-01 -6.02058691e-01  4.64232303e-02]\n",
      " [-2.55233155e-02  5.79480831e-03 -1.16685009e-02]\n",
      " [-1.28275801e-02  3.33891409e-03 -2.11923352e-03]\n",
      " [-1.59996295e-02  2.34204490e-03 -5.00773790e-03]\n",
      " [ 1.14867942e-01 -3.66954892e-02  6.77585404e-03]\n",
      " [-1.21564404e-02  3.25333228e-03 -2.46558362e-03]\n",
      " [-1.28475481e-02  3.21293456e-03 -2.27099641e-03]\n",
      " [-2.59491092e-02 -1.14069841e-02 -1.68649620e-02]\n",
      " [-1.90981828e-02  8.31841556e-03 -4.57763147e-03]\n",
      " [-1.83334649e-02  3.95806748e-03 -7.44225679e-03]\n",
      " [-1.43682918e-02  3.52628255e-03 -1.53145898e-03]\n",
      " [-9.98379656e-03 -8.96583155e-03 -1.79901637e-03]\n",
      " [-7.58331218e-03  6.75211123e-03 -1.41948072e-03]\n",
      " [-1.25906887e-02  3.31454433e-03 -2.31777241e-03]\n",
      " [-1.72570749e-02 -5.42822285e-03 -1.56802980e-02]\n",
      " [-1.23644095e-02  3.15079933e-03 -1.98165064e-03]\n",
      " [-1.76305440e-02  4.48715869e-03 -3.01400639e-03]\n",
      " [ 1.83084753e-01 -5.18827136e-01  4.38603793e-02]\n",
      " [-1.83504827e-02 -2.88823513e-03 -1.60918423e-02]\n",
      " [-1.23036613e-02  3.11875127e-03 -1.96533275e-03]\n",
      " [-3.63810281e-03 -2.94929945e-02 -7.00287181e-05]\n",
      " [-1.50320471e-02  3.43975542e-03 -3.56782362e-03]\n",
      " [-1.26464794e-02 -1.27148289e-03 -3.99011611e-03]\n",
      " [-1.40826116e-02  3.54119757e-03 -3.36830511e-03]\n",
      " [-1.23173224e-02  3.16275959e-03 -1.95976871e-03]\n",
      " [-1.23141721e-02  3.12239708e-03 -1.96709020e-03]\n",
      " [-1.09554922e-02  6.34667222e-03 -1.52155683e-02]\n",
      " [-1.61049855e-02  6.31370643e-03  2.89940896e-03]\n",
      " [ 9.98945281e-02  6.25745456e-02  1.33770331e-03]\n",
      " [-5.85458340e-03 -1.23606040e-02 -9.26578063e-03]\n",
      " [-6.79454001e-03  5.75397725e-03 -2.29940515e-03]\n",
      " [-1.30287957e-02 -3.25083753e-03 -5.56752454e-03]\n",
      " [-1.19084360e-02  2.56771205e-03 -1.89866326e-03]\n",
      " [-1.54804641e-02  4.18867089e-03 -4.95878753e-03]\n",
      " [-1.62397656e-02  3.90102450e-04 -5.13575584e-03]\n",
      " [-1.65814490e-02  1.87927657e-03 -6.45501879e-03]\n",
      " [-1.40687361e-02  2.64733742e-03 -3.49295646e-03]\n",
      " [-1.30084009e-02  3.40479039e-03 -2.89245141e-03]\n",
      " [-1.70213833e-02 -1.58724506e-03 -1.07039216e-02]\n",
      " [-3.21857282e-02  4.40037492e-03 -1.87420732e-02]\n",
      " [-2.29361006e-02 -1.74456013e-03 -2.24463319e-02]\n",
      " [-1.78079582e-02  1.47700478e-03 -8.83291440e-03]\n",
      " [-1.41179821e-02 -1.65131956e-03 -1.16154504e-02]\n",
      " [-1.33174162e-02  2.81401770e-03 -2.95588547e-03]\n",
      " [-1.23136611e-02  3.11791626e-03 -1.97389614e-03]\n",
      " [-2.07642928e-02  4.09178593e-03 -7.58252755e-03]\n",
      " [-1.23730702e-02  3.14874056e-03 -1.99154185e-03]\n",
      " [-1.23588237e-02  3.40309565e-03 -1.81891701e-03]\n",
      " [-1.47555287e-02  1.45193737e-03 -8.84570018e-03]\n",
      " [-1.30389505e-02  2.91314220e-03 -2.76284270e-03]\n",
      " [-9.87116534e-03  2.51104628e-03 -3.06683807e-03]\n",
      " [-1.30036910e-02  3.25978113e-03 -2.45900345e-03]\n",
      " [-1.53320841e-02  5.91610376e-03 -7.07407881e-03]\n",
      " [-2.48927481e-02  6.04583157e-03 -7.07821356e-03]\n",
      " [-1.23523840e-02  2.86847891e-03 -1.99470799e-03]\n",
      " [-1.72662304e-02  1.05398858e-02 -4.83749377e-03]\n",
      " [ 1.28098666e-01  6.19257070e-02 -2.12851781e-03]\n",
      " [-1.47465417e-02  3.51190650e-03 -4.78544854e-03]\n",
      " [-1.23056922e-02  3.11965369e-03 -1.96574214e-03]\n",
      " [-3.72097570e-03 -1.17325802e-02 -4.19388613e-03]\n",
      " [-1.24964124e-02  3.22798079e-03 -2.04469458e-03]\n",
      " [-1.29892333e-02  3.49126673e-03 -2.42975819e-03]\n",
      " [-1.23300651e-02  3.15194883e-03 -1.98660807e-03]\n",
      " [-1.32667483e-02  3.17750277e-03 -3.64023685e-03]\n",
      " [-1.38247346e-02  8.91224229e-03 -8.95978514e-03]\n",
      " [-1.13696394e-02  4.09875674e-03 -2.33987459e-03]\n",
      " [-1.25869978e-02  5.60097966e-03 -2.18155967e-03]\n",
      " [ 8.75156496e-02  2.56225314e-02 -6.61628930e-03]\n",
      " [-1.23424302e-02  3.13108007e-03 -1.97332023e-03]\n",
      " [-2.73966073e-02  5.10364331e-03 -1.92119032e-02]\n",
      " [-1.22796259e-02  3.25948276e-03 -1.37124795e-03]\n",
      " [-1.21595392e-02  3.97188508e-03 -1.40530558e-03]\n",
      " [-1.14814169e-02  4.13561154e-03 -2.46005630e-03]\n",
      " [-1.25928285e-02  2.83657862e-03 -2.27894153e-03]\n",
      " [-1.11508321e-02 -2.03570908e-03 -5.50062305e-03]\n",
      " [-1.22632052e-02  3.31599937e-03 -2.28496196e-03]\n",
      " [-1.33569050e-02  3.24640301e-03 -3.06844859e-03]\n",
      " [ 3.86493475e-01  1.80599722e-01  7.16453675e-03]\n",
      " [-4.66822663e-02  3.69403852e-02  6.91505666e-01]\n",
      " [-1.22066199e-02 -2.24926235e-02 -5.38038905e-03]\n",
      " [-1.41742206e-03  8.16297573e-03 -2.40772954e-03]\n",
      " [-7.00870286e-05  6.21827101e-04 -2.98709488e-03]\n",
      " [-1.56255673e-02  3.01697971e-03 -4.64626195e-03]\n",
      " [ 1.34682011e-01 -2.89244702e-01  2.39616003e-02]\n",
      " [-1.23150789e-02  3.12663623e-03 -1.96794260e-03]\n",
      " [-1.29496030e-02  3.26163491e-03 -2.26107868e-03]\n",
      " [-4.07946645e-02  7.58616941e-03 -3.42064265e-02]\n",
      " [-1.61341426e-02  3.21087468e-03 -5.01396272e-03]\n",
      " [-1.60287843e-02  3.36694829e-03 -5.91312211e-03]\n",
      " [-1.23208779e-02  3.14302785e-03 -1.97959107e-03]\n",
      " [-1.60650633e-02  2.51907897e-03 -8.05513267e-03]\n",
      " [-9.76787502e-04  1.65021809e-02 -5.09041049e-03]\n",
      " [ 4.04592722e-03  9.75951001e-04 -6.86711077e-02]\n",
      " [-1.38374203e-02 -4.44843327e-04 -4.04561316e-03]\n",
      " [-1.54268271e-02  1.77895637e-03 -5.26003842e-03]\n",
      " [-1.50220300e-02  3.93739668e-03 -2.80806239e-03]\n",
      " [-9.66708827e-03  3.55822339e-03 -2.11247104e-03]\n",
      " [-3.44544625e-03  8.81958621e-03 -6.15215613e-03]\n",
      " [-1.44783458e-02  1.05987657e-02 -1.68049377e-02]\n",
      " [-1.50795587e-02  2.33198039e-03 -1.49459288e-02]\n",
      " [-1.27560512e-02  3.25576893e-03 -2.76641206e-03]\n",
      " [-1.23243293e-02  3.12302350e-03 -1.97687597e-03]\n",
      " [-1.28790723e-02  3.20166788e-03 -2.38122036e-03]\n",
      " [-3.01991846e-02 -7.53083727e-03 -3.60122147e-02]\n",
      " [-1.23021783e-02  3.11940055e-03 -1.96476330e-03]\n",
      " [ 3.57276164e-02 -1.12982459e-01 -2.84815060e-02]\n",
      " [-1.33486972e-02  3.70076041e-03 -2.30763349e-03]\n",
      " [ 1.05986391e-02 -3.67201387e-02  1.61244873e-03]\n",
      " [-1.06355088e-02 -5.30823965e-03 -3.35408512e-02]\n",
      " [ 3.16718968e-02  3.34439057e-02 -2.02279340e-03]\n",
      " [-1.28992734e-02  3.29970057e-03 -2.23625337e-03]\n",
      " [-1.23058080e-02  3.12497300e-03 -1.96613646e-03]\n",
      " [-1.23997002e-02  3.28244310e-03 -1.49673524e-03]\n",
      " [ 4.38862623e-01  1.46996463e-01  1.18590421e-02]\n",
      " [ 1.15450263e-03  1.58000979e-02 -5.27204140e-03]\n",
      " [-1.34565356e-02  3.42336094e-03 -2.64807461e-03]\n",
      " [-2.06795775e-02 -6.35093903e-03 -1.81544935e-02]\n",
      " [-1.24642068e-02  3.28208531e-03 -2.08773310e-03]\n",
      " [-1.66938373e-02  3.55854944e-03 -4.47227387e-03]\n",
      " [ 1.19777535e-01  7.76436122e-02  1.25878763e-03]\n",
      " [-2.02117951e-02  5.54331545e-03 -4.80151890e-03]\n",
      " [-1.24182983e-02  3.35410485e-03 -2.35835775e-03]\n",
      " [-1.40092168e-02 -6.95558309e-04 -4.57888825e-03]\n",
      " [-9.92712553e-03  4.77055979e-03 -2.30804086e-03]\n",
      " [-1.55495601e-02  4.30454580e-03 -5.63498889e-03]\n",
      " [-1.81285324e-02 -2.71563369e-03 -1.03307140e-02]\n",
      " [-8.77596082e-03  5.30039948e-03 -1.21724923e-03]\n",
      " [ 2.10977173e-02  2.65164027e-02 -1.37524359e-03]\n",
      " [-1.32434079e-02  3.13884058e-03 -2.31652506e-03]\n",
      " [-1.17639683e-02  5.09974739e-03 -2.12761300e-03]\n",
      " [-1.48737540e-02  3.90140010e-03 -3.98685925e-03]\n",
      " [-1.20968154e-02  3.98344764e-03 -2.29471603e-03]\n",
      " [ 4.60874194e-04  8.76518094e-03 -1.87467053e-03]\n",
      " [-1.39990608e-02  3.57698077e-03 -1.86223768e-03]\n",
      " [-1.20567831e-02  3.22002082e-03 -2.00384774e-03]\n",
      " [-1.78112177e-02  8.21135135e-03  5.29452915e-02]\n",
      " [-1.05377451e-02  8.97887441e-03 -5.96992245e-03]\n",
      " [-1.24815370e-02  3.45590223e-03 -2.19677632e-03]\n",
      " [-1.45780082e-02  3.85180236e-03 -4.05357873e-03]\n",
      " [-1.23346825e-02  3.15107650e-03 -1.97883518e-03]\n",
      " [-1.68681957e-02 -5.88499591e-03 -1.71276454e-02]\n",
      " [-4.85567836e-03 -9.67568840e-03 -1.58468261e-02]\n",
      " [ 3.92850723e-02  2.03369612e-02 -3.08013672e-03]\n",
      " [-4.60050141e-03  1.11069708e-02 -2.96476934e-03]\n",
      " [-1.43351469e-02  3.94260781e-03 -1.96785722e-03]\n",
      " [-1.09819742e-02  4.25380063e-03 -2.00613131e-03]\n",
      " [ 4.11766543e-03  2.98528651e-03 -5.75377593e-03]\n",
      " [-1.88485918e-02  1.22710101e-03 -1.08600634e-02]\n",
      " [-1.37020321e-02  3.60797045e-03 -2.58644834e-03]\n",
      " [-1.25805031e-02  4.50203224e-03 -1.20178380e-03]\n",
      " [-1.53149150e-02  3.88263051e-03 -6.40854300e-03]\n",
      " [-4.66870342e-03  1.18763246e-02 -5.19368960e-03]\n",
      " [-6.33559098e-03  1.00228603e-02 -5.08662851e-03]\n",
      " [-1.14158599e-02  6.99167557e-03 -7.42093459e-03]\n",
      " [ 1.16953871e-02  1.76277880e-02  1.40918067e-02]\n",
      " [-2.73221414e-02  1.30507769e-02  4.83682096e-02]\n",
      " [-1.24677429e-02  3.58285337e-03 -2.34086757e-03]\n",
      " [-1.33119266e-02  3.56565113e-03 -1.73118445e-03]\n",
      " [ 2.82518718e-01  1.65139031e-01  6.53825324e-03]\n",
      " [-1.23981910e-02  3.09565317e-03 -2.02317046e-03]\n",
      " [-1.57540804e-02  4.00746573e-03 -8.06173304e-03]\n",
      " [-1.24098348e-02  3.11969135e-03 -2.05607241e-03]\n",
      " [-1.24095489e-02  1.02066939e-02 -2.59376114e-03]\n",
      " [-1.22210084e-02  3.19261719e-03 -2.06598333e-03]\n",
      " [-1.22485081e-02  3.15865984e-03 -1.96495693e-03]\n",
      " [-2.98247449e-03  1.05921947e-02 -5.43746541e-03]\n",
      " [-1.23151182e-02  3.09792644e-03 -1.97263291e-03]\n",
      " [-1.73248513e-02 -6.99381334e-03 -1.42263502e-02]\n",
      " [-2.44193625e-02  5.89255899e-03 -1.02151659e-02]\n",
      " [-1.22731766e-02  3.25606297e-03 -2.01933714e-03]\n",
      " [ 1.36187742e-02  1.00923389e-02 -1.09900542e-02]\n",
      " [ 6.14951288e-03 -9.18629218e-02 -1.80478927e-03]\n",
      " [-1.67085118e-03  1.09302439e-03 -2.78167541e-03]\n",
      " [-1.59606429e-02  7.26982815e-03 -4.54678416e-03]\n",
      " [-1.06002719e-02  4.04371118e-04 -5.38207102e-03]\n",
      " [-1.62810708e-02  2.98550814e-03 -5.29585542e-03]\n",
      " [-1.43062850e-02  3.66619428e-03 -3.59801864e-03]\n",
      " [-2.82131445e-03  3.02826406e-03 -1.09994766e-02]\n",
      " [-9.77755151e-03  4.11753657e-03 -2.41761005e-03]\n",
      " [-1.09706836e-02 -3.16579467e-03 -5.90947609e-03]\n",
      " [-1.60757942e-02  4.12067807e-03 -3.64545158e-03]\n",
      " [-1.22845462e-02  3.00476862e-03 -2.00218727e-03]\n",
      " [-1.41442692e-02  3.63458547e-03 -2.56572858e-03]\n",
      " [-1.04158130e-02  7.22519119e-03 -3.17286707e-03]\n",
      " [-1.23506117e-02  4.43634494e-03 -4.35030846e-03]\n",
      " [ 2.76233750e-02  2.50543245e-02  2.07071199e-02]\n",
      " [-5.19434571e-03  1.36610552e-02 -4.49636835e-03]\n",
      " [-1.57716610e-02  8.95746833e-03 -5.10881066e-03]\n",
      " [-1.67940299e-02  7.27946779e-03 -6.46839156e-03]\n",
      " [-1.53717149e-02  3.01651400e-03 -5.89240074e-03]\n",
      " [-1.25628160e-02  3.21863206e-03 -2.03129439e-03]\n",
      " [-1.18570611e-02  4.53349935e-03 -1.60266644e-03]\n",
      " [-1.23041212e-02  3.11431348e-03 -1.96650052e-03]\n",
      " [-1.31959964e-02  2.87438202e-03 -3.50188492e-03]\n",
      " [-2.50710362e-02  4.61733392e-03 -1.30881665e-02]\n",
      " [-1.74344545e-02  1.15184792e-03 -1.14971670e-02]\n",
      " [-1.54247232e-02  4.38048324e-03 -4.54652834e-03]\n",
      " [-1.23329672e-02  3.13745627e-03 -1.97312311e-03]\n",
      " [-1.23020273e-02  3.11879673e-03 -1.96356341e-03]\n",
      " [ 7.11108495e-02  5.40871861e-02 -8.81354639e-04]\n",
      " [ 2.90726615e-02  2.20517149e-03 -1.73588445e-03]\n",
      " [-2.14203415e-02  1.69768932e-03 -1.28990651e-02]\n",
      " [ 9.03996274e-03  9.11752737e-03 -1.84494474e-03]\n",
      " [-1.27256889e-02  3.24211667e-03 -2.26808082e-03]\n",
      " [-1.21191210e-02  3.38347353e-03 -2.32690300e-03]\n",
      " [-2.01838487e-02  5.49334710e-03 -5.00656186e-03]\n",
      " [-1.09126110e-02 -1.87390690e-03 -1.59373157e-03]\n",
      " [-1.23648616e-02  3.07178138e-03 -2.00741624e-03]\n",
      " [-1.15443936e-02  1.16670101e-02 -9.01888056e-03]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "\n",
    "def kernel_pca(X, gamma=1.0, n_components=2):\n",
    "    \"\"\"\n",
    "    Perform Kernel PCA on the input data X.\n",
    "    \n",
    "    Parameters:\n",
    "    - X: Input data, shape (N, D), where N is the number of data points and D is the number of features.\n",
    "    - gamma: Parameter for the RBF kernel, default is 1.0.\n",
    "    - n_components: Number of principal components to return.\n",
    "\n",
    "    Returns:\n",
    "    - X_kpca: The data projected onto the principal components.\n",
    "    - eigenvectors: The eigenvectors corresponding to the largest eigenvalues.\n",
    "    - eigenvalues: The eigenvalues of the kernel matrix.\n",
    "    \"\"\"\n",
    "    N = X.shape[0]\n",
    "    \n",
    "    # Compute the RBF kernel matrix K\n",
    "    K = rbf_kernel(X, gamma=gamma)\n",
    "    \n",
    "    # Center the kernel matrix K (centering as in standard PCA)\n",
    "    one_n = np.ones((N, N)) / N\n",
    "    K_centered = K - one_n @ K - K @ one_n + one_n @ K @ one_n\n",
    "    \n",
    "    # Perform eigen-decomposition\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(K_centered)\n",
    "    \n",
    "    # Sort eigenvalues and eigenvectors in descending order\n",
    "    sorted_idx = np.argsort(eigenvalues)[::-1]\n",
    "    eigenvalues = eigenvalues[sorted_idx]\n",
    "    eigenvectors = eigenvectors[:, sorted_idx]\n",
    "    \n",
    "    # Select the top n_components eigenvectors\n",
    "    eigenvectors = eigenvectors[:, :n_components]\n",
    "    \n",
    "    # Project the data onto the first n_components principal components\n",
    "    X_kpca = K_centered @ eigenvectors\n",
    "    \n",
    "    return X_kpca, eigenvectors, eigenvalues\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "# Generate some random data (300 points in 10 dimensions)\n",
    "np.random.seed(42)\n",
    "X = np.random.randn(300, 10)\n",
    "\n",
    "# Apply Kernel PCA\n",
    "X_kpca, eigenvectors, eigenvalues = kernel_pca(X, gamma=1.0, n_components=3)\n",
    "\n",
    "# Print the results\n",
    "print(\"Projected data (Kernel PCA):\\n\", X_kpca[:5])  # Print the first 5 projected points\n",
    "print(\"\\nEigenvalues:\\n\", eigenvalues[:3])  # Print the first 3 eigenvalues\n",
    "print(\"\\nEigenvectors:\\n\", eigenvectors[:, :3])  # Print the first 3 eigenvectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd79728b",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11433/446586368.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;31m# Apply Kernel PCA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m \u001b[0mX_kpca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meigenvectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meigenvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel_pca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;31m# Print the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_11433/446586368.py\u001b[0m in \u001b[0;36mkernel_pca\u001b[0;34m(X, gamma, n_components)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m# Step 5: Project the data onto the new principal components\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mX_kpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK_centered\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0meigenvectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX_kpca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meigenvectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meigenvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_11433/446586368.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m# Step 5: Project the data onto the new principal components\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mX_kpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK_centered\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0meigenvectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX_kpca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meigenvectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meigenvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_11433/446586368.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m# Step 5: Project the data onto the new principal components\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mX_kpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK_centered\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0meigenvectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX_kpca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meigenvectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meigenvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_11433/446586368.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m# Step 5: Project the data onto the new principal components\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mX_kpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK_centered\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0meigenvectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX_kpca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meigenvectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meigenvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "from scipy.linalg import eigh\n",
    "\n",
    "# Compute the RBF (Gaussian) kernel\n",
    "def rbf_kernel(X, gamma=1.0):\n",
    "    N = len(X)\n",
    "    K = [[0] * N for _ in range(N)]\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            distance_squared = sum((X[i][d] - X[j][d]) ** 2 for d in range(len(X[i])))\n",
    "            K[i][j] = math.exp(-gamma * distance_squared)\n",
    "    return K\n",
    "\n",
    "# Center the kernel matrix\n",
    "def center_kernel_matrix(K):\n",
    "    N = len(K)\n",
    "    one_n = [[1 / N] * N for _ in range(N)]  # Create the 1/N matrix\n",
    "    K_centered = [[K[i][j] - sum(K[i]) / N - sum(K[k][j] for k in range(N)) / N + sum(sum(K[k][l] for l in range(N)) / N for k in range(N)) / N for j in range(N)] for i in range(N)]\n",
    "    return K_centered\n",
    "\n",
    "# Perform eigen-decomposition\n",
    "def eigen_decomposition(K_centered):\n",
    "    # Using scipy's eigh for eigenvalue/eigenvector computation since it's complex to do from scratch\n",
    "    eigenvalues, eigenvectors = eigh(K_centered)\n",
    "    return eigenvalues, eigenvectors\n",
    "\n",
    "# Kernel PCA function\n",
    "def kernel_pca(X, gamma=1.0, n_components=2):\n",
    "    N = len(X)\n",
    "    \n",
    "    # Step 1: Compute the RBF kernel matrix\n",
    "    K = rbf_kernel(X, gamma)\n",
    "    \n",
    "    # Step 2: Center the kernel matrix\n",
    "    K_centered = center_kernel_matrix(K)\n",
    "    \n",
    "    # Step 3: Perform eigen-decomposition to get eigenvectors and eigenvalues\n",
    "    eigenvalues, eigenvectors = eigen_decomposition(K_centered)\n",
    "    \n",
    "    # Sort the eigenvalues and corresponding eigenvectors in descending order\n",
    "    sorted_indices = sorted(range(len(eigenvalues)), key=lambda i: eigenvalues[i], reverse=True)\n",
    "    eigenvalues = [eigenvalues[i] for i in sorted_indices]\n",
    "    eigenvectors = [[eigenvectors[i][j] for i in sorted_indices] for j in range(len(eigenvectors[0]))]\n",
    "    \n",
    "    # Step 4: Select the top n_components eigenvectors\n",
    "    eigenvectors = eigenvectors[:n_components]\n",
    "    \n",
    "    # Step 5: Project the data onto the new principal components\n",
    "    X_kpca = [[sum(K_centered[i][j] * eigenvectors[j][k] for j in range(N)) for k in range(n_components)] for i in range(N)]\n",
    "    \n",
    "    return X_kpca, eigenvectors, eigenvalues\n",
    "\n",
    "# Example usage:\n",
    "# Generate some random data (300 points in 10 dimensions)\n",
    "random.seed(42)\n",
    "X = [[random.gauss(0, 1) for _ in range(10)] for _ in range(300)]\n",
    "\n",
    "# Apply Kernel PCA\n",
    "X_kpca, eigenvectors, eigenvalues = kernel_pca(X, gamma=1.0, n_components=3)\n",
    "\n",
    "# Print the results\n",
    "print(\"Projected data (Kernel PCA):\\n\", X_kpca[:5])  # Print the first 5 projected points\n",
    "print(\"\\nEigenvalues:\\n\", eigenvalues[:3])  # Print the first 3 eigenvalues\n",
    "print(\"\\nEigenvectors:\\n\", eigenvectors[:3])  # Print the first 3 eigenvectors\n"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "c4187de6",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)\n",
    "\n",
    "### Kernel PCA and Nonlinear Principal Components\n",
    "\n",
    "Fig.16 illustrates a schematic representation of Kernel PCA. In this approach, a dataset in the original data space (left-hand plot) is projected by a nonlinear transformation $ \\phi(x) $ into a feature space (right-hand plot). By performing standard PCA in the feature space, we obtain the principal components, of which the first principal component is shown in blue and denoted by the vector $ v_1 $. The green lines in the feature space indicate the linear projections onto the first principal component, which correspond to nonlinear projections in the original data space. Note that, in general, it is not possible to represent the nonlinear principal component as a vector in the original data space.\n",
    "\n",
    "Now, we perform standard PCA in the feature space, which implicitly defines a nonlinear principal component model in the original data space, as shown in Fig.16. For the moment, let us assume that the projected dataset also has zero mean, so that $ \\mathbb{E}[\\phi(x)] = 0 $. We will return to this assumption shortly.\n",
    "\n",
    "The $ M \\times M $ sample covariance matrix in the feature space is given by:\n",
    "\n",
    "$$\n",
    "C = \\frac{1}{N} \\sum_{n=1}^N \\phi(x_n) \\phi(x_n)^T\n",
    "$$\n",
    "\n",
    "Its eigenvector expansion is defined by:\n",
    "\n",
    "$$\n",
    "C v_i = \\lambda_i v_i \\quad \\text{for} \\quad i = 1, \\dots, M\n",
    "$$\n",
    "\n",
    "Our goal is to solve this eigenvalue problem without working explicitly in the feature space. From the definition of $ C $, the eigenvector equation tells us that $ v_i $ satisfies:\n",
    "\n",
    "$$\n",
    "C v_i = \\lambda_i v_i\n",
    "$$\n",
    "\n",
    "Thus, the vector $ v_i $ is given by a linear combination of the mapped data points $ \\phi(x_n) $, and we can express it as:\n",
    "\n",
    "$$\n",
    "v_i = \\sum_{n=1}^N \\alpha_{in} \\phi(x_n)\n",
    "$$\n",
    "\n",
    "where $ \\alpha_{in} $ are the coefficients to be determined.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e15c94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from scipy.linalg import eigh\n",
    "\n",
    "# Compute the RBF (Gaussian) kernel\n",
    "def rbf_kernel(X, gamma=1.0):\n",
    "    N = len(X)\n",
    "    K = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            distance_squared = np.sum((X[i] - X[j]) ** 2)\n",
    "            K[i, j] = math.exp(-gamma * distance_squared)\n",
    "    return K\n",
    "\n",
    "# Center the kernel matrix\n",
    "def center_kernel_matrix(K):\n",
    "    N = K.shape[0]\n",
    "    one_n = np.ones((N, N)) / N  # Create the 1/N matrix\n",
    "    K_centered = K - np.dot(np.dot(one_n, K), one_n)  # Centering formula\n",
    "    return K_centered\n",
    "\n",
    "# Kernel PCA function\n",
    "def kernel_pca(X, gamma=1.0, n_components=2):\n",
    "    N = len(X)\n",
    "    \n",
    "    # Step 1: Compute the RBF kernel matrix\n",
    "    K = rbf_kernel(X, gamma)\n",
    "    \n",
    "    # Step 2: Center the kernel matrix\n",
    "    K_centered = center_kernel_matrix(K)\n",
    "    \n",
    "    # Step 3: Perform eigen-decomposition to get eigenvectors and eigenvalues\n",
    "    eigenvalues, eigenvectors = eigh(K_centered)\n",
    "    \n",
    "    # Sort the eigenvalues and corresponding eigenvectors in descending order\n",
    "    sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "    eigenvalues = eigenvalues[sorted_indices]\n",
    "    eigenvectors = eigenvectors[:, sorted_indices]\n",
    "    \n",
    "    # Step 4: Select the top n_components eigenvectors\n",
    "    X_kpca = np.dot(K_centered, eigenvectors[:, :n_components])\n",
    "    \n",
    "    return X_kpca, eigenvectors, eigenvalues\n",
    "\n",
    "# Example usage:\n",
    "# Generate some random data (300 points in 10 dimensions)\n",
    "np.random.seed(42)\n",
    "X = np.random.randn(300, 10)\n",
    "\n",
    "# Apply Kernel PCA\n",
    "X_kpca, eigenvectors, eigenvalues = kernel_pca(X, gamma=1.0, n_components=3)\n",
    "\n",
    "# Print the results\n",
    "print(\"Projected data (Kernel PCA):\\n\", X_kpca[:5])  # Print the first 5 projected points\n",
    "print(\"\\nEigenvalues:\\n\", eigenvalues[:3])  # Print the first 3 eigenvalues\n",
    "print(\"\\nEigenvectors:\\n\", eigenvectors[:, :3])  # Print the first 3 eigenvectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d3dd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from scipy.linalg import eigh\n",
    "\n",
    "# Compute the RBF (Gaussian) kernel\n",
    "def rbf_kernel(X, gamma=1.0):\n",
    "    N = len(X)\n",
    "    K = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            distance_squared = np.sum((X[i] - X[j]) ** 2)\n",
    "            K[i, j] = math.exp(-gamma * distance_squared)\n",
    "    return K\n",
    "\n",
    "# Center the kernel matrix\n",
    "def center_kernel_matrix(K):\n",
    "    N = K.shape[0]\n",
    "    one_n = np.ones((N, N)) / N  # Create the 1/N matrix\n",
    "    K_centered = K - np.dot(np.dot(one_n, K), one_n)  # Centering formula\n",
    "    return K_centered\n",
    "\n",
    "# Kernel PCA function\n",
    "def kernel_pca(X, gamma=1.0, n_components=2):\n",
    "    N = len(X)\n",
    "    \n",
    "    # Step 1: Compute the RBF kernel matrix\n",
    "    K = rbf_kernel(X, gamma)\n",
    "    \n",
    "    # Step 2: Center the kernel matrix\n",
    "    K_centered = center_kernel_matrix(K)\n",
    "    \n",
    "    # Step 3: Perform eigen-decomposition to get eigenvectors and eigenvalues\n",
    "    eigenvalues, eigenvectors = eigh(K_centered)\n",
    "    \n",
    "    # Sort the eigenvalues and corresponding eigenvectors in descending order\n",
    "    sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "    eigenvalues = eigenvalues[sorted_indices]\n",
    "    eigenvectors = eigenvectors[:, sorted_indices]\n",
    "    \n",
    "    # Step 4: Select the top n_components eigenvectors\n",
    "    X_kpca = np.dot(K_centered, eigenvectors[:, :n_components])\n",
    "    \n",
    "    return X_kpca, eigenvectors, eigenvalues\n",
    "\n",
    "# Example usage:\n",
    "# Generate some random data (300 points in 10 dimensions)\n",
    "np.random.seed(42)\n",
    "X = np.random.randn(300, 10)\n",
    "\n",
    "# Apply Kernel PCA\n",
    "X_kpca, eigenvectors, eigenvalues = kernel_pca(X, gamma=1.0, n_components=3)\n",
    "\n",
    "# Print the results\n",
    "print(\"Projected data (Kernel PCA):\\n\", X_kpca[:5])  # Print the first 5 projected points\n",
    "print(\"\\nEigenvalues:\\n\", eigenvalues[:3])  # Print the first 3 eigenvalues\n",
    "print(\"\\nEigenvectors:\\n\", eigenvectors[:, :3])  # Print the first 3 eigenvectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7057a5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from scipy.linalg import eigh\n",
    "\n",
    "# Step 1: Compute the RBF (Gaussian) kernel\n",
    "def rbf_kernel(X, gamma=1.0):\n",
    "    \"\"\"\n",
    "    Compute the RBF kernel matrix between all pairs of data points.\n",
    "    \"\"\"\n",
    "    N = X.shape[0]\n",
    "    K = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            distance_squared = np.sum((X[i] - X[j]) ** 2)\n",
    "            K[i, j] = math.exp(-gamma * distance_squared)\n",
    "    return K\n",
    "\n",
    "# Step 2: Center the kernel matrix\n",
    "def center_kernel_matrix(K):\n",
    "    \"\"\"\n",
    "    Center the kernel matrix by subtracting the row means and column means,\n",
    "    and adding the overall mean.\n",
    "    \"\"\"\n",
    "    N = K.shape[0]\n",
    "    one_n = np.ones((N, N)) / N  # Matrix of 1/N\n",
    "    K_centered = K - np.dot(np.dot(one_n, K), one_n)  # Centering formula\n",
    "    return K_centered\n",
    "\n",
    "# Step 3: Kernel PCA function\n",
    "def kernel_pca(X, gamma=1.0, n_components=2):\n",
    "    \"\"\"\n",
    "    Perform Kernel PCA on the dataset X using the RBF kernel.\n",
    "    \n",
    "    Parameters:\n",
    "    - X: Input data matrix (N x D), where N is the number of samples and D is the number of features\n",
    "    - gamma: Parameter for the RBF kernel (default 1.0)\n",
    "    - n_components: Number of principal components to compute (default 2)\n",
    "    \n",
    "    Returns:\n",
    "    - X_kpca: The data projected onto the principal components\n",
    "    - eigenvalues: The eigenvalues of the kernel matrix\n",
    "    - eigenvectors: The eigenvectors of the kernel matrix\n",
    "    \"\"\"\n",
    "    # Compute the RBF kernel matrix\n",
    "    K = rbf_kernel(X, gamma)\n",
    "    \n",
    "    # Center the kernel matrix\n",
    "    K_centered = center_kernel_matrix(K)\n",
    "    \n",
    "    # Perform eigen-decomposition of the centered kernel matrix\n",
    "    eigenvalues, eigenvectors = eigh(K_centered)\n",
    "    \n",
    "    # Sort the eigenvalues and eigenvectors in descending order\n",
    "    sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "    eigenvalues = eigenvalues[sorted_indices]\n",
    "    eigenvectors = eigenvectors[:, sorted_indices]\n",
    "    \n",
    "    # Select the top `n_components` eigenvectors\n",
    "    X_kpca = np.dot(K_centered, eigenvectors[:, :n_components])\n",
    "    \n",
    "    return X_kpca, eigenvectors, eigenvalues\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate random data (300 samples, 10 features)\n",
    "    np.random.seed(42)\n",
    "    X = np.random.randn(300, 10)\n",
    "    \n",
    "    # Perform Kernel PCA with gamma=1.0 and 3 principal components\n",
    "    X_kpca, eigenvectors, eigenvalues = kernel_pca(X, gamma=1.0, n_components=3)\n",
    "    \n",
    "    # Print the results\n",
    "    print(\"Projected data (Kernel PCA):\\n\", X_kpca[:5])  # Show the first 5 data points in the new feature space\n",
    "    print(\"\\nEigenvalues:\\n\", eigenvalues[:3])  # Show the first 3 eigenvalues\n",
    "    print(\"\\nEigenvectors:\\n\", eigenvectors[:, :3])  # Show the first 3 eigenvectors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21854e1f",
   "metadata": {},
   "source": [
    "### Kernel PCA\n",
    "\n",
    "Substituting this expansion back into the eigenvector equation, we obtain:\n",
    "\n",
    "$$\n",
    "\\left( \\mathbf{x}_2, \\mathbf{x}_n \\right) \\; \\text{dim} \\; k(\\mathbf{x}_n, \\mathbf{x}_m) = d_i \\; d_i \\; k(\\mathbf{x}, \\mathbf{x}_n)\n",
    "$$\n",
    "\n",
    "This can be written in matrix notation as:\n",
    "\n",
    "$$\n",
    "K \\mathbf{a}_i = \\lambda_i K \\mathbf{a}_i\n",
    "$$\n",
    "\n",
    "where $ \\mathbf{a}_i $ is an $ N $-dimensional column vector with elements $ a_{i,n} $ for $ n = 1, \\ldots, N $. We can find solutions for $ \\mathbf{a}_i $ by solving the following eigenvalue problem:\n",
    "\n",
    "$$\n",
    "K \\mathbf{a}_i = \\lambda_i \\mathbf{a}_i\n",
    "$$\n",
    "\n",
    "In which we have removed a factor of $ K $ from both sides of (12.79). Note that the solutions of (12.79) and (12.80) differ only by eigenvectors of $ K $ having zero eigenvalues that do not affect the principal component projections.\n",
    "\n",
    "The normalization condition for the coefficients $ a_i $ is obtained by requiring that the eigenvectors in feature space be normalized. Using (12.76) and (12.80), we have:\n",
    "\n",
    "$$\n",
    "\\sum_{n=1}^{N} a_i \\, k(\\mathbf{x}, \\mathbf{x}_n) = a_i \\, K \\, \\mathbf{a}_i\n",
    "$$\n",
    "\n",
    "After solving the eigenvector problem, the resulting principal component projections can then be expressed in terms of the kernel function. Thus, using (12.76), the projection of a point $ \\mathbf{x} $ onto eigenvector $i $ is given by:\n",
    "\n",
    "$$\n",
    "\\Phi_i(\\mathbf{x}) = \\langle \\mathbf{x}, \\mathbf{v}_i \\rangle = \\sum_{n=1}^{N} a_{i,n} k(\\mathbf{x}, \\mathbf{x}_n)\n",
    "$$\n",
    "\n",
    "In the original $ D $-dimensional $ \\mathbf{x} $-space, there are $ D $ orthogonal eigenvectors, and hence we can find at most $ D $ linear principal components. The dimensionality $ M $ of the feature space, however, can be much larger than $ D $ (even infinite), and thus we can find a number of nonlinear principal components that can exceed $ D $.\n",
    "\n",
    "Note, however, that the number of nonzero eigenvalues cannot exceed the number $ N $ of data points because, even if $ M > N $, the covariance matrix in feature space has rank at most $ N $. This is reflected in the fact that Kernel PCA involves the eigenvector expansion of the $ N \\times N $ matrix $ K $.\n",
    "\n",
    "So far, we have assumed that the projected data set given by $ \\Phi(\\mathbf{x}) $ has zero mean, which in general will not be the case. We cannot simply compute and subtract off the mean, since we wish to avoid working directly in feature space. Thus, we formulate the algorithm purely in terms of the kernel function.\n",
    "\n",
    "The projected data points after centralizing, denoted $ \\Phi(\\mathbf{x}) $, are given by:\n",
    "\n",
    "$$\n",
    "\\Phi(\\mathbf{x}) = \\mathbf{a}_i K\n",
    "$$\n",
    "\n",
    "The corresponding elements of the Gram matrix are given by:\n",
    "\n",
    "$$\n",
    "K(\\mathbf{x}, \\mathbf{x}) - \\frac{1}{N} \\mathbf{1} = k(\\mathbf{x}_n, \\mathbf{x}_m) - \\langle \\mathbf{x}, \\mathbf{x}_m \\rangle\n",
    "$$\n",
    "\n",
    "This can be expressed in matrix notation as:\n",
    "\n",
    "$$\n",
    "K - \\frac{1}{N} \\mathbf{1} K - \\frac{1}{N} K \\mathbf{1} + \\frac{1}{N^2} \\mathbf{1} K \\mathbf{1}\n",
    "$$\n",
    "\n",
    "where $ \\mathbf{1} $ denotes the $ N \\times N $ matrix in which every element takes the value $ \\frac{1}{N} $. Thus, we can evaluate $ K $ using only the kernel function and then use $ K $ to determine the eigenvalues and eigenvectors.\n",
    "\n",
    "Note that the standard PCA algorithm is recovered as a special case if we use a linear kernel:\n",
    "\n",
    "$$\n",
    "k(\\mathbf{x}, \\mathbf{x'}) = \\mathbf{x}^T \\mathbf{x'}\n",
    "$$\n",
    "\n",
    "#### Gaussian Kernel Example\n",
    "\n",
    "A Gaussian kernel can be used in Kernel PCA. The Gaussian kernel is given by:\n",
    "\n",
    "$$\n",
    "k(\\mathbf{x}, \\mathbf{x'}) = \\exp\\left( - \\frac{\\|\\mathbf{x} - \\mathbf{x'}\\|^2}{\\sigma^2} \\right)\n",
    "$$\n",
    "\n",
    "where $ \\sigma^2 $ controls the width of the Gaussian kernel.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef6cbdb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projection of point [1, 2]: [0.4498184888451915, 0.7160145206923716]\n",
      "Projection of point [2, 3]: [0.7702426163554145, -0.17013403454846376]\n",
      "Projection of point [3, 3]: [0.6274224354959366, -0.5798750965387943]\n",
      "Projection of point [4, 5]: [-0.6870004686726657, -0.17979015874419518]\n",
      "Projection of point [5, 6]: [-0.7535809155673168, -0.03818229388745241]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "# Kernel function: Gaussian Kernel\n",
    "def gaussian_kernel(x, x_prime, sigma=1.0):\n",
    "    \"\"\"Compute the Gaussian kernel (RBF kernel) between two vectors.\"\"\"\n",
    "    norm = sum((xi - xpi) ** 2 for xi, xpi in zip(x, x_prime))\n",
    "    return math.exp(-norm / (2 * sigma ** 2))\n",
    "\n",
    "# Compute the Gram matrix K (Kernel matrix)\n",
    "def compute_gram_matrix(X, kernel_function):\n",
    "    \"\"\"Compute the Gram matrix K using the provided kernel function.\"\"\"\n",
    "    N = len(X)\n",
    "    K = [[0] * N for _ in range(N)]\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            K[i][j] = kernel_function(X[i], X[j])\n",
    "    return K\n",
    "\n",
    "# Center the kernel matrix K\n",
    "def center_kernel_matrix(K):\n",
    "    \"\"\"Center the kernel matrix to have zero mean in feature space.\"\"\"\n",
    "    N = len(K)\n",
    "    \n",
    "    # Compute row and column means\n",
    "    row_means = [sum(K[i]) / N for i in range(N)]\n",
    "    col_means = [sum(K[i][j] for i in range(N)) / N for j in range(N)]\n",
    "    \n",
    "    # Compute the grand mean (total mean)\n",
    "    grand_mean = sum(row_means) / N\n",
    "    \n",
    "    # Center the kernel matrix\n",
    "    K_centered = [[K[i][j] - row_means[i] - col_means[j] + grand_mean for j in range(N)] for i in range(N)]\n",
    "    return K_centered\n",
    "\n",
    "# Power method to find the top eigenvector\n",
    "def power_method(K, num_iterations=1000):\n",
    "    \"\"\"Find the top eigenvector using the power method.\"\"\"\n",
    "    N = len(K)\n",
    "    v = [random.random() for _ in range(N)]  # Initialize with random values\n",
    "    for _ in range(num_iterations):\n",
    "        v_new = [0] * N\n",
    "        for i in range(N):\n",
    "            v_new[i] = sum(K[i][j] * v[j] for j in range(N))\n",
    "        \n",
    "        # Normalize the vector\n",
    "        norm = math.sqrt(sum(val ** 2 for val in v_new))\n",
    "        v = [val / norm for val in v_new]\n",
    "    \n",
    "    return v\n",
    "\n",
    "# Compute Kernel PCA\n",
    "def kernel_pca(X, kernel_function=gaussian_kernel, num_components=2):\n",
    "    \"\"\"Perform Kernel PCA and return the top eigenvectors corresponding to the principal components.\"\"\"\n",
    "    K = compute_gram_matrix(X, kernel_function)\n",
    "    K_centered = center_kernel_matrix(K)\n",
    "    \n",
    "    # Find the top eigenvectors\n",
    "    eigenvectors = []\n",
    "    for _ in range(num_components):\n",
    "        eigenvector = power_method(K_centered)\n",
    "        eigenvectors.append(eigenvector)\n",
    "        \n",
    "        # Deflate the kernel matrix by removing the influence of the current eigenvector\n",
    "        eigenvalue = sum(K_centered[i][j] * eigenvector[i] * eigenvector[j] for i in range(len(K_centered)) for j in range(len(K_centered)))\n",
    "        for i in range(len(K_centered)):\n",
    "            for j in range(len(K_centered)):\n",
    "                K_centered[i][j] -= eigenvalue * eigenvector[i] * eigenvector[j]\n",
    "    \n",
    "    return eigenvectors\n",
    "\n",
    "# Project data onto the principal components\n",
    "def project_data(X, eigenvectors, kernel_function=gaussian_kernel):\n",
    "    \"\"\"Project data points onto the principal components obtained from Kernel PCA.\"\"\"\n",
    "    K = compute_gram_matrix(X, kernel_function)\n",
    "    projections = []\n",
    "    for i in range(len(X)):\n",
    "        projection = [sum(K[i][j] * eigenvector[j] for j in range(len(eigenvector))) for eigenvector in eigenvectors]\n",
    "        projections.append(projection)\n",
    "    return projections\n",
    "\n",
    "# Example usage\n",
    "# Generate a synthetic 2D dataset (for visualization purposes)\n",
    "X = [\n",
    "    [1, 2],\n",
    "    [2, 3],\n",
    "    [3, 3],\n",
    "    [4, 5],\n",
    "    [5, 6]\n",
    "]\n",
    "\n",
    "# Perform Kernel PCA with 2 components\n",
    "eigenvectors = kernel_pca(X, kernel_function=gaussian_kernel, num_components=2)\n",
    "projections = project_data(X, eigenvectors, kernel_function=gaussian_kernel)\n",
    "\n",
    "# Output the projections\n",
    "for i, projection in enumerate(projections):\n",
    "    print(f\"Projection of point {X[i]}: {projection}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33233e42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
