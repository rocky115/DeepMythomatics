{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ade5946",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " * Copyright (c) 2008 Radhamadhab Dalai\n",
    " *\n",
    " * Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    " * of this software and associated documentation files (the \"Software\"), to deal\n",
    " * in the Software without restriction, including without limitation the rights\n",
    " * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    " * copies of the Software, and to permit persons to whom the Software is\n",
    " * furnished to do so, subject to the following conditions:\n",
    " *\n",
    " * The above copyright notice and this permission notice shall be included in\n",
    " * all copies or substantial portions of the Software.\n",
    " *\n",
    " * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    " * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    " * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    " * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    " * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    " * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
    " * THE SOFTWARE.\n",
    "'''"
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "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"
    },
    "image-3.png": {
     "image/png": "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"
    },
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "90810556",
   "metadata": {},
   "source": [
    "![image-3.png](attachment:image-3.png)\n",
    "\n",
    "Fig.15 The ﬁrst of three examples of graphs over three variables a, b, and c used to discuss conditional independence properties of directed graphical models.\n",
    "\n",
    "![image-2.png](attachment:image-2.png)\n",
    "\n",
    "Fig.16 As in Fig.15 but where we have conditioned on the value of variable c.\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Fig.17 The second of our three examples of 3-node graphs used to motivate the conditional independence framework for directed graphical models.\n",
    "\n",
    "\n",
    "##  Conditional Independence\n",
    "\n",
    "Conditional independence is a critical concept in probability distributions involving multiple variables (Dawid, 1980). Let's consider three variables $a$, $b$, and $c$. Suppose the conditional distribution of $a$ given $b$ and $c$ does not depend on $b$:\n",
    "\n",
    "$$\n",
    "p(a | b, c) = p(a | c)\n",
    "\\tag{8.20}\n",
    "$$\n",
    "\n",
    "This means that \\(a\\) is **conditionally independent** of $b$ given $c$.\n",
    "\n",
    "## Joint Distribution Factorization\n",
    "\n",
    "The joint distribution of $a$ and $b$ conditioned on $c$ can be expressed as:\n",
    "\n",
    "$$\n",
    "p(a, b | c) = p(a | b, c) p(b | c) = p(a | c) p(b | c)\n",
    "\\tag{8.21}\n",
    "$$\n",
    "\n",
    "Here, the product rule of probability and Equation $8.20$ are used. This shows that, conditioned on $c$, the joint distribution of $a$ and $b$ factorizes into the product of their marginal distributions (conditioned on $c$).\n",
    "\n",
    "Thus, $a$ and $b$ are **statistically independent given $c$**.\n",
    "\n",
    "### Notation for Conditional Independence\n",
    "\n",
    "To simplify notation, we denote conditional independence as:\n",
    "\n",
    "$$\n",
    "a \\perp\\!\\!\\!\\perp b \\, | \\, c\n",
    "\\tag{8.22}\n",
    "$$\n",
    "\n",
    "This is equivalent to Equation \\(8.20\\).\n",
    "\n",
    "### Importance of Conditional Independence\n",
    "\n",
    "Conditional independence simplifies the structure and computations of probabilistic models, enabling efficient inference and learning. Graphical models allow us to directly identify conditional independence properties without analytical manipulations.\n",
    "\n",
    "---\n",
    "\n",
    "## Three Example Graphs\n",
    "\n",
    "### Example 1: Graph with Tail-to-Tail Connections\n",
    "\n",
    "Consider a graph where variables $a$, $b$, and $c$ form a structure as shown:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Joint Distribution\n",
    "\n",
    "The joint distribution is written as:\n",
    "\n",
    "$$\n",
    "p(a, b, c) = p(a | c) p(b | c) p(c)\n",
    "\\tag{8.23}\n",
    "$$\n",
    "\n",
    "#### Marginal Independence ($\\emptyset$)\n",
    "\n",
    "If none of the variables are observed, marginalizing over $c$ yields:\n",
    "\n",
    "$$\n",
    "p(a, b) = \\sum_c p(a | c) p(b | c) p(c)\n",
    "\\tag{8.24}\n",
    "$$\n",
    "\n",
    "In general, this does not factorize into $p(a) p(b)$, so:\n",
    "\n",
    "$$\n",
    "a \\not\\!\\perp\\!\\!\\!\\perp b \\, | \\, \\emptyset\n",
    "\\tag{8.25}\n",
    "$$\n",
    "\n",
    "#### Conditional Independence ($c$)\n",
    "\n",
    "Now suppose we condition on $c$. The conditional distribution becomes:\n",
    "\n",
    "$$\n",
    "p(a, b | c) = \\frac{p(a, b, c)}{p(c)} = p(a | c) p(b | c)\n",
    "$$\n",
    "\n",
    "This implies:\n",
    "\n",
    "$$\n",
    "a \\perp\\!\\!\\!\\perp b \\, | \\, c\n",
    "$$\n",
    "\n",
    "Graphically, $c$ blocks the path between $a$ and $b$, making them conditionally independent.\n",
    "\n",
    "---\n",
    "\n",
    "### Example 2: Graph with Head-to-Tail Connections\n",
    "\n",
    "Now consider the following graph:\n",
    "\n",
    "\n",
    "\n",
    "#### Joint Distribution\n",
    "\n",
    "The joint distribution is given by:\n",
    "\n",
    "$$\n",
    "p(a, b, c) = p(a) p(c | a) p(b | c)\n",
    "\\tag{8.26}\n",
    "$$\n",
    "\n",
    "#### Marginal Independence ($\\emptyset$)\n",
    "\n",
    "If none of the variables are observed, marginalizing over $c$ gives:\n",
    "\n",
    "$$\n",
    "p(a, b) = p(a) \\sum_c p(c | a) p(b | c)\n",
    "$$\n",
    "\n",
    "In general, this does not factorize into $p(a) p(b)$, so:\n",
    "\n",
    "$$\n",
    "a \\not\\!\\perp\\!\\!\\!\\perp b \\, | \\, \\emptyset\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "These examples demonstrate how conditional independence properties can be derived and interpreted using directed graphs. The concept of **d-separation** will generalize this framework to arbitrary graphs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33a5d9d",
   "metadata": {},
   "source": [
    "\n",
    "#### Joint Distribution\n",
    "\n",
    "The joint distribution is:\n",
    "\n",
    "$$\n",
    "p(a, b, c) = p(a)p(b)p(c|a, b)\n",
    "\\tag{8.28}\n",
    "$$\n",
    "\n",
    "#### No Variables Observed (\\(\\emptyset\\))\n",
    "\n",
    "If none of the variables are observed, marginalizing over \\(c\\) gives:\n",
    "\n",
    "$$\n",
    "p(a, b) = p(a)p(b)\n",
    "$$\n",
    "\n",
    "Thus:\n",
    "\n",
    "$$\n",
    "a \\perp\\!\\!\\!\\perp b \\, | \\, \\emptyset\n",
    "\\tag{8.29}\n",
    "$$\n",
    "\n",
    "#### Conditioning on \\(c\\)\n",
    "\n",
    "Conditioning on \\(c\\) gives:\n",
    "\n",
    "$$\n",
    "p(a, b|c) = \\frac{p(a)p(b)p(c|a, b)}{p(c)}\n",
    "$$\n",
    "\n",
    "In general, this does not factorize into \\(p(a)p(b)\\):\n",
    "\n",
    "$$\n",
    "a \\not\\!\\perp\\!\\!\\!\\perp b \\, | \\, c\n",
    "$$\n",
    "\n",
    "Here, \\(c\\) is a head-to-head node, which unblocks the path and renders \\(a\\) and \\(b\\) dependent.\n",
    "\n",
    "---\n",
    "\n",
    "### Subtlety of Head-to-Head Nodes\n",
    "\n",
    "A head-to-head node blocks a path if it is unobserved. However, if the node or any of its descendants is observed, the path becomes unblocked.\n",
    "\n",
    "#### Terminology: Descendants\n",
    "\n",
    "A node \\(y\\) is a descendant of \\(x\\) if there is a path from \\(x\\) to \\(y\\) following the direction of the arrows.\n",
    "\n",
    "#### Summary of Path Blocking:\n",
    "\n",
    "1. **Tail-to-tail** or **head-to-tail** nodes:\n",
    "   - Leave paths unblocked unless observed.\n",
    "\n",
    "2. **Head-to-head** nodes:\n",
    "   - Block paths if unobserved.\n",
    "   - Unblock paths if the node or its descendants are observed.\n",
    "\n",
    "---\n",
    "\n",
    "## Example: Explaining Away\n",
    "\n",
    "Consider a specific head-to-head graph with three binary random variables:\n",
    "\n",
    "\n",
    "- **$B$:** Battery state $(B = 1$: charged, $B = 0$: flat)\n",
    "- **$F$:** Fuel tank state $(F = 1$: full, $F = 0$: empty)\n",
    "- **$G$:** Fuel gauge reading $(G = 1$: full, $G = 0$: empty)\n",
    "\n",
    "### Prior Probabilities:\n",
    "\n",
    "- $p(B = 1) = 0.9\\), \\(p(F = 1) = 0.9$\n",
    "- Given $B$ and $F$, the probabilities for $G$ are:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "p(G = 1|B = 1, F = 1) &= 0.8 \\\\\n",
    "p(G = 1|B = 1, F = 0) &= 0.2 \\\\\n",
    "p(G = 1|B = 0, F = 1) &= 0.2 \\\\\n",
    "p(G = 1|B = 0, F = 0) &= 0.1\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "### Observing \\(G = 0\\) (Gauge Reads Empty)\n",
    "\n",
    "Using Bayes' theorem:\n",
    "\n",
    "#### Denominator of Bayes' Theorem:\n",
    "\n",
    "$$\n",
    "p(G = 0) = \\sum_{B \\in \\{0, 1\\}} \\sum_{F \\in \\{0, 1\\}} p(G = 0|B, F)p(B)p(F) = 0.315\n",
    "\\tag{8.30}\n",
    "$$\n",
    "\n",
    "#### Posterior Probability:\n",
    "\n",
    "$$\n",
    "p(F = 0|G = 0) = \\frac{p(G = 0|F = 0)p(F = 0)}{p(G = 0)} = \\frac{0.81 \\times 0.1}{0.315} = 0.257\n",
    "\\tag{8.32}\n",
    "$$\n",
    "\n",
    "Thus, observing $G = 0$ makes $F = 0$ more likely $(p(F = 0|G = 0) > p(F = 0)$).\n",
    "\n",
    "---\n",
    "\n",
    "### Observing $B = 0$ (Battery is Flat)\n",
    "\n",
    "Now suppose \\(B = 0\\). The posterior probability of \\(F = 0\\) becomes:\n",
    "\n",
    "$$\n",
    "p(F = 0|G = 0, B = 0) = \\frac{p(G = 0|B = 0, F = 0)p(F = 0)}{\\sum_{F \\in \\{0, 1\\}} p(G = 0|B = 0, F)p(F)} = 0.111\n",
    "\\tag{8.33}\n",
    "$$\n",
    "\n",
    "### Explaining Away:\n",
    "\n",
    "Observing \\(B = 0\\) reduces the probability of \\(F = 0\\) because \\(B = 0\\) \"explains away\" the observation \\(G = 0\\).\n",
    "\n",
    "### General Observations:\n",
    "\n",
    "1. Observing \\(G = 0\\) made \\(F = 0\\) more likely.\n",
    "2. Observing \\(B = 0\\) reduced the probability of \\(F = 0\\), as \\(B = 0\\) explains the gauge reading.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c6ae72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(G=0): 0.315\n",
      "P(F=0 | G=0): 0.257\n",
      "P(F=0 | G=0, B=0): 0.111\n"
     ]
    }
   ],
   "source": [
    "# Conditional Independence and Explaining Away Implementation\n",
    "import numpy as np\n",
    "\n",
    "# Define the probabilities\n",
    "p_B = 0.9  # P(B=1)\n",
    "p_F = 0.9  # P(F=1)\n",
    "\n",
    "# Conditional probabilities for G given B and F\n",
    "p_G_given_B_F = {\n",
    "    (1, 1): 0.8,  # P(G=1 | B=1, F=1)\n",
    "    (1, 0): 0.2,  # P(G=1 | B=1, F=0)\n",
    "    (0, 1): 0.2,  # P(G=1 | B=0, F=1)\n",
    "    (0, 0): 0.1   # P(G=1 | B=0, F=0)\n",
    "}\n",
    "\n",
    "# Remaining probabilities for G\n",
    "p_G_given_B_F = {k: (v, 1 - v) for k, v in p_G_given_B_F.items()}  # (P(G=1), P(G=0))\n",
    "\n",
    "# Compute prior probability of G=0\n",
    "def compute_prior_G():\n",
    "    prob_G_0 = 0\n",
    "    for B in [0, 1]:\n",
    "        for F in [0, 1]:\n",
    "            p_B_val = p_B if B == 1 else 1 - p_B\n",
    "            p_F_val = p_F if F == 1 else 1 - p_F\n",
    "            prob_G_0 += p_G_given_B_F[(B, F)][1] * p_B_val * p_F_val  # P(G=0)\n",
    "    return prob_G_0\n",
    "\n",
    "p_G_0 = compute_prior_G()\n",
    "print(f\"P(G=0): {p_G_0:.3f}\")\n",
    "\n",
    "# Posterior probability of F=0 given G=0\n",
    "def posterior_F_given_G(F_obs, G_obs):\n",
    "    # P(G=0 | F=F_obs) * P(F=F_obs) / P(G=0)\n",
    "    prob_G_given_F = 0\n",
    "    for B in [0, 1]:\n",
    "        p_B_val = p_B if B == 1 else 1 - p_B\n",
    "        prob_G_given_F += p_G_given_B_F[(B, F_obs)][G_obs] * p_B_val\n",
    "    p_F_val = p_F if F_obs == 1 else 1 - p_F\n",
    "    return (prob_G_given_F * p_F_val) / p_G_0\n",
    "\n",
    "p_F_0_given_G_0 = posterior_F_given_G(F_obs=0, G_obs=1)\n",
    "print(f\"P(F=0 | G=0): {p_F_0_given_G_0:.3f}\")\n",
    "\n",
    "# Posterior probability of F=0 given G=0 and B=0\n",
    "def posterior_F_given_G_and_B(F_obs, G_obs, B_obs):\n",
    "    # P(G=0 | F=F_obs, B=B_obs) * P(F=F_obs) / sum_F P(G=0 | F, B=B_obs) * P(F)\n",
    "    prob_G_given_B_F = p_G_given_B_F[(B_obs, F_obs)][G_obs]\n",
    "    p_F_val = p_F if F_obs == 1 else 1 - p_F\n",
    "\n",
    "    denominator = 0\n",
    "    for F in [0, 1]:\n",
    "        prob_G_given_B_F_all = p_G_given_B_F[(B_obs, F)][G_obs]\n",
    "        p_F_all = p_F if F == 1 else 1 - p_F\n",
    "        denominator += prob_G_given_B_F_all * p_F_all\n",
    "\n",
    "    return (prob_G_given_B_F * p_F_val) / denominator\n",
    "\n",
    "p_F_0_given_G_0_B_0 = posterior_F_given_G_and_B(F_obs=0, G_obs=1, B_obs=0)\n",
    "print(f\"P(F=0 | G=0, B=0): {p_F_0_given_G_0_B_0:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f58a417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(G=0): 0.315\n",
      "P(F=0 | G=0): 0.257\n",
      "P(F=0 | G=0, B=0): 0.111\n"
     ]
    }
   ],
   "source": [
    "# Conditional Independence and Explaining Away Implementation (Pure Python)\n",
    "\n",
    "# Define probabilities\n",
    "p_B = 0.9  # P(B=1)\n",
    "p_F = 0.9  # P(F=1)\n",
    "\n",
    "# Conditional probabilities for G given B and F\n",
    "p_G_given_B_F = {\n",
    "    (1, 1): 0.8,  # P(G=1 | B=1, F=1)\n",
    "    (1, 0): 0.2,  # P(G=1 | B=1, F=0)\n",
    "    (0, 1): 0.2,  # P(G=1 | B=0, F=1)\n",
    "    (0, 0): 0.1   # P(G=1 | B=0, F=0)\n",
    "}\n",
    "\n",
    "# Compute prior probability of G=0\n",
    "def compute_prior_G():\n",
    "    prob_G_0 = 0\n",
    "    for B in [0, 1]:\n",
    "        for F in [0, 1]:\n",
    "            # P(B), P(F)\n",
    "            p_B_val = p_B if B == 1 else 1 - p_B\n",
    "            p_F_val = p_F if F == 1 else 1 - p_F\n",
    "            # Add P(G=0 | B, F) * P(B) * P(F)\n",
    "            prob_G_0 += (1 - p_G_given_B_F[(B, F)]) * p_B_val * p_F_val\n",
    "    return prob_G_0\n",
    "\n",
    "p_G_0 = compute_prior_G()\n",
    "print(f\"P(G=0): {p_G_0:.3f}\")\n",
    "\n",
    "# Posterior probability of F=0 given G=0\n",
    "def posterior_F_given_G(F_obs, G_obs):\n",
    "    # Numerator: P(G=0 | F=F_obs) * P(F=F_obs)\n",
    "    prob_G_given_F = 0\n",
    "    for B in [0, 1]:\n",
    "        p_B_val = p_B if B == 1 else 1 - p_B\n",
    "        prob_G_given_F += (1 - p_G_given_B_F[(B, F_obs)]) * p_B_val\n",
    "\n",
    "    p_F_val = p_F if F_obs == 1 else 1 - p_F\n",
    "    numerator = prob_G_given_F * p_F_val\n",
    "\n",
    "    # Denominator: P(G=0)\n",
    "    denominator = p_G_0\n",
    "\n",
    "    return numerator / denominator\n",
    "\n",
    "p_F_0_given_G_0 = posterior_F_given_G(F_obs=0, G_obs=0)\n",
    "print(f\"P(F=0 | G=0): {p_F_0_given_G_0:.3f}\")\n",
    "\n",
    "# Posterior probability of F=0 given G=0 and B=0\n",
    "def posterior_F_given_G_and_B(F_obs, G_obs, B_obs):\n",
    "    # Numerator: P(G=0 | F=F_obs, B=B_obs) * P(F=F_obs)\n",
    "    prob_G_given_B_F = (1 - p_G_given_B_F[(B_obs, F_obs)])\n",
    "    p_F_val = p_F if F_obs == 1 else 1 - p_F\n",
    "    numerator = prob_G_given_B_F * p_F_val\n",
    "\n",
    "    # Denominator: Sum_F P(G=0 | F, B=B_obs) * P(F)\n",
    "    denominator = 0\n",
    "    for F in [0, 1]:\n",
    "        prob_G_given_B_F_all = (1 - p_G_given_B_F[(B_obs, F)])\n",
    "        p_F_all = p_F if F == 1 else 1 - p_F\n",
    "        denominator += prob_G_given_B_F_all * p_F_all\n",
    "\n",
    "    return numerator / denominator\n",
    "\n",
    "p_F_0_given_G_0_B_0 = posterior_F_given_G_and_B(F_obs=0, G_obs=0, B_obs=0)\n",
    "print(f\"P(F=0 | G=0, B=0): {p_F_0_given_G_0_B_0:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cf9d05",
   "metadata": {},
   "source": [
    "## D-separation\n",
    "\n",
    "We now give a general statement of the d-separation property (Pearl, 1988) for directed graphs. Consider a general directed graph in which $ A $, $ B $, and $ C $ are arbitrary non-intersecting sets of nodes (whose union may be smaller than the complete set of nodes in the graph). We wish to ascertain whether a particular conditional independence statement $ A \\perp\\!\\!\\!\\perp B | C $ is implied by a given directed acyclic graph. \n",
    "\n",
    "To do so, we consider all possible paths from any node in $ A $ to any node in $ B $. Any such path is said to be blocked if it includes a node such that either:\n",
    "\n",
    "1. The arrows on the path meet either head-to-tail or tail-to-tail at the node, and the node is in the set $ C $, or\n",
    "2. The arrows meet head-to-head at the node, and neither the node, nor any of its descendants, is in the set $ C $.\n",
    "\n",
    "If all paths are blocked, then $ A $ is said to be d-separated from $ B $ by $ C $, and the joint distribution over all of the variables in the graph will satisfy $ A \\perp\\!\\!\\!\\perp B | C $.\n",
    "\n",
    "The concept of d-separation is illustrated in Fig.22. In graph (a), the path from $ a $ to $ b $ is not blocked by node $ f $ because it is a tail-to-tail node for this path and is not observed, nor is it blocked by node $ e $ because, although the latter is a head-to-head node, it has a descendant $ c $ which is in the conditioning set. Thus the conditional independence statement $ a \\perp\\!\\!\\!\\perp b | c $ does not follow from this graph. In graph (b), the path from $ a $ to $ b $ is blocked by node $ f $ because this is a tail-to-tail node that is observed, and so the conditional independence property $ a \\perp\\!\\!\\!\\perp b | f $ will be satisfied by any distribution that factorizes according to this graph. Note that this path is also blocked by node $ e $ because $ e $ is a head-to-head node and neither it nor its descendant are in the conditioning set.\n",
    "\n",
    "For the purposes of d-separation, parameters such as $ \\alpha $ and $ \\sigma^2 $ in Fig.5, indicated by small filled circles, behave in the same way as observed nodes. However, there are no marginal distributions associated with such nodes. Consequently, parameter nodes never themselves have parents and so all paths through these nodes will always be tail-to-tail and hence blocked. Consequently, they play no role in d-separation.\n",
    "\n",
    "### Example: Gaussian Distribution\n",
    "\n",
    "Another example of conditional independence and d-separation is provided by the concept of i.i.d. (independent identically distributed) data introduced in Section 1.2.4. Consider the problem of finding the posterior distribution for the mean $ \\mu $ of a univariate Gaussian distribution. This can be represented by the directed graph shown in Fig.23 in which the joint distribution is defined by a prior $ p(\\mu) $ together with a set of conditional distributions $ p(x_n | \\mu) $ for $ n = 1, \\ldots, N $.\n",
    "\n",
    "In practice, we observe $ D = \\{x_1, \\ldots, x_N\\} $ and our goal is to infer $ \\mu $. Suppose, for a moment, that we condition on $ \\mu $ and consider the joint distribution of the observations. Using d-separation, we note that there is a unique path from any $ x_i $ to any other $ x_j \\neq i $ and that this path is tail-to-tail with respect to the observed node $ \\mu $. Every such path is blocked and so the observations $ D = \\{x_1, \\ldots, x_N\\} $ are independent given $ \\mu $, so that\n",
    "\n",
    "$$\n",
    "\\prod_{n=1}^N p(x_n | \\mu) = p(D | \\mu)\n",
    "$$\n",
    "\n",
    "### Example: Naive Bayes Classifier\n",
    "\n",
    "A related graphical structure arises in an approach to classification called the **naive Bayes** model, in which we use conditional independence assumptions to simplify the model structure. Suppose our observed variable consists of a $ D $-dimensional vector $ x = (x_1, \\ldots, x_D)^T $, and we wish to assign observed values of $ x $ to one of $ K $ classes. Using the 1-of-$ K $ encoding scheme, we can represent these classes by a $ K $-dimensional binary vector $ z $. We can then define a generative model by introducing a multinomial prior $ p(z | \\mu) $ over the class labels, where the $ k $-th component $ \\mu_k $ of $ \\mu $ is the prior probability of class $ C_k $, together with a conditional distribution $ p(x | z) $ for the observed vector $ x $.\n",
    "\n",
    "The key assumption of the naive Bayes model is that, conditioned on the class $ z $, the distributions of the input variables $ x_1, \\ldots, x_D $ are independent. The graphical representation of this model is shown in Fig.24. We see that observation of $ z $ blocks the path between $ x_i $ and $ x_j $ for $ j \\neq i $ (because such paths are tail-to-tail at the node $ z $) and so $ x_i $ and $ x_j $ are conditionally independent given $ z $.\n",
    "\n",
    "If, however, we marginalize out $ z $ (so that $ z $ is unobserved), the tail-to-tail path from $ x_i $ to $ x_j $ is no longer blocked. This tells us that in general the marginal density $ p(x) $ will not factorize with respect to the components of $ x $.\n",
    "\n",
    "We encountered a simple application of the naive Bayes model in the context of fusing data from different sources for medical diagnosis in Section 1.5. If we are given a labelled training set, comprising inputs $ \\{x_1, \\ldots, x_N\\} $ together with their class labels, then we can fit the naive Bayes model to the training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf775ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.factors.discrete import TabularCPD\n",
    "from pgmpy.inference import VariableElimination\n",
    "\n",
    "# Step 1: Define the directed acyclic graph (DAG)\n",
    "# Example: A -> B, C -> B, A -> C, and C -> D\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Adding edges to the graph\n",
    "G.add_edges_from([('A', 'B'), ('C', 'B'), ('A', 'C'), ('C', 'D')])\n",
    "\n",
    "# Step 2: Function to check if nodes are d-separated\n",
    "def check_d_separation(graph, node_a, node_b, conditioning_set):\n",
    "    \"\"\"\n",
    "    This function checks if nodes `node_a` and `node_b` are d-separated given `conditioning_set`\n",
    "    in a directed acyclic graph (DAG).\n",
    "    \"\"\"\n",
    "    # Using networkx's d-separation function to check if node_a and node_b are d-separated\n",
    "    return nx.d_separated(graph, node_a, node_b, conditioning_set)\n",
    "\n",
    "# Step 3: Check d-separation for some nodes in the graph\n",
    "conditioning_set = {'C'}\n",
    "is_d_separated = check_d_separation(G, 'A', 'B', conditioning_set)\n",
    "print(f\"Are A and B d-separated given C? {is_d_separated}\")\n",
    "\n",
    "# Step 4: Create a Bayesian Network\n",
    "# Define a simple Bayesian Network: A -> B, A -> C, C -> D\n",
    "model = BayesianNetwork([('A', 'B'), ('A', 'C'), ('C', 'D')])\n",
    "\n",
    "# Define conditional probability distributions (CPDs)\n",
    "cpd_A = TabularCPD(variable='A', variable_card=2, values=[[0.6], [0.4]])  # P(A)\n",
    "cpd_B = TabularCPD(variable='B', variable_card=2, values=[[0.7, 0.2], [0.3, 0.8]], evidence=['A'], evidence_card=[2])  # P(B|A)\n",
    "cpd_C = TabularCPD(variable='C', variable_card=2, values=[[0.5], [0.5]])  # P(C)\n",
    "cpd_D = TabularCPD(variable='D', variable_card=2, values=[[0.8, 0.3], [0.2, 0.7]], evidence=['C'], evidence_card=[2])  # P(D|C)\n",
    "\n",
    "# Add CPDs to the model\n",
    "model.add_cpds(cpd_A, cpd_B, cpd_C, cpd_D)\n",
    "\n",
    "# Step 5: Perform inference using Variable Elimination\n",
    "inference = VariableElimination(model)\n",
    "\n",
    "# Perform a query: P(B | A)\n",
    "prob_B_given_A = inference.query(variables=['B'], evidence={'A': 1})\n",
    "print(prob_B_given_A)\n",
    "\n",
    "# Step 6: Another example of conditional independence and d-separation\n",
    "# Create a new graph example for testing\n",
    "G2 = nx.DiGraph()\n",
    "G2.add_edges_from([('A', 'B'), ('A', 'C'), ('C', 'B')])\n",
    "\n",
    "# Check if A and B are d-separated given C in this new graph\n",
    "conditioning_set2 = {'C'}\n",
    "is_d_separated2 = check_d_separation(G2, 'A', 'B', conditioning_set2)\n",
    "print(f\"Are A and B d-separated given C in the second graph? {is_d_separated2}\")\n",
    "\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "def check_d_separation(graph, node_a, node_b, conditioning_set):\n",
    "    \"\"\"\n",
    "    Check if node_a and node_b are d-separated given conditioning set.\n",
    "    \n",
    "    Parameters:\n",
    "    - graph: A directed acyclic graph (networkx.DiGraph).\n",
    "    - node_a: The first node to check d-separation for.\n",
    "    - node_b: The second node to check d-separation for.\n",
    "    - conditioning_set: A set or list of nodes conditioning on which d-separation is checked.\n",
    "    \n",
    "    Returns:\n",
    "    - True if node_a and node_b are d-separated given the conditioning set, else False.\n",
    "    \"\"\"\n",
    "    # Make sure conditioning_set is a set (it should be iterable, e.g., a list or set)\n",
    "    if isinstance(conditioning_set, str):\n",
    "        conditioning_set = {conditioning_set}  # Convert a single string to a set\n",
    "    \n",
    "    # Use networkx's d-separation function to check if node_a and node_b are d-separated\n",
    "    return nx.d_separated(graph, node_a, node_b, conditioning_set)\n",
    "\n",
    "# Example Usage:\n",
    "# Create a simple directed graph\n",
    "graph = nx.DiGraph()\n",
    "\n",
    "# Add edges (A -> B, A -> C, B -> D, etc.)\n",
    "graph.add_edges_from([('A', 'B'), ('A', 'C'), ('B', 'D'), ('C', 'D')])\n",
    "\n",
    "# Check if nodes A and D are d-separated given node B\n",
    "result = check_d_separation(graph, 'A', 'D', {'B'})\n",
    "print(\"Are A and D d-separated given B?\", result)\n"
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAATUAAABSCAIAAAC6+9QFAAAVJElEQVR4Ae1db6gcRbbvjeJm8RqTkLyM+JcX/ySSN2DELBt2cYnz4WU/qC/hamYJLr7cJQRvJuyHjbAQsqPmQxaDGwdcEFe/vFaIQWVlIH5ZwYyYRHBlXAxidAQJMSMJwdt6vbdzcx51f3Nrerqrq6uqu6f7Jj1ckurq+nvq/OqcOnWq2qLiV1CgoEBeKWDltWFFuwoKFBSgAp8FExQUyC8FCnzmd2yKlhUUKPBZ8EBBgfxSoMBnfsemaFlBgQKfBQ8UFMgvBQp85ndsipYVFCjwWfBAQYH8UqDAZ37HpmhZQYECnwUPFBTILwUKfCY/Np0O1WpkWcUfVavUbidP4SunxAKfCY91p8NgCb7sdOhK/mu3e/NUAVFjJivwaUw6ccZajYGz+HEK1OtUqfCnIqBHgQKfevSKTG1ZWWt0rsuktm1Tvc7+bbfJcSKbnV6CdpspFMXPjAL5olynQ80mU4rKZSqVmCACg7muWe8yyGVZDB2Z/ZpNRjjLYjKrWmX/Yh1s21k1CQp/VrXHr7fbZTxZrw/wZKs1pEkvL/h0HMZOlsWoUKsxijSb1Gj0Iksl9jgvfpnh03V7q70gFG27h9gs5rn5i0/X9fNkqzVsnswFPtttNulXKtTtCjDouowoMLpkwWCCJkmiMsNno8GIKKQgEYvHzCdpejqv5ik+wZPlcqg2xCe9VFcPw8Bnt0utFvsTMg/62WiQHHtgsPxbGrLBJ0Agt5OqpEkBovnEZ7fLFuZhPNlqMXlQr0fwpOMwoVKpRCSLQ9QU8dlq9dQD305gtcrogp/jsEk/qJEJu9TtssT1uvBlXiKzwWetxpTbyF+9zoZkuL9c4bPdHuBJLNWxWucLKNfV4EkwcHo8mQo++WKyXh8wHzoOe+TKKpKVyxr8golNKIc1SkkzaTb4VFygZ2FLzQk+Hae3PAdPchby8iRWWDAFybU5LwehgykZBZPHZ6vFpp+wxSQ61u2yBJCruh0rlxnCc/vLAJ+uy0ipQkfHYSk5bw6FiHnAJ3hSspgkYvZYWCgNdsgqlbTUuoTxicFQxA+MtLpMgh0EngsLCez2VauMxJggeYIhBxSRkmSr1FGnjuTk2pc5PrtdpcUketxqqa62vBQC/rnIdZzeDjQ2IOLwZJL4dN1h2Ag5N3KNBeuHWo1R1rZ7khkrVRWh4iV0/HAG+CRiGgtf00v6kAVWsqizTwLXZfyQ9qKbz3uOw8QDFEPUC56EZDbgySTxWa8zPuGzSJ9ISYdgW8NmqRCBjsPYFURRND4l1cZs8IkpOrIPjQbj1uH+ssWnbTOeTHULBOT08qRwqnTdPk8qKphEid6vaVlKk3h89lB3iWk2e7pN/EoVS8gGnzD8COcq3m7oedxMyeNTDmSLT0XDWXwagCdVDLlQhhVFemLyExwyBOFJxASjcIoSUhn8MTQpmg0+iZh1slwOlRTD0fNEA5AhPjEjDUF4gifVpz7sFKpI0cTwmYXqJGIHURyk6HDMlpnhEwgslegf//DT4PhxpuRJ0OvPkORzhvi0bdbpfP6wUyjXeJLUb+HLnk9aELFll8p0Fb/9MnzCkarZVNoLMWvK3r1MoYcrn233hKpl0e9+l5ZhQO4dRqyvWZ1fUfTaMKN0/FwqRoPE5Ge1OiQAmNGl2RzSVCrAJ3cgtiwmx7jTSqRPo0FXy2Xavbt34ALj32zS3/7GKk127aHcqQzxadupW24NhohnwUKUPwoDieEz57TguzJCKiQY6ccnXDFgpuArIdiXoXNGqjjqjYPOxGvhGbU81nguSQDO0JJOedYSBT7DCIldGbnTdJL4HLrpPqzj4vjhqLgD+MSOcKUiNtvgRFiC5v9yOdSNBfsMiYhQxU7N1ZUtPnO7/gSP1mqhI4YEieETw+CZN8UgyTB2OBJ+AJ848zXHqYK+g9cVbe2C/J6oMOGJJAmK0FotQlse9FPJEJ9QmhJUUDzkTiYYyZOJ4RM2GJX9n2R6pl9Kva50xkO/4IEcfXzCui9XX2jOfhKfiSTCEw1MRIRqdWp2ts4Qn9j2UDnYMzCEQ3xIF5+wEcDrtVplBpisLHUqJB2OhbmPTwg0lZaVyyZOn96S5cITKRMRoSo2DVRXLuPOiyHj03UZLX08GVySe4mXYTjSqmouP+GnjtObcDK07VzfQjLHMOkORx+fcI5WqS3+PkCk8EQz4otQrU7NalPDxCdmj1KJbSXMC56MlBkm+MROuGUxKkjWViqcGUxz9OjR9957Lxj/1ltvffrpp8F4xRjuwayYHsm61O2Q3m1ffXyq37SpzvTC1qsIT2SML0IjDRq8hXOdMsZni1ouaVwMB3frNHiS9ynxQORZNhN8pudz/M033zz22GMzMzNBQkxOTj7yyCOOqaYSaakJ1khENtkWWS2au+5BmGgwso9Pde+VSC1nsAr/k6LwRLaYIhTng/wtED3PiQYzfHaoY5FVoYoiRNGtRMyTFy5c+PLLL8+cOeMGhM/MzMzXX3/9+ezv3Llzom5rxKngSBufsImpuxpqtJdobGzsxIkTYVls237mmWfC3kriwSLqLru8KJvsEpW0INrHJ2oNjDEvvBeAZDdoHPKrC0+kjylCtTo1axuLg88SlVQgGrNPfEROnjy5efPmpUuX3n777XffffeyZcv27Nlz6dIlIpqZmTlw4MDatWsXLVr0wAMPbNiwYcWKFd9//z3PqxtQPK2gjU+4Yeu2Rpj++PHj27dvf/HFF3ft2nXs2LGLFy/efPPNIMejjz5aqVSefPLJQ4cOVSqV8fFxIvr888/vueceYVHySOMTgDbZVaq2qKUO0T4+wTWR1kNIdlO9gBnldI3mxiK006EtW5gN8Pe/lxOcrXzm9nXj4LNLXRWI6t5IImz85OTkQw895DjOvffe+8YbbxDRiRMnRkZG3nzzTSLat2/f66+//tRTT42NjSH75OSksBzFSFxOHJlYG5+RGnNklTzBzp07t23b9sQTT5w/f/7OO+/86quvVq1ahbcTExMPP/zwHXfc8fjjj+/fv//bb78lounp6YULFwq1X16mL+C6jHvnWMX3MvoR+CQidYj28UnEbluSH7oD8xprI7rCEz02EDedTu80bbVKR46wTkn2jQY7FQef7GJQBYjKaRw9zLMppmZ/MzMz11577alTp5DrwQcf3Lt3LxFNTEwQ0bp16w4fPqxYYFgy7hmpoo2b4DP+Xh2a/t13361evfrjjz8+evTo9ddf3263169fz3vlOM5tt922cuXK6elpHrl8+XJ1pYJb88J4qUKVyI+M1ah3L54iRAfwScSmB8sSb5/gZtE4zgkGwhOkVBehXmTygY/slEdrEOKzSc1Iyltzh5MjIeqnOWcX/cCpU6eWLFnCZcD69evffvttFHP27NkFCxbceOONN910k216XrHdZhqP4nUXJudXEqTFmTNnFi9ePDMzU6/Xx8fHz549e+utt3KSvvLKK5s3b77hhht27NiByMnJyZGRESjAPJkw0O32pnu5Nc8iq0lN+UfGvPYJFYgK6IOdKGCp2WRHVxsNWrUqFLfCLgUjzYQnylERoUJk8mY0m7RwIa1cyfrCO4Ud8EHeFeLTJrtCFTnlu9S/rVwOUQHNeTs1AwcPHty2bRsyffDBB6Ojoxyrzz777K5du4jo4sWLmqWy5Pz+schrdb2FZyk/X3vttZGRkd27d2/duhX6w5o1a3788UcoEtdcc8277747Pj5+9dVXr1u3johOnjy5ceNGb+vDwrjCM1J/sMjS3T4BRCW5xLziOL1dc5xfqVbp5ZcjVN+wvvF4Y+GJEiQiVI5MZMfs8PLLbCLknbLtoKdxGD6rpHcTLyDK1RlOBiZk1G4v9GYJC99///3vvPPOxMTESy+9tHPnzqmpKSI6ffr01NTULbfc8sUXX4RljIyHthSmyoVlN8Gnbh1hdW/fvv3AgQM//PADT7B///5XX32ViC55fngkoqeffvrQoUM8sSSgeO21AT7rVJfn0uAVmDUk3ZC8iiM8UaxQhKogE9mVZ4ek8ImZsUGCu1Xly2EJFX2vjhw5smDBgvvuu290dPT999/H2/Pnzy9atGjDhg11XTvcYOmgt+4hZG18KtqdBtsmePrwww/vuusurrsiheu6o6OjsAb58nz22WdjY2Mqyi0y4s4EuVnUIqtO9dlL/7i3iT/g1bIATvl2qAY+sVVltrOiDA8fGQcevSJUHZnMXDb7/QM5cedqCsNnmcpyyrep/+VtgLNO4m8HwLd0rsLk/z99+vRHH32kznthLYC5MFKt82bXxqfivo23Dq3wuXPnPvnkk2CWEydO6Fq0I91aG9SYvTGXe2v6A2UqczVMBZzaupaZCNWBR5CS/RhM6X/9a982yy1A/USikM7sIMRnm9pyysN0h7rl4MTSTv0rIaL+DC9O9yZrbXwyr5rZOwvlG+/4/JPWVJE4kdQdeMKq5vsriuDUxqeZCNWBR1jXWHynQ+vXs9Xbli0aV65ozg5CfMpaNfsO/kN8ZytMcvJysLqTS/ROR8NwyktONuC7XT2ycBN84nxfuSy+RI9v71hW0FgQ2Z4kE5hxhrcFwKc6OLXxiQ0YrUPEmvDwdqcf5trsli20fLl4+6efejCkOTuYjQLwGSk5vS2rVNjWRdhyASbDoX/dwttAFtb1AzfBJzQK7IGBIt0um387HbZrXan07HmePTB/K4fzrEuLYKvgf6vuPGSCT10RqgkPf6c4MqvVnsxUUYd4KfqzQxx8wkDAK5cH4IuC29Hw4cAgT8bZbJbXrv5Ww0IR835q7232uJ8XX9HFkCRl5lXveTClFi2C2WP5xweLC4tRX4Xqw6NfZxCZeCc05PazDYb0Z4c4+IxUawcbx57CeBJ2kzDpGiwnvRgtnjSUn97Wu67/lFn8hZ+3/DhhLVoEK3LJ9dpvgwmCMSY1qotQfXiwFoYhk7deUYQazQ5m+GSt1jzZx3sDNdK3FtVd+HlLSzasxSEJ4DPY+shbG4JZUorRokUibTCsUUWEGsAjEpnos6IINZodjPGZyHDwQvLDk1r3BFzO+Iy//uSjqx4wxCcXoUKTt+MwFUULHorI5B2DCJ2cFH8dtNPR2vPkpfL7lbwxmYRzgk/MhOpq9uWMz0xUGkN8EtEf/kCLFrHdjuBxlqVLaWSEvbpwIZq5dZGJEicnafHiXi2+OiABf/pTmnNM9b2XPxby00sf6EDyvUlv+ssZn7p7wV66GIcN8Ql3p7APsyH+Jz+hZctkDTNDJkqEvz4q8rEP9hbx6uBBWQNE7wp8eqmi8k0Hb/pU8JmJ4PL2ip0bnP1qslBb9KVM9tEQn90uOwty1VVMSA6e/2DNAzYsi8LgEQeZ6D8mdlTk8yLi+Fy6VKz9SimYE3zqCi5pnwxfYhGjta+RCj5jXtmB3uODaL6pXJ0w9frwP0XLWmeIT9gcf/lLln/t2t6hEHwYfPfuHj69qxZunYyPTE7TVot+9jOyrIvjtalfVVDp1OYtl/57Iwv/4hdm7iY5wafuwo9TxRtoNJgRwJgnDfY1UsEnvkYZxz8BMw3400sgxTAckbUmKsWSI5OZ45OI/vUvdqhyyRJ2qLLVYvsitk3btzN4bN3a54sdO5iie+qUtt+svPWue+npZ8iy/r3qfw5vsp/b1XlhR/vwJvu7a/9j5qqrBZ8tlJc29zYn+ISnVpxPkIAnSyU27xtAFHQI6kZzdBL/nxY+DVz1vQ3ELUf4jKnusR6zXN7a44TN8Qk1UniivNPpnbp3XcIXBBcsYKDlPkBxWoy8rjt9/wMT15Ve2NH+85/J93d4k02Wdel5wdmuyJrzg0+0xHjJgy0wcJeuH5IxT6aFT3zuwUwZwFIB0g80VYco7jTRJV8kk6knMMRn5LEg6Ge/+Q3UTvbv4sUm03hITy4935i4rrTvT44PmfzxhR2zdyn5lqYhpXmj84NPfO6hVDJYRPd2l8CTumDDWREzqZsiPnGNtW6zMJxeNQBwxa6uRK9ot3t3/egegfUyU/ywIT5xsk1ePXQSbivatMlsQSioZHZ2+L/fNjkahYFjP6+5q7W/R50rfJrxZBCQgBwOtUl4stPp8aS6gPGNTor4hMlDS1/HLkOwM47Tu7ERFIHfc6fD+BOvcPFNtSq7Vs7X85QeTfCp7kiR0jcSbfuL/6wIMemN3Pcnh8ltTQUxV/gET1YqbA3JTWxyTsBmRJAn8aEXXO1i28xWgD8fT1YqsXgyXXxinwMXlnlFYpAi3AwZ3JzniTlFuAhBAOewFcnNS0spYIJPdRZOxwtmesfOf/667oViWNhZVAo9wRVCUPXOhRSQfDR8sVSkX63GZiQJ66bNk6njEzMWvMdKJSbuYZjsdNhE3G6zzldmjfnVqu7UzNJrzubJD7avRBN8qn80ASqur8rYj1O/qhzeZIdh0hvfXlOVcauoJTnEJ5oZxpOwmuNrLgYGOMdJkieHgU+Qw3GY4xomJK8AhJdP3mAm4jSlOBN8qqNOHclKje0lmtq8pbmx4cVhWPjsDf8lcD+U1pVbfEJygCdLpb7dDbt69TrTVzP/DQ+fwa5eNpj0ds0En9hZUyGH+ufDvG2KDNt2e001DJM8vr7HZVysybZ5xmeQMCqDEMyVXkyW+EyvVxmWrM/As40tl5kFTP7DraFeLyJ5evW3swL8L3/scigKA4c32e6yknqpSDm/8Knbu7TTF/hMmMKG+ISKKxdNSV1tKuqxO1qVm3D/8sdZh2aJ+U5UbH7Ol4W0Lu/RBT4THiFDfMIlslQSa4/8ap301C/HmV624tjPa/U9blB4Prer882Ksjuqd+M7KFvIzzgcVuAzDvUEec3x6bo961mj0Uep4zAbN3ao0vYn7nbd1eWJ60p//98W13Wf29VpbmyQZTFwSnbiBZToRRX4DKdN9JsCn9E00kphjk9UAzR6DdyWxXaljLCh1XKW2HUvPd9gi0xPA6ZWadtsvfUW+PRSQzdc4FOXYhHp1T8dJyvIdZkIbbeT3EqT1Rd4B7nd6cSfF+CeGaigiFCiQIFPJTKpJ8Iph+FIO/VWZZXSddkZmzgnDbNqeU7qLfCZ8EBgEwSeUv5vLcm/B3TZvcVH7vU9dhMekXldXIHP5IfPdZkPo/9bS/LvAV2mb5vN+Apy8gM0j0os8DmPBqto6hVHgQKfV9yQFx2eRxQo8DmPBqto6hVHgQKfV9yQFx2eRxQo8DmPBqto6hVHgQKfV9yQFx2eRxT4f2zWrAkQPfdKAAAAAElFTkSuQmCC"
    },
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "2dfd067e",
   "metadata": {},
   "source": [
    "![image-2.png](attachment:image-2.png)\n",
    "\n",
    "Fig.25 We can view a graphical model (in this case a directed graph) as a ﬁlter in which a prob- ability distribution p(x) is allowed through the ﬁlter if, and only if, it satisﬁes the directed factorization property (8.5). The set of all possible probability distributions p(x) that pass through the ﬁlter is denoted DF . We can alternatively use the graph to ﬁlter distributions according to whether they respect all of the conditional independencies implied by the d-separation properties of the graph. The d-separation theorem says that it is the same set of distributions DF that will be allowed through this second kind of ﬁlter.\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Fig.26 The Markov blanket of a node $x_i$ comprises the set of parents, children and co-parents of the node. It has the property that the conditional distribution of $x_i$ , conditioned on all the remaining variables in the graph, is dependent only on the variables in the Markov blanket.\n",
    "\n",
    "## Maximum Likelihood and Naive Bayes\n",
    "\n",
    "## Naive Bayes with Gaussian Densities\n",
    "\n",
    "Using **maximum likelihood** estimation, we assume the data are drawn independently from the model. The solution is obtained by fitting the model for each class separately using the correspondingly labeled data.\n",
    "\n",
    "### Gaussian Example\n",
    "Suppose that the probability density within each class is chosen to be Gaussian. Under the **Naive Bayes assumption**, the covariance matrix for each Gaussian is diagonal. This implies that the contours of constant density within each class are axis-aligned ellipsoids. \n",
    "\n",
    "However, the marginal density is given by a superposition of these diagonal Gaussians, weighted by the class priors, and therefore does not factorize with respect to its components.\n",
    "\n",
    "$$\n",
    "p(x) = \\sum_{k=1}^K p(C_k)p(x|C_k)\n",
    "$$\n",
    "\n",
    "This approach is helpful when the dimensionality $D$ of the input space is high, making density estimation in the full $D$-dimensional space more challenging. It is also useful if the input vector contains both discrete and continuous variables. For example:\n",
    "- **Discrete variables**: Modeled using Bernoulli distributions.\n",
    "- **Continuous variables**: Modeled using Gaussians.\n",
    "\n",
    "### Strong Independence Assumptions\n",
    "The conditional independence assumption in Naive Bayes is strong and may lead to poor representations of the class-conditional densities. However, **decision boundaries** may still yield good classification performance even if the assumption is not perfectly satisfied.\n",
    "\n",
    "---\n",
    "\n",
    "## Conditional Independence and d-Separation\n",
    "\n",
    "We represent a joint probability distribution $p(x)$ using directed graphs, where:\n",
    "1. **Factorization**: The graph decomposes $p(x)$ into a product of conditional probabilities.\n",
    "2. **d-Separation**: The graph expresses conditional independence properties via the **d-separation criterion**.\n",
    "\n",
    "The **d-separation theorem** states that these two representations are equivalent.\n",
    "\n",
    "### Graphical Models as Filters\n",
    "A directed graph can be viewed as a filter:\n",
    "- It allows distributions $p(x)$ to pass if and only if they satisfy the factorization implied by the graph.\n",
    "\n",
    "This set of distributions is denoted as $DF$, the set of directed factorizations.\n",
    "\n",
    "---\n",
    "\n",
    "## Markov Blanket\n",
    "\n",
    "The **Markov blanket** of a node $x_i$ is the minimal set of nodes that isolates $x_i$ from the rest of the graph. It consists of:\n",
    "1. **Parents** of $x_i$,\n",
    "2. **Children** of $x_i$,\n",
    "3. **Co-parents** (other parents of the children of $x_i$).\n",
    "\n",
    "### Conditional Distribution\n",
    "Using the factorization property:\n",
    "\n",
    "$$\n",
    "p(x_i | x_{j \\neq i}) = \\frac{p(x_1, \\ldots, x_D)}{\\int p(x_1, \\ldots, x_D) \\, dx_i}\n",
    "$$\n",
    "\n",
    "Only the following terms affect $p(x_i | x_{j \\neq i})$:\n",
    "- $p(x_i | \\text{parents of } x_i)$,\n",
    "- $p(x_k | \\text{parents of } x_k)$, where $x_k$ is a child of $x_i$.\n",
    "\n",
    "Thus, the Markov blanket ensures that $x_i$ is independent of all other variables in the graph when conditioned on its blanket.\n",
    "\n",
    "### Illustration of Markov Blanket\n",
    "\n",
    "The Markov blanket includes:\n",
    "1. **Parents** of $x_i$,\n",
    "2. **Children** of $x_i$,\n",
    "3. **Co-parents** of $x_i$.\n",
    "\n",
    "This ensures all dependencies involving $x_i$ are captured.\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "- The **Naive Bayes assumption** simplifies modeling, especially for high-dimensional data, but relies on strong independence assumptions.\n",
    "- Directed graphs represent **joint probability distributions** via **factorization** and **d-separation**.\n",
    "- The **Markov blanket** isolates a node from the rest of the graph, making it sufficient for conditional independence.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01f6cf73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [0 0 1 1]\n",
      "Is d-separated (A, E | {B})? True\n",
      "Markov blanket of node 'C': {'B', 'A', 'E', 'D'}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "\n",
    "# Naive Bayes Classifier with Gaussian Assumption\n",
    "class NaiveBayesGaussian:\n",
    "    def __init__(self):\n",
    "        self.class_priors = {}\n",
    "        self.class_means = {}\n",
    "        self.class_variances = {}\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the Naive Bayes model assuming Gaussian densities.\n",
    "        \n",
    "        Parameters:\n",
    "        - X: numpy array of shape (n_samples, n_features), feature matrix.\n",
    "        - y: numpy array of shape (n_samples,), class labels.\n",
    "        \"\"\"\n",
    "        classes = np.unique(y)\n",
    "        for cls in classes:\n",
    "            X_cls = X[y == cls]\n",
    "            self.class_priors[cls] = len(X_cls) / len(y)\n",
    "            self.class_means[cls] = np.mean(X_cls, axis=0)\n",
    "            self.class_variances[cls] = np.var(X_cls, axis=0)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict class labels for input data.\n",
    "        \n",
    "        Parameters:\n",
    "        - X: numpy array of shape (n_samples, n_features).\n",
    "        \n",
    "        Returns:\n",
    "        - numpy array of predicted class labels.\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            posteriors = {}\n",
    "            for cls in self.class_priors:\n",
    "                mean = self.class_means[cls]\n",
    "                var = self.class_variances[cls]\n",
    "                prior = np.log(self.class_priors[cls])\n",
    "                likelihood = -0.5 * np.sum(np.log(2 * np.pi * var)) - 0.5 * np.sum(((x - mean) ** 2) / var)\n",
    "                posteriors[cls] = prior + likelihood\n",
    "            predictions.append(max(posteriors, key=posteriors.get))\n",
    "        return np.array(predictions)\n",
    "\n",
    "\n",
    "# Graph-Based Functions: d-Separation and Markov Blanket\n",
    "def is_d_separated(graph, node_a, node_b, conditioning_set):\n",
    "    \"\"\"\n",
    "    Check if two nodes are d-separated given a conditioning set.\n",
    "    \n",
    "    Parameters:\n",
    "    - graph: networkx.DiGraph, the directed acyclic graph.\n",
    "    - node_a: str, the first node.\n",
    "    - node_b: str, the second node.\n",
    "    - conditioning_set: set of nodes.\n",
    "    \n",
    "    Returns:\n",
    "    - bool: True if node_a and node_b are d-separated, False otherwise.\n",
    "    \"\"\"\n",
    "    return nx.d_separated(graph, {node_a}, {node_b}, set(conditioning_set))\n",
    "\n",
    "\n",
    "def find_markov_blanket(graph, node):\n",
    "    \"\"\"\n",
    "    Find the Markov blanket of a given node.\n",
    "    \n",
    "    Parameters:\n",
    "    - graph: networkx.DiGraph, the directed acyclic graph.\n",
    "    - node: str, the node for which to find the Markov blanket.\n",
    "    \n",
    "    Returns:\n",
    "    - set: Markov blanket of the node.\n",
    "    \"\"\"\n",
    "    parents = set(graph.predecessors(node))\n",
    "    children = set(graph.successors(node))\n",
    "    co_parents = set()\n",
    "    for child in children:\n",
    "        co_parents.update(set(graph.predecessors(child)))\n",
    "    co_parents.discard(node)\n",
    "    return parents.union(children).union(co_parents)\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Naive Bayes Example\n",
    "    X = np.array([[1.5, 2.0], [1.2, 1.8], [3.5, 4.0], [3.8, 3.5]])\n",
    "    y = np.array([0, 0, 1, 1])\n",
    "    nb = NaiveBayesGaussian()\n",
    "    nb.fit(X, y)\n",
    "    predictions = nb.predict(X)\n",
    "    print(\"Predictions:\", predictions)\n",
    "\n",
    "    # Directed Graph Example\n",
    "    G = nx.DiGraph()\n",
    "    G.add_edges_from([(\"A\", \"B\"), (\"A\", \"C\"), (\"B\", \"D\"), (\"C\", \"D\"), (\"E\", \"C\")])\n",
    "    print(\"Is d-separated (A, E | {B})?\", is_d_separated(G, \"A\", \"E\", {\"B\"}))\n",
    "    print(\"Markov blanket of node 'C':\", find_markov_blanket(G, \"C\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b92d1f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
