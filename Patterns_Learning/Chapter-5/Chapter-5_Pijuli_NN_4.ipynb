{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9482bb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " * Copyright (c) 2008 Radhamadhab Dalai\n",
    " *\n",
    " * Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    " * of this software and associated documentation files (the \"Software\"), to deal\n",
    " * in the Software without restriction, including without limitation the rights\n",
    " * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    " * copies of the Software, and to permit persons to whom the Software is\n",
    " * furnished to do so, subject to the following conditions:\n",
    " *\n",
    " * The above copyright notice and this permission notice shall be included in\n",
    " * all copies or substantial portions of the Software.\n",
    " *\n",
    " * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    " * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    " * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    " * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    " * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    " * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
    " * THE SOFTWARE.\n",
    "'''"
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAccAAAEOCAIAAABzeUuZAAAgAElEQVR4Ae19DXwUxd3/autfK608rZbGwgPyQZ8qSKwvhUL7SJWIIuALCLJECAhSrRKVqiBK6GEVKlbEM75VQYTDFwSE3gEaIE9MCuGlh55BDAgb4LDk4IQzd3Cwufv9P8uEYdjd28zt7eztJXOffGB2dnZ+v/nNd78785s3AfiPW4BbgFuAW8A6CwjWZcVz4hbgFuAW4BYAzqocBNwC3ALcAlZagLOqldbkeXELcAtwC3BW5RjgFuAW4Baw0gKcVa20Js+LW4BbgFuAsyrHALcAtwC3gJUW4KxqpTV5XtwC3ALcApxVOQa4BbgFuAWstABnVSutyfPiFuAW4BbgrMoxwC3ALcAtYKUFOKtaaU2eF7cAtwC3AGdVjgFuAW4BbgErLcBZ1Upr8ry4BbgFuAU4q56BgZEjR86bN++MqNy8WLNmzR/+8Ifc1J1r3WSB/fv3FxQUfPHFFy3MIi0enLnBqtFotK6u7ptvvtm9e3cwGNyzZw89zpLJ5Pr165PJJM0jbrd7+vTpaeUPAPQiEonE7t27d+3aJUlSMBjcvXt3PB6nUQyl2bZt23fffUeZvn379sFg8OjRo5TpTYhIK+eWlPjgwYN1dXW7du2qq6vbu3fvgQMH6Et3/PjxTZs2UaYfMmTIqlWrDh06RJkeJaMXYeGb9e9//9vv91PqaQ6coVCotraWUkQWk+UGq+7ateuyyy4bPXr0Oeec89RTT40cOZLSZAcOHBg1atTZZ5998OBBmkfcbnf37t3vv//+N954gyY9AKQlQpblm2+++dZbb23Tps3zzz9/9dVXUyoGAI899li7du0WL15MqdgPf/jDZ5999oYbbqAn1nRFUGrS8pKtW7fuJz/5yZAhQ3r27Dlw4MC3336bsowVFRX9+/fv1q0bZfo77rhj6NChAwcOpCestERY9WaVlpZOnTp1ypQpb731Fk3RTIDzzTff/PWvf/3ggw/S5J/dNM5l1UgkUlFRceLECWSgOXPmdOnS5dxzz/3tb38bCoXSslqbNm1SkdeJEycqKysPHz6MMnS73dOmTdu5c+fVV1/NSMQXX3zRuXPnH/3oR9dcc83y5cvTkjJgwAADVg0EAt988w3O8MILLwSAwsLCtKQYi8CZt8KAyrx33nnnZZddlpeXd8cdd6Rljc2bNxuwqgr2Q4YMKS8v/8c//vHoo4/SS0lLROZvViKRuOiiiw4cOFBXV/fLX/5St1+4b9++TZs24VvmwDlr1izOqvQwUKf8/PPPb7rpphUrVvTr16+8vHz9+vXhcLhjx45r1qy55ZZbyNTxeHzcuHF3E7+xY8equtWpWDUSifTr12/RokW33Xbbli1b3nrrLbfbfeONNxYWFi5ZsgRLsVYEAFxzzTXr16/v0KGDLMtYCgDMmDGDKIcS3LFjB5kgFeUlk8kHH3zwmWeemThx4gcffDBr1iwAuPTSS8ePHz969OhoNIozMS0C59AKA7rmXbNmzYABA6ZMmfLiiy+SNlm+fLmqElVfNQPK08J++PDhoigOGzbsq6++wlJ27typEjFjxgx8FwDSEpH5mxUOhwVBaGhoQIFYLEYqAwALFy6855575s6d+9BDD82ZMycej+uCs1nTcVZVGTa9S9yO++1vf9u9e/ejR49++eWXzzzzzIkTJxKJhCqvhoaGw8SvoaFBlSAVq06cOBE1ASZPnvzTn/70iy++2Lt3r9vt/vrrr1U5WCiivr7e5XKtWLGisbFRJeXYsWNEOZQg/rajlKlYdcWKFahxvXr16gsuuKC0tPT48eOvnvypuv+mRahUbVWXWvMmk8l169aVlpYmEglVHcmyrKpE1bfTgPJSwf748eOkwZPJpErEsWPHyARpiQgEAk8//fTWrVtNv1mRSEQQhMOHD4dCIUEQVJA7cOBAmzZtvvvuu3g8LgjCvffeCwBer3f69On79+8n1W7WdJxVSXOlF5Zl+fzzz49EIgBw3XXXud1uAPjoo49+9rOf4a46zjEejxcWFg4gfoWFhanaqgcOHAiHw/jZfv36rVixAgCeeOIJ1I9bv359z549ly1bhtMAgLUihg8fvmXLlt/97nerVq0ipQDA9OnTiXIowZ07d5JpMKvG4/Fdu3bhW88999zEiRMBYOXKlRdddNGJEydef/310tLSiRMnTpo0CSdLSwT5VCsPa82bSCRcLtdVV12ltcyyZctUlbh06VIyGUl5O3bswJxLD/tvvvlGJcLlcpkTkUgkevbsuWfPnp/97GeqgVB62CeTyUsuuWT37t21tbWXXHJJMpncvn071mf9+vXXXHMNABw9elQQhF27dm3fvn3EiBFLly7t2bMnTgYAzZqOsypprrTDkyZNeuyxx+67775bbrnlrrvuQl7RTp06aVnVOOvvv/++qKjovPPOGz58+O7du//yl7/cfffd+JHly5ePGDHikUceEUXxpptuWrduHQAUFRWpWBWn1w2kK2Lfvn3RaPRXv/qVtkWsmz+OnDJlSqdOnW644YaVK1euWbOmffv2+FZdXV3//v2feuqpe++9t3fv3m+88cahQ4disdiwYcPSmihGisCZ84DWvAAgSZIuqxqba9OmTQMHDrzooovGjx8PAH369CHHRS2Bfboi9u3bV1NT06VLF23nyaAsKtgvXLhw9OjRRUVFXq/3yJEjP/7xj3GDIJFI3HbbbVOnTi0qKurRo8eUKVNkWf7Pf/7z6quvFhUVGYhQ3Xr33Xd/85vfdOvWTeVyUSVzwqVzR6saGhpQ3wp3f0ywavLkD01+SiaTDQ0NM2fOJO1+9OhRBCYsJV1WTVdENBodNGjQ7NmzN2zYQGrSbBh10JLJJApMnTqVfESWZdQNRAVJJpOTJ0+eOnXqwoULyWTGYZUI48St6q7KvKZZFaMFmbqioqKsrIy0ZOawT1fEjh07brjhhjlz5qQa0SXVw2EsBQfq6+txa/f555///vvvycTIL5dIJFDb/OOPPx48ePBrr72G0zQbQBYDABxo9pFsJXAuq6osMmPGjJ/+9KfIKaO6RX+5du1alStH9eyyZcsuv/zyG2+8sa6uTnWL8rJZESNGjBAE4bzzzlu7di1lntpk+/fvRy1r7S0U8+abbwqC0KZNGxX5pkrP49O1wNChQ3/xi1/Mnj073QfJ9O+99x72AJDxOJw57I1FNDY2tm3bVhCE888/X+U3wzqkG0gmk8bf8pqaGkEQfvSjH7XUhSo5w6qo3aoaGUi3vptNj6WwFtSsJjyBwy2AocJUT3ukMC1CK8w8I1Y9evToRx991AqtxovsNAuUl5fv27cPAILB4Pz58417JE5TnuvTwiyQEav+8Y9/7Nu3bwuzCC9OzllAkqRzzz23srKyvr6+d+/en3zySa9everr63OuIFzhlmEB86yKsMtZtWXgIHdL0djYOGzYsE6dOlVWVs6cOfPhhx8GgAkTJvztb3/L3UJxzXPaAiZZ9dChQ3fdddeyZcs4q+Z09bcA5WfMmOHz+a699trKysqhQ4eWlJQAwJQpU4YNG9YCSseLkIsWMMmqhYWFDz300Lhx4y677DKfz4dK3tDQIPAft4DGAkeOHGH0bmzbtq1r166zZ8/u0KHDhAkT7r777qeffhoAJk2ahOdCclhqKoRHKBZgB0uTrPraa69NmzatsLCwc+fO5H4fgmAyQwvfOifoAABOUMMJOjA1xfbt26ed/LVv337MmDGvvvrq2LFjAWD06NHk5B4n2MEJOjCtC/pXuMWbIiMSXLVqlcoD4BB70VcwT2mDBWxARc+ePSsrK2VZLiwsnDBhQmFhITkP1AYFbDAjF2GtBdihIiNW1RaSnaJaWTwmVyxgMyq02+vYrECu1Esr15MdKjirtnJo2VF8dvCl1D7rClDqyZPZaQF2qOCsamc9tlJZ7OBLadCsK0CpJ09mpwXYoYKzqp312EplsYMvpUGzrgClnjyZnRZghwrOqnbWYyuVxQ6+lAbNugKUevJkdlqAHSo4q9pZj61UFjv4Uho06wpQ6smT2WkBdqjgrGpnPbZSWezgS2nQrCtAqSdPZqcF2KGCs6qd9dhKZbGDL6VBs64ApZ48mZ0WYIcKzqp21mMrlcUOvpQGzboClHryZPZZQJLYoYKzqn312GolsYMvpUmzrgClnjwZEwvIMkgS+Hzg8YAoQn4+CIKyopzZ8nrOqkzqkWdKWoAdfEkpBuGsK2CgG79lpQWiUYVAq6oUAi0uVjj0JIEq/+blKZdut0KvkgSyzA4VnFWtrFOel64F2MFXV5w2MusKaFXiMRlZgGRPt1uhy4ICNYG6XAq3BgIKh+r92KGCs6qevXmchRYIhdjBl1LNrCtAqSdPdtoCoZDChpKkMKPHo7QxRfGMtidqhKJIlAalP51FMyF2qDDPqvv371+0aBF5Pq1D9hlrxpb8NjsLIAcW6n/Z4sACgMbGxtWrV2/cuBEVS/fcKnbvDztbtsycEUIQ/QUCTYyJe+sEZk43PPPzm/gUUWdVlUK1oVDm9mGHCpOsunXr1uuvv37AgAH//d//HY1GcQnZKYpF8IAjLIBeD/RiuFwK7vPymt4E5MBC/S9JgmiUKSrGjRtXWFh48cUXv/zyy6nOrWKqgCOqw34lcFtSkpReNqI89C9yaKJWJAkM7OLEAZwGocXjaXJ6WsSbxlZhhwqTrDp37tx4PJ5MJi+44ILa2lqsPTtFsQgesNUCJHuiIVRyBEAQFD4tLlZeKtSIkGWteuxQ0dDQsGDBAgD4+9//LopiqnOr2CmgLWxux2CuRCPmHg+gTyaiP/zhxLSIA5gfMR4wzyJgoPbpyWEih5iIHSpMsiqySzAY7Nq1KzqyHMWwU9QhNdEC1cCdMtRzx9SpeoUKChQCdbsVAk09AqBrHxtQcd99933wwQepzq2yQQHdgjsxEo3z4NYlYsNTk410+t3ok0n2vhE/Ej1UJxaTQid2qDDPqolEYsiQIZs2bcL6yycnK7DTFQviASoL4NYBdvmTTQ9yzBS1OFDPHVMnmoCSYvyUSoGTx8ygM5Io05tLVlVVJYpiMpkcNWqU9tyq1gtL3DdH7U0VdSI+RZ9JXNe5z5U0EEKYZMdUJlk1mUw++uijS5cujUQiH330ES4JO0WxiFYXwG1JxJK4Y0VSZLMdNNTSRMlwDph2GduUKSq++uqrIUOGHD58eOXKlU4+t4qtjVELFI+Vk/0MXOmYOtmqkjO5s4OlSVZ9/vnnMd877TTA3KhVzJW4L0aOhGobktiBRfKjKJ4xSoBfG0SXei7OrBiHHXzD4XD79u0RFLt163bixInWcm4VWiyE5hthbKDhcjzm4xgAZAV1zQplB0uTrJpKY3aKppLo3HjMm6htiL3++B3AAUyUeCTU42marIf40bmFpNLMZlS0wHOrEJbQdxd35DGHouEgqqrgiU5bgB0sOauetrL5EBo5xf0vVUsTkSb2+qOhnsz8leZVzcaT7OBLWZqsK0Cp5xnJkDe8uBivW1eWDyEUOWkk/Qydc+qCHSo4q6YJBNRq0OzUoAyeIvZE7n+H9cHTLKTFydnBl1LRrCtApWc0qsxOc7tPL77Mz1doFDl2qLJgmCgeisekWKq/eCjOUDabrNmhgrNqczUWCjVt1kAu/FDt1NA6Rk6bs1TK++zgm1LkmTeyrsCZ6hBXyD1aXHx6DQXylQcCwMwripgxEogEPUH0V1Nc4xf96K8iv8IreK39qy6oxvmjgOSWsHQyUO+rT0XcuvEJOUFYUx2Uo7LuUyiSHSo4q6prQnFo+nzK5GfckVdxKDO4a1RpIRHs4EtpoKwrcIaeqGuPF1Pk5ytg8/ksWYWJBSHiIElTS5eY6WpdtZjaUvGacWvUgL9I+sZSsGhVQKuktfxO5sYOFZxVQUFzVdUZNIrHAQIB4O1Q/KaaDbCDL6VGWVZAlpV1E+R4fUGBcllVlTm6SPZEDEUSR0V+hV/01xTXBD1BTJdyVGf9G6UlHZUsIScMmqIxKfb9zpjhnF2L2Q8bx+J8swxfXCzjAEI5WkSEBuJRaxStGuJNUWPrpX8366jIjgKqNiliUrNde8Qg4apw0BNEHfayvDJMoKiLjbrVkUAkJsWMu8bp16HTn0ATdtF4h2pjVbSsGnlWkI8a7c3CDhWthlVxgxRPTLGuveB0xGVbP3bwpSyZfQqEQsoMYty7N8WkWgLF7OkVvLjtGa4Kx6RYi2l4UlYlnOxbklv7Y0cd3pma3FjVoI3EDhUtmlVDIcVdhYcC8vJOT0yhr0OeMjMLyLJymEVmeWT6NFsFVDBDflLqNmlMiiHPY62r1i/6MYGW5ZX5RT/yeKLmZ6ZWyMHnVVMWcYtIEJT5ZnhxtbktrtihwmK4s1OUFhK424UW7bEZCqBVppWlw+8A3qHl1EIHi2GWrl2th6UsN/ni0Yuel6f45Zvzk6IhnXpfveSW/KKfHJlRtUBbW/8dQPEwky1QawlUFzDWo+KUGIvhzk7RUwrr/Y8bC+glRkzaHMT1MuJxVBZAc3Z191ZVNSLQiofsoIIoimUKSNIZ80lF0WDsHjdCkRsUN0LRCJLkltDwUSvswiP84M3NyS585i1QotqbCVqGCo2cnGVVzKRkm5QzqaaCM4wgWxC6gwBosQ8aBEg1XYIdfClLl5ECGGnom41cpWcujUOe0HpffdATTNUIbbW9eDwKr8IPGiHGm5tbsbs/JRyakmWECkNR5lk1C0dZoMUnLlfTGj66bpdh8fnN0xYgCdTU6Wqns1KF2MFXJQgAtLCMxZST39G89urqgqbJ7qfmSdbWupqmwp+cS9m0eOj7nfGt/6d06vU6+PFQXNcTyhuhAEovHjdCyV483szaOZsWsIOlSVa17ygLPNcP9xPQGj77P23aNzhnY1TLbrFpVf13c4MAWquwg69Kli4sEwnljGJElySBojBJstWfXa9eVPTRuZ/Ov2L9y3+uevbJ/xvw7porluOOfHVBNZoHisbiVZq0kksEJLQnJYmiM4+Idqgx2MHSJKsyP8pCO0MFbePk0ApytFrGXTC8bwG77xQ7+KrsbgaWqANUXJz4xS9jQrtwl0HBork1I/5v89B/YQJdc8XyqtuXfvbEtKpnnyx//3rvR+ci8i0ry/P7xZqa4mDQE4kE4nELjqhTlchpl5hGyV1f0HYF6AVN5QVyWkGYHl1qklWZHGVxCt9Na6LTnKHiwGqzXyU8Co8W8qg2L0Y+0DSPR7GgELaxKiUsFTfoKn/4kTeDVz5YI4z3nzcVEyjlfCZZjsZiUjhcFQx6amtdfr+IG7nV1QWIZ2MxKZFoCauYtEu4SRo1mBBqAXRYZsEOliZZVfcoi2j0W7R/sKqfFQ5XkXvdyPLpM1kVo6HFfNiBhTr4OfTJY1nxxnmHQk2nW5Ibv+DNs5yweTHe2ty4IFbd1YXl8WPHkRr+O9dX/xqzn7fs/33g77W09pGNQU/Qkl48olrEs9XVBUhSRUU+Jlmrisk6H7x5Fl7NQE71zl0axXZjDUuTrLpgwYKxY8cCwOjRoxcuXIjUlWXljGLSUYXCp4GMmwSnAhVuwf+44H/hFzVLbg5ufSkY9NTX+xAFYxPwwCnzKkMBuj4sPJDqzI8Ru0aBChu6sIxtO6jA8rypkjAw+N8jI396Pra4gt2OUKRKsZhUX++rrXVVVOSjt6C6ukCS3JFIwFHNWLJfj/s3ePMsZ4KKtLO5MDtYmmRVWZbTPsri1MTpeK+usXZC7PrLYzMeqS+fFdzzLu5G+f1iWVkeycIVFfl+vyhJbuS6isUkcxbM4lN4Ox/V5j2nRqHP+AyRi7tPfXpIe5wOVw7ybxp6xrMoQ3L/IbxFUKpNKOyZLMkOvqpq1YdlKKQoYPWmUCrRzV4mEnIkEpAkN27G+v1iMOjJljcWTRgjt2YrKGCxeVazhslaAnawNMmqyBJUR1mkM3EaGziRkMlBW79fxFj0egVEtcGgJxyuyhYosaoAgKYrxqQYYjHEbtUF1VpaJJlUd4vJbYvDi16KPTFa+ei0E5S/wb+LzXgk5p0bq6087UdRETRmTzRfkpTiF/26mmh1YxfDDr5kLeAwFSxx6mwEMMOiNmxZWV5trSsSCTDVBe2EQe6c1cL69elajx0sM2JVbTGaFI1Gz1iAj/eY0D6QZgzpuiKHCFB7ljXJIvZEjIYWHaoIC20dhFuLqIVovDEl3vUFT0yxcwP4VG1Ya+PZwZcSPllXwEBPWY7W1/sQmBG9hsNVmfsH8OQ5dF7aqaXDytp5tDVbS+3XG5hadYsdKixl1ajiV9WdOK0qj4WXshxFHStMsmi+SzDoycRdgJds49Yf2ZRDjUHUQkQERL9w22AbwpZ6HBE7+NIAKQoKLEPg9GlPiYQcDlfV1BQjL09NTTFN6xWxJ15Br1q/RG4UzG7mHE0tODANO1hayqrIgeXxWLureVr1EY+HwuEqcnzA7xfr630GjgIVgZLNT7Rahtw3iJ49SbUR6Mkpfq1qG0J28CWNnCr8VUgZrRLEReeJS7uLXxaIoaGijJf6oANwTfyrOiYcHVRmyb+7d8vbtlWtX6/Q6+rVeWvWuBYtkpCGqP8uikqTEw8r4d0vRFFxjKKm6JlLalPZplXHs4OlpawK2d/zjYSJLEdJhq2oyP96m6s+4D/0WQi1QLUEinydMSlm3G0npeiGsQ8rK/16XZWyGMkOvjSFikYVWL7tOfa4Z+vNnvltPQ8InhFXep7rU/z5ILEBMZSJf1WkhrvYFgbOPlu+7jrf888rk7QWLMh/8knPPfdE0aoNPG2upfZvaGo2wzTsYNmSWZVcr7152PrTXfj/WlDe/x+fT1qzb8GezAkUQJmlg2dKk1P8uA8L4Z4dfCnfK5UCEkhucBdAgQBCHuQVQ3EVVEXhzGnUlFnbkkyWo5LkRkNbfr8YDlfZIraFC1GhwsLSthBWNdg0SLVeW+u9SmtwAC1eQvtHIB8WbrNwH1YqXLKDbyqJqvhUCkQhWgVVxVCcB3kCCAVQ4AGPkz2wkUgAOV7LyvIkya1eUKMqNr80tEAqVBg+RHXTSlaVosrEwBLP1297jtE4qkx7pnZuiW9fFdn1dlB3+3TcizeejKmi140bXdu3B5BfDJ1+g4qA+oa4I4/6d2gTM7QAFO3B0wIWnFDhxVQidvClVIdGgQAE3ODOh3wBhHzId4ErAGynOlEqr02Gpg3wpqvWMmnF0KAirQxxYktZNaQMtp4nLhXERf8lruwuftlfPHy3mEjltMKtPANX1NlCop0Qu06o7yMEHxf8buH0YeV/FarHCzV9hOAVQridEDPIxPjW2WfLV1xRNX68MjiwYEHe8OGuSy8NYZ2xGwstn+cDqRg69AF28KXUIS0FQhDygQ/5BwQQnOwfiMUk1HStqMgPBj286UqJB5QsLVSkl3NaqZtNjBQNQcgDHhFEARRCE0H0gY+mY4W3T6dphFoy3ooyQS1N1ARAyw0qKvLr632ZTxts1mKtIQE7+FJaz5wCMsgq/wAljCm1siqZLEeDQQ9qutbUFGcyodAqlXIiH3OooCmalW1V7eZaMsgBCLjApepYySDHQ3G0GKnZM3xoimFtmng8VFvrQmtna2tdHKYZmpcdfCkVy1wBlX/ADW4JHLd4OhyuQrO2Kyry0xotoDRjC0uWOSpSGYQtqyKpiEC/8nzldXtfEV9x57vxcHx5frlf9Ac9QQee4YMcrximvOmaCkPNxrODb7OiUQILFUD9MDx/ALlfZXDQjn+oTeD1CnxEyxgeFqJCJcg8q0aj0ffff3/Pnj04x4ScEASBPHyCPEUSnz+xx7OnQqp4NvQsHnh1g5vGP4AF2RxA81pw09VgQYHNiuWKOHbwBYDGxsbVq1dv3LgRWUN7woq2C2WJ3aIQ9YGvGIqRm8tp7tdEQuZuAeOKZgdLk6za0NBwww03jBw5sk2bNv/+97+R9jEpphwQJHjxgs5mW6Bo5qDKP2Bsi2zdRU1X5HWtri7gcwbpK4IdfAFg3LhxhYWFF1988csvv6x7wgojVsXFR+5XF7hwK8FR7tdIJID7W9wtgGuNKSpMsuq//vWvL774AgAGDRr0xhtvIF1RW5XUmz6Mvvy4Y4W+/I7qWOGy8B4WNgVlgB2rNjQ0LFiwAAD+/ve/i6Jo5oQVyjLQJdO6Xx0yPUuWo2iogLsFcE2yg6VJVkWaJRKJK6+8ct++fRYqigdeyfkDDlz3wntYuNKbDbCDLxZ93333ffDBB5QnrOCn2AVU7leH+Ac4aMkaZwdLWlYdN27chcRvw4YNADBz5sxXXnkFKyrLymGWFuqK5g/gjpUz3a984BUDQBtAeLAQEjt27CBgeOGdd94JAFVVVaIoJpNJ3RNWLIeltpgGMdrlW25wZ70BS4K2FQ7DWg5LFQBoWbWxsVEmfslk8oMPPpg8efLRo0c9Hg/O1ML3B+cJACEI4XUveZDnwHUv3C1A1pcqbCEqkskkAUO5sbHxq6++GjJkyOHDh1euXPnqq69qD/5h6kFTldT4ktx/AM3jzu4CWewW8HqFVjiD0EJYquqdllVVj1VVVf3whz9ElP/ggw/iu+wURSKQ+xWvL3BIxwoXn/ewsCnIADtUhMPh9u3bIxx269btxIkTaR/8QypqVxgPcKFxWrTDS7bGuMhhWLT4pZWs0WIHS5Osmgp+7BRVScTuV2f6B8geFp8tYBsqEEicf8IKCWaViyCLDBuPhyTJjWYQ1tQUt3jcsoNlrrIqiUtyehbyD1RBlRPmD3C3AKomdvAlYWAQzroCBrqRt9AWBHgPrTzIE0H0gMfmdVzkzlg2HKhFWsDOMDtUtARWxTWhmpjtkI3dSLdA69wckx18cdUbB7KugLF6undRGxav9kZ+WDTSZc+UGNIzYM95hbp2YBfJDhUtilXJCiBnDjpkZ2KyCdCqNsdkB1+yxg3CWVfAQDeaW1GIIjzjEYV8yC+GYtSMZd0tI3cdKoIbun4AACAASURBVCvLQ86BFrDxEDtUtFhWxWDFDVjkgUVbZ2Zx73dyhyG0RqsFABRbWzfADr664rSRWVdAq1ImMRJIaLEsGuxC+227wOUDH1NfATqyCJ9XWF1dYHwiXCZltOFZdqho+axKVo9qi8LsMmwsJuGdsSgP1CTLkkNhdvClNELWFaDU00QyGWQJJA94iqGYJFnWLdlIJIDP3EQN2JxjWHaoaF2sSqIWYVHVpbJ/dgvyXuFjM1rk4AA7+JIVahDOugIGull7S5dk8ahXFVRZ3phVnbmJz42PRAIOn6HFDhWtl1VJNKvGXvEM7QAEWDutsBpaem0xe2Gwgy+2nnEg6woYq8f0LnIXuMGNGxDIY4AaswEIWLhdHGJYSXKj/VzQboR+vxgMesLhqlhMcpSzix0qOKuqIY3GXvEZnOgUI9yfUqdmcE3Sq9cr5Lr3yglLm9i9Pwzqn22WUYiiXpoLXKl41qr2bCwm1df7EMmiabDekzsr+09uahcMeoJBTywmZYtt2aGCs2ozINZ1WtkwMoDUIr1XFRX5tbWucLjK4R0rrUHZwVcrSzcm6wroauWQyFQ8mw/5aLYsGgTLfDpXIiHHYlI4XBUMemprXX6/iPbVRFSL/q2uLkCcW1NTjGhX9S9iYe2/KFtV4mDQgzgd5Yn+xfzODhWcVdPAtq7Typ45LvF4qL7eV1NTjDCBGLa+3pcTp7+wgy9l5WVdAUo9HZIM8awPfMhvgAfBkGcM9duQi9YS/xhiW0SUmBYR7ZJs6PeL6GwukoXJsCoxvsR5ogDyRcRiEjtUcFY1j2SSZPGRnExHBpCuKoZFXgJJcjvQdYUUZgdfysrLugKUejo5mQRSAAIe8CDXAZqniLfrJFu1FjpqmRqEHSo4q1pZceTIAIYdbsxaOzKA9JblaCQSCAY9fr+IuzZoHLa21hUMeiKRQLb8Vtiy7OCLRRgHsq6AsXq5exdTrbZVixwILnB5wIMatpn7EKw1FDtUZMqqaCd2XFp2imIRORRo1mPFYqYLdl2hHhDZRcJOK9wnQpyLvVTpDtHG4yH8LA7gzFGgpqbYBlSUl5ej3dNtO7cqh3Bos6ohCKHmBZpFK4KIWxho7FcEEbkRkMfWqsGxdIvJDpYZseqSJUtUmqku0y1ni0+v4lmMNuQ3cIMbrUG0vA9FOq2w/147VkBSsOkw5m5E67W1LtaokCTp3HPPrayszMq5VS0etFYVUMu2pMcWzfcSQUTNWxsIlx0szbPqt99+O2jQoLPOOos0OjtFSSktKYycsz7wecAjgoj9s/irzo5qVWYkBw1ww9M4QDkbgSkqGhsbhw0b1qlTp8rKyqyfW6UyKb+ksQB6BdBkG9y8VREu8icg7y12KWTYyGUHS5OsmkwmR4wY8fXXX//gBz8gDcdOUVJKiw+jr7oHPKncVYhqAxDIEFj2WJIpKmbMmOHz+a699trKykrnnFtlj2FbvBRMuKjZgV4HcpotGi7DnIveC9Thk0Ay7vOxgyUtq6rOrZo8efItt9wyc+bMs846C5+xmt0Dglo8wsgOlKpVi6a84C+5BJJD2NbyA4JU51b17du3a9eus2fP7tChw4QJE+6+++6nn34aACZNmlRUVIQgwWHZUl8NFeei3p721RBAQB427F6wHJYqC9OyqurcqpUrV06bNu2pp54666yzZs2ahTNlR/9YBA+QFkDAQlNe0Jec9CFgtiXbtvYPxVqICtW5VTU1NdNO/tq3bz9mzBiHn1tFVhwP22ABNIyBh86we6FpAE2gZb90Vc0o32PHjnEPQLoWtyc9ybb4G466S+hf/PX2gAc7qox7TKY1t5BVU+nQs2fPyspKWZZz4tyqVKXg8XZagB0sM2JVrQnYKaqVxWPMWQB5EqqgCvtttY6qAijA01884EEOXNOcazMqcuvcKnOVyJ/K3ALsYMlZNfPaaTk54B4TasCiVTRazk13cIAdfClNn3UFKPXkyey0ADtUcFa1sx5zWxbmXNWArGoSjO7gQHZLzu79yW65uPRMLMAOFZxVM6kX/uwZFlDRLh4cYAffM8Snvsi6AqlV43eyZgF2qOCsmrVKbT2C2cGX0oZZV4BST57MTguwQwVnVTvrsZXKYgdfSoNmXQFKPXkyOy3ADhWcVe2sx1Yqix18KQ2adQUo9eTJ7LQAO1RwVrWzHlupLHbwpTRo1hWg1JMns9MC7FDBWdXOemylstjBl9KgWVeAUk+ezE4LsEMFZ1U767GVymIHX0qDZl0BSj15MjstwA4VnFXtrMdWKosdfCkNmnUFKPXkyey0ADtUcFa1sx5bqSx28KU0aNYVoNSTJ7PTAuxQkRGrHj9+fPXq1R999BG2BTtFsQgeyDkL2ICKTZs2lZaWAgA/YSXn4JEthdnB0jyr7tq1q6CgYP78+eRmFuwUzZbpudzMLcAUFUePHi0sLCwpKfn222/5CSuZV1bryYEdLE2yqizL11133bx58/bv309WAztFSSnGYSfoAABOUMMJOrA2xSOPPPLAAw988803yWTSySestIa6MH4x8d0WbwqTrLpp06Yf/OAHw4cP79y5M3nMqhPs5QQdWFMJBqhxoMWborGx8Sc/+UlBQUGPHj3Gjx/v5BNWWnxdGEORvNviTUHLqqoTVmbOnNmlSxcAmDt37tVXX41M1tDQgI8u4AFuAWyBs88+m3ypMgmrTlgZMGCAIAj79u3bvXu3IAjDhw/XnrDCYYkrggdIC1gISxWkaVlVdcLKrl27zjvvvOPHjy9evPiuu+5SZcovuQUYWUB1wkpjY2Pnzp3Ly8sPHjzYrl27+fPnjx07FgBGjx69cOFCRjrwbLkFjC1Ay6raXFwulyiK/fv337Rpk/Yuj+EWsMcCK1eu7Nu374gRI15//fVUJ6zYowmXwi2ALGCeVQEgEok0NjZyU3ILZNcCx44dO3r0KNaBnJSCI3mAW8A2C2TEqiott2/f/vXXX6sibbhMJBKrT/4SiQQWF4vFFi9e/OGHH65atQpH2hPQ1cce0QDw+eefv/fee9FolJS4cuXKxYsXz58/n4y0J3zo0KHPPvvMHlm6UjgskVkaGhree++9zz//XNdKTCN134gsvqEAwBSWlrGqx+O5+OKLyfkATOuJzHz69OklJSVPP/30M888g+NLS0t79erVt2/fzZs340h7Arr62CO6vLz8tttuW7JkSb9+/ZLJJBJaU1NzxRVX9O3b9+2337ZHDSxl48aNPXr0QL5OHGlngMMSWTuZTN50001Lly4dNGhQeXm5nVUAALpvRBbfUNawtIxVAaBPnz72s2o8Hm/btu3hw4fD4XDbtm2PHz8OAI2NjV26dBk8ePCWLVtsBpCuPrbpcMsttyxbtgwAunfvvnHjRiR3zJgxPXr0eP/99zHP2qYPAEybNi2LrMphieq6urr6qquuAoAlS5b079/fTgDovhFZfENR2ZnCMudZddu2bYIgJBKJEydOCILw1VdfAUAikZg/f/6YMWPOOeccm7s8uvrYBuKf//zn69atA4DevXu/+uqrSO7atWsff/zxCy64AK3ptE0ZG+BLU5asfOx1YZBFWJaWll5//fUA8Omnn7Zr147GblalcZopbIClSVadN2/ehcTvhRdesK1RoJqx2K9fP0EQZFk+duyYIAiSJJFoKCoqmjVrFhnDOowmTqbSh7X0jh07rlmzBgB69uw5b948Uty8efMGDBhAxtgTZtooUBVBNat6w4YNtsFS9UY8+eSTjoLl3Llzf//73wPAqlWrOnXqpLIb00vjN8L+NxQVliksTbJqIpGQiR8aJrr++utt8ACoZizKstylS5d9+/bV1dVdeumliURi7969yWQyHo8DwNixYz/++GOmoFFlnkwmSX1s7nSPHTt2wYIFSIe9J3/YFAsWLHjkkUdU2tpwWVJSYpsHQDWrGhnfHliq3gjUw3UOLPfs2XPZZZclk8l33nln3LhxNtQ7FqF6I7L+hiLFmMLSJKtik+HAihUrLrzwwoEDB6p2BsAJ2AU+/fTTIUOGDB48eM2aNdu3b+/QocOGDRvatWsnimJJSYnNvIY6WVgfdqXWzXn//v39+/cfP378jBkzEolEhw4dtm7d2rFjx9tvv/3ee+89fPiw7lPsIgOBwLXXXnvllVeuX7+enRSDnDkssXGeffbZP/7xj7feeuu3336LI+0JOO0NZQ1Ly1jVnurhUrgFuAW4BRxuAc6qDq8grh63ALdAjlmAs2qOVRhXl1uAW8DhFuCs6vAK4upxC3AL5JgFOKvmWIVxdbkFuAUcbgHOqg6vIK4etwC3QI5ZgLOqToXNnj27uLhY50YLitq/f39BQcEXX3zRgsrUYosycuRI1ZqOFlvUkwXLdXA6glUPHjxYV1e3a9euurq6vXv3HjhwgB40x48fxxu8njhxYu3atXv37kWP79mzZ+3atbIsA4DqlnH+X375Zb9+/Xbv3k1ugmX8CLq7bdu27777LkPpwWBQkqTdu3fv379/9+7dR44coRGN0oRCodraWsr0Q4YMWbVq1aFDhyjTmxCRVs7OSZxJFZAYOHLkyOrVqyORCCrav//9b7/fj8KqW8Zld7vd06dP37Nnj3Ey1d1kMrl+/Xo8X9tAOnlLlYnq0qpXVZWt9tIcOEk20OZpW4wjWHXdunU/+clPhgwZ0rNnz4EDB9JvrVRRUdG/f/9u3boBQDKZHDZs2NKlS4cNG+b3+zdv3jx06NDFixePGjVKdatZ43755Zdt2rR57rnn7rnnnmYT4wSPPfZYu3btFi9eDACZSH/mmWe6du3arVu3P//5z7/61a/o99x68803f/3rXz/44INYJePAHXfcMXTo0IEDB+JX3Tg9AKQrotkMnZnAdBWQGPjuu+9uvPHGioqKm2+++fDhw6WlpVOnTp0yZcpbb72lutWsEdxud/fu3e+///433nij2cQowYEDB0aNGnX22WcfPHgQAAykk7eazdySV7VZKQBgApwkG9CIYJcma6y6b9++TZs24Q/pnXfeedlll+Xl5d1xxx1plXbz5s2IVQOBwOWXXw4A77zzzogRIwYPHvz+++8DwCWXXPLPf/6TvKWbfyAQ+Oabb9CtL7/8sk+fPgDQoUOHtJqKAwYMQKyaifTjx4937ty5U6dOV1111Z///GddbVNFzpo1y4BVVTYfMmRIeXn5P/7xj0cffTRVhtp4YxHa9DkRc+LEicrKSrz2LJMqwBh4+eWX77//fnTcy+uvv37RRRcdOHCgrq7ul7/85Zw5c/CtN998U2silT5ut3vatGk7d+7EZ8RpH9GNadOmzcGDBxOJRCrpKsXw+0jmpoJN5q8qmTkORyKRioqKEydOoBhz4MRsgLPNSiA7rLpw4cJ77rln7ty5Dz300Jw5c+Lx+Jo1awYMGDBlypQXX3yRNMTOnTvvPvM3Y8YMMgG245IlS6699lq019lvfvOb7t27//Of/0R74k2ZMoW8RT6OGrkPPvjgM888M3HixA8++GDWrFlffvnl5Zdfft9995WUlJCJZ8yYcaYud+/YsYNMgN+oTKQDwOTJk2fPnn311Vdv376dzH/58uUqBZYvX04mMKA8rc2HDx8uiuKwYcPQRl8on0xEkJrkUDgSifTr12/RokW33Xbbli1b3nrrLYMqoMfAhAkT0EdxwoQJDz30kCAIDQ0N4XBYEIT7778f33r88cdVttLq43a7b7zxxsLCwiVLluDE8Xh83LhxJB7Gjh2Ltr/AaRCrIqG60lWKxWIx/CwKaGGT+auqEoG2Wr/ppptWrFjRr1+/8vLy9evX64KTng20IuyMyQKrHjhwoE2bNt999108HhcE4d57700mk+vWrSstLU0kEqqvZTKZPHzm79ixY6SBMKsuX74c7SD54Ycf9ujR4+qrr0Y7jXbt2rWkpIS8RT4OACtWrEBNgNWrV6Pt8o4cOfLRRx8hUiYTHzt27ExdDqu0xayaifTjx4+/8sorr732mmo/fwCQZVmlAPIaYyVTsarW5gDg9XqnT58eDAbx45mIIDPJrfDEiRNRa33y5Mk//elPv/jiiyNHjnz44Yc+n0/rWKfHwKOPPvrwww8DwJ/+9KeHH35YEITDhw+HQiFBECZMmIBvPfHEEypzafXZu3ev2+3WHrTR0NBA4kF7tAxi1Ugkkkq6SjHyoBoAMIDNvn37VOCnf1VV5QWAa665BrUPfvvb33bv3v3o0aOBQOCpp55S+aYyEaEVyi4mC6y6fv36a665BgCOHj0qCMKuXbsSiYTL5ULEpyrqN998M+DMn8vlItNgVpUkCW1x9sYbb4w++Zs7d24ymbz44osrKyvJW/F4fNeuXTiT5557buLEiQCwcuXKiy666MSJE3v27LnnnnsQ7nEytKX5mboM2LlzJ5kAs+ro0aNNS3/99ddLS0snTpw4adIkMnMAWLZsmUqBpUuXkmlIViXbuVqbb9++fcSIEUuXLu3ZsyeZQ1oiyAdzN9yvX78VK1YAwBNPPIEcUKkAkBYG3nnnnVGjRgGAKIrz5s275JJLdu/eXVtbe8kll8ybNw/feueddw4cOBAOh7EBtfqsX7++Z8+eqJWAk8Xj8cLCQhIPhYWFum3VZDKZSrpKsWQyaQ42AED/qgLAjh07cINAluXzzz8fjeldd911brc7kUj07Nlzz549P/vZz/Dwb7oisKHsD2SBVROJxG233TZ16tSioqIePXpMmTIFACRJ0mVVY4ts2rRp4MCBF1100fjx4wHg/vvv/+tf/zpo0CBJkr788stbb711+vTpKH/y1po1a9q3b49zrqur69+//1NPPXXvvff27t0bDQjMmzdPy6r4Ed3AlClTOnXqdMMNN6xcuTIT6YcOHYrFYsOGDUt3Ms277777m9/8plu3bi+++OKRI0d+/OMfY9LX2lyW5f/85z+vvvpqUVGRbnF0I0kRuglyMXL58uUjRox45JFHRFG86aab0LbfJgAAACQGvv/++379+pWWlg4ePDgejy9cuHD06NFFRUVer1d16y9/+cvdd9+NTaerT1FRkYpVcXrdwPfff19UVHTeeecNHz589+7dBtLJW4xgAwCqV7VPnz7kyNukSZMee+yx++6775ZbbrnrrrsOHjy4b9++mpqaLl260J83qhKhaxZ7IrPAqsiViXoraFdK06yaPPlDm/+jbCVJQoesAEA0Gt23bx+yYzKZJG9NnTqVtC/aZBoA8LMmXirUW0wmkyhgWnoymZw8efLUqVPTPdEed1dR4Pnnn//+++9xMZPJpMrmH3/88eDBg1977TWcptmASkSz6XMlwdGjR9HbmwkASBwiQ8myvGvXLtxTrq+vxy0v8lZDQ8PMmTNJW2n1SZdV8auBA6mkAwB5iwVs0LuJ7IAsU1FRUVZWRha5oaEBJUBVsGPHjhtuuGHOnDloDgOZMlUYlxSjNFVK1vHZYVVtqYYOHfqLX/xi9uzZ2luWx+zfvx+1R1Ll/PXXX//v//5vfn4+i/NZm5X+5ptvCoLQpk0bFfWn0lY3PplMGpNyTU2NIAg/+tGP/vCHP+jm0JojmQJAa9i1a9ca70q8bNmyyy+//MYbb6yrq9M+bmGMbbB57733sAdAq39jY2Pbtm0FQTj//PNVPg1tYgfGOIVV0WcKf9Wzayn00cOtzuwqw6XbbwGnAQC/HQ55QeyvkdySaJ5V6+rqFi9e/O6779bU1ORWmbm2LdgCHJYtuHJzpWjmWXXkyJF9+/YdNGhQWvPkc8UuXM8ctQCHZY5WXEtS2ySr7tq1q23btg888EBaa/ZbkuF4WRxoAQ5LB1ZKK1TJJKuGw+E5c+b07du3Y8eOqpnDrdCIvMgOsQCHpUMqopWrYZJVkdUSiUTnzp3J7T8MxvVsM7QTdECLlGwrcipBrdMUHJap8MBhSVqG3dthklWPHz+OVpd27dq1vr4e6drQ0CDwH7eAngVINLMLc1jq2Z7HpbQAIyiaZNUXX3zx0ksvHTly5KJFi0jNBMFkhmQmGYadoAMANK9GIAAezxl/kpRh2VWPN6+D6gE2l7apwWHZbAXaVhcGmjhBB6o31KAMhrfMk+Dhw4e1i8kcYi/DIjvjpiyDIEBBAYhi019BAeTlOUM5i7WwExUclkrluVwQCllciy0uO3awNM+qukZmp6iuOIdGut0KrI1/gYDCqifPKWhKGI0qMVVVxs/l4t2soyLrCthaax6PAiS321ahOSiMHSo4q1oHh2gUJEnhU0FQM6ZWiMulNFFVP5cL8vNVcS3gkh18KY3DRAFU3ZKkVLpz/tDXOj+/RQKJsropkzFBxUnZnFUpq6C5ZNGo0n8XBOXfUEgJGLc68/MVj6rqhx9M9ZaSbVvVsw6+ZAdfykIzUQBVN/qCOupfUWxCYDRKaZ/WmYwJKk6aMrdZNQCBM4d7VKM/OpcBCDDBkCQpTIp/xcVgcEor6uzrer6Ki5V8Uv0161jACjgpwA6+lKW0XgFU3U7+yOXlgc9HaZ/Wmcx6VJyyI0EEp6Iy+Z+dolqtZJAFEAqg4NRwDx73SRkogII8yAsBA0e+ilWrqs4gWZX2Pp+ZgSmPR8dpoMrZkZd2okLXANYroKpuXanZjdR1MWVXJYdJtx4VpwqYw6wqgSSAIINyMDX9rxiK8yAvClZ3jjweZUAf/9AQv8+neNy0P+OWrDY9ikEus1R3HRzPDr6UhbZegaoqM99FSnUtSYa+66lcSbbFW1IWNplYj4pTeuYwq3rAkw9pj+2gFq4EemR3yihm/tc2JPGwldbBmp9vpneGvK66fgMzGtv3DDv4UpbBegW01U2pim3JZLnJ0Z/Km2RPvIOnIliPilOVm8OsWgzFLmhuAtOpcpL/50O+D6x2Oblc+o5UUVTPcUHNWN02LKmlblgQIMDGL6wrzqJIdvClVNB6BZzPqpSmYZrM53PyVATrUXHKmDnMqqbJUQTRA5rx91MWMfm/KOqM6QMokaoZVJkMdKSSYlJpmx5jB1/KAlivgPZjSalKq0pmMCrrADtYj4pThcpVVs2kI28rq2qdoZl8wN1uNUefqkgn/88OvpSltl6B3Py8UZrLymQFBeq+mpW5Z5SX9ag4pU6usmoAAgKYVF4E0Q1WrzxJ1TfXfq4zGZw1N3ngVGVn63928KUskfUKmPOMU6rbkpJl0oZgbAfrUXFKYZPEdOpx9f/sFFVJ8oCnAIgxd9Vtw0sPeETQrGsyfKT5m4KgP9wPoAwakANWmTRzMvEeNF8GVilsQ0WqAlivgEF1p1KidcajVgXa8sJh03utR8WpKraSVbdIhwRB+J/iVYOkCfRzSM2lzIM8c0NViqvTclbVNkhP2Vf5X+WDS9WqJR8xCAuCsigWrW+oqlKo3GFg1erODr5aWboxaSkgSW6vV0B/ZWV5sqw3CY+zqq6hdSNDIQWleXn6Aw+6j9gSmRYq0tLISlY9IkcFQbi5+GtBgCL35nRXPaWb3vRkfutZ1XhOODlglfnsqOJihabRH1o0mZ/vcGJlB19KrKelQHV1QW2tKxaTYjHJ6xXCYc1+N7nZY6C0FatkHo9CrE5qAaSFirTMYiWr4i0L0QRksteblk6sE2fik9XXTTskRabD87GjUWVeFLmwlUxmLoymJaqmGZjLitlT7OBLqXJaCni9QiTSNH3N7xclSeOCN/6IUurU2pIhoGr3vsieHdJCRVpqMmFVtMGjY3dfQouy0jJTM4lVC6tUqU9uvCILP/QII5S/m+frbE+QbkOdTP9aRMn28a1ktj4fOGdvDXbwVVk61SW9ArIc9XqFeLxpTbMkuf1+jQve+QurUhkiu/Foi0K91Qen3w70jtjyLz0q0jUbK1ZFWzg56ct02jJMWLW51qLyJrZLiIMaxLsTuAdvWeDaWrHTv8jckG/AIfZnB9/TlWoYolcA9fpxZuFwldereUdIlw5OygM0FkixUtbzUijvIll5O2z8o0cFTcnINBrEkDfTD5OKIkdK+nkwfyIKUQEE025ZHf0o1vWzfRP1HAvO2ayVRIWO9dhH0SsQDHqqq0/PLYnHQ2TTtUlTtnXJ3hzOk5CVedj0qEjXYAxZFa3MdKZ3VQDByq0AKCZLsX0T0SSEM1fBOsf7xw6+lHCnV6C21lVTU0xmqzNgJYrNn/VAZsHDzVmA4gVqLov079OjIt28GbIq8q421zNOV2Fr0lvMqgUFzc4aYf411myDrce01lgv3VzYwZdSE3oF/H4xGDxjNbPOgJXtHBAOVwWDHso/7BSmNI4TktluUaXQ9KhI10RWsmosJglC00Q/POMvtwJlZXlmQEkxe5E5bvSWbDV7IkG6cDGXnh18KfWhV+B0y9TnQ5OCpcVF/qW9miYIowFBzQeMUg0TyeLxUHV1gdcr+P0izV9FRb6qrW1CqP2PqBbK2KMAPSrS1cdKVk0kZEEQ0EQ//O/110szZihT/xz1Ny42aFHsJa1K1dUFOjNpDI0aj4fKFpz+lpSV6Z+TypxV9fbJZi7U0DL4Jjv4YhHGAUoFEgnZ61UArEyrPHUCbuSB/tltGVRXF9B/6YNBj86kBWPrOOAuRbPEei0pUWFCsJWsqtuoRi+7c2b5IBul2mBFktzkYAWNQas/u776r0Ls4LZYTEJDxrqrcZgTnN76Lr32K02ZLE7DDr6UilIqcHoCwJnz/OPxkPYDbFsMZRlRslxk1Uy2xkzLOKrElKhQPUVzyZxVAZQtFp123lIqVo1EAjozaVIbMhj0KGPEF5w2IzmHnHwuw3WqZFYpwwUFqh2tjOfRpszH6hvs4EupKamALEdTOShraoorKk7ug+7xOHljUINS19f7mopgkMhht7I1rEqiwlqTnKYDS/LVVRRN+zlzgNoSaeYzcYNbd4OV031AirwTCbmsLC+4rkRZinfqpx3uQHfs6OMgeBLbWmcLr6eM0fS/LipUaZhekgr4/WJFRX4qH2XTUBXFVDmmCpvOlerFLAAAGvhJREFU/HRz23QWtj+YLZSSqLC20OZZNRgMzp8/f//+/aRCqRQVRfXOTeRT9ocNtgKori5QjQKnUi8Y9JSV5SU875ItxNpal65jyw5WxWva0HlZkhQ9IguCcoxxdn+pUMFCK2NYItJRPKfGv5zd6C8XWTVbmwWyg6VJVq2vr+/du/cnn3zSq1ev+vp6DFEDRd1uZQAgP1+hIHJtpf1hZXQ39bZV+osUcQmJgNJQDXqUTXmJ6WP19T7tgBXaUwU7l4OeYK2rNibFiMwsCsqyctALcVS94nkQuiumz96fASosKnZTNs3CsqamWPebd4Ya2fLznaGEyQvEqolEekdkmhRm0WNsp3KnVpIdLE2y6syZMx9++GEAmDBhwt/+9jesubGioZByCB4aQiGXV9ocFgRYLG3Og9Pddqw/ACDXairXG46vrXV5vYIyMHXmOBSCtWrAStXHqS6oLssr8wremuKahJwgpVsZlmWQJLQE0PNSqGrxt1Llvqz8GaPCwiLrwlI+uZUaqrjTE6cMpKpqyyClI281TWNwpG66Sp3ZLNFNwiSSHSxNsurQoUNLSkoAYMqUKcOGDcOFZqcoFpF5oKAAXvKEUh0lkEjIqEWTyvWG45v2iDuTVQFAO2Clek+9gjcmxeKheFleWXVBdeYlMsihqkqhfVHMYlOV4XRrVcF1YRmPhwShab4n1bQ5h4zxqcpGfZlzrKp5gaiLmllCdmRlklVHjRr19NNPA8CkSZOKiopQ6WRZma/KTtfMbHj6aVGEv7gPoeVVkrKhrtGfDDqdKTT7Vo6evCUIPqmUTLZ+1aBdGxadlgfKUQB4QCshJxCrAkA8FMdhMn2LCSM82AYJXVhGdkaQGvFQnMawgRkjPEuGkJuCUYat3FmCRlEiTb2vHq+98j7WZ/fcrfiSMkBpHEKmZUH7WZU1LE2y6oIFC8aOHQsAo0ePXrhwITawbe8Plmgi4HbDUFHOgzwaX2MxnLEqHAAkt4S2iveLfgCItlEcluSuAusnvKniStJzFJNiXsGLO/4V+RX1vtOOaRPFcf4jtqFCF5YJOaG0VUU/ZbegoOL/5UcuObUxOK13Kh/ytVCxp2oigYhX8OK1V6v7Plt1+1J8SROoyK9AYLZHYZWUbK0AZAdLk6wqy3JhYeGECRMKCwtlYn9vdoqqaiKTS/oeHtrfmmyHAkB1QbXklsJVYa/ghVCo6ncKq1bB6R3j/+/3H3sFb1leGaZOLati/WuKa2pdtfiyRQZsQ4UBLFG3oNkPmBw9onwj91WmWxEe8OTDybmu6T6ZcfqgJ0hyYqq5fQZymsBskILlLZumx2iKwA6WJlkVadjQ0KBSlZ2iKkGZXOptm6efHzofOwBNO8MDgByVvYI3Hoo3NTl37naVKKzqgdNbcngF74a5xRX5FZK7aQYPucYp6AmSjSbVpb4eOR5rMypSwTLoCZbllRnbsuqb+akc7sYPok17VR9g40esuusX/RhpAGCCVTGqrVKJPp8s7gHEDpYZsarWduwU1coyHYPGjogWtlFOBVDwQvQ17HkNzK0vu7wCzZFSuvmr/PlfNLFquCqckBOoTfTpio71vvqK/AqUNek5UrUsVA4BI1UccC8hJyryK06dlUe7Pj7rqEAKIFM3ecNTGNP1xRBx7S9S3FRHJ+QE9lru8ezp4+mz1ZO2QxPngAORQMRYSZUeZXllZBu8pqa4ttalStPspSqTZtNblUA1kGtVtjT5sINla2TVtOYjzgh4f5h3UCHOk39/FaqHC7Vo6Kkiv2LPpAXoziJpkVfwRgKRcFX401+sViZdnWrVolNW8bb8qpYFOXhFA4XspqkprinLK0t3qxx28KW0BlZA5e/WPp6/5788S4Zo43VjwlXhsrwy7Lh8Vnx2qZieQxM/SwaQ+0hXojYSwYyc+2xuK4BseaLcbig4vUu4tnwMYzAqLJfRGln15C4wyrl8Bj80AqDbKPvOH0GL+v2if+2fXhFAEEF8L/CeV/DWumolt7RpaCXaTAB5YAEU3JCsGvQESdEV+RWqGPKuc8L1vvpmWUlXW3bw1RWnjcQKGLfI0CER0rq52hx0Y1TdjmJlAYZ6bFP3QeNIRJSRQMQ4GbqLGuBkSnOsGvQEcdeKzI11OD9fWUaTlR9GheXSLWXVkzOrDOcpGc9isu+uOKjB89LJY8px3/7MQPClrdW/Kx98bfiJIfXddl6+aMsrtesratdX7Py8QtpXOXrM/kcm1m2ZvuYfv58m1l4rgvih50PUxPCL/t1ztyJWxU4AcmsVr+ANV4XJiqwprqkpriFjHBhGAxrm2J8dfGkMJcvHBEEZgJL2VVbe/snWl9eisPLvoS0k5jzH3lacqtQ7VqjadxYOWFUXVFOOYWr98qpDYmhMBABZ8UTp7bNGqa8FydjB0lJWlZRdq7M73ZxSuigscgsPGST2C4/XCKPQck/3Q5pSVf1OyPvPdb7r3PnuwGelIohvut6sLqhGbdv9a7YhVkU+1ngoTo5yapt79b56siNJdgadEy7LK6N8z7V4ZwdfrSxtjLSv8uQkaqUSh7uGjy8eb4BR90NpvBF+0U9+ZiwcsEKQ0JZFG6NidoUfYxKCnzaxcQzqbGH3boYB0imRSq7Pd3oed6o07OLZwTINDNEUj52iNNLp05BTnXSfUijy8SCeuq9Kgzyz/lXKzFMAZVeBV8RXUKtBIc1vv8NHyCFaxKyKeFY1FkEOemQIZXaPk+MhKms0e5l1VGAFVH125XRv1bIzYkuHZsuFPOk4GZoxQs5cxrfSDWi9paly0LqPTLOq5Jas+oqjNdl4ZmEq5YuLs7lHKEZFKvVMx7deVjX2kXsF7+DfxQy2hS0uhnuGKrOsYlLMAx7Ur0eeR7Ro9YknJFGEcYMU5m0nxNCUA60XzHTN5dCD7OBLaQSsAHKXq58inT+UU0MAdIcZ8yHfBz51/qaucddH17lPRqpahWmxaiDQtKCZdrUD3eqIEXcnFp9X9mSvoHG22Zr/jyoEo8JU/Rg91EpZ1Xg+B2pRXiDEDUa0QiFl/y2v4H2gf6T33bu9gnfcoJgoKlQrispWAIMHS2g7rqW9/N4+fjRuLrmlrIwJGEGA/T128KXR/eSGYQJ6vdFHbsTdCeO3neYuykqVspP4r16i8jXN/O+eofK4QTGaP5WsESOUc2LGjWtSo9hw/MztVmDMYt+4Dx5XxjbfmxFZ9FIs1Z93rm0nKugIYgfLVsqqaGs+jbu0ydHaTlAamKm6/+Sb7O3jX1wk/fklZQonCU1yh4uYFEM7VKH2hfMHpsgCWhJmB18a9U4OiQi4dryCd9FLMXxpOvB+SXhF2zLV47087j95qlSR9l96vcKiRcpH3eVSII23oNSaSxQZDsHTN7fJprdtYXawbKWsCqDs5Uz2/Mjw1peC5b+rNsAiRicaVXi/6v3FeYtxJPIANL81MvlAiw6zgy+l2UgFyvLKVHMwKDNRJVO7aE/eTnVyj+pZ1pder1Bb60KbH/bp49m6Vf/U60gkkLPbc1tgQhIVFmRHZNF6WZUwgjpY66qlbFGiUYXl+ctfEF8gc6moyKc8UIB8CofRYcW0S5ds+7ibFcQOvthixgFSAdXAvfGDBne1g+/Kcg8QybXLBo8zvYUOpEBbVj7+uFhZqXPqNcIYHkdlqo8zMydRYa2GnFV17JnWi1dTXOMVvMNdw8mMTKzFxo+jg1ojkYCOKyjdVU3OSM8OvthoxgFSAatmB+uCxAUu3fPQjNVjepdcgUIKisdDXq9w7rlRmj4Z+WCLCZOosLZQnFV17JlWJxFNj+/j6UNmlAmrVlcXmFjHTUp3WpgdfClLSiqA6qumuCbDL45qWhXSxODkHkpVLU9G7kGhytzrFdq1a+4IL9UzLeiSRIW1xbKSVU9Od1c2ssz1P+1EfWOjV4qV50bPJdOYZlU0LaaF+WTZwZe0uUFYpUBMipnYI0bl/yjLK1PNO0Yzl53WVjU4LnbFiryRI0/vYGlgwBZ5S4UKC8toJavKUeUsAHYT0W3LOd0Z72hRDVkrplmV6rg6UlIuhNnBl7L0tingwLaqwYKXd98Vn3vu9A6WlMZsMcnYocJKVj25a4nFGeZEFWpZlf6gVlUBy8ry6uutmUauyjmLl+zgS1ko2xRwJqumWvDywgvFH32U9p6BlDZ3fjJ2qLCYBNkp6uRK0i4AN7dvkCxHyYmuTi5yWrplHRW2KYAOj0jLOKwTGyx4uf12zyefiKwVcGz+7FDBWdWaSlcdXWWOVdGh2dYo5KRc2MGXspS2KaDttVBqyC5ZKlaVZejTx1NWlp1TYdiVlz5ndqjgrEpfC0YpLWFVc1xspJYz7rGDL2X5bFPAgayqe4SJz6csu2rXzuTuVpRmd3gydqjgrGpN1WtZtbo67S3O/X6R6sB6a1S2Lxd28KUsg20KOJBV0R7t5J6xaLm2KMJrrymsmkjonM1OadicTsYOFZxVrQGGilXT2jcIa+D1CuFwC5zpwg6+2HTGAdsU0HrYjRWz525eHlQRsEI7qiDRLdKPT2lVdqjgrEpZBc0ky5xV0VqXeDzUjKQcvM0OvpTGsE0BC7dYpSwaTTLVQoCCgtM7qni9QiRieNYQjYDcTMMOFZxVrUFE5qwaDleVleVZok0VVOVBnsGO93bfEiyGWbpWYvf+aDVRIUGbwP4YcmMqlZvV9MRq+0thuUR2qLAY7uwUtdym1mZYAAXkthqUHoBYTCory8O7qNTUGO6FSadxFKJ5kOcCF3kiU3bDWUeFnQo4kFXdbmW/V/RTHWrSUl35NO8KO1SYZ9VYLLZ48eIPP/xw1apVuAzsFMUinBlQbVaEWLXZcQC0txDeRaXZ9DRlF0EsgAIZHDQEYScq6urqFi9e/O6779bUnD5g0U4FHMiqPl/TxsH5+coe1eQJF6aXq9BA0eFp2KHCPKuWlpb26tWrb9++mzdvxuZjpygW4cyAilVptlhFc/6tHZ4KQUgAIQTOcs7aiYqRI0f27dt30KBBR44cwVCxUwEBhAA4zlOJtg9GjVZyPkB9vc/rFaqrC1qkQx8DQDfADhUmWbWxsbFLly6DBw/esmULqTE7RUkpDgwbs2o8HsINUhyorXVVVFg8B7sKqpSzlx32sw0Vu3btatu27QMPPHDgwAHSBrYp4JwtVsniG4cjkQDaD8k4WYZ3dV8B/C5kJcAOFSbfwEQiMX/+/DFjxpxzzjmff/45tjg7RbEIZwYMWBUN7mPnKRmwtqHqzD2T7NwdIhwOz5kzp2/fvh07djx69CiGip2w1CIBq+HYQH29z/IPPFnYYNBDwt4hYXaooGXVcePGXUj8NmzYgKxWVFQ0a9YsFJZlZc8qdrqS9eS0sPZdwjMB0TpU7deYRZ9LBNENbucYB+GBHSR0YZlIJDp37owdUzbDUosE51RHKk0oB1dTPW4cj3ZhDwY92lcgWzGsYUnLqo2NjTLxSyQS8XgcAMaOHfvxxx9js7J7f7AIZwbc4FZtrFlWloeaonauQ82DvCogJnw7w1jsUKGCZTweTyQSyWSya9eu9fX1uPTsFMAicCAXWTWRUI5lZbGrbyIhl5XlOXMXdnaooGVVDBoU2LhxY7t27URRLCkpSSaT+C47RbEIZwa0W8DhmYA1NcX2oMqZU9Dt9AC8+OKLl1566ciRIxctWkTixE5YiiC6IPe212O0ro9yMgxZWbaF2aHCJKsCQDQaJV1XyBbsFLXN1uYEIVaVQfacOlx9qb/Xh8E/ecDzcfWVKOABjwQMD7Rw5iJ0O1kVAA4fPtzY2KiqRDthqf2+qpRp9jIAAYwi2wIYrtZK/DD4p+UV/21tniZy050Vww4V5llVFxzsFNUV55xI9C55wJMHeaIy51p8trb7CzX/I4Lo9QoPRPqjaaQCCMVgwVR/3YJ7wFMAaW/popuVtZFZR4WdCmTIqm5wCyAUQAFCkW3/YrhaK5FRtmkpmQ/5Ku8cgjc7VHBWtYZA0LvkAhcmTbQCVbW6H+1qHIWoNVLPzKUYlDOKzoxzxBU7+FIWz04FMmFVBI+sTHcNBj0mdllr1v7V1QWZHOHebP40CVAfTttNZIcKzqo09dJ8GvQuketW0SR/NKeEfD4f8hkN05PSSYlZD7ODL2XR7FQgE1bVjnlSFjDzZIymATAaBEu3vKhtq3qKHSo4q6pMbfISb2hCNjSqqwvQwhUyUze488Hiyf8AgOb/6/qPSOlZCbODL2Vx7FTABz7T9ZvFiXGqThWlYY2TOWeoCjVXVdNj2KGCs6oxMGjvomoTQCB795Lk9noFv//UzhYnM4tCVADBBz4LdzzxgU8AgdzehVZvW9Kxgy+l+nYqkMmYoQCC6s2nLKAlySzfFZD14oK0So0c1uR7xw4VnFXTqpqUiTGrkinQ/H+tX6kYii3fi4+RV4EsjukwO/hSqmSnAqZZFe3hQH6VKUtnVTK/Xywry7Nwu1W0eZBV6mWeD+5QNr19zDao5KyaeWUpOaB3STvUiNcCWCMmN3Oxk9R0LWSnAqZZ1Qe+PLBmg11dI9BE1ta6rF1Oqm1S0KhhTxp2qOCsak0NondJO/1blpkM91ujtF25sIMvZQnsVMA0q7rApf0qUxbQwmSyHLVwIaklm1taWDoyK3ao4KxK2tl8GL1LPvCZz6LlPskOvpQ2s1MB05sxOnYKB6WRcy4ZO1RwVrUGDGgMSjsnzprcczwXdvClNIzNCpibxu/A7a4pzZujydihgrOqZZCogipH7cBvWcEyzogdfClVs1kBH/hMrKr0gY/jh7JCLUnGDhWcVS2pIJ6JkQXYwddIKnEv6woQuvCgUyzADhWcVZ1Sxy1YD3bwpTRa1hWg1JMns9MC7FDBWdXOemylstjBl9KgWVeAUk+ezE4LsEMFZ1U767GVymIHX0qDZl0BSj15MjstwA4VnFXtrMdWKosdfCkNmnUFKPXkyey0ADtUcFa1sx5bqSx28KU0aNYVoNSTJ7PTAuxQwVnVznpspbLYwZfSoFlXgFJPnsxOC7BDBWdVO+uxlcpiB19Kg2ZdAUo9eTI7LcAOFZxV7azHViqLHXwpDZp1BSj15MnstAA7VHBWtbMeW6ksdvClNGjWFaDUkyez0wLsUMFZ1c56bKWy2MGX0qBZV4BST57MTguwQwVnVTvrsZXKYgdfSoNmXQFKPXkyOy3ADhWcVe2sx1Yqix18KQ2adQUo9eTJ7LQAO1Skx6rHjx/3+Zq2EG1oaHjvvfc+//xz0hDsFCWl8HBuWYA1Kg4dOvTZZ58hmwSDwfnz5+/fv580EWsFSFk8nCsWYIeKNFi1vr5+6NChXbp0AYBkMnnTTTctXbp00KBB5eXl2I7sFMUieCDnLMAUFRs3buzRo8fYsWMBoL6+vnfv3p988kmvXr3q6+uxoZgqgKXwQG5ZgB0q0mBVACgvL0esWl1dfdVVVwHAkiVL+vfvj63JTlEsggdyzgKsUTFt2jTEqjNnznz44YcBYMKECX/729+woVgrgAXxQA5ZgB0qTLJqaWnp9ddfDwCffvppu3btsCnZKYpFNBtwgg4A4AQ1nKCDDabArDp06NCSkhIAmDJlyrBhwzBUnGAHJ+hgQ11gmxsEWrwpUrLqjh07LiR+d955J9lWnTt37u9//3sAWLVqVadOnZAFGxoaBP7jFtBY4KyzzjJ4x9K6pQtLzKqjRo16+umnAWDSpElFRUUclpqq4BGnLWAhLFUYTsmqyWRSJn6NjY0AsG7dOuQB2LNnz2WXXZZMJt95551x48apMuWX3AKMLKALy5KSEuQBWLBgAQqMHj164cKFjHTg2XILGFsgJatqH4tEInfdddePf/zjRYsWAcCzzz77xz/+8dZbb/3222+1iXkMt4A9FggEAtdee+2VV165fv16WZYLCwsnTJhQWFgoy7I9CnAp3AIqC6TBqqonAaChoSGZTGrjeQy3QBYt0NDQkEXpXDS3QEasqjLf9u3bv/76a1WkDZeJRGL1yV8ikcDiYrHY4sWLP/zww1WrVuFIewK6+tgjGgA+//zz9957LxqNkhJXrly5ePHi+fPnk5H2hMnJpPZIVEnhsEQG0Z1grrIVo0vdNyKLbygAMIWlZazq8XguvvjiBQsWMKoYg2ynT59eUlLy9NNPP/PMMzhZaWlpr169+vbtu3nzZhxpT0BXH3tEl5eX33bbbUuWLOnXrx/uRtTU1FxxxRV9+/Z9++237VEDSyEnk+JIOwMclsjaqSaY21MXum9EFt9Q1rC0jFUBoE+fPvazajweb9u27eHDh8PhcNu2bY8fPw4AjY2NXbp0GTx48JYtW+zBDZaiqw++yzpwyy23LFu2DAC6d+++ceNGJG7MmDE9evR4//33Mc+yVoPMHw/Qk5F2hjksASDVBHMbKkL3jcjiG4qKzBSWOc+q27ZtEwQhkUicOHFCEISvvvoKABKJxPz588eMGXPOOeeo1tSyhpGuPqyF4vx//vOfr1u3DgB69+796quvovi1a9c+/vjjF1xwQWlpKU5pW4ApfGlKkRVW1YVBFmGZaoI5jQEzTOM0U6DiMIWlSVadN28eMZn1whdeeMG2tqpqxmK/fv0EQZBl+dixY4IgSJJEgqCoqGjWrFlkDOvw7t27DfRhLb1jx45r1qwBgJ49e86bN48UN2/evAEDBpAx9oSZwldVhHHjxpGw3LBhg22wVL0RTz75pAEM7Iel7gRzlfUYXRq/EfabAhWTKSxNsmoikSAms8pomOj666+3wQOgmrEoy3KXLl327dtXV1d36aWXJhKJvXv3JpPJeDwOAGPHjv34448ZwUU322QySepjc6d77NixCxYsQDrsPfnDpliwYMEjjzyiqzPTSDyZlKkUlHljYyMJS2R8e2CpeiNQD9c5sMziBHPVG5H1NxRBhSksTbKq9g1ZsWLFhRdeOHDgQNV2QdqUlsd8+umnQ4YMGTx48Jo1a7Zv396hQ4cNGza0a9dOFMWSkhKbeQ2t4sX6WF5Y4wz379/fv3//8ePHz5gxI5FIdOjQYevWrR07drz99tvvvffew4cPGz9u+V1yMqnlmdNkyGGJrZTFCeZOe0NZw9IyVsWVl5XA8ZM/JPrEiRMAEI1Gjx49mhVlAIDUx2YdkskknrCJTCHL8pEjR2xWg4tTwcAJsMziBHPyjXCCKZjis4WwKlMb8cy5BbgFuAXoLcBZld5WPCW3ALcAt0DzFuCs2ryNeApuAW4BbgF6C/x/Cnllzj9zNW0AAAAASUVORK5CYII="
    },
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "4482b5e9",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)\n",
    "\n",
    "Fig.12 An illustration of the behaviour of training set error (left) and validation set error (right) during a typical training session, as a function of the iteration step, for the sinusoidal data set. The goal of achieving the best generalization performance suggests that training should be stopped at the point shown by the vertical dashed lines, corresponding to the minimum of the validation set error.\n",
    "\n",
    "\n",
    "\n",
    "##  Early Stopping\n",
    "\n",
    "An alternative to regularization as a way of controlling the effective complexity of a network is the procedure of **early stopping**. The training of nonlinear network models corresponds to an iterative reduction of the error function defined with respect to a set of training data. For many of the optimization algorithms used for network training, such as conjugate gradients, the error is a nonincreasing function of the iteration index. However, the error measured with respect to independent data, generally called a **validation set**, often shows a decrease at first, followed by an increase as the network starts to overfit.\n",
    "\n",
    "Training can therefore be stopped at the point of smallest error with respect to the validation data set, as indicated in Figure 5.12, in order to obtain a network having good generalization performance. The behaviour of the network in this case is sometimes explained qualitatively in terms of the effective number of degrees of freedom in the network. This number starts out small and then grows during the training process, corresponding to a steady increase in the effective complexity of the model. Halting training before this growth becomes too large corresponds to limiting the effective complexity of the model.\n",
    "\n",
    "### Visualizing Early Stopping\n",
    "\n",
    "![image-2.png](attachment:image-2.png)\n",
    "\n",
    "\n",
    "Fig.11 Illustration of the effect of the hyperparameters governing the prior distribution over weights and biases in a two-layer network having a single input, a single linear output, and 12 hidden units having ‘tanh’ activation functions. The priors are governed by four hyperparameters $α_1^b$ , $α_1^w$ , $α_2^b$ , and $α_2^w$ , which represent the precisions of the Gaussian distributions of the ﬁrst-layer biases, ﬁrst-layer weights, second-layer biases, and second-layer weights, respectively. We see that the parameter α2w governs the vertical scale of functions (note the different vertical axis ranges on the top two diagrams),$α_1^w$ governs the horizontal scale of variations in the function values, and $α_1^b$ governs the horizontal range over which variations occur. The parameter $α_2^b$ , whose effect is not illustrated here, governs the range of vertical offsets of the functions.\n",
    "\n",
    "Fig.11 illustrates the effect of the hyperparameters governing the prior distribution over weights and biases in a two-layer network having a single input, a single linear output, and 12 hidden units with 'tanh' activation functions. The priors are governed by four hyperparameters:\n",
    "\n",
    "- $ \\alpha_{1b} $: Precision of the first-layer biases.\n",
    "- $ \\alpha_{1w} $: Precision of the first-layer weights.\n",
    "- $ \\alpha_{2b} $: Precision of the second-layer biases.\n",
    "- $ \\alpha_{2w} $: Precision of the second-layer weights.\n",
    "\n",
    "The plots show that the parameter $ \\alpha_{2w} $ governs the vertical scale of the function, $ \\alpha_{1w} $ governs the horizontal scale of variations, and $ \\alpha_{1b} $ governs the horizontal range over which variations occur. The parameter $ \\alpha_{2b} $ governs the range of vertical offsets.\n",
    "\n",
    "### Early Stopping and Regularization\n",
    "\n",
    "In the case of a quadratic error function, we can verify the insight that early stopping should exhibit similar behaviour to regularization using a simple weight-decay term. This can be understood from the illustration in Figure 5.13, where the axes in weight space are rotated to be parallel to the eigenvectors of the Hessian matrix. \n",
    "\n",
    "If, in the absence of weight decay, the weight vector starts at the origin and proceeds during training along a path that follows the local negative gradient vector, then the weight vector will move initially parallel to the $ w_2 $ axis, through a point corresponding roughly to $ w^* $, and then move towards the minimum of the error function $ w_{ML} $. This follows from the shape of the error surface and the widely differing eigenvalues of the Hessian. Stopping at a point near $ w^* $ is therefore similar to weight decay.\n",
    "\n",
    "### Relationship Between Early Stopping and Regularization\n",
    "\n",
    "The relationship between early stopping and weight decay can be made quantitative, thereby showing that the quantity $ \\tau \\eta $ (where $ \\tau $ is the iteration index, and $ \\eta $ is the learning rate parameter) plays the role of the reciprocal of the regularization parameter $ \\lambda $. The effective number of parameters in the network grows during the course of training, suggesting that early stopping controls the complexity by halting the increase of effective parameters.\n",
    "\n",
    "---\n",
    "\n",
    "### Exercise 5.25\n",
    "\n",
    "**Question:** Describe the relationship between early stopping and weight decay mathematically. How does the early stopping iteration correlate with regularization in terms of weight decay?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65285f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000, Training Error: 0.792694967657274, Validation Error: 1.048789889420754\n",
      "Early stopping triggered at epoch 21\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Activation function and its derivative\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "# Loss Function (Mean Squared Error)\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "# Initialize network architecture\n",
    "n_features = 5  # Number of features in the input\n",
    "n_hidden = 10  # Number of neurons in hidden layer\n",
    "n_output = 1  # Single output (for simplicity, can be modified)\n",
    "\n",
    "# Example dataset (100 samples with 5 features each)\n",
    "X = np.random.randn(100, n_features)  # Input features (100 samples)\n",
    "T = np.random.randn(100, n_output)  # Target values (100 samples)\n",
    "\n",
    "# Train/Validation Split (80% training, 20% validation)\n",
    "train_size = int(0.8 * X.shape[0])  # 80% for training\n",
    "X_train, X_val = X[:train_size], X[train_size:]  # Split into training and validation\n",
    "T_train, T_val = T[:train_size], T[train_size:]  # Same for targets\n",
    "\n",
    "# Add bias term (column of ones) to the training and validation data\n",
    "X_train = np.hstack([np.ones((X_train.shape[0], 1)), X_train])  # Add bias to input\n",
    "X_val = np.hstack([np.ones((X_val.shape[0], 1)), X_val])  # Add bias to input\n",
    "\n",
    "# Initialize weights for a 2-layer neural network with bias terms\n",
    "weights1 = np.random.randn(n_hidden, n_features + 1) * 0.01  # Including bias\n",
    "weights2 = np.random.randn(n_output, n_hidden + 1) * 0.01  # Including bias\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.01\n",
    "epochs = 1000\n",
    "patience = 10  # Early stopping patience\n",
    "min_delta = 0.001  # Minimum change in validation error to qualify as improvement\n",
    "\n",
    "# Training loop with Early Stopping\n",
    "def train_neural_network(X_train, T_train, X_val, T_val, weights1, weights2, learning_rate, epochs, patience, min_delta):\n",
    "    best_val_error = float('inf')\n",
    "    epochs_without_improvement = 0  # Counter to track early stopping\n",
    "    best_weights1, best_weights2 = weights1.copy(), weights2.copy()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Forward pass (Training)\n",
    "        z_hidden = np.dot(X_train, weights1.T)  # Input to hidden layer\n",
    "        a_hidden = sigmoid(z_hidden)  # Hidden layer output\n",
    "        a_hidden = np.hstack([np.ones((a_hidden.shape[0], 1)), a_hidden])  # Add bias term to hidden layer output\n",
    "        y_output = np.dot(a_hidden, weights2.T)  # Output layer\n",
    "\n",
    "        # Compute training error (Loss)\n",
    "        train_error = mean_squared_error(T_train, y_output)\n",
    "        \n",
    "        # Backpropagation (Gradient Computation)\n",
    "        delta_output = y_output - T_train  # Error at output\n",
    "        grad_w2 = np.dot(delta_output.T, a_hidden)  # Gradient w.r.t. weights2\n",
    "        delta_hidden = np.dot(delta_output, weights2[:, 1:]) * sigmoid_derivative(z_hidden)  # Backpropagate to hidden layer\n",
    "        grad_w1 = np.dot(delta_hidden.T, X_train)  # Gradient w.r.t. weights1\n",
    "\n",
    "        # Ensure grad_w1 has the correct shape (n_hidden, n_features + 1)\n",
    "        grad_w1 = grad_w1  # This is the correct shape for grad_w1\n",
    "\n",
    "        # Update weights (Gradient Descent)\n",
    "        weights1 -= learning_rate * grad_w1\n",
    "        weights2 -= learning_rate * grad_w2\n",
    "\n",
    "        # Validation step (for early stopping)\n",
    "        z_hidden_val = np.dot(X_val, weights1.T)\n",
    "        a_hidden_val = sigmoid(z_hidden_val)\n",
    "        a_hidden_val = np.hstack([np.ones((a_hidden_val.shape[0], 1)), a_hidden_val])\n",
    "        y_output_val = np.dot(a_hidden_val, weights2.T)\n",
    "        val_error = mean_squared_error(T_val, y_output_val)\n",
    "\n",
    "        # Early stopping check\n",
    "        if val_error < best_val_error - min_delta:\n",
    "            best_val_error = val_error\n",
    "            best_weights1, best_weights2 = weights1.copy(), weights2.copy()\n",
    "            epochs_without_improvement = 0  # Reset counter if validation error improved\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "        if epoch % 100 == 0:  # Print progress every 100 epochs\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Training Error: {train_error}, Validation Error: {val_error}\")\n",
    "\n",
    "    # Return the best weights found during training\n",
    "    return best_weights1, best_weights2\n",
    "\n",
    "# Train the model with early stopping\n",
    "weights1, weights2 = train_neural_network(X_train, T_train, X_val, T_val, weights1, weights2, learning_rate, epochs, patience, min_delta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a82183e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000, Training Error: 1.0118206869462256, Validation Error: 0.8816763397121641\n",
      "Early stopping triggered at epoch 57\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "# Activation function and its derivative\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "# Loss Function (Mean Squared Error)\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    total_error = 0\n",
    "    for i in range(len(y_true)):\n",
    "        total_error += (y_true[i] - y_pred[i]) ** 2\n",
    "    return total_error / len(y_true)\n",
    "\n",
    "# Initialize network architecture\n",
    "n_features = 5  # Number of features in the input\n",
    "n_hidden = 10  # Number of neurons in hidden layer\n",
    "n_output = 1  # Single output (for simplicity)\n",
    "\n",
    "# Example dataset (100 samples with 5 features each)\n",
    "X = [[random.gauss(0, 1) for _ in range(n_features)] for _ in range(100)]\n",
    "T = [[random.gauss(0, 1)] for _ in range(100)]\n",
    "\n",
    "# Train/Validation Split (80% training, 20% validation)\n",
    "train_size = int(0.8 * len(X))  # 80% for training\n",
    "X_train, X_val = X[:train_size], X[train_size:]  # Split into training and validation\n",
    "T_train, T_val = T[:train_size], T[train_size:]  # Same for targets\n",
    "\n",
    "# Add bias term (column of ones) to the training and validation data\n",
    "for i in range(len(X_train)):\n",
    "    X_train[i] = [1] + X_train[i]  # Add bias to input\n",
    "\n",
    "for i in range(len(X_val)):\n",
    "    X_val[i] = [1] + X_val[i]  # Add bias to input\n",
    "\n",
    "# Initialize weights for a 2-layer neural network with bias terms\n",
    "weights1 = [[random.gauss(0, 0.01) for _ in range(n_features + 1)] for _ in range(n_hidden)]\n",
    "weights2 = [[random.gauss(0, 0.01) for _ in range(n_hidden + 1)] for _ in range(n_output)]\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.01\n",
    "epochs = 1000\n",
    "patience = 10  # Early stopping patience\n",
    "min_delta = 0.001  # Minimum change in validation error to qualify as improvement\n",
    "\n",
    "# Training loop with Early Stopping\n",
    "def train_neural_network(X_train, T_train, X_val, T_val, weights1, weights2, learning_rate, epochs, patience, min_delta):\n",
    "    best_val_error = float('inf')\n",
    "    epochs_without_improvement = 0  # Counter to track early stopping\n",
    "    best_weights1, best_weights2 = weights1, weights2\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Forward pass (Training)\n",
    "        z_hidden = [[0 for _ in range(n_hidden)] for _ in range(len(X_train))]\n",
    "        for i in range(len(X_train)):\n",
    "            for j in range(n_hidden):\n",
    "                z_hidden[i][j] = sum(X_train[i][k] * weights1[j][k] for k in range(n_features + 1))\n",
    "\n",
    "        a_hidden = [[sigmoid(z) for z in row] for row in z_hidden]\n",
    "\n",
    "        # Add bias term to hidden layer output\n",
    "        a_hidden_with_bias = [[1] + row for row in a_hidden]\n",
    "\n",
    "        # Output layer\n",
    "        y_output = [0] * len(X_train)\n",
    "        for i in range(len(X_train)):\n",
    "            y_output[i] = sum(a_hidden_with_bias[i][j] * weights2[0][j] for j in range(n_hidden + 1))\n",
    "\n",
    "        # Compute training error (Loss)\n",
    "        train_error = mean_squared_error([t[0] for t in T_train], y_output)\n",
    "        \n",
    "        # Backpropagation (Gradient Computation)\n",
    "        delta_output = [y_output[i] - T_train[i][0] for i in range(len(y_output))]\n",
    "\n",
    "        grad_w2 = [[0 for _ in range(n_hidden + 1)] for _ in range(n_output)]\n",
    "        for i in range(n_output):\n",
    "            for j in range(n_hidden + 1):\n",
    "                grad_w2[i][j] = sum(delta_output[k] * a_hidden_with_bias[k][j] for k in range(len(X_train)))\n",
    "\n",
    "        delta_hidden = [[0 for _ in range(n_hidden)] for _ in range(len(X_train))]\n",
    "        for i in range(len(X_train)):\n",
    "            for j in range(n_hidden):\n",
    "                delta_hidden[i][j] = sum(delta_output[i] * weights2[0][j+1] for i in range(len(X_train))) * sigmoid_derivative(z_hidden[i][j])\n",
    "\n",
    "        grad_w1 = [[0 for _ in range(n_features + 1)] for _ in range(n_hidden)]\n",
    "        for j in range(n_hidden):\n",
    "            for k in range(n_features + 1):\n",
    "                grad_w1[j][k] = sum(delta_hidden[i][j] * X_train[i][k] for i in range(len(X_train)))\n",
    "\n",
    "        # Update weights (Gradient Descent)\n",
    "        for i in range(n_hidden):\n",
    "            for j in range(n_features + 1):\n",
    "                weights1[i][j] -= learning_rate * grad_w1[i][j]\n",
    "\n",
    "        for i in range(n_output):\n",
    "            for j in range(n_hidden + 1):\n",
    "                weights2[i][j] -= learning_rate * grad_w2[i][j]\n",
    "\n",
    "        # Validation step (for early stopping)\n",
    "        z_hidden_val = [[0 for _ in range(n_hidden)] for _ in range(len(X_val))]\n",
    "        for i in range(len(X_val)):\n",
    "            for j in range(n_hidden):\n",
    "                z_hidden_val[i][j] = sum(X_val[i][k] * weights1[j][k] for k in range(n_features + 1))\n",
    "\n",
    "        a_hidden_val = [[sigmoid(z) for z in row] for row in z_hidden_val]\n",
    "        a_hidden_val_with_bias = [[1] + row for row in a_hidden_val]\n",
    "\n",
    "        y_output_val = [0] * len(X_val)\n",
    "        for i in range(len(X_val)):\n",
    "            y_output_val[i] = sum(a_hidden_val_with_bias[i][j] * weights2[0][j] for j in range(n_hidden + 1))\n",
    "\n",
    "        val_error = mean_squared_error([t[0] for t in T_val], y_output_val)\n",
    "\n",
    "        # Early stopping check\n",
    "        if val_error < best_val_error - min_delta:\n",
    "            best_val_error = val_error\n",
    "            best_weights1, best_weights2 = weights1, weights2\n",
    "            epochs_without_improvement = 0  # Reset counter if validation error improved\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "\n",
    "        if epochs_without_improvement >= patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "        if epoch % 100 == 0:  # Print progress every 100 epochs\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Training Error: {train_error}, Validation Error: {val_error}\")\n",
    "\n",
    "    # Return the best weights found during training\n",
    "    return best_weights1, best_weights2\n",
    "\n",
    "# Train the model with early stopping\n",
    "weights1, weights2 = train_neural_network(X_train, T_train, X_val, T_val, weights1, weights2, learning_rate, epochs, patience, min_delta)\n"
   ]
  },
  {
   "attachments": {
    "image-2.png": {
     "image/png": "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"
    },
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "b412ec5e",
   "metadata": {},
   "source": [
    "![image-2.png](attachment:image-2.png)\n",
    "\n",
    "Fig.13 A schematic illustration of why early stopping can give similar results to weight decay in the case of a quadratic error function. The ellipse shows a contour of constant error, and wML denotes the minimum of the error function. If the weight vector starts at the origin and moves according to the local negative gradient direction, then it will follow the path shown by the curve. By stopping training early, a weight vector $ \\tilde w $ is found that is qualitatively similar to that obtained with a simple weight-decay reg- ularizer and training to the minimum of the regularized error\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "Fig.14 Illustration of the synthetic warping of a handwritten digit. The original image is shown on the left. On the right, the top row shows three examples of warped digits, with the corresponding displacement ﬁelds shown on the bottom row. These displacement ﬁelds are generated by sampling random displacements ∆x, ∆y ∈ (0, 1) at each pixel and then smoothing by convolution with Gaussians of width 0.01, 30 and 60 respectively.\n",
    "\n",
    "## Invariances in Neural Networks\n",
    "\n",
    "In many pattern recognition applications, predictions should remain unchanged, or invariant, under certain transformations of the input variables. For example, in image classification (e.g., handwritten digit recognition), the classification should be invariant to transformations like **translation** (shifting the object within the image) or **scale** (changing the object's size).\n",
    "\n",
    "In speech recognition, small nonlinear warping along the time axis should not alter the interpretation of the signal. These invariances can be learned if there is a sufficiently large amount of data available, but in practice, this is often not feasible due to the exponential growth in the number of training patterns required when considering multiple transformations.\n",
    "\n",
    "We can encourage invariance in neural networks using the following approaches:\n",
    "\n",
    "### 1. Data Augmentation\n",
    "   - The training set is augmented by creating transformed versions of each pattern.\n",
    "   - For example, in image recognition tasks, we could make multiple copies of each image where the digit is shifted to different positions or resized to different scales.\n",
    "\n",
    "### 2. Regularization\n",
    "   - A regularization term is added to the error function that penalizes changes in the model output when the input is transformed. \n",
    "   - This leads to a method known as **tangent propagation**, which helps the model to be invariant to certain transformations.\n",
    "\n",
    "### 3. Invariant Feature Extraction\n",
    "   - We could preprocess the data to extract features that are invariant to transformations like translation and scale.\n",
    "   - Any classifier or regression model that uses these invariant features will automatically respect these invariances.\n",
    "\n",
    "### 4. Neural Network Structure (Convolutional Networks)\n",
    "   - The neural network architecture itself can be designed to incorporate invariances. \n",
    "   - A common approach is to use **local receptive fields** and **shared weights**, as seen in **Convolutional Neural Networks (CNNs)**.\n",
    "\n",
    "---\n",
    "\n",
    "### Mathematical Formulation of Invariance\n",
    "\n",
    "In mathematical terms, consider a transformation $ T $ applied to an input $ x $ such that the transformed input $ T(x) $ yields the same output from the model. For a neural network model $ f(x; \\theta) $ with parameters $ \\theta $, we require that:\n",
    "\n",
    "$$ f(T(x); \\theta) \\approx f(x; \\theta) $$\n",
    "\n",
    "This means that the model should produce approximately the same output when the input is transformed, encouraging invariance under the transformation $ T $.\n",
    "\n",
    "---\n",
    "\n",
    "### Code Implementation for Data Augmentation\n",
    "\n",
    "The most straightforward approach to implement invariance is **data augmentation**. Below is a Python code snippet that augments the training data by applying simple transformations, such as translations and scaling:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd822724",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/radha/anaconda3/envs/cv37/lib/python3.7/site-packages/ipykernel_launcher.py:47: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAwAAAAMVCAYAAADAmpOmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAgG0lEQVR4nO3dXYhc9f3H8e+YfUBMkca0ahKaLBM0aitaq6BeWLWFKuFfkKAIRaspTVFJL7S9qNVoTECoUGghaFU2bSM1WEJ9ILT1IUgvAsZeVVFwwRW92KDxRks3ceX3vxDDrkk00cnOms/rBXOxs+ec+c3uzpd9c/bsdFprrQAAgAjH9XsBAADA7BEAAAAQRAAAAEAQAQAAAEEEAAAABBEAAAAQRAAAAEAQAQAAAEEEAAAABBEAs2jz5s3V6XTqxRdf7MnxOp1O3XLLLT051vRj3nXXXZ97/w8++KDuvvvuWrZsWQ0PD9eKFSvq97//fe8WCMcQMwGYzkxgtgz0ewEcW2666ab685//XPfcc0+df/759Y9//KN+/vOf13vvvVe/+tWv+r08YJaZCcB0ZsLcIADomZdffrkefvjh2rhxY/3iF7+oqqrvfve7tWfPntqwYUP97Gc/qwULFvR5lcBsMROA6cyEucOfAM0xk5OTdeutt9Y555xTJ554Yi1YsKAuvPDCevzxxw+5zwMPPFCnnXZaDQ8P15lnnlmPPvroAdtMTEzUmjVrasmSJTU0NFQjIyN1991319TUVM/W/re//a1aa3XDDTfMuP+GG26o//3vf/X3v/+9Z48FKcwEYDozgV5wBmCO2bt3b7377rt122231eLFi2vfvn31zDPP1FVXXVWjo6N13XXXzdj+iSeeqB07dtT69evrhBNOqE2bNtW1115bAwMDtWrVqqr66EV9wQUX1HHHHVd33nlndbvd2rlzZ23YsKHGx8drdHT0U9e0bNmyqqoaHx//1O1eeuml+trXvlannHLKjPvPPvvs/Z8HjoyZAExnJtATjVkzOjraqqrt2rXrsPeZmppqH3zwQVu9enU799xzZ3yuqtrxxx/fJiYmZmy/YsWKtnz58v33rVmzps2fP7+98cYbM/a/7777WlW1l19+ecYx161bN2O7brfbut3uZ671+9//fjv99NMP+rmhoaH205/+9DOPAUnMBDMBpjMTzITZ4k+A5qDHHnusLr744po/f34NDAzU4OBgPfzww/XKK68csO3ll19eJ5988v6P582bV9dcc02NjY3VW2+9VVVVTz31VF166aW1aNGimpqa2n+74oorqqrq+eef/9T1jI2N1djY2GGtvdPpfK7PAYdmJgDTmQl8UQJgjtm2bVtdffXVtXjx4tqyZUvt3Lmzdu3aVTfeeGNNTk4esP0nT6NNv2/Pnj1VVbV79+568skna3BwcMbtrLPOqqqqd955pydrP+mkk/Y/5nT//e9/a9++fS7sgc/BTACmMxPoBdcAzDFbtmypkZGR2rp164wS3rt370G3n5iYOOR9J510UlVVLVy4sM4+++zauHHjQY+xaNGiL7rsqqr61re+VY8++mhNTEzMGDj/+c9/qqrqm9/8Zk8eB5KYCcB0ZgK94AzAHNPpdGpoaGjGi3piYuKQV/c/++yztXv37v0ff/jhh7V169bqdru1ZMmSqqpauXJlvfTSS9Xtdus73/nOAbdevbB/+MMfVqfTqT/+8Y8z7t+8eXMdf/zx9YMf/KAnjwNJzARgOjOBXnAGoA+ee+65g14pf+WVV9bKlStr27ZtddNNN9WqVavqzTffrHvuuadOPfXUeu211w7YZ+HChXXZZZfVHXfcsf/q/ldffXXGv/hav359Pf3003XRRRfV2rVr6/TTT6/JyckaHx+v7du31/33379/CBzM8uXLq6o+8+/7zjrrrFq9enWtW7eu5s2bV+eff37985//rD/84Q+1YcMGp/bgEMwEYDozgaOu31chJ/n46v5D3V5//fXWWmv33ntvW7ZsWRseHm5nnHFGe/DBB9u6devaJ79dVdVuvvnmtmnTptbtdtvg4GBbsWJFe+SRRw547LfffrutXbu2jYyMtMHBwbZgwYJ23nnntdtvv729//77M475yav7ly5d2pYuXXpYz3Hfvn1t3bp17Rvf+EYbGhpqp512Wvvd7353RF8nSGEmANOZCcyWTmutzUZoAAAA/ecaAAAACCIAAAAgiAAAAIAgAgAAAIIIAAAACCIAAAAgyGG/Edj0d5wD+meu/OdeMwHmhrkyE6rMBZgrPmsuOAMAAABBBAAAAAQRAAAAEEQAAABAEAEAAABBBAAAAAQRAAAAEEQAAABAEAEAAABBBAAAAAQRAAAAEEQAAABAEAEAAABBBAAAAAQRAAAAEEQAAABAEAEAAABBBAAAAAQRAAAAEEQAAABAEAEAAABBBAAAAAQRAAAAEEQAAABAEAEAAABBBAAAAAQRAAAAEEQAAABAEAEAAABBBAAAAAQRAAAAEEQAAABAEAEAAABBBAAAAAQRAAAAEEQAAABAEAEAAABBBAAAAAQRAAAAEEQAAABAEAEAAABBBAAAAAQRAAAAEEQAAABAEAEAAABBBAAAAAQRAAAAEEQAAABAEAEAAABBBAAAAAQRAAAAEEQAAABAEAEAAABBBAAAAAQRAAAAEEQAAABAEAEAAABBBAAAAAQRAAAAEEQAAABAEAEAAABBBAAAAAQRAAAAEEQAAABAEAEAAABBBAAAAAQRAAAAEGSg3wv4smqt9XsJ9ECn0+n3EgA4Rvld4dhwLP6u4AwAAAAEEQAAABBEAAAAQBABAAAAQQQAAAAEEQAAABBEAAAAQBABAAAAQQQAAAAEEQAAABBEAAAAQBABAAAAQQQAAAAEEQAAABBEAAAAQBABAAAAQQQAAAAEEQAAABBEAAAAQBABAAAAQQQAAAAEEQAAABBkoN8LAKA/Wmv9XgIAfeAMAAAABBEAAAAQRAAAAEAQAQAAAEEEAAAABBEAAAAQRAAAAEAQAQAAAEEEAAAABBEAAAAQRAAAAEAQAQAAAEEEAAAABBEAAAAQRAAAAEAQAQAAAEEEAAAABBEAAAAQRAAAAEAQAQAAAEEEAAAABBEAAAAQRAAAAEAQAQAAAEEEAAAABBEAAAAQRAAAAEAQAQAAAEEEAAAABBEAAAAQRAAAAEAQAQAAAEEEAAAABBEAAAAQRAAAAEAQAQAAAEEEAAAABBEAAAAQRAAAAEAQAQAAAEEEAAAABBEAAAAQRAAAAEAQAQAAAEEEAAAABBEAAAAQRAAAAEAQAQAAAEEEAAAABBEAAAAQRAAAAEAQAQAAAEEEAAAABBEAAAAQRAAAAEAQAQAAAEEEAAAABBEAAAAQRAAAAEAQAQAAAEEEAAAABBEAAAAQRAAAAEAQAQAAAEEEAAAABBEAAAAQRAAAAEAQAQAAAEEEAAAABBEAAAAQRAAAAEAQAQAAAEEEAAAABBEAAAAQRAAAAEAQAQAAAEEEAAAABBEAAAAQRAAAAEAQAQAAAEEEAAAABBEAAAAQRAAAAEAQAQAAAEEEAAAABBEAAAAQRAAAAEAQAQAAAEEEAAAABBEAAAAQZKDfC/iy6nQ6/V4CADCH+V2BucoZAAAACCIAAAAgiAAAAIAgAgAAAIIIAAAACCIAAAAgiAAAAIAgAgAAAIIIAAAACCIAAAAgiAAAAIAgAgAAAIIIAAAACCIAAAAgiAAAAIAgAgAAAIIIAAAACCIAAAAgiAAAAIAgAgAAAIIIAAAACDLQ7wUA0B+dTqffS6AHWmv9XgLwJeMMAAAABBEAAAAQRAAAAEAQAQAAAEEEAAAABBEAAAAQRAAAAEAQAQAAAEEEAAAABBEAAAAQRAAAAEAQAQAAAEEEAAAABBEAAAAQRAAAAEAQAQAAAEEEAAAABBEAAAAQRAAAAEAQAQAAAEEEAAAABBEAAAAQpNNaa/1eBAAAMDucAQAAgCACAAAAgggAAAAIIgAAACCIAAAAgCACAAAAgggAAAAIIgAAACCIAAAAgCACAAAAgggAAAAIIgAAACCIAAAAgCACAAAAgggAAAAIIgBm0ebNm6vT6dSLL77Yk+N1Op265ZZbenKs6ce86667Pvf+v/71r2vlypW1ePHi6nQ69eMf/7hna4NjjZkATGcmMFsEAD3129/+tvbs2VP/93//V0NDQ/1eDtBnZgIwnZkwNwz0ewEcW95777067riPuvLPf/5zn1cD9JuZAExnJswNzgDMMZOTk3XrrbfWOeecUyeeeGItWLCgLrzwwnr88ccPuc8DDzxQp512Wg0PD9eZZ55Zjz766AHbTExM1Jo1a2rJkiU1NDRUIyMjdffdd9fU1FRP1//xixroDTMBmM5MoBecAZhj9u7dW++++27ddttttXjx4tq3b18988wzddVVV9Xo6Ghdd911M7Z/4oknaseOHbV+/fo64YQTatOmTXXttdfWwMBArVq1qqo+elFfcMEFddxxx9Wdd95Z3W63du7cWRs2bKjx8fEaHR391DUtW7asqqrGx8ePxlMGPoWZAExnJtATjVkzOjraqqrt2rXrsPeZmppqH3zwQVu9enU799xzZ3yuqtrxxx/fJiYmZmy/YsWKtnz58v33rVmzps2fP7+98cYbM/a/7777WlW1l19+ecYx161bN2O7brfbut3uYa/5YyeccEK7/vrrj3g/SGEmANOZCcwW52HmoMcee6wuvvjimj9/fg0MDNTg4GA9/PDD9corrxyw7eWXX14nn3zy/o/nzZtX11xzTY2NjdVbb71VVVVPPfVUXXrppbVo0aKampraf7viiiuqqur555//1PWMjY3V2NhYD58hcCTMBGA6M4EvSgDMMdu2baurr766Fi9eXFu2bKmdO3fWrl276sYbb6zJyckDtj/llFMOed+ePXuqqmr37t315JNP1uDg4IzbWWedVVVV77zzzlF8RsAXYSYA05kJ9IJrAOaYLVu21MjISG3durU6nc7++/fu3XvQ7ScmJg5530knnVRVVQsXLqyzzz67Nm7ceNBjLFq06IsuGzhKzARgOjOBXhAAc0yn06mhoaEZL+qJiYlDXt3/7LPP1u7du/ef3vvwww9r69at1e12a8mSJVVVtXLlytq+fXt1u9366le/evSfBNAzZgIwnZlALwiAPnjuuecOeqX8lVdeWStXrqxt27bVTTfdVKtWrao333yz7rnnnjr11FPrtddeO2CfhQsX1mWXXVZ33HHH/qv7X3311Rn/4mv9+vX19NNP10UXXVRr166t008/vSYnJ2t8fLy2b99e999///4hcDDLly+vqjqsv+97/vnn6+23366qj4bMG2+8UX/961+rquqSSy6pr33ta595DEhjJgDTmQkcdf2+CjnJx1f3H+r2+uuvt9Zau/fee9uyZcva8PBwO+OMM9qDDz7Y1q1b1z757aqqdvPNN7dNmza1brfbBgcH24oVK9ojjzxywGO//fbbbe3atW1kZKQNDg62BQsWtPPOO6/dfvvt7f33359xzE9e3b906dK2dOnSw3qOl1xyySGf344dO47kywXHPDNhx5F8ueCYZybsOJIvF19Ap7XWep8VAADAXOS/AAEAQBABAAAAQQQAAAAEEQAAABBEAAAAQBABAAAAQQ77jcCmv+Mc0D9z5T/3mgkwN8yVmVBlLsBc8VlzwRkAAAAIIgAAACCIAAAAgCACAAAAgggAAAAIIgAAACCIAAAAgCACAAAAgggAAAAIIgAAACCIAAAAgCACAAAAgggAAAAIIgAAACCIAAAAgCACAAAAgggAAAAIIgAAACCIAAAAgCACAAAAgggAAAAIIgAAACCIAAAAgCACAAAAgggAAAAIIgAAACCIAAAAgCACAAAAgggAAAAIIgAAACCIAAAAgCACAAAAgggAAAAIIgAAACCIAAAAgCACAAAAgggAAAAIIgAAACCIAAAAgCACAAAAgggAAAAIIgAAACCIAAAAgCACAAAAgggAAAAIIgAAACCIAAAAgCACAAAAgggAAAAIIgAAACCIAAAAgCACAAAAgggAAAAIIgAAACCIAAAAgCACAAAAgggAAAAIIgAAACCIAAAAgCACAAAAgggAAAAIIgAAACCIAAAAgCACAAAAgggAAAAIIgAAACDIQL8X8GXVWuv3EuiBTqfT7yVA35hjAJmcAQAAgCACAAAAgggAAAAIIgAAACCIAAAAgCACAAAAgggAAAAI4n0AAACY07xvSW85AwAAAEEEAAAABBEAAAAQRAAAAEAQAQAAAEEEAAAABBEAAAAQRAAAAEAQAQAAAEEEAAAABBEAAAAQRAAAAEAQAQAAAEEEAAAABBEAAAAQRAAAAEAQAQAAAEEEAAAABBEAAAAQRAAAAEAQAQAAAEEEAAAABBEAAAAQRAAAAECQgX4vAAA4NrTW+r2Enuh0Ov1eAp8wW9+TY+Vn+LM4AwAAAEEEAAAABBEAAAAQRAAAAEAQAQAAAEEEAAAABBEAAAAQRAAAAEAQAQAAAEEEAAAABBEAAAAQRAAAAEAQAQAAAEEEAAAABBEAAAAQRAAAAEAQAQAAAEEEAAAABBEAAAAQRAAAAEAQAQAAAEEEAAAABBEAAAAQRAAAAECQgX4vAABgLmmtzcrjdDqdWXkcDt9sfE9m6+fr0zgDAAAAQQQAAAAEEQAAABBEAAAAQBABAAAAQQQAAAAEEQAAABBEAAAAQBABAAAAQQQAAAAEEQAAABBEAAAAQBABAAAAQQQAAAAEEQAAABBEAAAAQBABAAAAQQQAAAAEEQAAABBEAAAAQBABAAAAQQQAAAAEEQAAABBEAAAAQJCBfi8AACBRa+2oP0an0znqj8GRmY3vyWf9bDkDAAAAQQQAAAAEEQAAABBEAAAAQBABAAAAQQQAAAAEEQAAABBEAAAAQBABAAAAQQQAAAAEEQAAABBEAAAAQBABAAAAQQQAAAAEEQAAABBEAAAAQBABAAAAQQQAAAAEEQAAABBEAAAAQBABAAAAQQQAAAAEEQAAABBEAAAAQBABAAAAQQb6vQAAAI6O1tpRf4xOp3PUH4PecgYAAACCCAAAAAgiAAAAIIgAAACAIC4C/pxc8AJ82Zljx4bZuMgTOLY4AwAAAEEEAAAABBEAAAAQRAAAAEAQAQAAAEEEAAAABBEAAAAQRAAAAEAQAQAAAEEEAAAABBEAAAAQRAAAAEAQAQAAAEEEAAAABBEAAAAQRAAAAEAQAQAAAEEEAAAABBEAAAAQZKDfCwAAjg2dTueoP0Zr7ag/BkdmNr4ns/GzlcQZAAAACCIAAAAgiAAAAIAgAgAAAIIIAAAACCIAAAAgiAAAAIAgAgAAAIIIAAAACCIAAAAgiAAAAIAgAgAAAIIIAAAACCIAAAAgiAAAAIAgAgAAAIIIAAAACCIAAAAgiAAAAIAgAgAAAIIIAAAACCIAAAAgiAAAAIAgAgAAAIJ0Wmut34sAAABmhzMAAAAQRAAAAEAQAQAAAEEEAAAABBEAAAAQRAAAAEAQAQAAAEEEAAAABBEAAAAQRAAAAEAQAQAAAEEEAAAABBEAAAAQRAAAAEAQAQAAAEEEwCzavHlzdTqdevHFF3tyvE6nU7fccktPjjX9mHfdddfn2vff//533XzzzfWtb32rvvKVr9TJJ59c3/ve9+q5557r6RrhWGEmANOZCcwWAUDP/OUvf6kXXnihbrzxxnr88cfroYcequHh4br88svrT3/6U7+XB8wyMwGYzkyYOwb6vQCOHb/85S/rvvvum3HflVdeWd/+9rdr/fr1dd111/VpZUA/mAnAdGbC3OEMwBwzOTlZt956a51zzjl14okn1oIFC+rCCy+sxx9//JD7PPDAA3XaaafV8PBwnXnmmfXoo48esM3ExEStWbOmlixZUkNDQzUyMlJ33313TU1N9WztX//61w+4b968eXXeeefVm2++2bPHgSRmAjCdmUAvOAMwx+zdu7fefffduu2222rx4sW1b9++euaZZ+qqq66q0dHRA+r4iSeeqB07dtT69evrhBNOqE2bNtW1115bAwMDtWrVqqr66EV9wQUX1HHHHVd33nlndbvd2rlzZ23YsKHGx8drdHT0U9e0bNmyqqoaHx8/4uczNTVV//rXv+qss8464n0BMwGYyUygJxqzZnR0tFVV27Vr12HvMzU11T744IO2evXqdu655874XFW1448/vk1MTMzYfsWKFW358uX771uzZk2bP39+e+ONN2bsf99997Wqai+//PKMY65bt27Gdt1ut3W73cNe83S33357q6r2t7/97XPtD8cyMwGYzkxgtvgToDnoscceq4svvrjmz59fAwMDNTg4WA8//HC98sorB2x7+eWX18knn7z/43nz5tU111xTY2Nj9dZbb1VV1VNPPVWXXnppLVq0qKampvbfrrjiiqqqev755z91PWNjYzU2NnbEz+Ohhx6qjRs31q233lo//OEPj3h/4CNmAjCdmcAXJQDmmG3bttXVV19dixcvri1bttTOnTtr165ddeONN9bk5OQB259yyimHvG/Pnj1VVbV79+568skna3BwcMbt49Nt77zzTs+fx+joaK1Zs6Z++tOf1m9+85ueHx9SmAnAdGYCveAagDlmy5YtNTIyUlu3bq1Op7P//r179x50+4mJiUPed9JJJ1VV1cKFC+vss8+ujRs3HvQYixYt+qLLnmF0dLR+8pOf1PXXX1/333//jOcBHBkzAZjOTKAXBMAc0+l0amhoaMaLYWJi4pBX9z/77LO1e/fu/af3Pvzww9q6dWt1u91asmRJVVWtXLmytm/fXt1ut7761a8e1fVv3ry5fvKTn9SPfvSjeuihh7yo4QsyE4DpzAR6QQD0wXPPPXfQK+WvvPLKWrlyZW3btq1uuummWrVqVb355pt1zz331KmnnlqvvfbaAfssXLiwLrvssrrjjjv2X93/6quvzvgXX+vXr6+nn366Lrroolq7dm2dfvrpNTk5WePj47V9+/a6//779w+Bg1m+fHlV1Wf+fd9jjz1Wq1evrnPOOafWrFlTL7zwwozPn3vuuTU8PPypx4BEZgIwnZnAUdfvq5CTfHx1/6Fur7/+emuttXvvvbctW7asDQ8PtzPOOKM9+OCDbd26de2T366qajfffHPbtGlT63a7bXBwsK1YsaI98sgjBzz222+/3dauXdtGRkba4OBgW7BgQTvvvPPa7bff3t5///0Zx/zk1f1Lly5tS5cu/cznd/311x/W8wM+Yia8fqRfMjimmQmvH+mXjM+p01prPW4KAABgjvJfgAAAIIgAAACAIAIAAACCCAAAAAgiAAAAIIgAAACAIAIAAACCHPY7AXurZpgb5spbd5gJMDfMlZlQZS7AXPFZc8EZAAAACCIAAAAgiAAAAIAgAgAAAIIIAAAACCIAAAAgiAAAAIAgAgAAAIIIAAAACCIAAAAgiAAAAIAgAgAAAIIIAAAACCIAAAAgiAAAAIAgAgAAAIIIAAAACCIAAAAgiAAAAIAgAgAAAIIIAAAACCIAAAAgiAAAAIAgAgAAAIIIAAAACCIAAAAgiAAAAIAgAgAAAIIIAAAACCIAAAAgiAAAAIAgAgAAAIIIAAAACCIAAAAgiAAAAIAgAgAAAIIIAAAACCIAAAAgiAAAAIAgAgAAAIIIAAAACCIAAAAgiAAAAIAgAgAAAIIIAAAACCIAAAAgiAAAAIAgAgAAAIIIAAAACCIAAAAgiAAAAIAgAgAAAIIIAAAACCIAAAAgiAAAAIAgAgAAAIIIAAAACCIAAAAgiAAAAIAgAgAAAIIIAAAACCIAAAAgiAAAAIAgAgAAAIIIAAAACCIAAAAgyEC/F/Bl1Vrr9xLogU6n0+8lAHCM8rvCseFY/F3BGQAAAAgiAAAAIIgAAACAIAIAAACCCAAAAAgiAAAAIIgAAACAIAIAAACCCAAAAAgiAAAAIIgAAACAIAIAAACCCAAAAAgiAAAAIIgAAACAIAIAAACCCAAAAAgiAAAAIIgAAACAIAIAAACCCAAAAAgiAAAAIMhAvxcAQH+01vq9BAD6wBkAAAAIIgAAACCIAAAAgCACAAAAgggAAAAIIgAAACCIAAAAgCACAAAAgggAAAAIIgAAACCIAAAAgCACAAAAgggAAAAIIgAAACCIAAAAgCACAAAAgggAAAAIIgAAACCIAAAAgCACAAAAgggAAAAIIgAAACCIAAAAgCACAAAAgggAAAAIIgAAACCIAAAAgCACAAAAgggAAAAIIgAAACCIAAAAgCACAAAAgggAAAAIIgAAACCIAAAAgCACAAAAgggAAAAIIgAAACCIAAAAgCACAAAAgggAAAAIIgAAACCIAAAAgCACAAAAgggAAAAIIgAAACCIAAAAgCACAAAAgggAAAAIIgAAACCIAAAAgCACAAAAgggAAAAIIgAAACCIAAAAgCACAAAAgggAAAAIIgAAACCIAAAAgCACAAAAgggAAAAIIgAAACCIAAAAgCACAAAAgggAAAAIIgAAACCIAAAAgCACAAAAgggAAAAIIgAAACCIAAAAgCACAAAAgggAAAAIIgAAACCIAAAAgCACAAAAgggAAAAIIgAAACCIAAAAgCACAAAAgggAAAAIIgAAACCIAAAAgCACAAAAgggAAAAIIgAAACCIAAAAgCACAAAAgggAAAAIIgAAACDIQL8X8GXV6XT6vQQAYA7zuwJzlTMAAAAQRAAAAEAQAQAAAEEEAAAABBEAAAAQRAAAAEAQAQAAAEEEAAAABBEAAAAQRAAAAEAQAQAAAEEEAAAABBEAAAAQRAAAAEAQAQAAAEEEAAAABBEAAAAQRAAAAEAQAQAAAEEEAAAABBEAAAAQZKDfCwCgPzqdTr+XQA+01vq9BOBLxhkAAAAIIgAAACCIAAAAgCACAAAAgggAAAAIIgAAACCIAAAAgCACAAAAgggAAAAIIgAAACCIAAAAgCACAAAAgggAAAAIIgAAACCIAAAAgCACAAAAgggAAAAIIgAAACCIAAAAgCACAAAAgggAAAAIIgAAACBIp7XW+r0IAABgdjgDAAAAQQQAAAAEEQAAABBEAAAAQBABAAAAQQQAAAAEEQAAABBEAAAAQBABAAAAQf4f/SHm1wbNoW4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example image: 2D array\n",
    "def generate_example_image(size=(10, 10)):\n",
    "    # Generate a simple \"digit\" or object in an image (e.g., a 5x5 square)\n",
    "    image = np.zeros(size)\n",
    "    image[3:8, 3:8] = 1  # create a square in the center\n",
    "    return image\n",
    "\n",
    "# Translate (shift) image\n",
    "def translate_image(image, shift_x, shift_y):\n",
    "    # Roll the image for translation\n",
    "    return np.roll(image, shift=(shift_x, shift_y), axis=(0, 1))\n",
    "\n",
    "# Scale (resize) image\n",
    "def scale_image(image, scale_factor):\n",
    "    # Simple scaling by resizing\n",
    "    new_size = int(image.shape[0] * scale_factor), int(image.shape[1] * scale_factor)\n",
    "    scaled_image = np.array(image)\n",
    "    scaled_image = np.resize(scaled_image, new_size)\n",
    "    return scaled_image\n",
    "\n",
    "def augment_data(X_train, T_train):\n",
    "    augmented_X = []\n",
    "    augmented_T = []\n",
    "\n",
    "    for i in range(len(X_train)):\n",
    "        # Original example\n",
    "        augmented_X.append(X_train[i])\n",
    "        augmented_T.append(T_train[i])\n",
    "\n",
    "        # Apply translation (shift the image)\n",
    "        translation_x = random.randint(-2, 2)  # horizontal shift\n",
    "        translation_y = random.randint(-2, 2)  # vertical shift\n",
    "        shifted_image = translate_image(X_train[i], translation_x, translation_y)\n",
    "        augmented_X.append(shifted_image)\n",
    "        augmented_T.append(T_train[i])\n",
    "\n",
    "        # Apply scaling\n",
    "        scale_factor = random.uniform(0.8, 1.2)  # scale factor\n",
    "        scaled_image = scale_image(X_train[i], scale_factor)\n",
    "        augmented_X.append(scaled_image)\n",
    "        augmented_T.append(T_train[i])\n",
    "\n",
    "    return np.array(augmented_X), np.array(augmented_T)\n",
    "\n",
    "# Example: Create a simple dataset of images\n",
    "X_train = np.array([generate_example_image() for _ in range(5)])  # 5 example images\n",
    "T_train = np.array([0, 1, 2, 3, 4])  # corresponding labels\n",
    "\n",
    "# Augment the training data\n",
    "X_train_augmented, T_train_augmented = augment_data(X_train, T_train)\n",
    "\n",
    "# Plot original and augmented images\n",
    "plt.figure(figsize=(8, 8))\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    plt.imshow(X_train_augmented[i], cmap='gray')\n",
    "    plt.title(f\"Label: {T_train_augmented[i]}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75088f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "# Sigmoid function and its derivative\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# Manual matrix operations\n",
    "def matmul(A, B):\n",
    "    \"\"\" Matrix multiplication for two matrices A and B \"\"\"\n",
    "    result = [[sum(a * b for a, b in zip(A_row, B_col)) for B_col in zip(*B)] for A_row in A]\n",
    "    return result\n",
    "\n",
    "def add_bias(matrix, bias):\n",
    "    \"\"\" Add bias to each row of the matrix \"\"\"\n",
    "    return [[x + b for x, b in zip(row, bias)] for row in matrix]\n",
    "\n",
    "def transpose(matrix):\n",
    "    \"\"\" Transpose a matrix \"\"\"\n",
    "    return list(zip(*matrix))\n",
    "\n",
    "def matmul_elementwise(A, B):\n",
    "    \"\"\" Element-wise multiplication of two matrices of the same size \"\"\"\n",
    "    return [[a * b for a, b in zip(A_row, B_row)] for A_row, B_row in zip(A, B)]\n",
    "\n",
    "# Neural Network Class\n",
    "class SimpleNN:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        # Initialize weights and biases with small random values\n",
    "        self.weights1 = [[random.random() for _ in range(hidden_size)] for _ in range(input_size)]\n",
    "        self.weights2 = [[random.random() for _ in range(output_size)] for _ in range(hidden_size)]\n",
    "        self.bias1 = [random.random() for _ in range(hidden_size)]\n",
    "        self.bias2 = [random.random() for _ in range(output_size)]\n",
    "\n",
    "    def forward(self, X):\n",
    "        # Forward pass through the network\n",
    "        self.z1 = matmul(X, transpose(self.weights1))\n",
    "        self.a1 = [sigmoid(x + b) for x, b in zip(self.z1[0], self.bias1)]  # Apply sigmoid on hidden layer\n",
    "        self.z2 = matmul(self.a1, transpose(self.weights2))\n",
    "        self.a2 = [sigmoid(x + b) for x, b in zip(self.z2[0], self.bias2)]  # Apply sigmoid on output layer\n",
    "        return self.a2\n",
    "\n",
    "    def backward(self, X, y, learning_rate=0.01):\n",
    "        # Backpropagation to compute gradients and update weights\n",
    "        output_error = [o - t for o, t in zip(self.a2[0], y)]  # error at output layer\n",
    "        d_output = matmul_elementwise([[sigmoid_derivative(o) for o in self.a2[0]]], [output_error])\n",
    "\n",
    "        hidden_error = matmul(d_output, self.weights2)\n",
    "        d_hidden = matmul_elementwise([[sigmoid_derivative(h) for h in self.a1]], hidden_error)\n",
    "\n",
    "        # Update weights and biases using gradient descent\n",
    "        self.weights2 = matmul(self.transpose(self.a1), d_output)\n",
    "        self.bias2 = [sum(d) * learning_rate for d in d_output]\n",
    "\n",
    "        self.weights1 = matmul(self.transpose(X), d_hidden)\n",
    "        self.bias1 = [sum(d) * learning_rate for d in d_hidden]\n",
    "\n",
    "    def train(self, X_train, y_train, epochs=1000, learning_rate=0.01):\n",
    "        for epoch in range(epochs):\n",
    "            self.forward(X_train)  # forward pass\n",
    "            self.backward(X_train, y_train, learning_rate)  # backward pass\n",
    "\n",
    "            # Optionally print loss for tracking\n",
    "            if epoch % 100 == 0:\n",
    "                loss = sum([(o - t) ** 2 for o, t in zip(self.a2[0], y_train)]) / len(y_train)\n",
    "                print(f\"Epoch {epoch}/{epochs}, Loss: {loss}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.forward(X)\n",
    "\n",
    "\n",
    "# Example training and testing\n",
    "input_size = 10  # Number of input features (e.g., flattened image size)\n",
    "hidden_size = 5  # Number of neurons in the hidden layer\n",
    "output_size = 1  # Output size (e.g., one output per class)\n",
    "\n",
    "# Create some dummy data\n",
    "X_train = [[random.random() for _ in range(input_size)] for _ in range(10)]  # 10 examples, each with 10 features\n",
    "y_train = [[random.random()] for _ in range(10)]  # 10 target values\n",
    "\n",
    "# Create neural network model\n",
    "model = SimpleNN(input_size, hidden_size, output_size)\n",
    "\n",
    "# Train the network\n",
    "model.train(X_train, y_train, epochs=1000, learning_rate=0.01)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_train)\n",
    "\n",
    "# Display the predictions\n",
    "print(predictions)\n"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "57f93c24",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)\n",
    "\n",
    "Fig.16 Illustration showing (a) the original image x of a hand- written digit, (b) the tangent vector τ corresponding to an inﬁnitesimal clockwise rotation, (c) the result of adding a small contribution from the tangent vector to the original image giving x + τ with = 15 degrees, and (d) the true image rotated for comparison.\n",
    "\n",
    "##  Tangent Propagation\n",
    "\n",
    "In pattern recognition, **regularization** techniques are used to encourage the model to be **invariant** to transformations of the input. One such technique is **tangent propagation**, which helps the model learn invariances like translation or rotation. \n",
    "\n",
    "### Concept\n",
    "\n",
    "Consider the effect of a transformation on a particular input vector $ \\mathbf{x}_n $. If the transformation is continuous (such as translation or rotation), the transformed pattern will sweep out a manifold $ \\mathcal{M} $ within the input space. For simplicity, assume that the transformation is governed by a single parameter $ \\xi $, for example, a **rotation angle**.\n",
    "\n",
    "In this case, the subspace $ \\mathcal{M} $ swept out by $ \\mathbf{x}_n $ will be one-dimensional, and will be parameterized by $ \\xi $. The transformation applied to $ \\mathbf{x}_n $ will result in a vector $ \\mathbf{s}(\\mathbf{x}_n, \\xi) $, where:\n",
    "\n",
    "$$\n",
    "\\mathbf{s}(\\mathbf{x}_n, 0) = \\mathbf{x}_n\n",
    "$$\n",
    "\n",
    "The tangent to the curve $ \\mathcal{M} $ at point $ \\mathbf{x}_n $ can be approximated by the **directional derivative**:\n",
    "\n",
    "$$\n",
    "\\tau_n = \\frac{\\partial \\mathbf{s}(\\mathbf{x}_n, \\xi)}{\\partial \\xi} \\bigg|_{\\xi = 0}\n",
    "$$\n",
    "\n",
    "This **tangent vector** $ \\tau_n $ describes the local change in the input vector $ \\mathbf{x}_n $ as a result of a small change in the transformation parameter $ \\xi $.\n",
    "\n",
    "### Effect on Output\n",
    "\n",
    "Under a transformation of the input vector, the output vector of the network will, in general, change. The derivative of output $ y_k $ with respect to $ \\xi $ is given by:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial y_k}{\\partial \\xi} = \\sum_{i=1}^{D} J_{ki} \\tau_i\n",
    "$$\n",
    "\n",
    "where $ J_{ki} $ is the $ (k,i) $-th element of the **Jacobian matrix** $ \\mathbf{J} $, which represents the change in the output with respect to the change in the input.\n",
    "\n",
    "### Regularization Function\n",
    "\n",
    "The idea is to modify the error function $ E $ by adding a regularization term $ \\Omega $ that encourages local invariance in the neighborhood of the data points:\n",
    "\n",
    "$$\n",
    "E_{\\text{total}} = E + \\lambda \\Omega\n",
    "$$\n",
    "\n",
    "where $ \\lambda $ is a regularization coefficient. The regularization term is:\n",
    "\n",
    "$$\n",
    "\\Omega = \\frac{1}{2} \\sum_{n=1}^{N} \\sum_{k=1}^{K} \\sum_{i=1}^{D} J_{nki} \\tau_{ni}^2\n",
    "$$\n",
    "\n",
    "Here:\n",
    "- $ N $ is the number of training samples.\n",
    "- $ K $ is the number of output units.\n",
    "- $ D $ is the dimensionality of the input space.\n",
    "- $ \\tau_{ni} $ is the tangent vector corresponding to input $ \\mathbf{x}_n $.\n",
    "\n",
    "The regularization function $ \\Omega $ will be zero when the network mapping is invariant under the transformation in the neighborhood of each input vector $ \\mathbf{x}_n $. By minimizing the total error function $ E_{\\text{total}} $, the network learns to be invariant to the transformations of the input data.\n",
    "\n",
    "### Practical Implementation\n",
    "\n",
    "In practice, the tangent vector $ \\tau_n $ can be approximated using **finite differences**. The idea is to subtract the original vector $ \\mathbf{x}_n $ from the corresponding vector after the transformation, and then divide by a small value of $ \\xi $:\n",
    "\n",
    "$$\n",
    "\\tau_n = \\frac{\\mathbf{s}(\\mathbf{x}_n, \\xi) - \\mathbf{x}_n}{\\xi}\n",
    "$$\n",
    "\n",
    "This method approximates the **directional derivative** by taking the difference between the original and transformed vectors, scaled by the parameter $ \\xi $.\n",
    "\n",
    "### Visual Example\n",
    "\n",
    "The following illustrates how the tangent vector $ \\tau_n $ corresponds to an infinitesimal clockwise rotation:\n",
    "\n",
    "- **(a)** Original image $ \\mathbf{x} $ of a handwritten digit.\n",
    "- **(b)** Tangent vector $ \\tau $ corresponding to a small clockwise rotation.\n",
    "- **(c)** The result of adding a small contribution from the tangent vector to the original image, giving $ \\mathbf{x} + \\tau $ with $ \\xi = 15^\\circ $.\n",
    "- **(d)** The true image rotated for comparison.\n",
    "\n",
    "This illustration shows how the tangent vector can be used to modify the input and create an approximation of the transformed input.\n",
    "\n",
    "### Summary\n",
    "\n",
    "Tangent propagation is a powerful regularization technique that encourages the model to be invariant to transformations of the input. It does this by adding a regularization term to the error function, which penalizes changes in the output when the input is transformed. By learning the invariance properties, the model can generalize better, especially when limited training data is available for transformed inputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f06b1133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Total Error: 1.8706161448592484\n",
      "Epoch 2/100, Total Error: 1.8706161448592484\n",
      "Epoch 3/100, Total Error: 1.8706161448592484\n",
      "Epoch 4/100, Total Error: 1.8706161448592484\n",
      "Epoch 5/100, Total Error: 1.8706161448592484\n",
      "Epoch 6/100, Total Error: 1.8706161448592484\n",
      "Epoch 7/100, Total Error: 1.8706161448592484\n",
      "Epoch 8/100, Total Error: 1.8706161448592484\n",
      "Epoch 9/100, Total Error: 1.8706161448592484\n",
      "Epoch 10/100, Total Error: 1.8706161448592484\n",
      "Epoch 11/100, Total Error: 1.8706161448592484\n",
      "Epoch 12/100, Total Error: 1.8706161448592484\n",
      "Epoch 13/100, Total Error: 1.8706161448592484\n",
      "Epoch 14/100, Total Error: 1.8706161448592484\n",
      "Epoch 15/100, Total Error: 1.8706161448592484\n",
      "Epoch 16/100, Total Error: 1.8706161448592484\n",
      "Epoch 17/100, Total Error: 1.8706161448592484\n",
      "Epoch 18/100, Total Error: 1.8706161448592484\n",
      "Epoch 19/100, Total Error: 1.8706161448592484\n",
      "Epoch 20/100, Total Error: 1.8706161448592484\n",
      "Epoch 21/100, Total Error: 1.8706161448592484\n",
      "Epoch 22/100, Total Error: 1.8706161448592484\n",
      "Epoch 23/100, Total Error: 1.8706161448592484\n",
      "Epoch 24/100, Total Error: 1.8706161448592484\n",
      "Epoch 25/100, Total Error: 1.8706161448592484\n",
      "Epoch 26/100, Total Error: 1.8706161448592484\n",
      "Epoch 27/100, Total Error: 1.8706161448592484\n",
      "Epoch 28/100, Total Error: 1.8706161448592484\n",
      "Epoch 29/100, Total Error: 1.8706161448592484\n",
      "Epoch 30/100, Total Error: 1.8706161448592484\n",
      "Epoch 31/100, Total Error: 1.8706161448592484\n",
      "Epoch 32/100, Total Error: 1.8706161448592484\n",
      "Epoch 33/100, Total Error: 1.8706161448592484\n",
      "Epoch 34/100, Total Error: 1.8706161448592484\n",
      "Epoch 35/100, Total Error: 1.8706161448592484\n",
      "Epoch 36/100, Total Error: 1.8706161448592484\n",
      "Epoch 37/100, Total Error: 1.8706161448592484\n",
      "Epoch 38/100, Total Error: 1.8706161448592484\n",
      "Epoch 39/100, Total Error: 1.8706161448592484\n",
      "Epoch 40/100, Total Error: 1.8706161448592484\n",
      "Epoch 41/100, Total Error: 1.8706161448592484\n",
      "Epoch 42/100, Total Error: 1.8706161448592484\n",
      "Epoch 43/100, Total Error: 1.8706161448592484\n",
      "Epoch 44/100, Total Error: 1.8706161448592484\n",
      "Epoch 45/100, Total Error: 1.8706161448592484\n",
      "Epoch 46/100, Total Error: 1.8706161448592484\n",
      "Epoch 47/100, Total Error: 1.8706161448592484\n",
      "Epoch 48/100, Total Error: 1.8706161448592484\n",
      "Epoch 49/100, Total Error: 1.8706161448592484\n",
      "Epoch 50/100, Total Error: 1.8706161448592484\n",
      "Epoch 51/100, Total Error: 1.8706161448592484\n",
      "Epoch 52/100, Total Error: 1.8706161448592484\n",
      "Epoch 53/100, Total Error: 1.8706161448592484\n",
      "Epoch 54/100, Total Error: 1.8706161448592484\n",
      "Epoch 55/100, Total Error: 1.8706161448592484\n",
      "Epoch 56/100, Total Error: 1.8706161448592484\n",
      "Epoch 57/100, Total Error: 1.8706161448592484\n",
      "Epoch 58/100, Total Error: 1.8706161448592484\n",
      "Epoch 59/100, Total Error: 1.8706161448592484\n",
      "Epoch 60/100, Total Error: 1.8706161448592484\n",
      "Epoch 61/100, Total Error: 1.8706161448592484\n",
      "Epoch 62/100, Total Error: 1.8706161448592484\n",
      "Epoch 63/100, Total Error: 1.8706161448592484\n",
      "Epoch 64/100, Total Error: 1.8706161448592484\n",
      "Epoch 65/100, Total Error: 1.8706161448592484\n",
      "Epoch 66/100, Total Error: 1.8706161448592484\n",
      "Epoch 67/100, Total Error: 1.8706161448592484\n",
      "Epoch 68/100, Total Error: 1.8706161448592484\n",
      "Epoch 69/100, Total Error: 1.8706161448592484\n",
      "Epoch 70/100, Total Error: 1.8706161448592484\n",
      "Epoch 71/100, Total Error: 1.8706161448592484\n",
      "Epoch 72/100, Total Error: 1.8706161448592484\n",
      "Epoch 73/100, Total Error: 1.8706161448592484\n",
      "Epoch 74/100, Total Error: 1.8706161448592484\n",
      "Epoch 75/100, Total Error: 1.8706161448592484\n",
      "Epoch 76/100, Total Error: 1.8706161448592484\n",
      "Epoch 77/100, Total Error: 1.8706161448592484\n",
      "Epoch 78/100, Total Error: 1.8706161448592484\n",
      "Epoch 79/100, Total Error: 1.8706161448592484\n",
      "Epoch 80/100, Total Error: 1.8706161448592484\n",
      "Epoch 81/100, Total Error: 1.8706161448592484\n",
      "Epoch 82/100, Total Error: 1.8706161448592484\n",
      "Epoch 83/100, Total Error: 1.8706161448592484\n",
      "Epoch 84/100, Total Error: 1.8706161448592484\n",
      "Epoch 85/100, Total Error: 1.8706161448592484\n",
      "Epoch 86/100, Total Error: 1.8706161448592484\n",
      "Epoch 87/100, Total Error: 1.8706161448592484\n",
      "Epoch 88/100, Total Error: 1.8706161448592484\n",
      "Epoch 89/100, Total Error: 1.8706161448592484\n",
      "Epoch 90/100, Total Error: 1.8706161448592484\n",
      "Epoch 91/100, Total Error: 1.8706161448592484\n",
      "Epoch 92/100, Total Error: 1.8706161448592484\n",
      "Epoch 93/100, Total Error: 1.8706161448592484\n",
      "Epoch 94/100, Total Error: 1.8706161448592484\n",
      "Epoch 95/100, Total Error: 1.8706161448592484\n",
      "Epoch 96/100, Total Error: 1.8706161448592484\n",
      "Epoch 97/100, Total Error: 1.8706161448592484\n",
      "Epoch 98/100, Total Error: 1.8706161448592484\n",
      "Epoch 99/100, Total Error: 1.8706161448592484\n",
      "Epoch 100/100, Total Error: 1.8706161448592484\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Define the sigmoid function and its derivative\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# Define a simple 2-layer neural network\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        # Initialize weights with small random values\n",
    "        self.weights1 = [[random.random() for _ in range(input_size)] for _ in range(hidden_size)]\n",
    "        self.weights2 = [[random.random() for _ in range(hidden_size)] for _ in range(output_size)]\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def forward(self, X):\n",
    "        # Forward pass for the hidden layer\n",
    "        self.hidden = [sum(X[i] * self.weights1[j][i] for i in range(self.input_size)) for j in range(self.hidden_size)]\n",
    "        self.hidden = [sigmoid(h) for h in self.hidden]\n",
    "        \n",
    "        # Add bias term to the hidden layer outputs\n",
    "        self.hidden = [1] + self.hidden  # Add a bias of 1\n",
    "\n",
    "        # Forward pass for the output layer\n",
    "        self.output = [sum(self.hidden[j] * self.weights2[k][j] for j in range(self.hidden_size)) for k in range(self.output_size)]\n",
    "        self.output = [sigmoid(o) for o in self.output]\n",
    "\n",
    "        return self.output\n",
    "\n",
    "    def compute_jacobian(self, X):\n",
    "        # Calculate the Jacobian matrix J\n",
    "        jacobian = []\n",
    "        for i in range(self.output_size):\n",
    "            row = []\n",
    "            for j in range(self.hidden_size):\n",
    "                # Derivative of the output w.r.t. the hidden unit (using sigmoid derivative)\n",
    "                row.append(self.weights2[i][j] * sigmoid_derivative(self.output[i]) * self.hidden[j])\n",
    "            jacobian.append(row)\n",
    "        return jacobian\n",
    "\n",
    "    def tangent_vector(self, X, epsilon=0.01):\n",
    "        # Compute tangent vector using finite differences (approximates the derivative)\n",
    "        original_output = self.forward(X)\n",
    "        X_prime = [x + epsilon for x in X]  # Apply small perturbation to input\n",
    "        perturbed_output = self.forward(X_prime)\n",
    "\n",
    "        tangent_vec = [perturbed_output[i] - original_output[i] for i in range(self.output_size)]\n",
    "        return tangent_vec\n",
    "\n",
    "    def regularization_term(self, X, lambda_reg=0.1):\n",
    "        # Compute the regularization term Omega using the tangent vectors\n",
    "        jacobian = self.compute_jacobian(X)\n",
    "        tangent_vec = self.tangent_vector(X)\n",
    "\n",
    "        reg_term = 0\n",
    "        for i in range(self.output_size):\n",
    "            for j in range(self.hidden_size):\n",
    "                reg_term += (jacobian[i][j] * tangent_vec[i])**2\n",
    "        reg_term *= lambda_reg / 2\n",
    "        return reg_term\n",
    "\n",
    "    def train(self, X_train, y_train, epochs, learning_rate, lambda_reg):\n",
    "        for epoch in range(epochs):\n",
    "            # Training loop\n",
    "            total_error = 0\n",
    "            for X, y in zip(X_train, y_train):\n",
    "                # Forward pass\n",
    "                self.forward(X)\n",
    "\n",
    "                # Compute the error (Mean Squared Error)\n",
    "                error = sum((self.output[i] - y[i])**2 for i in range(self.output_size))\n",
    "                total_error += error\n",
    "\n",
    "                # Backpropagation (simplified for illustration)\n",
    "                # Compute gradient for weights and update weights here\n",
    "                # This is a simplified example; you would need to implement full backprop here.\n",
    "\n",
    "                # Add regularization to the error function\n",
    "                total_error += self.regularization_term(X, lambda_reg)\n",
    "\n",
    "            print(f'Epoch {epoch + 1}/{epochs}, Total Error: {total_error}')\n",
    "\n",
    "# Example usage\n",
    "input_size = 3  # Example input size\n",
    "hidden_size = 4  # Example hidden layer size\n",
    "output_size = 2  # Example output size\n",
    "\n",
    "# Create training data (example)\n",
    "X_train = [\n",
    "    [0.1, 0.2, 0.3],\n",
    "    [0.4, 0.5, 0.6],\n",
    "    [0.7, 0.8, 0.9],\n",
    "]\n",
    "y_train = [\n",
    "    [0, 1],\n",
    "    [1, 0],\n",
    "    [0, 1],\n",
    "]\n",
    "\n",
    "# Initialize and train the neural network\n",
    "nn = NeuralNetwork(input_size, hidden_size, output_size)\n",
    "nn.train(X_train, y_train, epochs=100, learning_rate=0.01, lambda_reg=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678cfd2a",
   "metadata": {},
   "source": [
    "### Training with Transformed Data\n",
    "\n",
    "In this section, we explore the technique of **training with transformed data** to encourage invariance to input transformations. This method is connected to **tangent propagation** (Bishop, 1995b; Leen, 1995). Here's the detailed explanation:\n",
    "\n",
    "#### Error Function for Transformed Data\n",
    "\n",
    "Given an input vector $ x $, consider a transformation governed by a parameter $ \\xi $, described by the function $ s(x, \\xi) $, where $ s(x, 0) = x $. The error function for untransformed inputs can be written as:\n",
    "\n",
    "$$\n",
    "E = \\int \\frac{1}{2} \\left( y(x) - t \\right)^2 p(t|x) p(x) \\, dx \\, dt\n",
    "$$\n",
    "\n",
    "Now, if we perturb the input data by a transformation governed by a distribution $ p(\\xi) $ with zero mean and small variance, the error function over the transformed data set can be written as:\n",
    "\n",
    "$$\n",
    "E_{\\xi} = \\int \\frac{1}{2} \\left( y(s(x, \\xi)) - t \\right)^2 p(t|x) p(x) p(\\xi) \\, dx \\, dt \\, d\\xi\n",
    "$$\n",
    "\n",
    "#### Taylor Expansion of the Transformation\n",
    "\n",
    "For small transformations, we can expand the transformation function as a Taylor series:\n",
    "\n",
    "$$\n",
    "s(x, \\xi) = x + \\xi \\tau + \\frac{\\xi^2}{2} \\tau_2 + O(\\xi^3)\n",
    "$$\n",
    "\n",
    "where $ \\tau $ is the first derivative (tangent vector), and $ \\tau_2 $ is the second derivative of $ s(x, \\xi) $ evaluated at $ \\xi = 0 $.\n",
    "\n",
    "Expanding the model function $ y(s(x, \\xi)) $ yields:\n",
    "\n",
    "$$\n",
    "y(s(x, \\xi)) = y(x) + \\xi \\tau^T \\nabla y(x) + \\frac{\\xi^2}{2} \\tau^T \\nabla \\nabla y(x) \\tau + O(\\xi^3)\n",
    "$$\n",
    "\n",
    "Substituting this expansion into the error function, we have:\n",
    "\n",
    "$$\n",
    "E_{\\xi} = \\int \\frac{1}{2} \\left( y(x) - t \\right)^2 p(t|x) p(x) \\, dx \\, dt + E[\\xi] \\left( y(x) - t \\right) \\tau^T \\nabla y(x) p(t|x) p(x) \\, dx \\, dt + O(\\xi^2)\n",
    "$$\n",
    "\n",
    "Since $ E[\\xi] = 0 $ and $ E[\\xi^2] = \\lambda $, the error function simplifies to:\n",
    "\n",
    "$$\n",
    "E_{\\xi} = E + \\lambda \\Omega E\n",
    "$$\n",
    "\n",
    "where $ \\Omega $ is the regularization term that penalizes the change in the output due to small transformations of the input. The regularization term $ \\Omega $ takes the following form:\n",
    "\n",
    "$$\n",
    "\\Omega = \\frac{1}{2} \\int \\left( y(x) - E[t|x] \\right) \\tau^T \\nabla y(x) + \\tau^T \\nabla \\nabla y(x) \\tau + \\tau^T \\nabla y(x) p(x) \\, dx\n",
    "$$\n",
    "\n",
    "Simplifying further, the regularization term becomes:\n",
    "\n",
    "$$\n",
    "\\Omega = \\frac{1}{2} \\int \\tau^T \\nabla y(x) p(x) \\, dx\n",
    "$$\n",
    "\n",
    "This is equivalent to the **tangent propagation regularizer** introduced earlier:\n",
    "\n",
    "$$\n",
    "\\Omega = \\frac{1}{2} \\int \\left| \\nabla y(x) \\right|^2 p(x) \\, dx\n",
    "$$\n",
    "\n",
    "#### Tikhonov Regularization\n",
    "\n",
    "In the special case where the transformation is the addition of random noise $ x \\to x + \\xi $, the regularizer becomes:\n",
    "\n",
    "$$\n",
    "\\Omega = \\frac{1}{2} \\int \\left| \\nabla y(x) \\right|^2 p(x) \\, dx\n",
    "$$\n",
    "\n",
    "This is known as **Tikhonov regularization**, and it is related to adding random noise to the input. Tikhonov regularization is commonly used to improve generalization in neural networks.\n",
    "\n",
    "#### Conclusion\n",
    "\n",
    "By adding the regularization term $ \\Omega $, we penalize changes in the output due to small transformations in the input. This encourages the model to be invariant to such transformations, thus improving its generalization ability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dab7ee73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000, Regularization Term: 6.5421321492185065\n",
      "Epoch 2/1000, Regularization Term: 6.54277783855075\n",
      "Epoch 3/1000, Regularization Term: 6.543335477604797\n",
      "Epoch 4/1000, Regularization Term: 6.5444194370256215\n",
      "Epoch 5/1000, Regularization Term: 6.544992211614606\n",
      "Epoch 6/1000, Regularization Term: 6.545909569294689\n",
      "Epoch 7/1000, Regularization Term: 6.54594740077364\n",
      "Epoch 8/1000, Regularization Term: 6.547151883910556\n",
      "Epoch 9/1000, Regularization Term: 6.547686164405918\n",
      "Epoch 10/1000, Regularization Term: 6.547769783174272\n",
      "Epoch 11/1000, Regularization Term: 6.548811532173772\n",
      "Epoch 12/1000, Regularization Term: 6.5491864344177735\n",
      "Epoch 13/1000, Regularization Term: 6.549723455296615\n",
      "Epoch 14/1000, Regularization Term: 6.5506674756421095\n",
      "Epoch 15/1000, Regularization Term: 6.550886349495234\n",
      "Epoch 16/1000, Regularization Term: 6.5518728102363815\n",
      "Epoch 17/1000, Regularization Term: 6.552484744098325\n",
      "Epoch 18/1000, Regularization Term: 6.553172494936494\n",
      "Epoch 19/1000, Regularization Term: 6.55382951408156\n",
      "Epoch 20/1000, Regularization Term: 6.555072097940862\n",
      "Epoch 21/1000, Regularization Term: 6.555629176776554\n",
      "Epoch 22/1000, Regularization Term: 6.556991123951639\n",
      "Epoch 23/1000, Regularization Term: 6.55758937526433\n",
      "Epoch 24/1000, Regularization Term: 6.557543616046237\n",
      "Epoch 25/1000, Regularization Term: 6.55860071363444\n",
      "Epoch 26/1000, Regularization Term: 6.559069325791625\n",
      "Epoch 27/1000, Regularization Term: 6.560119987901959\n",
      "Epoch 28/1000, Regularization Term: 6.560513924523645\n",
      "Epoch 29/1000, Regularization Term: 6.561123232771429\n",
      "Epoch 30/1000, Regularization Term: 6.561752945148608\n",
      "Epoch 31/1000, Regularization Term: 6.56263851393653\n",
      "Epoch 32/1000, Regularization Term: 6.563372629278948\n",
      "Epoch 33/1000, Regularization Term: 6.5647773831471845\n",
      "Epoch 34/1000, Regularization Term: 6.5659517308548905\n",
      "Epoch 35/1000, Regularization Term: 6.566095081013857\n",
      "Epoch 36/1000, Regularization Term: 6.566493906310516\n",
      "Epoch 37/1000, Regularization Term: 6.56668429616955\n",
      "Epoch 38/1000, Regularization Term: 6.567832640035316\n",
      "Epoch 39/1000, Regularization Term: 6.568518463686754\n",
      "Epoch 40/1000, Regularization Term: 6.569295531614676\n",
      "Epoch 41/1000, Regularization Term: 6.570066833567518\n",
      "Epoch 42/1000, Regularization Term: 6.570694573159718\n",
      "Epoch 43/1000, Regularization Term: 6.570897328491232\n",
      "Epoch 44/1000, Regularization Term: 6.571537974934367\n",
      "Epoch 45/1000, Regularization Term: 6.57213175678691\n",
      "Epoch 46/1000, Regularization Term: 6.573047564614755\n",
      "Epoch 47/1000, Regularization Term: 6.57369174555967\n",
      "Epoch 48/1000, Regularization Term: 6.574385107997873\n",
      "Epoch 49/1000, Regularization Term: 6.575086625166971\n",
      "Epoch 50/1000, Regularization Term: 6.575467877711701\n",
      "Epoch 51/1000, Regularization Term: 6.5756914285568895\n",
      "Epoch 52/1000, Regularization Term: 6.576012538690666\n",
      "Epoch 53/1000, Regularization Term: 6.5767798966942035\n",
      "Epoch 54/1000, Regularization Term: 6.577216967293538\n",
      "Epoch 55/1000, Regularization Term: 6.57828744507256\n",
      "Epoch 56/1000, Regularization Term: 6.5793156164186675\n",
      "Epoch 57/1000, Regularization Term: 6.580324220286283\n",
      "Epoch 58/1000, Regularization Term: 6.580573611332286\n",
      "Epoch 59/1000, Regularization Term: 6.581958288354194\n",
      "Epoch 60/1000, Regularization Term: 6.582264902776103\n",
      "Epoch 61/1000, Regularization Term: 6.582828577645539\n",
      "Epoch 62/1000, Regularization Term: 6.583129660571128\n",
      "Epoch 63/1000, Regularization Term: 6.583928219074363\n",
      "Epoch 64/1000, Regularization Term: 6.58446140815003\n",
      "Epoch 65/1000, Regularization Term: 6.58512783697338\n",
      "Epoch 66/1000, Regularization Term: 6.5859486742074225\n",
      "Epoch 67/1000, Regularization Term: 6.586652804063386\n",
      "Epoch 68/1000, Regularization Term: 6.587258722323249\n",
      "Epoch 69/1000, Regularization Term: 6.587915003925142\n",
      "Epoch 70/1000, Regularization Term: 6.588397565095529\n",
      "Epoch 71/1000, Regularization Term: 6.589144760719045\n",
      "Epoch 72/1000, Regularization Term: 6.58983875544174\n",
      "Epoch 73/1000, Regularization Term: 6.590417411757326\n",
      "Epoch 74/1000, Regularization Term: 6.591115532625813\n",
      "Epoch 75/1000, Regularization Term: 6.591656431543955\n",
      "Epoch 76/1000, Regularization Term: 6.592483018784227\n",
      "Epoch 77/1000, Regularization Term: 6.59264732522249\n",
      "Epoch 78/1000, Regularization Term: 6.5935630510465675\n",
      "Epoch 79/1000, Regularization Term: 6.594076568371699\n",
      "Epoch 80/1000, Regularization Term: 6.594946039851843\n",
      "Epoch 81/1000, Regularization Term: 6.595889361392244\n",
      "Epoch 82/1000, Regularization Term: 6.596986280168326\n",
      "Epoch 83/1000, Regularization Term: 6.597664675572696\n",
      "Epoch 84/1000, Regularization Term: 6.597975835094375\n",
      "Epoch 85/1000, Regularization Term: 6.59833480595894\n",
      "Epoch 86/1000, Regularization Term: 6.599362524730928\n",
      "Epoch 87/1000, Regularization Term: 6.599957652743508\n",
      "Epoch 88/1000, Regularization Term: 6.600631757681567\n",
      "Epoch 89/1000, Regularization Term: 6.601438470808084\n",
      "Epoch 90/1000, Regularization Term: 6.60135998731445\n",
      "Epoch 91/1000, Regularization Term: 6.601930259620901\n",
      "Epoch 92/1000, Regularization Term: 6.602590408888092\n",
      "Epoch 93/1000, Regularization Term: 6.602779629226504\n",
      "Epoch 94/1000, Regularization Term: 6.603837361632337\n",
      "Epoch 95/1000, Regularization Term: 6.604768248975928\n",
      "Epoch 96/1000, Regularization Term: 6.60496375920097\n",
      "Epoch 97/1000, Regularization Term: 6.605013822894853\n",
      "Epoch 98/1000, Regularization Term: 6.605886499654658\n",
      "Epoch 99/1000, Regularization Term: 6.606443027454147\n",
      "Epoch 100/1000, Regularization Term: 6.606206065209696\n",
      "Epoch 101/1000, Regularization Term: 6.605983049632598\n",
      "Epoch 102/1000, Regularization Term: 6.607100894369107\n",
      "Epoch 103/1000, Regularization Term: 6.607256987652774\n",
      "Epoch 104/1000, Regularization Term: 6.608094566982498\n",
      "Epoch 105/1000, Regularization Term: 6.608622410756429\n",
      "Epoch 106/1000, Regularization Term: 6.609505354934389\n",
      "Epoch 107/1000, Regularization Term: 6.610374936900691\n",
      "Epoch 108/1000, Regularization Term: 6.610447560565622\n",
      "Epoch 109/1000, Regularization Term: 6.610974267321956\n",
      "Epoch 110/1000, Regularization Term: 6.611456544875658\n",
      "Epoch 111/1000, Regularization Term: 6.6120964376764695\n",
      "Epoch 112/1000, Regularization Term: 6.612868271083356\n",
      "Epoch 113/1000, Regularization Term: 6.613522273734935\n",
      "Epoch 114/1000, Regularization Term: 6.614352445785001\n",
      "Epoch 115/1000, Regularization Term: 6.615104017033339\n",
      "Epoch 116/1000, Regularization Term: 6.615129060468191\n",
      "Epoch 117/1000, Regularization Term: 6.615428231241688\n",
      "Epoch 118/1000, Regularization Term: 6.615865093226648\n",
      "Epoch 119/1000, Regularization Term: 6.616590171184156\n",
      "Epoch 120/1000, Regularization Term: 6.617205242088054\n",
      "Epoch 121/1000, Regularization Term: 6.617555408436612\n",
      "Epoch 122/1000, Regularization Term: 6.617909492017218\n",
      "Epoch 123/1000, Regularization Term: 6.618183696490426\n",
      "Epoch 124/1000, Regularization Term: 6.618563063450582\n",
      "Epoch 125/1000, Regularization Term: 6.619033126908715\n",
      "Epoch 126/1000, Regularization Term: 6.618893043140552\n",
      "Epoch 127/1000, Regularization Term: 6.619498618863091\n",
      "Epoch 128/1000, Regularization Term: 6.619939596414817\n",
      "Epoch 129/1000, Regularization Term: 6.620912725520951\n",
      "Epoch 130/1000, Regularization Term: 6.621258149888152\n",
      "Epoch 131/1000, Regularization Term: 6.622291275374975\n",
      "Epoch 132/1000, Regularization Term: 6.62252550643577\n",
      "Epoch 133/1000, Regularization Term: 6.623269355511017\n",
      "Epoch 134/1000, Regularization Term: 6.623490926306835\n",
      "Epoch 135/1000, Regularization Term: 6.623849878080008\n",
      "Epoch 136/1000, Regularization Term: 6.623795417942534\n",
      "Epoch 137/1000, Regularization Term: 6.624475821836613\n",
      "Epoch 138/1000, Regularization Term: 6.625204132921219\n",
      "Epoch 139/1000, Regularization Term: 6.625664478679763\n",
      "Epoch 140/1000, Regularization Term: 6.626774216451898\n",
      "Epoch 141/1000, Regularization Term: 6.626854610490801\n",
      "Epoch 142/1000, Regularization Term: 6.627413356180049\n",
      "Epoch 143/1000, Regularization Term: 6.628070531093661\n",
      "Epoch 144/1000, Regularization Term: 6.628649725017402\n",
      "Epoch 145/1000, Regularization Term: 6.6296178828194625\n",
      "Epoch 146/1000, Regularization Term: 6.630289748693089\n",
      "Epoch 147/1000, Regularization Term: 6.630611123021225\n",
      "Epoch 148/1000, Regularization Term: 6.630805456167803\n",
      "Epoch 149/1000, Regularization Term: 6.631094276321968\n",
      "Epoch 150/1000, Regularization Term: 6.631503711424289\n",
      "Epoch 151/1000, Regularization Term: 6.632116529291268\n",
      "Epoch 152/1000, Regularization Term: 6.632657297048467\n",
      "Epoch 153/1000, Regularization Term: 6.633337331746593\n",
      "Epoch 154/1000, Regularization Term: 6.633878166587966\n",
      "Epoch 155/1000, Regularization Term: 6.6347075283151575\n",
      "Epoch 156/1000, Regularization Term: 6.635406036077145\n",
      "Epoch 157/1000, Regularization Term: 6.635892053379908\n",
      "Epoch 158/1000, Regularization Term: 6.6365745488062275\n",
      "Epoch 159/1000, Regularization Term: 6.63722360991205\n",
      "Epoch 160/1000, Regularization Term: 6.638087451000313\n",
      "Epoch 161/1000, Regularization Term: 6.638073833424632\n",
      "Epoch 162/1000, Regularization Term: 6.639259027636814\n",
      "Epoch 163/1000, Regularization Term: 6.63924297531126\n",
      "Epoch 164/1000, Regularization Term: 6.6396707204394785\n",
      "Epoch 165/1000, Regularization Term: 6.640396153463416\n",
      "Epoch 166/1000, Regularization Term: 6.640955367143823\n",
      "Epoch 167/1000, Regularization Term: 6.641433501225509\n",
      "Epoch 168/1000, Regularization Term: 6.641731626491512\n",
      "Epoch 169/1000, Regularization Term: 6.64194139001525\n",
      "Epoch 170/1000, Regularization Term: 6.642280622889504\n",
      "Epoch 171/1000, Regularization Term: 6.6426593594210175\n",
      "Epoch 172/1000, Regularization Term: 6.642603532872683\n",
      "Epoch 173/1000, Regularization Term: 6.643673605858961\n",
      "Epoch 174/1000, Regularization Term: 6.6441357711213005\n",
      "Epoch 175/1000, Regularization Term: 6.644990587035243\n",
      "Epoch 176/1000, Regularization Term: 6.64547020638608\n",
      "Epoch 177/1000, Regularization Term: 6.646041426547778\n",
      "Epoch 178/1000, Regularization Term: 6.646397306395525\n",
      "Epoch 179/1000, Regularization Term: 6.646813946138684\n",
      "Epoch 180/1000, Regularization Term: 6.647296145272127\n",
      "Epoch 181/1000, Regularization Term: 6.647962032841965\n",
      "Epoch 182/1000, Regularization Term: 6.648654894924023\n",
      "Epoch 183/1000, Regularization Term: 6.649076758659046\n",
      "Epoch 184/1000, Regularization Term: 6.648804841925433\n",
      "Epoch 185/1000, Regularization Term: 6.6497722091645075\n",
      "Epoch 186/1000, Regularization Term: 6.650259164546123\n",
      "Epoch 187/1000, Regularization Term: 6.650753095042989\n",
      "Epoch 188/1000, Regularization Term: 6.651291993092733\n",
      "Epoch 189/1000, Regularization Term: 6.651782420089949\n",
      "Epoch 190/1000, Regularization Term: 6.652254562934578\n",
      "Epoch 191/1000, Regularization Term: 6.653121090831424\n",
      "Epoch 192/1000, Regularization Term: 6.653663122865829\n",
      "Epoch 193/1000, Regularization Term: 6.654025870252359\n",
      "Epoch 194/1000, Regularization Term: 6.654496547278205\n",
      "Epoch 195/1000, Regularization Term: 6.655068949572655\n",
      "Epoch 196/1000, Regularization Term: 6.656194773865044\n",
      "Epoch 197/1000, Regularization Term: 6.656593533438882\n",
      "Epoch 198/1000, Regularization Term: 6.656634803581933\n",
      "Epoch 199/1000, Regularization Term: 6.657321502934905\n",
      "Epoch 200/1000, Regularization Term: 6.657786141427144\n",
      "Epoch 201/1000, Regularization Term: 6.658991866422058\n",
      "Epoch 202/1000, Regularization Term: 6.658749779850506\n",
      "Epoch 203/1000, Regularization Term: 6.659351438255232\n",
      "Epoch 204/1000, Regularization Term: 6.65997066063782\n",
      "Epoch 205/1000, Regularization Term: 6.660079212250005\n",
      "Epoch 206/1000, Regularization Term: 6.6610673553034925\n",
      "Epoch 207/1000, Regularization Term: 6.661296471350129\n",
      "Epoch 208/1000, Regularization Term: 6.662122389278559\n",
      "Epoch 209/1000, Regularization Term: 6.66210785031762\n",
      "Epoch 210/1000, Regularization Term: 6.662502494236311\n",
      "Epoch 211/1000, Regularization Term: 6.663079500035403\n",
      "Epoch 212/1000, Regularization Term: 6.6636399718683315\n",
      "Epoch 213/1000, Regularization Term: 6.663666071053251\n",
      "Epoch 214/1000, Regularization Term: 6.663729312099222\n",
      "Epoch 215/1000, Regularization Term: 6.663983495187511\n",
      "Epoch 216/1000, Regularization Term: 6.66446010789087\n",
      "Epoch 217/1000, Regularization Term: 6.6647599998128495\n",
      "Epoch 218/1000, Regularization Term: 6.665235763298842\n",
      "Epoch 219/1000, Regularization Term: 6.665726185739425\n",
      "Epoch 220/1000, Regularization Term: 6.666180826815374\n",
      "Epoch 221/1000, Regularization Term: 6.666818704311703\n",
      "Epoch 222/1000, Regularization Term: 6.667262057078417\n",
      "Epoch 223/1000, Regularization Term: 6.667592160999663\n",
      "Epoch 224/1000, Regularization Term: 6.6681256684094805\n",
      "Epoch 225/1000, Regularization Term: 6.6685909604603255\n",
      "Epoch 226/1000, Regularization Term: 6.669349052312148\n",
      "Epoch 227/1000, Regularization Term: 6.670025660833251\n",
      "Epoch 228/1000, Regularization Term: 6.670187532285066\n",
      "Epoch 229/1000, Regularization Term: 6.670770210936245\n",
      "Epoch 230/1000, Regularization Term: 6.671110476413274\n",
      "Epoch 231/1000, Regularization Term: 6.6716000984901775\n",
      "Epoch 232/1000, Regularization Term: 6.671709815795817\n",
      "Epoch 233/1000, Regularization Term: 6.672279145855749\n",
      "Epoch 234/1000, Regularization Term: 6.672869293786568\n",
      "Epoch 235/1000, Regularization Term: 6.673690376813378\n",
      "Epoch 236/1000, Regularization Term: 6.6743883201961\n",
      "Epoch 237/1000, Regularization Term: 6.6742000855778505\n",
      "Epoch 238/1000, Regularization Term: 6.674705148397857\n",
      "Epoch 239/1000, Regularization Term: 6.6749983694986925\n",
      "Epoch 240/1000, Regularization Term: 6.675104855396296\n",
      "Epoch 241/1000, Regularization Term: 6.675637157790376\n",
      "Epoch 242/1000, Regularization Term: 6.676440132598375\n",
      "Epoch 243/1000, Regularization Term: 6.67710289786405\n",
      "Epoch 244/1000, Regularization Term: 6.67780770759189\n",
      "Epoch 245/1000, Regularization Term: 6.677843690165945\n",
      "Epoch 246/1000, Regularization Term: 6.677965119585704\n",
      "Epoch 247/1000, Regularization Term: 6.678616375848654\n",
      "Epoch 248/1000, Regularization Term: 6.678948395819361\n",
      "Epoch 249/1000, Regularization Term: 6.6800610092350565\n",
      "Epoch 250/1000, Regularization Term: 6.6809407574366695\n",
      "Epoch 251/1000, Regularization Term: 6.681672256003387\n",
      "Epoch 252/1000, Regularization Term: 6.682273389658879\n",
      "Epoch 253/1000, Regularization Term: 6.683153246857477\n",
      "Epoch 254/1000, Regularization Term: 6.683653135327124\n",
      "Epoch 255/1000, Regularization Term: 6.683725628938425\n",
      "Epoch 256/1000, Regularization Term: 6.684039201587537\n",
      "Epoch 257/1000, Regularization Term: 6.684202961420083\n",
      "Epoch 258/1000, Regularization Term: 6.684854169848197\n",
      "Epoch 259/1000, Regularization Term: 6.685593807928492\n",
      "Epoch 260/1000, Regularization Term: 6.686697306532743\n",
      "Epoch 261/1000, Regularization Term: 6.687213772055747\n",
      "Epoch 262/1000, Regularization Term: 6.687606475892635\n",
      "Epoch 263/1000, Regularization Term: 6.688499306113878\n",
      "Epoch 264/1000, Regularization Term: 6.688868382589344\n",
      "Epoch 265/1000, Regularization Term: 6.689252502915584\n",
      "Epoch 266/1000, Regularization Term: 6.6896981898349654\n",
      "Epoch 267/1000, Regularization Term: 6.6899669055328985\n",
      "Epoch 268/1000, Regularization Term: 6.690406988961056\n",
      "Epoch 269/1000, Regularization Term: 6.6902075077077425\n",
      "Epoch 270/1000, Regularization Term: 6.690715118870335\n",
      "Epoch 271/1000, Regularization Term: 6.6912550359198\n",
      "Epoch 272/1000, Regularization Term: 6.691503063015183\n",
      "Epoch 273/1000, Regularization Term: 6.692407939598031\n",
      "Epoch 274/1000, Regularization Term: 6.693019751685481\n",
      "Epoch 275/1000, Regularization Term: 6.693789807672362\n",
      "Epoch 276/1000, Regularization Term: 6.694496507688148\n",
      "Epoch 277/1000, Regularization Term: 6.694489878374954\n",
      "Epoch 278/1000, Regularization Term: 6.695270791684904\n",
      "Epoch 279/1000, Regularization Term: 6.6963126951428835\n",
      "Epoch 280/1000, Regularization Term: 6.696713357700252\n",
      "Epoch 281/1000, Regularization Term: 6.696391271607298\n",
      "Epoch 282/1000, Regularization Term: 6.697172788828926\n",
      "Epoch 283/1000, Regularization Term: 6.697824473593781\n",
      "Epoch 284/1000, Regularization Term: 6.699069572824766\n",
      "Epoch 285/1000, Regularization Term: 6.699736540771588\n",
      "Epoch 286/1000, Regularization Term: 6.700012106618038\n",
      "Epoch 287/1000, Regularization Term: 6.7006436954196795\n",
      "Epoch 288/1000, Regularization Term: 6.701292429338747\n",
      "Epoch 289/1000, Regularization Term: 6.701831837050551\n",
      "Epoch 290/1000, Regularization Term: 6.702701778558753\n",
      "Epoch 291/1000, Regularization Term: 6.703465967142203\n",
      "Epoch 292/1000, Regularization Term: 6.70400880053318\n",
      "Epoch 293/1000, Regularization Term: 6.704840677807636\n",
      "Epoch 294/1000, Regularization Term: 6.705266668647846\n",
      "Epoch 295/1000, Regularization Term: 6.705639713505908\n",
      "Epoch 296/1000, Regularization Term: 6.70658869402844\n",
      "Epoch 297/1000, Regularization Term: 6.706868774920196\n",
      "Epoch 298/1000, Regularization Term: 6.707289672316406\n",
      "Epoch 299/1000, Regularization Term: 6.708222686295368\n",
      "Epoch 300/1000, Regularization Term: 6.708724959037618\n",
      "Epoch 301/1000, Regularization Term: 6.708796047675177\n",
      "Epoch 302/1000, Regularization Term: 6.7098646846698555\n",
      "Epoch 303/1000, Regularization Term: 6.710366304817248\n",
      "Epoch 304/1000, Regularization Term: 6.7109506944064865\n",
      "Epoch 305/1000, Regularization Term: 6.71166136484533\n",
      "Epoch 306/1000, Regularization Term: 6.712197260214978\n",
      "Epoch 307/1000, Regularization Term: 6.7125974456703865\n",
      "Epoch 308/1000, Regularization Term: 6.712787862684866\n",
      "Epoch 309/1000, Regularization Term: 6.713351074387395\n",
      "Epoch 310/1000, Regularization Term: 6.71419868670607\n",
      "Epoch 311/1000, Regularization Term: 6.71448872555952\n",
      "Epoch 312/1000, Regularization Term: 6.714922818939302\n",
      "Epoch 313/1000, Regularization Term: 6.715349065992505\n",
      "Epoch 314/1000, Regularization Term: 6.715446568635686\n",
      "Epoch 315/1000, Regularization Term: 6.715851594025349\n",
      "Epoch 316/1000, Regularization Term: 6.716354057313317\n",
      "Epoch 317/1000, Regularization Term: 6.716641623694271\n",
      "Epoch 318/1000, Regularization Term: 6.716882428789096\n",
      "Epoch 319/1000, Regularization Term: 6.717511809045874\n",
      "Epoch 320/1000, Regularization Term: 6.718716074199069\n",
      "Epoch 321/1000, Regularization Term: 6.718860011173755\n",
      "Epoch 322/1000, Regularization Term: 6.719110173110747\n",
      "Epoch 323/1000, Regularization Term: 6.719588508959772\n",
      "Epoch 324/1000, Regularization Term: 6.720170323585632\n",
      "Epoch 325/1000, Regularization Term: 6.7211804987822195\n",
      "Epoch 326/1000, Regularization Term: 6.72141638953221\n",
      "Epoch 327/1000, Regularization Term: 6.722187105191056\n",
      "Epoch 328/1000, Regularization Term: 6.72252331572993\n",
      "Epoch 329/1000, Regularization Term: 6.723325492321498\n",
      "Epoch 330/1000, Regularization Term: 6.723435970326986\n",
      "Epoch 331/1000, Regularization Term: 6.724200280138002\n",
      "Epoch 332/1000, Regularization Term: 6.724192504101978\n",
      "Epoch 333/1000, Regularization Term: 6.724340060900964\n",
      "Epoch 334/1000, Regularization Term: 6.724811533077378\n",
      "Epoch 335/1000, Regularization Term: 6.725610406974088\n",
      "Epoch 336/1000, Regularization Term: 6.725784422733703\n",
      "Epoch 337/1000, Regularization Term: 6.726919370008073\n",
      "Epoch 338/1000, Regularization Term: 6.727270436908171\n",
      "Epoch 339/1000, Regularization Term: 6.727773013250854\n",
      "Epoch 340/1000, Regularization Term: 6.728326706833585\n",
      "Epoch 341/1000, Regularization Term: 6.729406766956974\n",
      "Epoch 342/1000, Regularization Term: 6.7297149330594905\n",
      "Epoch 343/1000, Regularization Term: 6.730037746305749\n",
      "Epoch 344/1000, Regularization Term: 6.73013312442174\n",
      "Epoch 345/1000, Regularization Term: 6.730564824801052\n",
      "Epoch 346/1000, Regularization Term: 6.730809588750258\n",
      "Epoch 347/1000, Regularization Term: 6.731128155082362\n",
      "Epoch 348/1000, Regularization Term: 6.7321804802848035\n",
      "Epoch 349/1000, Regularization Term: 6.732310049595959\n",
      "Epoch 350/1000, Regularization Term: 6.732710648549744\n",
      "Epoch 351/1000, Regularization Term: 6.733532395403292\n",
      "Epoch 352/1000, Regularization Term: 6.734225617358803\n",
      "Epoch 353/1000, Regularization Term: 6.735183567513381\n",
      "Epoch 354/1000, Regularization Term: 6.73484273181163\n",
      "Epoch 355/1000, Regularization Term: 6.735035193011697\n",
      "Epoch 356/1000, Regularization Term: 6.735386294056255\n",
      "Epoch 357/1000, Regularization Term: 6.735943524587055\n",
      "Epoch 358/1000, Regularization Term: 6.735994463375749\n",
      "Epoch 359/1000, Regularization Term: 6.736775077328458\n",
      "Epoch 360/1000, Regularization Term: 6.737269893878866\n",
      "Epoch 361/1000, Regularization Term: 6.737418369865453\n",
      "Epoch 362/1000, Regularization Term: 6.7380055114151025\n",
      "Epoch 363/1000, Regularization Term: 6.738582565980142\n",
      "Epoch 364/1000, Regularization Term: 6.739445591725949\n",
      "Epoch 365/1000, Regularization Term: 6.7400783471648475\n",
      "Epoch 366/1000, Regularization Term: 6.739717456801728\n",
      "Epoch 367/1000, Regularization Term: 6.740253529125142\n",
      "Epoch 368/1000, Regularization Term: 6.740546092723866\n",
      "Epoch 369/1000, Regularization Term: 6.740897653899636\n",
      "Epoch 370/1000, Regularization Term: 6.741242320403192\n",
      "Epoch 371/1000, Regularization Term: 6.741634976420567\n",
      "Epoch 372/1000, Regularization Term: 6.742037159955182\n",
      "Epoch 373/1000, Regularization Term: 6.742219029970108\n",
      "Epoch 374/1000, Regularization Term: 6.742805241528184\n",
      "Epoch 375/1000, Regularization Term: 6.743731894304685\n",
      "Epoch 376/1000, Regularization Term: 6.744142071684521\n",
      "Epoch 377/1000, Regularization Term: 6.744991674062371\n",
      "Epoch 378/1000, Regularization Term: 6.745102270597173\n",
      "Epoch 379/1000, Regularization Term: 6.745527160808883\n",
      "Epoch 380/1000, Regularization Term: 6.745810624798828\n",
      "Epoch 381/1000, Regularization Term: 6.7464933963330544\n",
      "Epoch 382/1000, Regularization Term: 6.746764657972627\n",
      "Epoch 383/1000, Regularization Term: 6.747586960352757\n",
      "Epoch 384/1000, Regularization Term: 6.747987501634322\n",
      "Epoch 385/1000, Regularization Term: 6.747809755014857\n",
      "Epoch 386/1000, Regularization Term: 6.748489615325552\n",
      "Epoch 387/1000, Regularization Term: 6.748774139747026\n",
      "Epoch 388/1000, Regularization Term: 6.7490170983528115\n",
      "Epoch 389/1000, Regularization Term: 6.749146776619388\n",
      "Epoch 390/1000, Regularization Term: 6.749447959814968\n",
      "Epoch 391/1000, Regularization Term: 6.749653378140418\n",
      "Epoch 392/1000, Regularization Term: 6.750422110216671\n",
      "Epoch 393/1000, Regularization Term: 6.751207401026746\n",
      "Epoch 394/1000, Regularization Term: 6.752040292395206\n",
      "Epoch 395/1000, Regularization Term: 6.752756961066951\n",
      "Epoch 396/1000, Regularization Term: 6.75347566150692\n",
      "Epoch 397/1000, Regularization Term: 6.7542044446345235\n",
      "Epoch 398/1000, Regularization Term: 6.754855666855943\n",
      "Epoch 399/1000, Regularization Term: 6.755078265174273\n",
      "Epoch 400/1000, Regularization Term: 6.7554333724946884\n",
      "Epoch 401/1000, Regularization Term: 6.756067964606823\n",
      "Epoch 402/1000, Regularization Term: 6.756772024224091\n",
      "Epoch 403/1000, Regularization Term: 6.757318027523881\n",
      "Epoch 404/1000, Regularization Term: 6.757833903185102\n",
      "Epoch 405/1000, Regularization Term: 6.7580032209653425\n",
      "Epoch 406/1000, Regularization Term: 6.758128523050914\n",
      "Epoch 407/1000, Regularization Term: 6.7586264826933675\n",
      "Epoch 408/1000, Regularization Term: 6.758737644688341\n",
      "Epoch 409/1000, Regularization Term: 6.75895141268295\n",
      "Epoch 410/1000, Regularization Term: 6.759317149269225\n",
      "Epoch 411/1000, Regularization Term: 6.760111693088723\n",
      "Epoch 412/1000, Regularization Term: 6.760462236904488\n",
      "Epoch 413/1000, Regularization Term: 6.760413405481537\n",
      "Epoch 414/1000, Regularization Term: 6.76040318092993\n",
      "Epoch 415/1000, Regularization Term: 6.761221163310134\n",
      "Epoch 416/1000, Regularization Term: 6.761804941977728\n",
      "Epoch 417/1000, Regularization Term: 6.76203800043352\n",
      "Epoch 418/1000, Regularization Term: 6.763060438470612\n",
      "Epoch 419/1000, Regularization Term: 6.76359224846416\n",
      "Epoch 420/1000, Regularization Term: 6.763569325493546\n",
      "Epoch 421/1000, Regularization Term: 6.763603037031871\n",
      "Epoch 422/1000, Regularization Term: 6.763573543125814\n",
      "Epoch 423/1000, Regularization Term: 6.763772417889421\n",
      "Epoch 424/1000, Regularization Term: 6.76402981294712\n",
      "Epoch 425/1000, Regularization Term: 6.76430925983832\n",
      "Epoch 426/1000, Regularization Term: 6.765058271399819\n",
      "Epoch 427/1000, Regularization Term: 6.765472859693437\n",
      "Epoch 428/1000, Regularization Term: 6.7659825764027035\n",
      "Epoch 429/1000, Regularization Term: 6.766273008532677\n",
      "Epoch 430/1000, Regularization Term: 6.7664311336024365\n",
      "Epoch 431/1000, Regularization Term: 6.766353401471157\n",
      "Epoch 432/1000, Regularization Term: 6.767017241999156\n",
      "Epoch 433/1000, Regularization Term: 6.767789330201721\n",
      "Epoch 434/1000, Regularization Term: 6.768552568298367\n",
      "Epoch 435/1000, Regularization Term: 6.769444314039355\n",
      "Epoch 436/1000, Regularization Term: 6.76961360855232\n",
      "Epoch 437/1000, Regularization Term: 6.770432341795591\n",
      "Epoch 438/1000, Regularization Term: 6.7704987321641745\n",
      "Epoch 439/1000, Regularization Term: 6.77119788351848\n",
      "Epoch 440/1000, Regularization Term: 6.77126704598099\n",
      "Epoch 441/1000, Regularization Term: 6.77212904671876\n",
      "Epoch 442/1000, Regularization Term: 6.772694661314886\n",
      "Epoch 443/1000, Regularization Term: 6.773013915972187\n",
      "Epoch 444/1000, Regularization Term: 6.7731940539006565\n",
      "Epoch 445/1000, Regularization Term: 6.773445299368816\n",
      "Epoch 446/1000, Regularization Term: 6.773726951611099\n",
      "Epoch 447/1000, Regularization Term: 6.77434184683653\n",
      "Epoch 448/1000, Regularization Term: 6.7747383918402795\n",
      "Epoch 449/1000, Regularization Term: 6.775481689006677\n",
      "Epoch 450/1000, Regularization Term: 6.775574093264005\n",
      "Epoch 451/1000, Regularization Term: 6.775873762997155\n",
      "Epoch 452/1000, Regularization Term: 6.776102649390864\n",
      "Epoch 453/1000, Regularization Term: 6.777241740274091\n",
      "Epoch 454/1000, Regularization Term: 6.7782072283711114\n",
      "Epoch 455/1000, Regularization Term: 6.7787674706277805\n",
      "Epoch 456/1000, Regularization Term: 6.779425939035376\n",
      "Epoch 457/1000, Regularization Term: 6.780045006251363\n",
      "Epoch 458/1000, Regularization Term: 6.780281863669041\n",
      "Epoch 459/1000, Regularization Term: 6.7801976723536095\n",
      "Epoch 460/1000, Regularization Term: 6.780724158181977\n",
      "Epoch 461/1000, Regularization Term: 6.781585289990501\n",
      "Epoch 462/1000, Regularization Term: 6.782128334140054\n",
      "Epoch 463/1000, Regularization Term: 6.782030005243174\n",
      "Epoch 464/1000, Regularization Term: 6.782140097952652\n",
      "Epoch 465/1000, Regularization Term: 6.782551149803701\n",
      "Epoch 466/1000, Regularization Term: 6.7827817293218144\n",
      "Epoch 467/1000, Regularization Term: 6.783283667579835\n",
      "Epoch 468/1000, Regularization Term: 6.783427970802098\n",
      "Epoch 469/1000, Regularization Term: 6.784046710098136\n",
      "Epoch 470/1000, Regularization Term: 6.785626019290085\n",
      "Epoch 471/1000, Regularization Term: 6.785777194408642\n",
      "Epoch 472/1000, Regularization Term: 6.786536852475305\n",
      "Epoch 473/1000, Regularization Term: 6.787012479257557\n",
      "Epoch 474/1000, Regularization Term: 6.787562922863182\n",
      "Epoch 475/1000, Regularization Term: 6.7883794348864495\n",
      "Epoch 476/1000, Regularization Term: 6.78872869812024\n",
      "Epoch 477/1000, Regularization Term: 6.788783823211962\n",
      "Epoch 478/1000, Regularization Term: 6.788809262462416\n",
      "Epoch 479/1000, Regularization Term: 6.789528712955728\n",
      "Epoch 480/1000, Regularization Term: 6.790036889584219\n",
      "Epoch 481/1000, Regularization Term: 6.790829072168011\n",
      "Epoch 482/1000, Regularization Term: 6.791624639888166\n",
      "Epoch 483/1000, Regularization Term: 6.791203096864502\n",
      "Epoch 484/1000, Regularization Term: 6.791417130635773\n",
      "Epoch 485/1000, Regularization Term: 6.791688978938036\n",
      "Epoch 486/1000, Regularization Term: 6.792539736142782\n",
      "Epoch 487/1000, Regularization Term: 6.7926729227932485\n",
      "Epoch 488/1000, Regularization Term: 6.793493388655409\n",
      "Epoch 489/1000, Regularization Term: 6.793541222491627\n",
      "Epoch 490/1000, Regularization Term: 6.7942155277324465\n",
      "Epoch 491/1000, Regularization Term: 6.794807275681337\n",
      "Epoch 492/1000, Regularization Term: 6.79503671838958\n",
      "Epoch 493/1000, Regularization Term: 6.795007560726452\n",
      "Epoch 494/1000, Regularization Term: 6.795415403984126\n",
      "Epoch 495/1000, Regularization Term: 6.795429114672969\n",
      "Epoch 496/1000, Regularization Term: 6.796230473719771\n",
      "Epoch 497/1000, Regularization Term: 6.797039922985847\n",
      "Epoch 498/1000, Regularization Term: 6.797447706662834\n",
      "Epoch 499/1000, Regularization Term: 6.797745729357148\n",
      "Epoch 500/1000, Regularization Term: 6.79848647878763\n",
      "Epoch 501/1000, Regularization Term: 6.7992709118124015\n",
      "Epoch 502/1000, Regularization Term: 6.799790599657616\n",
      "Epoch 503/1000, Regularization Term: 6.800307927877363\n",
      "Epoch 504/1000, Regularization Term: 6.801086434495953\n",
      "Epoch 505/1000, Regularization Term: 6.801023768447493\n",
      "Epoch 506/1000, Regularization Term: 6.801571782014677\n",
      "Epoch 507/1000, Regularization Term: 6.802112888599783\n",
      "Epoch 508/1000, Regularization Term: 6.8023984883023685\n",
      "Epoch 509/1000, Regularization Term: 6.802864796750764\n",
      "Epoch 510/1000, Regularization Term: 6.80338166601673\n",
      "Epoch 511/1000, Regularization Term: 6.803971659021786\n",
      "Epoch 512/1000, Regularization Term: 6.804446232376515\n",
      "Epoch 513/1000, Regularization Term: 6.804427756676144\n",
      "Epoch 514/1000, Regularization Term: 6.804618151337119\n",
      "Epoch 515/1000, Regularization Term: 6.805040611252516\n",
      "Epoch 516/1000, Regularization Term: 6.805065296052816\n",
      "Epoch 517/1000, Regularization Term: 6.805699811686145\n",
      "Epoch 518/1000, Regularization Term: 6.806309057844328\n",
      "Epoch 519/1000, Regularization Term: 6.806600971329449\n",
      "Epoch 520/1000, Regularization Term: 6.8068777307600286\n",
      "Epoch 521/1000, Regularization Term: 6.808037923281379\n",
      "Epoch 522/1000, Regularization Term: 6.808448208778729\n",
      "Epoch 523/1000, Regularization Term: 6.809007183133156\n",
      "Epoch 524/1000, Regularization Term: 6.80970364841874\n",
      "Epoch 525/1000, Regularization Term: 6.810287567013922\n",
      "Epoch 526/1000, Regularization Term: 6.810684887276954\n",
      "Epoch 527/1000, Regularization Term: 6.810773470302372\n",
      "Epoch 528/1000, Regularization Term: 6.810839523173298\n",
      "Epoch 529/1000, Regularization Term: 6.811489687164899\n",
      "Epoch 530/1000, Regularization Term: 6.812028367268174\n",
      "Epoch 531/1000, Regularization Term: 6.81246510250773\n",
      "Epoch 532/1000, Regularization Term: 6.8131808094491575\n",
      "Epoch 533/1000, Regularization Term: 6.813663915375554\n",
      "Epoch 534/1000, Regularization Term: 6.813557222467496\n",
      "Epoch 535/1000, Regularization Term: 6.813961648939721\n",
      "Epoch 536/1000, Regularization Term: 6.8143126532757385\n",
      "Epoch 537/1000, Regularization Term: 6.815132487859954\n",
      "Epoch 538/1000, Regularization Term: 6.8155762423404544\n",
      "Epoch 539/1000, Regularization Term: 6.816209359129452\n",
      "Epoch 540/1000, Regularization Term: 6.816408128645642\n",
      "Epoch 541/1000, Regularization Term: 6.817042174452668\n",
      "Epoch 542/1000, Regularization Term: 6.817494412033412\n",
      "Epoch 543/1000, Regularization Term: 6.81757143522121\n",
      "Epoch 544/1000, Regularization Term: 6.818216970014099\n",
      "Epoch 545/1000, Regularization Term: 6.818402133553811\n",
      "Epoch 546/1000, Regularization Term: 6.819036179343583\n",
      "Epoch 547/1000, Regularization Term: 6.81932273821818\n",
      "Epoch 548/1000, Regularization Term: 6.819937146611181\n",
      "Epoch 549/1000, Regularization Term: 6.820049767077831\n",
      "Epoch 550/1000, Regularization Term: 6.820252134568701\n",
      "Epoch 551/1000, Regularization Term: 6.820246336984812\n",
      "Epoch 552/1000, Regularization Term: 6.820458409812558\n",
      "Epoch 553/1000, Regularization Term: 6.820617694564328\n",
      "Epoch 554/1000, Regularization Term: 6.820890728981378\n",
      "Epoch 555/1000, Regularization Term: 6.821399999010419\n",
      "Epoch 556/1000, Regularization Term: 6.822567799565476\n",
      "Epoch 557/1000, Regularization Term: 6.823156358868594\n",
      "Epoch 558/1000, Regularization Term: 6.823874226952997\n",
      "Epoch 559/1000, Regularization Term: 6.823926869367644\n",
      "Epoch 560/1000, Regularization Term: 6.824645842707405\n",
      "Epoch 561/1000, Regularization Term: 6.825264449681579\n",
      "Epoch 562/1000, Regularization Term: 6.825797732006572\n",
      "Epoch 563/1000, Regularization Term: 6.827059197154259\n",
      "Epoch 564/1000, Regularization Term: 6.827241096766468\n",
      "Epoch 565/1000, Regularization Term: 6.827561771146763\n",
      "Epoch 566/1000, Regularization Term: 6.828161453486348\n",
      "Epoch 567/1000, Regularization Term: 6.829161477540175\n",
      "Epoch 568/1000, Regularization Term: 6.829803011469345\n",
      "Epoch 569/1000, Regularization Term: 6.830249243147383\n",
      "Epoch 570/1000, Regularization Term: 6.830479795336013\n",
      "Epoch 571/1000, Regularization Term: 6.830947148620648\n",
      "Epoch 572/1000, Regularization Term: 6.832024575554158\n",
      "Epoch 573/1000, Regularization Term: 6.832047850990108\n",
      "Epoch 574/1000, Regularization Term: 6.8319370735777305\n",
      "Epoch 575/1000, Regularization Term: 6.832338958168423\n",
      "Epoch 576/1000, Regularization Term: 6.8329717953017655\n",
      "Epoch 577/1000, Regularization Term: 6.832995603381987\n",
      "Epoch 578/1000, Regularization Term: 6.833665574435645\n",
      "Epoch 579/1000, Regularization Term: 6.833899924808572\n",
      "Epoch 580/1000, Regularization Term: 6.8345243889042955\n",
      "Epoch 581/1000, Regularization Term: 6.834828119254582\n",
      "Epoch 582/1000, Regularization Term: 6.835282473774742\n",
      "Epoch 583/1000, Regularization Term: 6.835973982037565\n",
      "Epoch 584/1000, Regularization Term: 6.836472140133758\n",
      "Epoch 585/1000, Regularization Term: 6.836633849689806\n",
      "Epoch 586/1000, Regularization Term: 6.837101370505844\n",
      "Epoch 587/1000, Regularization Term: 6.837498324556539\n",
      "Epoch 588/1000, Regularization Term: 6.838013734938153\n",
      "Epoch 589/1000, Regularization Term: 6.838576607229512\n",
      "Epoch 590/1000, Regularization Term: 6.8387220902531505\n",
      "Epoch 591/1000, Regularization Term: 6.838830660660561\n",
      "Epoch 592/1000, Regularization Term: 6.83901435253563\n",
      "Epoch 593/1000, Regularization Term: 6.839380619124578\n",
      "Epoch 594/1000, Regularization Term: 6.839220150697559\n",
      "Epoch 595/1000, Regularization Term: 6.840332881609245\n",
      "Epoch 596/1000, Regularization Term: 6.840527402605647\n",
      "Epoch 597/1000, Regularization Term: 6.841215353002367\n",
      "Epoch 598/1000, Regularization Term: 6.84180618801031\n",
      "Epoch 599/1000, Regularization Term: 6.842426803911637\n",
      "Epoch 600/1000, Regularization Term: 6.842734298715674\n",
      "Epoch 601/1000, Regularization Term: 6.843200063778876\n",
      "Epoch 602/1000, Regularization Term: 6.843693245047657\n",
      "Epoch 603/1000, Regularization Term: 6.8441823837707\n",
      "Epoch 604/1000, Regularization Term: 6.844806038751267\n",
      "Epoch 605/1000, Regularization Term: 6.845306575661374\n",
      "Epoch 606/1000, Regularization Term: 6.84553527705473\n",
      "Epoch 607/1000, Regularization Term: 6.846284663145464\n",
      "Epoch 608/1000, Regularization Term: 6.847505064317538\n",
      "Epoch 609/1000, Regularization Term: 6.847902975002211\n",
      "Epoch 610/1000, Regularization Term: 6.848449685537791\n",
      "Epoch 611/1000, Regularization Term: 6.848501873710149\n",
      "Epoch 612/1000, Regularization Term: 6.848774245200724\n",
      "Epoch 613/1000, Regularization Term: 6.849844219255818\n",
      "Epoch 614/1000, Regularization Term: 6.850760673159453\n",
      "Epoch 615/1000, Regularization Term: 6.850493267638562\n",
      "Epoch 616/1000, Regularization Term: 6.850530583798076\n",
      "Epoch 617/1000, Regularization Term: 6.8512916683798935\n",
      "Epoch 618/1000, Regularization Term: 6.85224308267569\n",
      "Epoch 619/1000, Regularization Term: 6.852771844236914\n",
      "Epoch 620/1000, Regularization Term: 6.852908823788316\n",
      "Epoch 621/1000, Regularization Term: 6.852886968134244\n",
      "Epoch 622/1000, Regularization Term: 6.8532597886048565\n",
      "Epoch 623/1000, Regularization Term: 6.8540487977896305\n",
      "Epoch 624/1000, Regularization Term: 6.854860174050595\n",
      "Epoch 625/1000, Regularization Term: 6.854905192918089\n",
      "Epoch 626/1000, Regularization Term: 6.85553704459493\n",
      "Epoch 627/1000, Regularization Term: 6.8561872378121205\n",
      "Epoch 628/1000, Regularization Term: 6.856457354331339\n",
      "Epoch 629/1000, Regularization Term: 6.856711881415003\n",
      "Epoch 630/1000, Regularization Term: 6.856637715340508\n",
      "Epoch 631/1000, Regularization Term: 6.857086055238515\n",
      "Epoch 632/1000, Regularization Term: 6.856930312870264\n",
      "Epoch 633/1000, Regularization Term: 6.856893901639509\n",
      "Epoch 634/1000, Regularization Term: 6.856802486503996\n",
      "Epoch 635/1000, Regularization Term: 6.85750714488511\n",
      "Epoch 636/1000, Regularization Term: 6.857762029900584\n",
      "Epoch 637/1000, Regularization Term: 6.858268087894776\n",
      "Epoch 638/1000, Regularization Term: 6.858581812171352\n",
      "Epoch 639/1000, Regularization Term: 6.859203785617911\n",
      "Epoch 640/1000, Regularization Term: 6.8593919914348405\n",
      "Epoch 641/1000, Regularization Term: 6.85977836780271\n",
      "Epoch 642/1000, Regularization Term: 6.859304418798499\n",
      "Epoch 643/1000, Regularization Term: 6.860355460536129\n",
      "Epoch 644/1000, Regularization Term: 6.860567849437979\n",
      "Epoch 645/1000, Regularization Term: 6.86078888073964\n",
      "Epoch 646/1000, Regularization Term: 6.861137162915996\n",
      "Epoch 647/1000, Regularization Term: 6.861590680758329\n",
      "Epoch 648/1000, Regularization Term: 6.862138286601924\n",
      "Epoch 649/1000, Regularization Term: 6.862311446065287\n",
      "Epoch 650/1000, Regularization Term: 6.862429322298416\n",
      "Epoch 651/1000, Regularization Term: 6.862974634401756\n",
      "Epoch 652/1000, Regularization Term: 6.863394128313003\n",
      "Epoch 653/1000, Regularization Term: 6.864056167125313\n",
      "Epoch 654/1000, Regularization Term: 6.864066370536461\n",
      "Epoch 655/1000, Regularization Term: 6.86473482227703\n",
      "Epoch 656/1000, Regularization Term: 6.865538141868279\n",
      "Epoch 657/1000, Regularization Term: 6.8654364094362945\n",
      "Epoch 658/1000, Regularization Term: 6.865643997410767\n",
      "Epoch 659/1000, Regularization Term: 6.865712470902908\n",
      "Epoch 660/1000, Regularization Term: 6.866385741454514\n",
      "Epoch 661/1000, Regularization Term: 6.866496536196381\n",
      "Epoch 662/1000, Regularization Term: 6.86726755148617\n",
      "Epoch 663/1000, Regularization Term: 6.867759054269197\n",
      "Epoch 664/1000, Regularization Term: 6.86825047140939\n",
      "Epoch 665/1000, Regularization Term: 6.868502899979427\n",
      "Epoch 666/1000, Regularization Term: 6.868837408412673\n",
      "Epoch 667/1000, Regularization Term: 6.869424402609959\n",
      "Epoch 668/1000, Regularization Term: 6.869879151847305\n",
      "Epoch 669/1000, Regularization Term: 6.870216939799219\n",
      "Epoch 670/1000, Regularization Term: 6.870123543216108\n",
      "Epoch 671/1000, Regularization Term: 6.870067126933125\n",
      "Epoch 672/1000, Regularization Term: 6.870365721461909\n",
      "Epoch 673/1000, Regularization Term: 6.870931965904022\n",
      "Epoch 674/1000, Regularization Term: 6.871275606535026\n",
      "Epoch 675/1000, Regularization Term: 6.871354190976265\n",
      "Epoch 676/1000, Regularization Term: 6.872006652006509\n",
      "Epoch 677/1000, Regularization Term: 6.872939588345123\n",
      "Epoch 678/1000, Regularization Term: 6.873328797603338\n",
      "Epoch 679/1000, Regularization Term: 6.8734424327692585\n",
      "Epoch 680/1000, Regularization Term: 6.874178261746106\n",
      "Epoch 681/1000, Regularization Term: 6.874558823901876\n",
      "Epoch 682/1000, Regularization Term: 6.874709241248383\n",
      "Epoch 683/1000, Regularization Term: 6.874529091466525\n",
      "Epoch 684/1000, Regularization Term: 6.874866090497305\n",
      "Epoch 685/1000, Regularization Term: 6.874480945834525\n",
      "Epoch 686/1000, Regularization Term: 6.875050865148572\n",
      "Epoch 687/1000, Regularization Term: 6.8754975674832925\n",
      "Epoch 688/1000, Regularization Term: 6.87671626862094\n",
      "Epoch 689/1000, Regularization Term: 6.876890686380457\n",
      "Epoch 690/1000, Regularization Term: 6.877314530148871\n",
      "Epoch 691/1000, Regularization Term: 6.878064538554044\n",
      "Epoch 692/1000, Regularization Term: 6.878369724651773\n",
      "Epoch 693/1000, Regularization Term: 6.879055900780059\n",
      "Epoch 694/1000, Regularization Term: 6.879271947904052\n",
      "Epoch 695/1000, Regularization Term: 6.879638003726845\n",
      "Epoch 696/1000, Regularization Term: 6.880077514687497\n",
      "Epoch 697/1000, Regularization Term: 6.880254267225374\n",
      "Epoch 698/1000, Regularization Term: 6.880633975885947\n",
      "Epoch 699/1000, Regularization Term: 6.881516092792779\n",
      "Epoch 700/1000, Regularization Term: 6.881841519588188\n",
      "Epoch 701/1000, Regularization Term: 6.8825956217226\n",
      "Epoch 702/1000, Regularization Term: 6.882770328246451\n",
      "Epoch 703/1000, Regularization Term: 6.883088411000073\n",
      "Epoch 704/1000, Regularization Term: 6.883400565641544\n",
      "Epoch 705/1000, Regularization Term: 6.883823723635528\n",
      "Epoch 706/1000, Regularization Term: 6.884220891968665\n",
      "Epoch 707/1000, Regularization Term: 6.884626967564725\n",
      "Epoch 708/1000, Regularization Term: 6.884927782778011\n",
      "Epoch 709/1000, Regularization Term: 6.885146633281035\n",
      "Epoch 710/1000, Regularization Term: 6.885480072110829\n",
      "Epoch 711/1000, Regularization Term: 6.885973201255577\n",
      "Epoch 712/1000, Regularization Term: 6.886295195761348\n",
      "Epoch 713/1000, Regularization Term: 6.886378482462018\n",
      "Epoch 714/1000, Regularization Term: 6.886697439293645\n",
      "Epoch 715/1000, Regularization Term: 6.887085478276177\n",
      "Epoch 716/1000, Regularization Term: 6.8868336490978175\n",
      "Epoch 717/1000, Regularization Term: 6.88724098035667\n",
      "Epoch 718/1000, Regularization Term: 6.887922867992573\n",
      "Epoch 719/1000, Regularization Term: 6.888132461680439\n",
      "Epoch 720/1000, Regularization Term: 6.888497498163721\n",
      "Epoch 721/1000, Regularization Term: 6.888757578510358\n",
      "Epoch 722/1000, Regularization Term: 6.889807244364875\n",
      "Epoch 723/1000, Regularization Term: 6.890202834164747\n",
      "Epoch 724/1000, Regularization Term: 6.890924457074057\n",
      "Epoch 725/1000, Regularization Term: 6.891680694449267\n",
      "Epoch 726/1000, Regularization Term: 6.891447950662566\n",
      "Epoch 727/1000, Regularization Term: 6.892095352174683\n",
      "Epoch 728/1000, Regularization Term: 6.892693083106686\n",
      "Epoch 729/1000, Regularization Term: 6.892991935489495\n",
      "Epoch 730/1000, Regularization Term: 6.894109688663012\n",
      "Epoch 731/1000, Regularization Term: 6.894637680202326\n",
      "Epoch 732/1000, Regularization Term: 6.894906576879193\n",
      "Epoch 733/1000, Regularization Term: 6.895036374091605\n",
      "Epoch 734/1000, Regularization Term: 6.894927752184532\n",
      "Epoch 735/1000, Regularization Term: 6.894969093464928\n",
      "Epoch 736/1000, Regularization Term: 6.895520383352407\n",
      "Epoch 737/1000, Regularization Term: 6.8960519402665374\n",
      "Epoch 738/1000, Regularization Term: 6.896565842803795\n",
      "Epoch 739/1000, Regularization Term: 6.897309748007767\n",
      "Epoch 740/1000, Regularization Term: 6.898222116215246\n",
      "Epoch 741/1000, Regularization Term: 6.898723570422607\n",
      "Epoch 742/1000, Regularization Term: 6.899672296793313\n",
      "Epoch 743/1000, Regularization Term: 6.899811951947268\n",
      "Epoch 744/1000, Regularization Term: 6.900506466798402\n",
      "Epoch 745/1000, Regularization Term: 6.900658095760875\n",
      "Epoch 746/1000, Regularization Term: 6.901472697380653\n",
      "Epoch 747/1000, Regularization Term: 6.901542044483366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 748/1000, Regularization Term: 6.901616060524813\n",
      "Epoch 749/1000, Regularization Term: 6.901910442984765\n",
      "Epoch 750/1000, Regularization Term: 6.901851695708952\n",
      "Epoch 751/1000, Regularization Term: 6.901812691445983\n",
      "Epoch 752/1000, Regularization Term: 6.901792969798928\n",
      "Epoch 753/1000, Regularization Term: 6.902467593698037\n",
      "Epoch 754/1000, Regularization Term: 6.9033527782888635\n",
      "Epoch 755/1000, Regularization Term: 6.904157634374311\n",
      "Epoch 756/1000, Regularization Term: 6.904745967750374\n",
      "Epoch 757/1000, Regularization Term: 6.904945210876693\n",
      "Epoch 758/1000, Regularization Term: 6.905276795609703\n",
      "Epoch 759/1000, Regularization Term: 6.905862175839115\n",
      "Epoch 760/1000, Regularization Term: 6.906564063396193\n",
      "Epoch 761/1000, Regularization Term: 6.907090299852263\n",
      "Epoch 762/1000, Regularization Term: 6.906950740848721\n",
      "Epoch 763/1000, Regularization Term: 6.9075775653875775\n",
      "Epoch 764/1000, Regularization Term: 6.907442125757581\n",
      "Epoch 765/1000, Regularization Term: 6.9075960363877815\n",
      "Epoch 766/1000, Regularization Term: 6.908161234938415\n",
      "Epoch 767/1000, Regularization Term: 6.908655060092571\n",
      "Epoch 768/1000, Regularization Term: 6.908813504771441\n",
      "Epoch 769/1000, Regularization Term: 6.9092859695907345\n",
      "Epoch 770/1000, Regularization Term: 6.90959847389348\n",
      "Epoch 771/1000, Regularization Term: 6.910167364470949\n",
      "Epoch 772/1000, Regularization Term: 6.910602969186202\n",
      "Epoch 773/1000, Regularization Term: 6.911369879302998\n",
      "Epoch 774/1000, Regularization Term: 6.911546763652693\n",
      "Epoch 775/1000, Regularization Term: 6.9121625952197805\n",
      "Epoch 776/1000, Regularization Term: 6.9123430845142995\n",
      "Epoch 777/1000, Regularization Term: 6.912339471790599\n",
      "Epoch 778/1000, Regularization Term: 6.913132984703375\n",
      "Epoch 779/1000, Regularization Term: 6.9132293736753025\n",
      "Epoch 780/1000, Regularization Term: 6.913755371850376\n",
      "Epoch 781/1000, Regularization Term: 6.913952724547739\n",
      "Epoch 782/1000, Regularization Term: 6.91456475484944\n",
      "Epoch 783/1000, Regularization Term: 6.914309583805693\n",
      "Epoch 784/1000, Regularization Term: 6.9145516144859895\n",
      "Epoch 785/1000, Regularization Term: 6.914468719531449\n",
      "Epoch 786/1000, Regularization Term: 6.914858676142189\n",
      "Epoch 787/1000, Regularization Term: 6.91596634229368\n",
      "Epoch 788/1000, Regularization Term: 6.916207566372054\n",
      "Epoch 789/1000, Regularization Term: 6.916817963508179\n",
      "Epoch 790/1000, Regularization Term: 6.916641023138193\n",
      "Epoch 791/1000, Regularization Term: 6.917113317459503\n",
      "Epoch 792/1000, Regularization Term: 6.917713790917292\n",
      "Epoch 793/1000, Regularization Term: 6.917751695365227\n",
      "Epoch 794/1000, Regularization Term: 6.918007185764948\n",
      "Epoch 795/1000, Regularization Term: 6.918756979750662\n",
      "Epoch 796/1000, Regularization Term: 6.919148272620504\n",
      "Epoch 797/1000, Regularization Term: 6.920109228353561\n",
      "Epoch 798/1000, Regularization Term: 6.920153580844799\n",
      "Epoch 799/1000, Regularization Term: 6.921460802572728\n",
      "Epoch 800/1000, Regularization Term: 6.921947901602728\n",
      "Epoch 801/1000, Regularization Term: 6.922067186256399\n",
      "Epoch 802/1000, Regularization Term: 6.923106439776861\n",
      "Epoch 803/1000, Regularization Term: 6.92355541695497\n",
      "Epoch 804/1000, Regularization Term: 6.923609939265089\n",
      "Epoch 805/1000, Regularization Term: 6.923729248807391\n",
      "Epoch 806/1000, Regularization Term: 6.924609875321744\n",
      "Epoch 807/1000, Regularization Term: 6.924888344454101\n",
      "Epoch 808/1000, Regularization Term: 6.925198202610838\n",
      "Epoch 809/1000, Regularization Term: 6.925377371663254\n",
      "Epoch 810/1000, Regularization Term: 6.925438609846839\n",
      "Epoch 811/1000, Regularization Term: 6.925950802493753\n",
      "Epoch 812/1000, Regularization Term: 6.926449392516527\n",
      "Epoch 813/1000, Regularization Term: 6.926723131054073\n",
      "Epoch 814/1000, Regularization Term: 6.926997772759097\n",
      "Epoch 815/1000, Regularization Term: 6.926780956040638\n",
      "Epoch 816/1000, Regularization Term: 6.927308504004657\n",
      "Epoch 817/1000, Regularization Term: 6.927984164485105\n",
      "Epoch 818/1000, Regularization Term: 6.928340172510861\n",
      "Epoch 819/1000, Regularization Term: 6.928394013195186\n",
      "Epoch 820/1000, Regularization Term: 6.928858422219305\n",
      "Epoch 821/1000, Regularization Term: 6.9296016701574885\n",
      "Epoch 822/1000, Regularization Term: 6.929680831985591\n",
      "Epoch 823/1000, Regularization Term: 6.930176417580736\n",
      "Epoch 824/1000, Regularization Term: 6.930414125032362\n",
      "Epoch 825/1000, Regularization Term: 6.931651003985684\n",
      "Epoch 826/1000, Regularization Term: 6.932242933504608\n",
      "Epoch 827/1000, Regularization Term: 6.932481388878813\n",
      "Epoch 828/1000, Regularization Term: 6.93284148530006\n",
      "Epoch 829/1000, Regularization Term: 6.933517346626122\n",
      "Epoch 830/1000, Regularization Term: 6.9341793346704454\n",
      "Epoch 831/1000, Regularization Term: 6.934675900940775\n",
      "Epoch 832/1000, Regularization Term: 6.935292421624879\n",
      "Epoch 833/1000, Regularization Term: 6.936004912835934\n",
      "Epoch 834/1000, Regularization Term: 6.936135740583392\n",
      "Epoch 835/1000, Regularization Term: 6.93658929888698\n",
      "Epoch 836/1000, Regularization Term: 6.937044394092102\n",
      "Epoch 837/1000, Regularization Term: 6.937794408810159\n",
      "Epoch 838/1000, Regularization Term: 6.937843581648755\n",
      "Epoch 839/1000, Regularization Term: 6.938445673590287\n",
      "Epoch 840/1000, Regularization Term: 6.939038219414641\n",
      "Epoch 841/1000, Regularization Term: 6.939273421646368\n",
      "Epoch 842/1000, Regularization Term: 6.939766740755371\n",
      "Epoch 843/1000, Regularization Term: 6.940043321597658\n",
      "Epoch 844/1000, Regularization Term: 6.940136357153505\n",
      "Epoch 845/1000, Regularization Term: 6.9412563725224015\n",
      "Epoch 846/1000, Regularization Term: 6.94178904698821\n",
      "Epoch 847/1000, Regularization Term: 6.942024878125398\n",
      "Epoch 848/1000, Regularization Term: 6.94311657176403\n",
      "Epoch 849/1000, Regularization Term: 6.943061719823812\n",
      "Epoch 850/1000, Regularization Term: 6.943370255814714\n",
      "Epoch 851/1000, Regularization Term: 6.943800400451788\n",
      "Epoch 852/1000, Regularization Term: 6.944078100312662\n",
      "Epoch 853/1000, Regularization Term: 6.943988856344734\n",
      "Epoch 854/1000, Regularization Term: 6.944150248910636\n",
      "Epoch 855/1000, Regularization Term: 6.945069321383466\n",
      "Epoch 856/1000, Regularization Term: 6.94562854921473\n",
      "Epoch 857/1000, Regularization Term: 6.946435813694969\n",
      "Epoch 858/1000, Regularization Term: 6.947129898531759\n",
      "Epoch 859/1000, Regularization Term: 6.947553569986535\n",
      "Epoch 860/1000, Regularization Term: 6.947977403128376\n",
      "Epoch 861/1000, Regularization Term: 6.948165920131067\n",
      "Epoch 862/1000, Regularization Term: 6.948878654072629\n",
      "Epoch 863/1000, Regularization Term: 6.949117747849855\n",
      "Epoch 864/1000, Regularization Term: 6.949978746028899\n",
      "Epoch 865/1000, Regularization Term: 6.950338775235553\n",
      "Epoch 866/1000, Regularization Term: 6.9507655165921305\n",
      "Epoch 867/1000, Regularization Term: 6.951292365562203\n",
      "Epoch 868/1000, Regularization Term: 6.952348926694814\n",
      "Epoch 869/1000, Regularization Term: 6.953202852345899\n",
      "Epoch 870/1000, Regularization Term: 6.9541192487570545\n",
      "Epoch 871/1000, Regularization Term: 6.954810697752293\n",
      "Epoch 872/1000, Regularization Term: 6.954874497527534\n",
      "Epoch 873/1000, Regularization Term: 6.955157656545738\n",
      "Epoch 874/1000, Regularization Term: 6.955078524936231\n",
      "Epoch 875/1000, Regularization Term: 6.955593515319818\n",
      "Epoch 876/1000, Regularization Term: 6.956207808641689\n",
      "Epoch 877/1000, Regularization Term: 6.957055257172266\n",
      "Epoch 878/1000, Regularization Term: 6.9569056258761055\n",
      "Epoch 879/1000, Regularization Term: 6.956733786512951\n",
      "Epoch 880/1000, Regularization Term: 6.956991362309566\n",
      "Epoch 881/1000, Regularization Term: 6.9574336688511105\n",
      "Epoch 882/1000, Regularization Term: 6.957495992101683\n",
      "Epoch 883/1000, Regularization Term: 6.957554153149756\n",
      "Epoch 884/1000, Regularization Term: 6.957564748707779\n",
      "Epoch 885/1000, Regularization Term: 6.958266566595277\n",
      "Epoch 886/1000, Regularization Term: 6.958368030947003\n",
      "Epoch 887/1000, Regularization Term: 6.958695561632306\n",
      "Epoch 888/1000, Regularization Term: 6.958859076803872\n",
      "Epoch 889/1000, Regularization Term: 6.959260297383449\n",
      "Epoch 890/1000, Regularization Term: 6.958950903314388\n",
      "Epoch 891/1000, Regularization Term: 6.959511323970964\n",
      "Epoch 892/1000, Regularization Term: 6.959829974543398\n",
      "Epoch 893/1000, Regularization Term: 6.960928427417279\n",
      "Epoch 894/1000, Regularization Term: 6.961598227278937\n",
      "Epoch 895/1000, Regularization Term: 6.962392389509038\n",
      "Epoch 896/1000, Regularization Term: 6.962501176886451\n",
      "Epoch 897/1000, Regularization Term: 6.96282784111025\n",
      "Epoch 898/1000, Regularization Term: 6.963815081101367\n",
      "Epoch 899/1000, Regularization Term: 6.963504467893777\n",
      "Epoch 900/1000, Regularization Term: 6.963915952112683\n",
      "Epoch 901/1000, Regularization Term: 6.964275228716317\n",
      "Epoch 902/1000, Regularization Term: 6.964845619740908\n",
      "Epoch 903/1000, Regularization Term: 6.9651851402086375\n",
      "Epoch 904/1000, Regularization Term: 6.965041693683385\n",
      "Epoch 905/1000, Regularization Term: 6.966132489608826\n",
      "Epoch 906/1000, Regularization Term: 6.966742389293455\n",
      "Epoch 907/1000, Regularization Term: 6.967238132648342\n",
      "Epoch 908/1000, Regularization Term: 6.968105434682791\n",
      "Epoch 909/1000, Regularization Term: 6.968391620542645\n",
      "Epoch 910/1000, Regularization Term: 6.9688417396724915\n",
      "Epoch 911/1000, Regularization Term: 6.9691505828235\n",
      "Epoch 912/1000, Regularization Term: 6.969636209932625\n",
      "Epoch 913/1000, Regularization Term: 6.969990094221421\n",
      "Epoch 914/1000, Regularization Term: 6.970338833182998\n",
      "Epoch 915/1000, Regularization Term: 6.970934512998787\n",
      "Epoch 916/1000, Regularization Term: 6.9720822484470215\n",
      "Epoch 917/1000, Regularization Term: 6.972292672983001\n",
      "Epoch 918/1000, Regularization Term: 6.972328037691877\n",
      "Epoch 919/1000, Regularization Term: 6.972934457872441\n",
      "Epoch 920/1000, Regularization Term: 6.973170639360264\n",
      "Epoch 921/1000, Regularization Term: 6.972871249759421\n",
      "Epoch 922/1000, Regularization Term: 6.9737968686139595\n",
      "Epoch 923/1000, Regularization Term: 6.974223138848491\n",
      "Epoch 924/1000, Regularization Term: 6.97497526685322\n",
      "Epoch 925/1000, Regularization Term: 6.974681798077728\n",
      "Epoch 926/1000, Regularization Term: 6.974918442736374\n",
      "Epoch 927/1000, Regularization Term: 6.975520258015058\n",
      "Epoch 928/1000, Regularization Term: 6.975969081837923\n",
      "Epoch 929/1000, Regularization Term: 6.97635950885131\n",
      "Epoch 930/1000, Regularization Term: 6.976251184092982\n",
      "Epoch 931/1000, Regularization Term: 6.976439115813682\n",
      "Epoch 932/1000, Regularization Term: 6.976806148774355\n",
      "Epoch 933/1000, Regularization Term: 6.977655511768083\n",
      "Epoch 934/1000, Regularization Term: 6.978058703891179\n",
      "Epoch 935/1000, Regularization Term: 6.978568791097298\n",
      "Epoch 936/1000, Regularization Term: 6.979385558609446\n",
      "Epoch 937/1000, Regularization Term: 6.98070652940031\n",
      "Epoch 938/1000, Regularization Term: 6.981442060375785\n",
      "Epoch 939/1000, Regularization Term: 6.982420624801115\n",
      "Epoch 940/1000, Regularization Term: 6.982525646864859\n",
      "Epoch 941/1000, Regularization Term: 6.983217497125666\n",
      "Epoch 942/1000, Regularization Term: 6.983845414089259\n",
      "Epoch 943/1000, Regularization Term: 6.983921557723943\n",
      "Epoch 944/1000, Regularization Term: 6.984600274717228\n",
      "Epoch 945/1000, Regularization Term: 6.98496334180496\n",
      "Epoch 946/1000, Regularization Term: 6.985369600824921\n",
      "Epoch 947/1000, Regularization Term: 6.9851316546032765\n",
      "Epoch 948/1000, Regularization Term: 6.985606741599801\n",
      "Epoch 949/1000, Regularization Term: 6.985394705747861\n",
      "Epoch 950/1000, Regularization Term: 6.985532492823874\n",
      "Epoch 951/1000, Regularization Term: 6.986146836286121\n",
      "Epoch 952/1000, Regularization Term: 6.986461469278417\n",
      "Epoch 953/1000, Regularization Term: 6.987095274097285\n",
      "Epoch 954/1000, Regularization Term: 6.987510460848812\n",
      "Epoch 955/1000, Regularization Term: 6.988384444021215\n",
      "Epoch 956/1000, Regularization Term: 6.988759916744956\n",
      "Epoch 957/1000, Regularization Term: 6.9885028866277645\n",
      "Epoch 958/1000, Regularization Term: 6.989505892446305\n",
      "Epoch 959/1000, Regularization Term: 6.990142296902679\n",
      "Epoch 960/1000, Regularization Term: 6.990532122550697\n",
      "Epoch 961/1000, Regularization Term: 6.99145931664874\n",
      "Epoch 962/1000, Regularization Term: 6.992231249346938\n",
      "Epoch 963/1000, Regularization Term: 6.99317768474724\n",
      "Epoch 964/1000, Regularization Term: 6.993861499100861\n",
      "Epoch 965/1000, Regularization Term: 6.993798727552109\n",
      "Epoch 966/1000, Regularization Term: 6.994265562596127\n",
      "Epoch 967/1000, Regularization Term: 6.994686630597938\n",
      "Epoch 968/1000, Regularization Term: 6.994889992559175\n",
      "Epoch 969/1000, Regularization Term: 6.994989710314192\n",
      "Epoch 970/1000, Regularization Term: 6.995932539762427\n",
      "Epoch 971/1000, Regularization Term: 6.996001183642419\n",
      "Epoch 972/1000, Regularization Term: 6.9966647662463535\n",
      "Epoch 973/1000, Regularization Term: 6.997008067775805\n",
      "Epoch 974/1000, Regularization Term: 6.997596593961309\n",
      "Epoch 975/1000, Regularization Term: 6.997747098686651\n",
      "Epoch 976/1000, Regularization Term: 6.998201098575631\n",
      "Epoch 977/1000, Regularization Term: 6.99890586607251\n",
      "Epoch 978/1000, Regularization Term: 6.999543909731033\n",
      "Epoch 979/1000, Regularization Term: 6.999864704259827\n",
      "Epoch 980/1000, Regularization Term: 7.000467100859334\n",
      "Epoch 981/1000, Regularization Term: 7.0003001019424165\n",
      "Epoch 982/1000, Regularization Term: 7.0004232135212066\n",
      "Epoch 983/1000, Regularization Term: 7.001203848484661\n",
      "Epoch 984/1000, Regularization Term: 7.001991336685446\n",
      "Epoch 985/1000, Regularization Term: 7.002325153455909\n",
      "Epoch 986/1000, Regularization Term: 7.002526601922024\n",
      "Epoch 987/1000, Regularization Term: 7.0031291301886\n",
      "Epoch 988/1000, Regularization Term: 7.003149803270938\n",
      "Epoch 989/1000, Regularization Term: 7.003345550670464\n",
      "Epoch 990/1000, Regularization Term: 7.003525331142033\n",
      "Epoch 991/1000, Regularization Term: 7.003548962440862\n",
      "Epoch 992/1000, Regularization Term: 7.00357617204858\n",
      "Epoch 993/1000, Regularization Term: 7.00375932855555\n",
      "Epoch 994/1000, Regularization Term: 7.004290111433374\n",
      "Epoch 995/1000, Regularization Term: 7.0048636734291465\n",
      "Epoch 996/1000, Regularization Term: 7.005638472851449\n",
      "Epoch 997/1000, Regularization Term: 7.005944110254176\n",
      "Epoch 998/1000, Regularization Term: 7.006454487164654\n",
      "Epoch 999/1000, Regularization Term: 7.007040994575461\n",
      "Epoch 1000/1000, Regularization Term: 7.007431639532957\n"
     ]
    }
   ],
   "source": [
    "### Define a simple neural network model.\n",
    "### Apply transformations to the input data (in this case, adding noise).\n",
    "### Compute the regularization term.\n",
    "### Update the weights using gradient descent.\n",
    "\n",
    "import random\n",
    "import math\n",
    "\n",
    "# Sigmoid activation function and its derivative\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "# Initialize a neural network\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        # Random initialization of weights\n",
    "        self.weights1 = [[random.random() for _ in range(input_size)] for _ in range(hidden_size)]\n",
    "        self.weights2 = [[random.random() for _ in range(hidden_size)] for _ in range(output_size)]\n",
    "        \n",
    "    def forward(self, X):\n",
    "        self.hidden_input = [sum(X[i] * self.weights1[j][i] for i in range(self.input_size)) for j in range(self.hidden_size)]\n",
    "        self.hidden_output = [sigmoid(x) for x in self.hidden_input]\n",
    "        \n",
    "        self.output_input = [sum(self.hidden_output[i] * self.weights2[j][i] for i in range(self.hidden_size)) for j in range(self.output_size)]\n",
    "        self.output_output = [sigmoid(x) for x in self.output_input]\n",
    "        \n",
    "        return self.output_output\n",
    "\n",
    "    def backward(self, X, T, learning_rate):\n",
    "        # Compute the gradients of weights (backpropagation)\n",
    "        output_errors = [self.output_output[i] - T[i] for i in range(self.output_size)]\n",
    "        output_gradients = [output_errors[i] * sigmoid_derivative(self.output_input[i]) for i in range(self.output_size)]\n",
    "\n",
    "        hidden_errors = [sum(self.weights2[j][i] * output_gradients[j] for j in range(self.output_size)) for i in range(self.hidden_size)]\n",
    "        hidden_gradients = [hidden_errors[i] * sigmoid_derivative(self.hidden_input[i]) for i in range(self.hidden_size)]\n",
    "        \n",
    "        # Update the weights using gradient descent\n",
    "        for i in range(self.output_size):\n",
    "            for j in range(self.hidden_size):\n",
    "                self.weights2[i][j] -= learning_rate * output_gradients[i] * self.hidden_output[j]\n",
    "\n",
    "        for i in range(self.hidden_size):\n",
    "            for j in range(self.input_size):\n",
    "                self.weights1[i][j] -= learning_rate * hidden_gradients[i] * X[j]\n",
    "                \n",
    "    def compute_tikhonov_regularization(self, X):\n",
    "        # Compute the regularization term (Tikhonov regularization)\n",
    "        regularization = 0\n",
    "        for x in X:\n",
    "            output = self.forward(x)\n",
    "            for i in range(self.hidden_size):\n",
    "                for j in range(self.input_size):\n",
    "                    regularization += (self.weights1[i][j] ** 2)\n",
    "            for i in range(self.output_size):\n",
    "                for j in range(self.hidden_size):\n",
    "                    regularization += (self.weights2[i][j] ** 2)\n",
    "        \n",
    "        return regularization\n",
    "\n",
    "# Training the neural network\n",
    "def train_neural_network(X_train, T_train, input_size, hidden_size, output_size, epochs, learning_rate, lambda_reg):\n",
    "    nn = NeuralNetwork(input_size, hidden_size, output_size)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(len(X_train)):\n",
    "            X = X_train[i]\n",
    "            T = T_train[i]\n",
    "            \n",
    "            # Add random noise to the input to simulate transformations\n",
    "            noise = [random.gauss(0, 0.1) for _ in range(len(X))]\n",
    "            X_transformed = [X[j] + noise[j] for j in range(len(X))]\n",
    "\n",
    "            # Perform forward pass and backward pass\n",
    "            nn.forward(X_transformed)\n",
    "            nn.backward(X_transformed, T, learning_rate)\n",
    "\n",
    "        # Compute regularization term\n",
    "        regularization = nn.compute_tikhonov_regularization(X_train)\n",
    "\n",
    "        # Include regularization in the total error\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Regularization Term: {regularization}\")\n",
    "    \n",
    "    return nn\n",
    "\n",
    "# Example usage\n",
    "# Input data (X_train) and target labels (T_train) - small example for demonstration\n",
    "X_train = [[0.1, 0.5, 0.8], [0.9, 0.4, 0.2], [0.3, 0.6, 0.7]]  # 3 samples, 3 features each\n",
    "T_train = [[1], [0], [1]]  # 3 samples, 1 output each (binary classification)\n",
    "\n",
    "# Train the network with 2 hidden neurons, 3 input features, and 1 output neuron\n",
    "trained_nn = train_neural_network(X_train, T_train, input_size=3, hidden_size=2, output_size=1, epochs=1000, learning_rate=0.01, lambda_reg=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9919aec4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
