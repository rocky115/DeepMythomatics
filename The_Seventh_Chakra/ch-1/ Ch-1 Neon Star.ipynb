{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2147ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " * Copyright (c) 2004 Radhamadhab Dalai\n",
    " *\n",
    " * Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    " * of this software and associated documentation files (the \"Software\"), to deal\n",
    " * in the Software without restriction, including without limitation the rights\n",
    " * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    " * copies of the Software, and to permit persons to whom the Software is\n",
    " * furnished to do so, subject to the following conditions:\n",
    " *\n",
    " * The above copyright notice and this permission notice shall be included in\n",
    " * all copies or substantial portions of the Software.\n",
    " *\n",
    " * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    " * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    " * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    " * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    " * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    " * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
    " * THE SOFTWARE.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150ce621",
   "metadata": {},
   "source": [
    "# Chapter 1 :  1.1 The Ultron Neon  \n",
    "\n",
    "Let’s say we have a single neuron, and there are three inputs to this neuron. As in most cases, when you initialize parameters in neural networks, our network will have weights initialized randomly, and biases set as zero to start. Why we do this will become apparent later on. The input will be either actual training data or the outputs of neurons from the previous layer in the neural network. We’re just going to make up values to start with as input for now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eef6c55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.8, 1.21, 2.385]\n"
     ]
    }
   ],
   "source": [
    "inputs = [ 1, 2, 3, 2.5 ]\n",
    "weights = [[ 0.2, 0.8,- 0.5,1],[ 0.5, -0.91, 0.26,-0.5],[-0.26,-0.27,0.17,0.87]]\n",
    "biases = [ 2 , 3 , 0.5]\n",
    "\n",
    "layer_outputs = []\n",
    "\n",
    "for neuron_weight, n_biases in zip(weights, biases):\n",
    "    neuron_output=0\n",
    "    for n_input, n_weight in zip(inputs, neuron_weight):\n",
    "        neuron_output += n_input*n_weight\n",
    "    #add bias    \n",
    "    neuron_output += n_biases\n",
    "    #call empty list and add those\n",
    "    layer_outputs.append(neuron_output)\n",
    "    \n",
    "print(layer_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fbf4fb",
   "metadata": {},
   "source": [
    "### A Single Neuron\n",
    "\n",
    "Let’s say we have a single neuron, and there are three inputs to this neuron. As is typical when initializing parameters in neural networks, the weights are initialized randomly and biases are set to zero at the start. The input can be either actual training data or the outputs from neurons of the previous layer in the neural network.\n",
    "\n",
    "For now, let's represent the inputs to the neuron as:\n",
    "\n",
    "$$\n",
    "x_1, x_2, x_3\n",
    "$$\n",
    "\n",
    "The corresponding weights for each input are:\n",
    "\n",
    "$$\n",
    "w_1, w_2, w_3\n",
    "$$\n",
    "\n",
    "The bias term is:\n",
    "\n",
    "$$\n",
    "b\n",
    "$$\n",
    "\n",
    "The output of the neuron, \\( y \\), can be computed as the weighted sum of the inputs plus the bias:\n",
    "\n",
    "$$\n",
    "y = w_1 \\cdot x_1 + w_2 \\cdot x_2 + w_3 \\cdot x_3 + b\n",
    "$$\n",
    "\n",
    "Here, the weights and the bias are initialized randomly, and the bias \\( b \\) is set to 0 initially. The inputs are made up values for now, but in practice, they could be actual training data or outputs from the previous layer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddcc0ef",
   "metadata": {},
   "source": [
    "### Neuron with Three Inputs and Weights\n",
    "\n",
    "Each input also needs a weight associated with it. Inputs are the data we pass into the model to get desired outputs, while weights are the parameters that we’ll tune during training. Weights and biases are the values that change inside the model during training. These are the parameters that get “trained,” allowing the model to make predictions.\n",
    "\n",
    "Let's initialize the following inputs and weights for the neuron:\n",
    "\n",
    "$$\n",
    "\\text{inputs} = [1, 2, 3]\n",
    "$$\n",
    "\n",
    "The weights associated with these inputs are:\n",
    "\n",
    "$$\n",
    "\\text{weights} = [0.2, 0.8, -0.5]\n",
    "$$\n",
    "\n",
    "Next, we need a bias. Since we're modeling a single neuron with three inputs, there will be just one bias value. We’ll randomly choose a bias value of:\n",
    "\n",
    "$$\n",
    "\\text{bias} = 2\n",
    "$$\n",
    "\n",
    "#### Neuron Output Calculation\n",
    "\n",
    "This neuron sums each input multiplied by its corresponding weight and then adds the bias. The output \\( y \\) of the neuron is calculated as:\n",
    "\n",
    "$$\n",
    "y = (\\text{inputs}[0] \\cdot \\text{weights}[0]) + (\\text{inputs}[1] \\cdot \\text{weights}[1]) + (\\text{inputs}[2] \\cdot \\text{weights}[2]) + \\text{bias}\n",
    "$$\n",
    "\n",
    "Substituting the values:\n",
    "\n",
    "$$\n",
    "y = (1 \\cdot 0.2) + (2 \\cdot 0.8) + (3 \\cdot -0.5) + 2\n",
    "$$\n",
    "\n",
    "This simplifies to:\n",
    "\n",
    "$$\n",
    "y = 0.2 + 1.6 - 1.5 + 2 = 2.3\n",
    "$$\n",
    "\n",
    "Therefore, the output of the neuron is:\n",
    "\n",
    "$$\n",
    "y = 2.3\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "234e99d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3\n"
     ]
    }
   ],
   "source": [
    "inputs = [1, 2, 3]\n",
    "inputs = [1, 2, 3]\n",
    "weights = [0.2, 0.8, -0.5]\n",
    "bias = 2\n",
    "output = (inputs[0] * weights[0] + inputs[1] * weights[1] \n",
    "+ inputs[2]*weights[2] + bias)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11aef2a",
   "metadata": {},
   "source": [
    "![Neron](1.11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c755cdd8",
   "metadata": {},
   "source": [
    "### Neuron with Four Inputs\n",
    "\n",
    "When adding a fourth input to the neuron, we need to adjust both the inputs and the weights. For each new input, there needs to be an associated weight, which this input will be multiplied by. Let's assign new values for this additional input and its weight:\n",
    "\n",
    "The updated inputs and weights are:\n",
    "\n",
    "$$\n",
    "\\text{inputs} = [1.0, 2.0, 3.0, 2.5]\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{weights} = [0.2, 0.8, -0.5, 1.0]\n",
    "$$\n",
    "\n",
    "The bias remains the same:\n",
    "\n",
    "$$\n",
    "\\text{bias} = 2.0\n",
    "$$\n",
    "\n",
    "#### Neuron Output Calculation with Four Inputs\n",
    "\n",
    "The neuron now sums the products of each input with its corresponding weight and adds the bias. The output \\( y \\) is calculated as:\n",
    "\n",
    "$$\n",
    "y = (\\text{inputs}[0] \\cdot \\text{weights}[0]) + (\\text{inputs}[1] \\cdot \\text{weights}[1]) + (\\text{inputs}[2] \\cdot \\text{weights}[2]) + (\\text{inputs}[3] \\cdot \\text{weights}[3]) + \\text{bias}\n",
    "$$\n",
    "\n",
    "Substituting the values:\n",
    "\n",
    "$$\n",
    "y = (1.0 \\cdot 0.2) + (2.0 \\cdot 0.8) + (3.0 \\cdot -0.5) + (2.5 \\cdot 1.0) + 2.0\n",
    "$$\n",
    "\n",
    "This simplifies to:\n",
    "\n",
    "$$\n",
    "y = 0.2 + 1.6 - 1.5 + 2.5 + 2.0 = 4.8\n",
    "$$\n",
    "\n",
    "Therefore, the output of the neuron is:\n",
    "\n",
    "$$\n",
    "y = 4.8\n",
    "$$\n",
    "\n",
    "#### Visual Depiction\n",
    "\n",
    "This can be visually depicted as follows:\n",
    "\n",
    "- Each input is connected to the neuron via an arrow.\n",
    "- The weight associated with each input is placed on the arrow.\n",
    "- After the inputs are multiplied by their respective weights and summed, the bias is added to produce the final output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e24b2b3",
   "metadata": {},
   "source": [
    "![Neron](1.3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d4acb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.8\n"
     ]
    }
   ],
   "source": [
    "inputs  =  [  1.0 ,  2.0 ,  3.0 ,  2.5 ]\n",
    "weights  =  [  0.2 ,  0.8 ,  -  0.5 ,  1.0 ]\n",
    "bias  =  2.0\n",
    "output  =  (inputs[ 0  ]  *  weights[ 0  ]\n",
    "+ inputs[ 1  ]  *  weights[ 1  ]\n",
    "+ inputs[ 2  ]  *  weights[ 2  ]\n",
    "+ inputs[ 3  ]  *  weights[ 3  ]\n",
    "+ bias)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7560ef",
   "metadata": {},
   "source": [
    "![Neurn](1.4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49288863",
   "metadata": {},
   "source": [
    "### A Layer of Neurons\n",
    "\n",
    "In neural networks, layers typically consist of more than one neuron. A **layer** is simply a group of neurons that all receive the same input, but each neuron in the layer has its own set of weights and bias, producing a unique output. The layer’s output is a collection of outputs from each neuron.\n",
    "\n",
    "Let’s say we have 3 neurons in a layer and 4 inputs. The inputs to this layer are:\n",
    "\n",
    "$$\n",
    "\\text{inputs} = [1.0, 2.0, 3.0, 2.5]\n",
    "$$\n",
    "\n",
    "#### Neurons in the Layer\n",
    "\n",
    "Each neuron has its own set of weights and bias. For example:\n",
    "\n",
    "- **Neuron 1**:\n",
    "    - Weights: \\( [0.2, 0.8, -0.5, 1.0] \\)\n",
    "    - Bias: \\( 2.0 \\)\n",
    "    \n",
    "- **Neuron 2**:\n",
    "    - Weights: \\( [0.5, -0.91, 0.26, -0.5] \\)\n",
    "    - Bias: \\( 3.0 \\)\n",
    "    \n",
    "- **Neuron 3**:\n",
    "    - Weights: \\( [-0.26, -0.27, 0.17, 0.87] \\)\n",
    "    - Bias: \\( 0.5 \\)\n",
    "\n",
    "#### Outputs of the Neurons\n",
    "\n",
    "The output of each neuron is calculated as the weighted sum of the inputs plus the bias. For neuron \\( i \\), the output \\( y_i \\) is given by:\n",
    "\n",
    "$$\n",
    "y_i = (\\text{inputs}[0] \\cdot \\text{weights}_i[0]) + (\\text{inputs}[1] \\cdot \\text{weights}_i[1]) + (\\text{inputs}[2] \\cdot \\text{weights}_i[2]) + (\\text{inputs}[3] \\cdot \\text{weights}_i[3]) + \\text{bias}_i\n",
    "$$\n",
    "\n",
    "For each neuron, this becomes:\n",
    "\n",
    "- **Neuron 1**:\n",
    "  $$\n",
    "  y_1 = (1.0 \\cdot 0.2) + (2.0 \\cdot 0.8) + (3.0 \\cdot -0.5) + (2.5 \\cdot 1.0) + 2.0 = 4.8\n",
    "  $$\n",
    "\n",
    "- **Neuron 2**:\n",
    "  $$\n",
    "  y_2 = (1.0 \\cdot 0.5) + (2.0 \\cdot -0.91) + (3.0 \\cdot 0.26) + (2.5 \\cdot -0.5) + 3.0 = 0.96\n",
    "  $$\n",
    "\n",
    "- **Neuron 3**:\n",
    "  $$\n",
    "  y_3 = (1.0 \\cdot -0.26) + (2.0 \\cdot -0.27) + (3.0 \\cdot 0.17) + (2.5 \\cdot 0.87) + 0.5 = 2.18\n",
    "  $$\n",
    "\n",
    "#### Final Layer Output\n",
    "\n",
    "The output of the layer is the collection of the outputs from each neuron:\n",
    "\n",
    "$$\n",
    "\\text{output} = [y_1, y_2, y_3] = [4.8, 0.96, 2.18]\n",
    "$$\n",
    "\n",
    "This demonstrates how a layer with multiple neurons produces multiple outputs, one per neuron, based on the same input.\n",
    "\n",
    "### Summary\n",
    "\n",
    "We’ll keep the initial 4 inputs and set of weights for the first neuron the same as we’ve been using so far. We’ll add 2 additional, made up, sets of weights and 2 additional biases to form 2 new neurons for a total of 3 in the layer. The layer’s output is going to be a list of 3 values, not just a single value like for a single neuron."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4122ebc",
   "metadata": {},
   "source": [
    "![Neon](1.5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4fdc750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.8, 1.21, 2.385]\n"
     ]
    }
   ],
   "source": [
    "inputs  =  [  1  ,  2  ,  3  ,  2.5 ]\n",
    "weights1 = [ 0.2 ,  0.8 ,  - 0.5 ,  1  ]\n",
    "weights2 = [ 0.5 , - 0.91 ,  0.26 , - 0.5 ]\n",
    "weights3 = [ -  0.26 , -0.27 , 0.17 , 0.87 ]\n",
    "\n",
    "bias1 = 2\n",
    "bias2 = 3\n",
    "bias3 = 0.5\n",
    "outputs  =  [\n",
    "\n",
    "# Neuron 1:\n",
    "inputs[ 0  ]  *  weights1[ 0  ] +\n",
    "inputs[ 1  ]  *  weights1[ 1 ] +\n",
    "inputs[ 2  ]  *  weights1[ 2  ] +\n",
    "inputs[ 3  ]  *  weights1[ 3  ] + bias1,\n",
    "\n",
    "# Neuron 2:\n",
    "inputs[ 0  ]  *  weights2[ 0  ] +\n",
    "inputs[ 1  ]  *  weights2[ 1  ] +\n",
    "inputs[ 2  ]  *  weights2[ 2  ] +\n",
    "inputs[ 3  ]  *  weights2[ 3  ] + bias2,\n",
    "\n",
    "# Neuron 3:\n",
    "inputs[ 0  ]  *  weights3[ 0  ] +\n",
    "inputs[ 1 ]  *  weights3[ 1  ] +\n",
    "inputs[ 2  ]  *  weights3[ 2  ] +\n",
    "inputs[ 3  ]  *  weights3[ 3  ] +\n",
    " bias3]\n",
    "\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325088aa",
   "metadata": {},
   "source": [
    "![Neuron](1.6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f873ae8",
   "metadata": {},
   "source": [
    "### Fully Connected Neural Network Layer\n",
    "\n",
    "In the code described so far, we have three sets of weights and three biases, which define three neurons in a layer. Each neuron is **fully connected** to the same inputs, meaning each neuron in the current layer has connections to every neuron from the previous layer. This is a very common type of neural network, referred to as a **fully connected** or **dense** layer.\n",
    "\n",
    "#### Fully Connected Neural Network\n",
    "\n",
    "Each neuron applies its own set of weights and bias to the input. The formula for each neuron \\( i \\) is:\n",
    "\n",
    "$$\n",
    "y_i = \\sum_{j=1}^{n} (\\text{inputs}[j] \\cdot \\text{weights}_i[j]) + \\text{bias}_i\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- \\( y_i \\) is the output of neuron \\( i \\),\n",
    "- \\( n \\) is the number of inputs,\n",
    "- \\( \\text{weights}_i[j] \\) is the weight associated with input \\( j \\) for neuron \\( i \\),\n",
    "- \\( \\text{inputs}[j] \\) is the value of input \\( j \\),\n",
    "- \\( \\text{bias}_i \\) is the bias for neuron \\( i \\).\n",
    "\n",
    "#### Scaling to Multiple Neurons and Layers\n",
    "\n",
    "As the number of layers and neurons increases, manually coding each operation becomes impractical. Instead of hardcoding the operations for each neuron, we can use loops to iterate through the neurons and their corresponding weights and biases.\n",
    "\n",
    "By storing the weights for each neuron in a list of lists, we can dynamically scale the code for any number of neurons. Here’s an example of how to structure the code using loops:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a086fc49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.8, 1.21, 2.385]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "inputs = [1.0, 2.0, 3.0, 2.5]\n",
    "\n",
    "# Weights for 3 neurons, each having 4 inputs\n",
    "weights = [\n",
    "    [0.2, 0.8, -0.5, 1.0],   # Weights for Neuron 1\n",
    "    [0.5, -0.91, 0.26, -0.5], # Weights for Neuron 2\n",
    "    [-0.26, -0.27, 0.17, 0.87] # Weights for Neuron 3\n",
    "]\n",
    "\n",
    "# Biases for 3 neurons\n",
    "biases = [2.0, 3.0, 0.5]\n",
    "\n",
    "# Output calculation for each neuron\n",
    "layer_outputs = []  # Store the outputs of each neuron\n",
    "for neuron_weights, neuron_bias in zip(weights, biases):\n",
    "    neuron_output = 0  # Calculate output for this neuron\n",
    "    for n_input, weight in zip(inputs, neuron_weights):\n",
    "        neuron_output += n_input * weight\n",
    "    neuron_output += neuron_bias\n",
    "    layer_outputs.append(neuron_output)\n",
    "\n",
    "print(layer_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce754e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "This does the same thing as before, just in a more dynamic and scalable way. If you find yourself\n",
    "confused at one of the steps,  print () out the objects to see what they are and what’s happening.\n",
    "The zip () function lets us iterate over multiple iterables (lists in this case) simultaneously.\n",
    "Again, all we’re doing is, for each neuron (the outer loop in the code above, over neuron weights\n",
    "and biases), taking each input value multiplied by the associated weight for that input (the inner\n",
    "loop in the code above, over inputs and weights), adding all of these together, then adding a bias\n",
    "at the end. Finally, sending the neuron’s output to the layer’s output list.\n",
    "That’s it! How do we know we have three neurons? Why do we have three? We can tell we have\n",
    "three neurons because there are 3 sets of weights and 3 biases. When you make a neural network\n",
    "of your own, you also get to decide how many neurons you want for each of the layers. You can\n",
    "combine however many inputs you are given with however many neurons that you desire. As you\n",
    "progress through this book, you will gain some intuition of how many neurons to try using. We\n",
    "will start by usingWith our above code that uses loops, we could modify our number of inputs or neurons in our\n",
    "layer to be whatever we wanted, and our loop would handle it. As we said earlier, it would be\n",
    "a disservice not to show NumPy here since Python alone doesn’t do matrix/tensor/array math\n",
    "very efficiently. But first, the reason the most popular deep learning library in Python is\n",
    "called “TensorFlow” is that it’s all about doing operations on tensors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
